Mission - Go Green Team (Venkanna, Santhosh, Prasad & Sahil)
Inspiration:
  There are many inspirations, below are few ones.1) Amazon forest burning 2) Australia forest burning 3) world increasing pollution level
What it does:
 Mission – Go Green is a Corporate Social Responsibility initiative idea which focusses on reducing carbon footprint of organization by calculating carbon footprints of an individual at project level, site level, country level, Region level and also providing calculated suggestive approach using AI/ML to reduce or offset the carbon footprints. Our Computation logic will be an open API which anyone can use to calculate carbon footprints. Point to note here is that data can be pushed in to this engine using Open Air, Project Management and Online Internal Surveys.
How I built it:
JAVA, Springs, AI/ML, Micro services, HTML5, JS, JQuery, REST web services (Open API’s), Oracle, Google Charts
Challenges I ran into:
The greatest challenge we faced is data consolidation and calculation for each and every parameter contributing to carbon footprints.
Accomplishments that I'm proud of:
We are contributing to the society as it is CSR initiative and trying to Offset/reduce carbon emission for the globe.
What I learned:
Insights on carbon footprints and its related environmental impacts and resolutions.
What's next for Mission - Go Green:
Below are the few roadmap items 1) Use of carbon footprint calculator API for all conversion purposes. 2) Integration of Open-air system 3) Use of Artificial Intelligence in extracting relevant data from Open-air and using it for logical computation of carbon footprint. Also we thrive to use AI for suggestion-based approach for offsetting carbon footprints. 4) Enhanced UI UX
Built With
ai
api
google-chart
html5
java
javascript
jquery
microserviceses
ml
oracle
spring


Context
In an era of fast changing, new technologies, Open APis, and new regulations like PSD2, we are moving towards a cashless and cardless societies. However, we still have to withdraw and give money to our kids or use our credit cards on a daily basis to pay for them.
What is the problem?
Kids are excluded from the financial world and restricted to pay cash or using their parents' debit/credit card. As a kid, there is also a risk of carrying cash or credit cards. Parents, on the other hand, lack of visibility and control on how their kids are spending their money. It is time-consuming as a parent to open a bank account for your kid. Merchants are still paying fees on all transactions by credit card. Banks struggle to retain customers. With Family Pay we want to build a better future for family payments leveraging on new technologies and FusionFabric.cloud APIs.
What is Family Pay
Family Pay is an application installed on the parents', kids' and merchants devices.
Parent App
After getting onboard, parents have access to their bank account balance and the transaction history of the kids. Adding a new kid is simple: the parent puts a name and a phone number, then assigns a budget on a daily/weekly/montly basis and chooses the allowed expense categories. Payment requests within this limits are processed and approved automatically and the parent gets a notification and can view the transaction history details.
Merchant App
The merchant can use the Family Pay app to scan articles and generate a QR code with the amount to be payed.
Kid App
The kid can see how much money is available, and easily scan the vendor's QR code. A request for payment is initiated and sent to the parent device using the FusionFabric.cloud Realtime Payment Initiation API.
Payment request validation & security
Payment requests within the limit are automatically processed and all devices receive a confirmation message for payment success. As security is very important, we have used machine learning to train the system and detect abnormal behaviour. When an abnormal behaviour is detected, the payment transaction is pending and the parent receive a notification asking to manually accept or reject the payment.
Key Benefits
Kids
One key goal of Family Pay is to enhance kids or teenagers' financial inclusion by allowing them to be more autonomous in their expenses. With the application, they will learn how to manage their budget and save money to fund their projects.
Parents
Family Pay ensures a safe and secured environment for kids payments. In that way, parents don't need to worry about cash or credit card loss of their kids and can have more control and monitoring on their expenses. It is a new way to educate on financial responsibilities.
Merchants
For merchants, the traffic will increase as Family Pay democratizes cashless and cardless payments and allows more people to do payments with a frictionless experience. Moreover, merchants won't pay credit card transaction charges as payments are done from account to account directly.
Banks
By adopting Family Pay, banks can collect and monetize data on individuals who are not customers yet, kids are potential future customers and banks can already have data on their habits. Thus, it becomes easier to offer financial services to the parent for the kids, and kids will have a complete suitable and customized experience when they will be at age of opening an account. It ensures the stickiness of families as customers of the bank.
Finastra
We aim to push Family Pay on Fusion Store as a real fintech would have done in its user journey. In that way, we want to inspire other fintechs to create applications with a real use-case on top of FusionFabric.cloud. It will also increase traffic on FusionFablric.cloud APIs. Finally, we plan to involve Finastra in partnerships with fintechs and charities to build a better future for family payments.
Behind the scene
Application implemented with:
HTML/CSS/JS (UI)
Ionic (UI)
Node RED (API calls)
Realtime Payment Initiation API from FusionFabric.cloud
Open Food Facts API (Scan of food barcode)
TensorFlow.js (Machine Learning)
Built With
css3
ffdc
html5
ionic
openfoodfacts
tensorflowjs
Try it out
GitHub Repo
www.slideshare.net


Inspiration
Our existing customers
What it does
A stateless message hub with capability of identifying the destination location and protocol needed to transfer the request/response through central configuration.
How I built it
We created message hub as a sprint boot application which will interact with multiple product (GPP,LIQ Essernce etc.) acorss location
Challenges I ran into
Integration with different system
Accomplishments that I'm proud of
We are successfully able to integrate all the systems and put an impression on judges with our solution.
What I learned
Team Collabaration Being Innovative Facing challenges
What's next for Messaging HUB
Business case : More business cases need to be incorporated for payments Business cases need to be added for other Finastra products Acknowledgement flows needs to be incorporated Negative message flow handling Message E2E tracking using HUB Msg ID populated by originating system
Technical : Supporting multiple protocols Disaster recovery Integrate with transformation tool Integration with FFDC to provide HUB capabilities on platform
Built With
angular.js
api
docker
ffdc
hosts
jms
spring-boot


Inspiration
As per a study conducted by CGI, banking customers of leading banks want banks to help them save money. • 52% of the customers said, “Tell me what I am spending money on and how I can save”. • 55% of them wanted access to “wealth building advice by leveraging their financial data”. Today, few years later this study, these demands are becoming a reality. In this information age, customers of banks want their bank to evolve with their changing needs and offer more value in return of their relationship with bank.
We want to offer a solution on the FFDC platform that addresses both the above needs.
What it does
Our solution intends to help: • Banks, by being able to provide more value to their customers as an account holder by automatically offering new products that suite particular financial behaviour of a customer. • Customers, by being able to get valuable and easy to understand analytical insights into their financial lives and receive wealth creating recommendations based on their financial behaviour.
So, the idea is to automatically review account holders spending patterns and suggest an appropriate bank product that will help account holder make better investment choices.
• The new app will help account holders manage expenses by showing statistical data about their spending patterns, using machine learning. • The idea is to show account holders how their monthly cash-flow is made of, and predict of their account balances in the future if they continue with current spending patterns. This is particularly useful for customers with varying income sources. For e.g. SME, Freelances, Artists, etc. • Find a match with a bank product and make suggestions. Show how this product impacts there future bank balances using. • All this with a beautiful visual representation of the data.
A lot of such efforts have been made in the stock trading platforms, but the banking sector seems to have fallen behind to catchup. So we see good use-case for this solution in the future.
How I built it
We're a team of enthusiastic developers/QA and figured out that Python would be a quick way to start working on a solution like this. We used Pandas library for data parsing for bank account statements and were able to perform analytics on it. We pulled in interesting insights from this info for e.g. find recurring patterns of expenses, see how the cashflow is made of, what are the spending patterns etc. We wanted to show this on a nice to look at GUI so that they look different or refreshing when compared to a typical bank account statements. We used Dash Graphing framework from plotly to build the Graphs and GUI.
We used FFDC Get transaction details APIs to pull data from FFDC. But since not many records were available on FFDC we continued to use the data set of transactions we built for the test purpose.
Challenges I ran into
All the technologies we used here were very new. Python and Dash was completely new and everyone had to go through a very-very-short learning curve to learn and use the tech.
Accomplishments that I'm proud of
We're proud of the team work we were able to pull-off. Even though everyone was new to the tech we used we built up a nice app that was liked by our colleagues. We're also proud of the enthusiasm which helped us make this big journey of change of a mindset and learning/implementing on a different kind of problem which none of us had worked on before. In the end it was great learning experience for everyone on the team and we are glad of it. We had already won the hackathon when we completed the app.
What I learned
A positively spirited attitude can help you cross any difficulties that may come. In our case, everyone worked on a different portion of the app by learning himself/herself and then helping the other person do the same. That was great collaboration.
What's next for Fusion Wealthify
We want to complete the app for the remaining portions to add better machine learning capabilities based on huge datasets of data that can only be available with a bank
Built With
dash-graphing-framework
dash-ui-kit
ffdc
fushionfabric.cloud
html5
machine-learning
pandas
plotly
python


Inspiration
People around us
What it does
Help people in getting information as well help production person with real time error as well debug mode traces
How I built it
We team of 4 worked on different technology to make it success
Challenges I ran into
Connect with FFDC API and user machine learning
Accomplishments that I'm proud of
We finally manage to Create a prototype and present it successfully
What I learned
How to create something new a very less time with good presentation
What's next for NIRVANA
Production Support tool Machine Learning More FFDC API integration
Built With
angular.js
ffdc
java
javascript
machine-learning
rest
spring
webservice


This image is currently processing. Please be patient...
Inspiration
My inspiration to build hexatron came from insect, we all have an experience of owning a pet somewhere in our life as our companion but one may not have an insect or nature-inspired companion robot.
What it does
Hexatron has a wide range of applications, it's a dev kit, it's a companion robot, it's a surveillance robot and could be possibly used in industries for inspection.
How I built it
I build it by indulging different individual components together like raspberry, servo controller, and other relevant components then I programmed it to give life to it.
Challenges I ran into
Unavailability of parts challenges regarding building a platform where one can easily control the hexatron.
Accomplishments that I'm proud of
What I learned
What's next for Tacton Biotic Project Hexatron
Built With
css3
electronjs
flask
html5
opencv
raspberry-pi
robot
servo
socket.io
three.js


To cite Benjamin Franklin: "I have already made this paper too long, for which I must crave pardon, not having now time to make it shorter."
Keep It Simple is a fun side project to help you get to the point of your message: You have to summarize a long written text in your own words first and can edit the summary (with your keyboard) only after you have finished speaking. At the end, you have a nice short text!
How does it work? Your spoken text is turned into written text using speech recognition (currently using Google's speech recognition; because of the APIs used in the prototype, it currently works in Chrome only).
Go check it out at keepitsimple.rocks
I want to turn this into a real, working product when I find some time.
Built With
css3
google-web-speech-api
html5
javascript
Try it out
keepitsimple.rocks


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for T&T
-


Inspiration
Fusion Digital Front Office, is a digital banking solution where executives of the bank can service customers outside of branches. They can take the bank to the customer's convenience, anytime.
Let us consider the scenario.. Anupama, an employee of Finastra, holds a bank account with Wells Fargo. I, Shemeer, a customer service executive of Bank of America is on a marketing campaign at Finastra. I meet with Anupama and realizes she is interested in certificate of deposits. I make her an offer to give her a preferred rate of 3.5% for a 24 months CD where as Wells Fargo’s rate is 3%. Anupama is interested, but to fund the new account, the only option FDFO provides now is to use customer’s credit card. Or walk into the branch next day and make a cash payment, which is not a good user experience.
What it does
Our solution is a bundled package of various funding options, including google pay, apple pay, pay pal, alipay etc., where I can open an account for Anupama, and have that funded with her google pay account, which debits from her Wells Fargo account and credit her new account instantly.
How I built it
This was build using AngularJS version 8, Google Pay API and AP.NET Core Web API along with 2 APIs from FFDC
Challenges I ran into
Connecting with Google API from our code base took some time.
Accomplishments that I'm proud of
Participation, Team quickly consumed FFDC API, Learned Google Pay integration
What I learned
We have consumed FFDC API for Customer Profile and Account Listing and also integrated Google Pay API for testing purpose in Fusion Digital Front Office - Funding
What's next for Omni Pay
We have made this proposal in line with Finastra Mission 2021 strategy, Our proposed solution is to offer various options such as google pay, apple pay, paypal , remote deposit capture and same day ach funding for external transfers and internal transfers, for funding purposes. For internal transfer since we have FFDC API - For other payment options, we propose to contribute the APIs to FFDC, so that FDFO and uOpen and any other account opening products can readily consume the package.
Built With
angular.js
api
ffdc
sql


Inspiration
Customer feedback on the current template implementation within the DocuSign gateway
What it does
It removes manual processing steps when adding blocks (signature, initials...) to a DocuSign template
How I built it
Within the existing DocuSign gateway, I leveraged and implemented the use of the Composite templates to automatically map the party roles to their signatures
Challenges I ran into
Implementing a solution that would be generic yet effective enough to meet all of the customers
Accomplishments that I'm proud of
Being able to find a solution that meet most of our customer's needs
What I learned
I learned that putting the customer first and including them within our work makes our products better and our relationship stronger
What's next for Generic Composites
Talking to our customers and getting more feedback on how we could improve this feature before releasing it
Built With
.net
api
c#
docusign
sdk
visual-studio


Inspiration
A few weeks back, I had received a call from a financial product marketer, who wanted to sell me an exceptionally good investment product and the marketer knew an approximate of what I earned, but the issue was that I wasn't able to invest due to financial stress I was going through at that point of time. The product offered was good, and they had the data on me to know that I can afford to make the investment - but they failed to understand my financial situation; Which got me thinking, if only campaign could've understood my sentiments and stress beforehand, which could've enabled them to recommend the products more effectively and would've resulted in a conversion.
What it does
FinFit is a GDPR complaint, Financial Fitness analyzing and product recommendation tool. FinFit takes the customer through a series of questions (10) which are divided into three segments. Customer is asked to rate the questions from 1 to 10 a. Financial Stress - Measures Financial stress the customer faces at that point b. Financial Well being - Measures if the customer is able to live the life with the current financial situation c. Financial Status - Measures his satisfaction with his credit score, credit and mortgage etc.
The customer is lead to a demographic questionnaire page, where the questions now change to his age range, we make sure to collect only the non-personally identifiable information from the customer, any personally identifiable information otherwise entered is filtered out (Area code of the postcode is requested from the customer, if the customer accidentally enters the full postcode, area code is separated out)
From the answers, FinFit comes up with a score (average of the answers given in each segment) and compares it with the historical data to understand if the score matches the other customers belonging to the same demographics and assess the difference. The calculation is conveyed to the customer and our assertions of the customer's financial status is provided, along with the products which might help the customer overcome the hurdle.
The recommendations are shown through a machine learning algorithm, based on the feedback from the others customer who belonged to the same demographics and received a similar score.
The recommendations get more accurate over time as we're dynamically building the data-set based on the incoming customer information.
Once the customer selects the most suitable product, customer gets on-boarded through FFDC onboarding API (The initial checks to see if the customer is eligible for the product has not been included for sake of simplicity, but can be added as a future addition)
How I built it
FinFit UI is built on the JavaScript front-end framework vuejs, service layer on NodeJs, Azure SQLDB is used to store the user survey and demographics information. Azure ML Studio is used to create a linear progression ML model for score calculation and comparison. Bayesian inference recommendation algorithm is used to recommend the products to the customer.
Challenges I ran into
Understanding and implementing ML for the first time and which ML algorithm to suits best for the role.
Accomplishments that I'm proud of
Learning ML, Implementing the ML, utilizing Azure SQL DB to continuously improve the data-set. Winning 3rd place in Hackathon.
What I learned
One phone call from a random marketing person can be the beginning of a beautiful adventure...
What's next for FinFit
The eligibility check for the customer, before the customer gets on-boarded through FFDC API. Integration with actual retail banking products (currently we're using mock products). Collecting the proper data set, set it up with our algorithm.
Built With
azure
azure-ml-studio
ffdc-apis
vuejs


Architecture
Problem: More than 50% applications rejected by banks. (more operation cost without returns) Data has been tracked and stored in the platform for each bank (High investment for Banks)
Solutions: To provide valid appropriate application leads to Banks and Financial Institutions (FIs)


MARKET PIXEL OFFERINGS
Of late we have been working on areas which can help the Markets team, and we realized that Asset Managers & Traders often rely on internal research teams & more inhouse data to base their decision. They do have subscriptions to Bloomberg & Reuters, but often don’t take insights from other social & public channels. Some more digging & we realized that this pertains to decisions on ~ $80 Trillion Asset Under Management of which each of the Big 4 US banks holds about $1.5 Trillion. What we got KNOW to is that data which can help Assets managers is just not 1-dimensional (like inhouse research) but is omni-channel (and it comes from multiple directions such as news articles, social media, global geo-political que’s, inhouse research and many more). And this was the basis on which we started working on our idea MARKET PIXEL for OTC Trading Desk– A solution meant to be the Eyes & Ears of an Asset Manager for tomorrow. The soln. scans Data across sources as varied as news, articles, reports, blogs, search results, social networks, forums like Twitter, Facebook, Reddit, Instagram, reviews, ad engagement, and website clickstream. Very simply put, It then applies (artificial) intelligence to it and generates actionable and verifiable insights which can drive the big business decisions of Asset Managers of Future.
Let me show you a DEMO of what we have achieved thus far – We have sourced a databased of 500+ entities (the likes which Assets Managers are often trading or exchanging collaterals of), 22,000+ News Articles from various sources and 30,000+ Intel from those Articles and 2000+ tweets to base our model here.
If I were a Asset Manager/Trader how would this work – I go into the Soln. and then search for CITIGROUP The soln. gives me. So the intel/insights you are seeing came from the article from the web links, and that’s all an asset manager/trader needs to know without having to manually read through the whole article.
From a Technical view point we have used algorithms around Open Information Extraction using proprietary Decision Theory and have also developed a proprietary algorithm with a layer of dominating rules and finally layer which kicks off the aggregation and impact modeling At this point our accuracy/confidence is 75% and we are working on improving this. Our soln. is modular and can take in information from many many sources via API plug-ins (which ever the bank has already paid for like Bloomberg etc. etc. etc.)
We are looking onto revamping the architecture with some cutting edge state of art classifier and fine tuning some dictionary control with certain learning at its core
Built With
d3.js
finastra
google
heroku
java
multithreading
openie
python
twitter
Try it out
themarketpixel.herokuapp.com


Inspiration
Finastra have continued to have a glorious list of Bank names as their customers across payments/trading, etc for ages now. For e.g. in US hosted products, we’ve had around 250 customers.
Now, with the technological advancements and demands of the sector, Finastra has moved into the ‘Cloud’ future. This also marks a complete integration of all Finastra offerings under one platform – FFDC. Though a few names now, this platform will grow and have a similarly long list of Banks/FIs on the same cloud platform FFDC.
If we look at it bit differently, it’s a huge community of Banks/FIs hosted on the same platform - FFDC. This aspect of a huge community could be leveraged to offer more value to these Banks/FIs.
Similar platforms like Paytm exist for customers to help then do secure immediate payments. If this works out, we see a lot of potential in this idea to be able to build a Payments Wallet like immediate funds settlement experience for the banks also.
What it does
We want to offer a solution on the FFDC platform that will offer inter-connectivity between these banks – a Bridge This Bridge could have multiple use cases for these banks on the same platform. For e.g. Independent Wires/Payments network would be built for transaction processing between these members of the community – without needing an external network to relay payments from an FFDC bank to another FFDC bank.
Our solution intends to demonstrate this via a service prototype that can send wires directly from an FFDC bank to another FFDC bank without an external payment network (e.g. SWIFT).
• All banks on the Finastra platform should be able to send transactions directly within the Finastra network instead of reaching out directly to SWIFT. • This should save money to banks in terms of not sending these transactions to SWIFT and instead of using the new payments bridge. • This service will attract new customers and also help the Finastra to motivate existing customers to move\upgrade on FFDC and Fusion GPP.
How I built it
We're a team of enthusiastic developers/QA. We started with SCALA for REST APIs and FusionFabric.cloud APIS to submit Transactions to bank on FFDC.
Challenges I ran into
About Regulatory challenge: For the implementation point of view we need to solve regulatory challenges related to transaction reporting to Regulators.
Accomplishments that I'm proud of
We're proud of the teamwork we were able to pull-off. We're also proud of the enthusiasm. In the end, it was a great learning experience for everyone on the team and we are glad of it.
What I learned
A positively spirited attitude can help you cross any difficulties that may come. In our case, everyone worked on a different portion of the app by learning himself/herself and then helping the other person do the same. That was great collaboration
What's next for Fusion Bridge
The same architecture can be updated to work in P2P mode instead of current Relay mode
Built With
apis
ffdc
fushionfabric.cloud
html5
rest
scala


Inspiration
We had learned how to create a VR game using Unity and we decided to build one on our own.
What it does
It is a replica of the Fruit Ninja game. We have a sword that slices fruits falling from above. There is a timer and a score keeper. We also are planning on implementing three different levels of difficulty, which adjusts the speed of the fruits falling.
How we built it
We have fruit prefabs instantiate and drop, while our controller (the sword) has a collider that when a collision of the sword and a fruit occurs, it destroys the fruit prefab and increases the player's score.
Challenges we ran into
At one point, we lost our 360 view to the game in the headset and since we were working on the project as a group, we had multiple merge conflicts which caused us to eventually restart the entire project and build a new one.
Accomplishments that we're proud of
We learned a lot about the Oculus SDK and how it is different from the Google Daydream. We also came across many useful documentations and tutorials. We also are proud that we implemented our controller and were able to make the interactions with the UI work.
What we learned
We became much more comfortable using Unity and the Oculus Go headset.
What's next for VR Fruit Ninja
We look forward to implementing a teleport feature on our game which will make it more exciting.
Built With
c#
unity
Try it out
GitHub Repo


Limitless Home Page
Inspiration
"Limitations live only in our minds. But if we use our imaginations, our possibilities become limitless". Jamie Paolinetti
What it does
Based on McKinsey survey, 85% of the banks identify the new regulations in respect to capital allocation and liquidity as the main reason to push credit risk manager to broader role in the bank aligned with finance and treasury. Limitless is the FinTech App for Credit Limit Manager that oversees the development and monitoring of counterparty credit limits. It highlights opportunities to optimize the capital allocation and boost liquidity. .
How we built it
Limitless is built using FFDC Design Studio and angular.js, it empowered by insights from unsupervised and supervised ML models to guide Credit Manager decisions. The historic credit exposure is clustered using k-mean model and refreshed daily using the ML classification algorithms. It utilizes TCM Portfolio Optimization API to provide insights on counterparties. The credit exposure forecast for 2 weeks is done using the deep learning (LSTM). The data for ML training and validation is extracted from in-house client mangled DB. The client is using the core (Summit) credit limits management for the last 10 years.
Challenges we ran into
New technologies and skills
Accomplishments that we're proud of
We use FFDC Open API, FFDC Design Studio and angular.js; got meaningful results for ML models; able to leverage unsupervised, supervised and deep learning ML techniques.
We put together the end to end application workflow based on the user journey of Credit Manager persona.
What we learned
We learn about challenges faced by financial institutions in respect of credit risk, capital allocation and liquidity management; ML models and UXP insights
What's next for Limitless
Limitless won Best in City award in Bucharest city side HackForTheFuture. The next step is to compete for Global Hackathon for TCM.
VIDEO and PASSWORD for demo video link: FINTECHHACKA2019
https://vimeo.com/377597471
Built With
angular.js
ffdc
java
numpy
pandas
python
scikit-learn
tcm
Try it out
bucl7gs46s2.misys.global.ad


Inspiration
Small and medium-sized enterprises (SMEs) are frequently hailed as the backbone of the economies. However, the SMEs usually have severe difficulties with raising money. Considering the bank-dominated characteristic of economies, banks are the main source of financing, and the lack of a comprehensive credit rating database has been a bottleneck for SMEs.
What it does
through the Kyc of our platform users, we make sure that according to their credit rate they get the banks with a best interest rate
How we built it
First, we tested the Finestra APIs using postman. Then, we implemented our platform prototype. We used Angular8 for the front-end. And for the back-end, we integrated the Finestra PSD2 and Credit 2 APIs (we will use other APIs since we will implement other functionalities). The SMEs' data is finally stored in our MongoDB database. So, the user will request a credit. The data posted on our platform will be stored in our databank and sent to our banks' clients to get the credit rating. After getting results, we send the SME profile to the bank with the highest score. After that, the banks will contact the SME to continue the procedure. The credit information will be automatically updated. And, the use of the PSD2 allows as to update the SMEs dashboard automatically. At the end of the year, we provide clear and relevant reports to the banks based on the SMEs data saved with our platform.
Challenges we ran into
we changed our idea several times to finally obtain the most market oriented solution
Accomplishments that we're proud of
a mixed team with great synergy between us and incrdible mindset we won the prize of Best team
What we learned
how API actually works and how to consider all the market players
What's next for Credy
prototype by mars 2020 to sign with banks and stat working
Built With
angular.js
machine-learning
mongodb
psd2


Inspiration
A Mortgage loan application takes around 40-45 days for closure. Customers were unaware why their loans take much time for getting granted. Our app will speed up the loan processing by ease the most time taking phases.
What it does
• Instant eligibility checker (check credit score, check payment history) • Required Documents Notification • Apply for Lead instantly • Predict the time/date for completion of each phase • Order appraisal (Using location map sent by Customer) • 1003 Auto fill (with the above-mentioned data. • Pre-Automated Underwriting (With the history of customer data) • Instant Upload/Request missing documents • Quick view of possible delays in a loan (for customer as well as loan officer)
How we built it
We build this app using Azure ML Studio for borrowers credit check, Xamarin and apis. Machine learning and FFDC Apis are the main skills used
Built With
.net
apis
ffdc
machine-learning
xamarin
Try it out
losmobile.azurewebsites.net


leaderboard
Inspiration
I really like the my childhood minesweeper game.
What it does
Everybody know how to play it, for sure.
How I built it
It was build by ReactJS, Blockstack, Gaia Storage
Challenges I ran into
The boostrap component is so complicated. Gaia storage is still limited function to use.
Accomplishments that I'm proud of
The game is easy to play and really fun. You can also can show your best score to the others.
What I learned
Authentication with blockstack is not difficult, but gaia storage is really limited.
What's next for minesweeper
I will built a mobile version.
Built With
blockstack
firebase
gaia
react
Try it out
minesweeper.etherewine.com


Inspiration
We want to make a contribution to make the world a little more sustainable by offering green loans in the wordl of corporate and syndicated lending.
What it does
It offers the possibility to conncect loans ( with a sustainable purpose) with a so called "green label". I gives the users of LIQ the possibility to attract other (ideological) banks to invest ( and buy liq?).
How I built it
I am nog a technical guy
Challenges I ran into
No available API on the fabric for syndicated loans
Accomplishments that I'm proud of
The cooperation in the team and the result we achieve
What I learned
To think more out off the box. And that the subject doesn't have the same value everywhere.
What's next for Finastra Green Loan App
We have to discuss this as a team.
Built With
api


Ningbo Xiatao Plastic Industry Co., Ltd was established in 1998,and locates in the beautiful seaside city-Xiangshan,Ningbo. We are a creative and professional manufacturer that specializes in plastic Conduit connectors,plastic pipes,zinc die casting fittings,steel and malleable products. To control the quality,we have passed ISO9001:2015 and TS16949:2002 quality systemapproval,and some of the products got the approval of UL,CSA and ROHS etc. Xiatao has a team of skillful and experienced,which help customers to design reliable and effective solutions.Weadhere to"customers first,hearty service"principle,providing with high-quality.professional technique,and perfect after-sale service for our customers. Homepage: https://www.nbxiatao.com Add:Binhai Industrial Park,Xiangshan, Ningbo,Zhejiang,China Tel: 86-574-65803802/65803801 Fax: 86-574-65803805 Email: sales@xiatao-plastic.com
Built With
realsense
Try it out
www.nbxiatao.com


Inspiration
Considering the dynamics and the advancements in the payments sector in todays era, we have become more prone to frauds. There have been instances these days like there are automatic deductions from a savings account, addition of money to random Paytm accounts, automated UPI transactions, etc. By this initiative we are enabling the end customer to have an extra layer of authentication which will generate a push notification to authenticate each login attempt from a registered device.
What it does
This initiative comprises of having a custom API built which will generate a push notification on each login attempt (Authentic/Suspicious) on the registered mobile device which will enable the user to take an extra step towards a more secured authentication. As a part of this we are enabling the user to Register and Un register a device directly on the online banking web application.
Benefits
Extra Step towards a more secure Authentication. Reducing the number of Frauds/Hacks.
How I built it
Using Android Studio, some custom API, Finastra APIs,
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Push Notification -Secured Authentication in Digital Banking
Finastra can work more on this idea and make it ready with minimal resources and in less time.
Built With
android
customapi
finastraapi
mobileapplication
webservices


Inspiration
Look around you! Many people in companies make professional expenses. All these expenses are generating a lot of paperwork and a big waste of time.
We decided to invent the most innovative payment card in the world and to add ticketless technology.
This is the future of payment : easy, realtime, ecologic !
What it does
FOR MANAGERS & EMPLOYEES
Company managers can now confidently give configurable bank cards to each employee or to each department. Cardholder have a dedicated and secure space, accessible through web and mobile to track, justify and manage his business expenses. The expenses incurred by the employees are linked to the company’s bank account, eliminating the need to make repayments by transfer.
55 INNOVATIVE FEATURES All features are 100% configurable in real time.
Reporting and control Comprehensive history of card transactions in real time with filters that can accurately search and extract bank transactions, exportable onto four possible formats for accounting softwares (with or without supporting documents).
Configurable limits Set up payment and/or withdrawal limits per day, week and/or month. Define the number of allowed transactions per day. The manager.one card is the only card on the market that can be configured to have no limit.
Security Impose 3D-Secure, block/unblock cards in real-time, and activate/deactivate any of the following: payments in specific countries, ATM withdrawals, contactless, withdrawals, transactions in foreign currencies, internet payments, or cancel the card directly from mobile.
Up-to-date proof-of-payments Mandatory proof-of-purchase uploading (without proof, the card is blocked), intelligent reading of receipts to extract amounts, VAT and number of guests per meal, and automatic categorization of expenses.
Real time notifications For each transaction or crossing of a configured limit, a notification is received in real time by the cardholder.
Block and authorize spending It is possible to block the use of the debit card on: • certain days of the week and/or certain time-slots, • certain keywords or categories of transactions and, invertedly, authorize the card only with specific merchants.
Ticketless technology We have done an API that let all merchant to send the ticket of the transaction to bank. This solution could stop the print of billions of tickets !!
How we built it
With love and passion
We have a solution on the top of the Core Banking, we are connecting it with APIs to get the balance of the bank account and are able to know if the transaction can be.
PHP / vue.js / SQL / Docker / Azure / Java / Jpos
Challenges we ran into
It is a great challenges to discover in a few hours a totally new Core Banking solution and to plug in and succeed to match two visions of the way to providing great solutions.
Accomplishments that we're proud of
The best UX OCR Solution The coolest team Realtime technology A great payment server Ticketless technology that can save millions of trees !
What's next for Finastra brings you into the future of payment
Our goal is to find, with the help of Finastra, banks that can adopt our solution. These banks will be able to offer all their customers this innovative real-time control solution and put an end to the painstaking management of expense claims.
Our solution is ready and waiting for Finastra to be deployed ;)
Built With
api
cards
fun
java
javascript
jpos
php
vue.js
Try it out
staging-0-finastr-5edk3h.recette.manager.one


Tennis Clash Hack Mod – Cheat Tennis Clash Gems and Coins You can start using this new Tennis Clash Hack Cheat and as you do, you will see that your game is going to improve a lot. We are confident to tell you that you should try this Tennis Clash Cheat out and you will see that you will like it. We are going to tell you a lot more about this Tennis Clash Mod apk in this guide, but first we are going to talk about the game so that you know some additional things about it.First of all, you should always know that this new Tennis Clash Hack Cheat will be great because will add all of the Gems and Coins you need. There won`t be any waiting time and you will see that the needed features are going to be added pretty fast. You only need to wait a couple of seconds until the features will be added. Another important thing when it comes to this hack Tennis Clash is the fact that you will be able to use it on any device that you own. This means that you can easily use it on any iOS and also Android that you have.
Features of the Tennis Clash Hack Online Tool: – Get free unlimited Gems and Coins – Works on Android and iOS,Windows Devices. – No Download or Jailbreak necessary – No risk of being banned in the game – Use it anytime and anywhere – We update the hack almost daily
https://tennisclashhack.cheatonlinemod.com/
https://cheatgamesonline.com/tennis-clash-hack/
Tennis Clash hack, Tennis Clash hack online, Tennis Clash hack apk, Tennis Clash mod online, how to hack Tennis Clash without verification, how to hack Tennis Clash no survey, Tennis Clash cheats codes, Tennis Clash cheats, Tennis Clash Mod apk, Tennis Clash hack Gems and Coins, Tennis Clash unlimited Gems and Coins, Tennis Clash hack android, Tennis Clash cheat Gems and Coins, Tennis Clash tricks, Tennis Clash cheat unlimited Gems and Coins, Tennis Clash free Gems and Coins, Tennis Clash tips, Tennis Clash apk mod, Tennis Clash android hack, Tennis Clash apk cheats, mod Tennis Clash, hack Tennis Clash, cheats Tennis Clash, Tennis Clash triche, Tennis Clash astuce, Tennis Clash pirater, Tennis Clash jeu triche, Tennis Clash truc, Tennis Clash triche android, Tennis Clash tricher, Tennis Clash outil de triche, Tennis Clash gratuit Gems and Coins, Tennis Clash illimite Gems and Coins, Tennis Clash astuce android, Tennis Clash tricher jeu, Tennis Clash telecharger triche, Tennis Clash code de triche, Tennis Clash hacken, Tennis Clash beschummeln, Tennis Clash betrugen, Tennis Clash betrugen Gems and Coins, Tennis Clash unbegrenzt Gems and Coins, Tennis Clash Gems and Coins frei, Tennis Clash hacken Gems and Coins, Tennis Clash Gems and Coins gratuito, Tennis Clash mod Gems and Coins, Tennis Clash trucchi, Tennis Clash truffare, Tennis Clash enganar, Tennis Clash amaxa pros misthosi, Tennis Clash chakaro, Tennis Clash apati, Tennis Clash dorean Gems and Coins, Tennis Clash hakata, Tennis Clash huijata, Tennis Clash vapaa Gems and Coins, Tennis Clash gratis Gems and Coins, Tennis Clash hacka, Tennis Clash jukse, Tennis Clash hakke, Tennis Clash hakiranje, Tennis Clash varati, Tennis Clash podvadet, Tennis Clash kramp, Tennis Clash plonk listkov, Tennis Clash hile, Tennis Clash ateşe atacaklar, Tennis Clash osidit, Tennis Clash csal, Tennis Clash csapkod, Tennis Clash curang, Tennis Clash snyde, Tennis Clash klove, Tennis Clash האק, Tennis Clash 備忘, Tennis Clash 哈克, Tennis Clash entrar, Tennis Clash cortar
Built With
and
cheat
clash
gems
hack
mod
tennis
Try it out
tennisclashhack.cheatonlinemod.com


Loading...


Inspiration
Use the powerful Machine Learning technologies to add up new, interesting features to applications that are getting powered by FFDC financial data
What it does
It applies two ML technologies (one supervised learning, the other one unsupervised learning) for two different purposes in the same application: 1) it automatically configure the component structure of an FFDC Exchange Rate Assistant based on the traffic and backend systems loading by using a model generated with 2-layer deep, 10-neurons per layer convolutional neural network (CNN). The model needs retraining and updates at regular intervals, and is persisted on the local server disk for better performance. The UI configuration commands are based on month, day and hour and they are provided through REST API 2) for the user who intends to buy currencies and sees the current exchange rate provided by FFDC API, an unsupervised regression algorithm (based on AutoRegression Integrated Moving Averages or ARIMA) provides exchange rates forecasts for the selected two currencies for the next N-day prediction interval (with N configurable)
How we built it
Tarjinder and I have used a stack of technologies that include FFDC REST API, Angular 8 (TypeScript), Python 3.5.6 and 3.7 (with Keras and Tensorflow 2.0), .NET 4.6.1
Challenges we ran into
One of the important challenges was related to the evolving versions of Python interpreters and the inability of some packages to keep up.
Accomplishments that we're proud of
This was a fun project and we are really proud of how it came up: cool changing interface driven by ML, decent performance, ability to be configured and evolve to a real solution
What we learned
We have learned that the new technologies, centered around machine learning (and its subspace of AI) are becoming widely available, easy to use and integrate and it takes only a grain of creativity to boost up the existing Finastra applications with new, cool, and highly marketable features
What's next for Adaptive FFDC Forex Assistant Powered by AI
We hope that this POC will attract the attention of Finastra technical and business stakeholders and we might get involved in activities that could lead to a fully fledged solution
Built With
.net
angular.js
bootstrap
ffdc
python


Inspiration : To improve customer satisfaction and gain more members through automation by saving their money (by avoiding printing).
What it does: Creates an electronic form from the UD host to DocuSign.
How we built it: Created a new tool and then integrated with the DocuSign API.
Challenges we ran into: We are using demo sandbox from DocuSign and the token that we use will be active only for a few hours.
Accomplishments that we're proud of: Learning new technologies (API Integration), Saving the Customer money.
What we learned: DocuSign API Integration with UltraData.
What's next for UltraData Docs team: Value Discovery should put this on the PI roadmap for delivering it to all the customers.
Built With
api
c#
unidata


This image is currently processing. Please be patient...
Tennis Clash Triche – Astuce Tennis Clash Gemmes et Pieces Illimite Vous pouvez commencer à utiliser ce nouveau Tennis Clash Triche Astuce et vous constaterez que votre jeu va beaucoup s’améliorer. Nous sommes confiants de vous dire que vous devriez essayer celui-ci et vous verrez que cela vous plaira. Nous allons vous en dire beaucoup plus sur cet outil dans ce guide, mais nous allons d’abord parler du jeu afin que vous sachiez quelques informations supplémentaires à ce sujet.Tout d’abord, vous devez toujours savoir que ce nouveau Tennis Clash Triche Astuce sera formidable car il ajoutera toutes les Gemmes et Pieces nécessaires. Il n’y aura pas de temps d’attente et vous verrez que les fonctionnalités nécessaires vont être ajoutées assez rapidement. Il vous suffit d’attendre quelques secondes jusqu’à ce que les fonctionnalités soient ajoutées. Une autre chose importante quand il s’agit de celui-ci est le fait que vous pourrez l’utiliser sur n’importe quel appareil que vous possédez. Cela signifie que vous pouvez facilement l’utiliser sur n’importe quel iOS et Android que vous avez.
Caractéristiques de l’outil Tennis Clash Triche: – Obtenez gratuitement Gemmes et Pieces illimité – Fonctionne sur Android et iOS, les appareils Windows – Pas de téléchargement ou Jailbreak nécessaire – Aucun risque d’interdiction dans le jeu – Utilisez-le à tout moment et n’importe où – Nous mettons à jour le Triche presque quotidiennement
https://tennisclashtriche.astucejeuxgratuit.com/
https://jeuxtricheastuces.com/tennis-clash-triche/
Tennis Clash triche, Tennis Clash astuce, Tennis Clash pirater, Tennis Clash jeu triche, Tennis Clash truc, Tennis Clash triche et astuce, Tennis Clash triche android, Tennis Clash tricher, Tennis Clash outil de triche, Tennis Clash gratuit Gemmes et Pieces, Tennis Clash illimite Gemmes et Pieces, Tennis Clash astuce android, Tennis Clash tricher jeu, Tennis Clash telecharger triche, Tennis Clash code de triche, Tennis Clash triche france, Comment tricher Tennis Clash, Tennis Clash hack, Tennis Clash hack online, Tennis Clash hack apk, Tennis Clash mod online, how to hack Tennis Clash without verification, how to hack Tennis Clash no survey, Tennis Clash cheats codes, Tennis Clash cheats, Tennis Clash Mod apk, Tennis Clash hack Gemmes et Pieces, Tennis Clash unlimited Gemmes et Pieces, Tennis Clash hack android, Tennis Clash cheat Gemmes et Pieces, Tennis Clash tricks, Tennis Clash cheat unlimited Gemmes et Pieces, Tennis Clash free Gemmes et Pieces, Tennis Clash tips, Tennis Clash apk mod, Tennis Clash android hack, Tennis Clash apk cheats, mod Tennis Clash, hack Tennis Clash, cheats Tennis Clash, Tennis Clash hacken, Tennis Clash beschummeln, Tennis Clash betrugen, Tennis Clash betrugen Gemmes et Pieces, Tennis Clash unbegrenzt Gemmes et Pieces, Tennis Clash Gemmes et Pieces frei, Tennis Clash hacken Gemmes et Pieces, Tennis Clash Gemmes et Pieces gratuito, Tennis Clash mod Gemmes et Pieces, Tennis Clash trucchi, Tennis Clash truffare, Tennis Clash enganar, Tennis Clash amaxa pros misthosi, Tennis Clash chakaro, Tennis Clash apati, Tennis Clash dorean Gemmes et Pieces, Tennis Clash hakata, Tennis Clash huijata, Tennis Clash vapaa Gemmes et Pieces, Tennis Clash gratis Gemmes et Pieces, Tennis Clash hacka, Tennis Clash jukse, Tennis Clash hakke, Tennis Clash hakiranje, Tennis Clash varati, Tennis Clash podvadet, Tennis Clash kramp, Tennis Clash plonk listkov, Tennis Clash hile, Tennis Clash ateşe atacaklar, Tennis Clash osidit, Tennis Clash csal, Tennis Clash csapkod, Tennis Clash curang, Tennis Clash snyde, Tennis Clash klove, Tennis Clash האק, Tennis Clash 備忘, Tennis Clash 哈克, Tennis Clash entrar, Tennis Clash cortar
Built With
astuce
clash
et
gemmes
pieces
tennis
triche
Try it out
tennisclashtriche.astucejeuxgratuit.com


Inspiration
Reading about the PSD2 regulation and the evolving Open Banking trend has made me believe that regulators are taking radical steps to put the customer in driving seat and breaking the established banking model all over Europe. This seems to be an exciting time for developing applications
What it does
Provides single view of all accounts of a customer. Transaction history of all accounts can be downloaded and insights can be provided to the user.
Built With
psd


Inspiration
Make life better
What it does
Enables
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Let's OPEN openAPI !!!
Built With
angular.js
excel
json
powershell
sql


Hardworks of SMEs,BAs, and Implementation Team.
Its a Automation Tool which reduce the manual woks done by Implementation engineer's, and many employees directed connected to the Customers.
we build a SpringMVC , rest services and the will be building it a Rest APIs so can use any one with Finastra.
controlling the customer environment and make it quite intelligent through different different technologies.
Make easy for the employees as well as Finastra
team work, different technologies, different approaches.
will make more intelligent.
Built With
http
java
restapi
restful
springboot
springmvc


This whole idea is originated by Richard (Audette) and expanded via the further investigation of the whole hack team:
Note FYI: ES(Enhancement Services) and Filogix/CMT are the 2 LOBs in Finastra (Canada).
Technically, Enhancement Services (ID Assist) has a user’s personal info and credit bureau. It's cool to add a button on ID Assist, that spits out an XML file. Then we could just have the payload on FCXLink, and ingest a loan to submit to Filogix Expert...
Based on above mentioned , our hack team are working together to create an ability for user to apply for a mortgage from "ID Assist" via a button click and submit it to Filogix "Expert” for a Loan. We are sing some api/window services from Filogix (CMT) and most important of all, by consuming the existing FFDC Fusion MortgageBotLOS Api we are capable of providing U.S. mortgage applications to our users.
The idea also resonates with Filogix's Mortgage Ecosystem in the initiative of "Direct to Consumer"(D2C) and will create more potential sales volumes and revenue opportunities with minimum cost (as the core components are existing and resources from both ES and Filogix teams are familiar with the functionality...).
For the future monetization opportunities, we also have our "Next Steps" to act with based on below 2 points:
Add “Intelligence” to target Broker selection;
Add Trigger(s) to ES so as to selected users
To put it in short, "Complicated life, uncomplicated mortgage"-- As a FinTech member, let's hack and facilitate our customers with their mortgage/loan applications.
Built With
angular8
c#
sassy


Think Globally...Act Locally
Inspiration ھر فرد ھے ملت کے مقدر کا ستارہ
What it does INDIVIDUAL ORIENTED FOR SDGs awareness
How I built it SDGs in mother language and gross root level engagement
Challenges I ran into PER CAPITA VERY LITTLE INFORMATION OF THIS NEW IDEA
Accomplishments that I'm proud of Now people are showing intrest to learn about this global and national road map of development
What I learned.... WE ARE UNIQUE AND MUST SHOW OUR UNIQUENESS
What's next for SDGs awareness IMPLEMENTATION AND PER CAPITA ENGAGEMEMT IN PRACTICAL LIFE
Built With
language


Inspiration
Ajudar com uma causa nobre
What it does
Busca auxiliar instituições de caridade a obter fundos financeiros.
How we built it
Vamos desenvolver uma ferramenta composta por um back-end java e front angular onde disponibilizaremos funcionalidades para arrecadar fundos, através de alguns meios de comunicação trazer doadores para nossa plataforma. Todo processo de captação poderá ser monitorado em tempo real.
Challenges we ran into
O Primeiro contato para tentativa de captação.
Accomplishments that we're proud of
Doar tempo e conhecimento para poder ajudar a um causa nobre.
What we learned
Podemos ajudar com nossas habilidades também.
What's next for dev4change_donators_generics
Levar a plataforma para captar novos recursos fora do pais.
Built With
angular.js
ci/cd
docker
git
java
jsf
rancher


Inspiration
To enhance member experience for the credit union clients.
What it does
Opens additional membership communication opportunities
How we built it
Using SMS gateway provider
Challenges we ran into
Accomplishments that we're proud of
Introduced SMS module to the core legacy product that has been running for the past 40 years. .
What we learned
.
What's next for ULTRADATA ALERT SYSTEM
.
Built With
api
azure
c#.net
unidata


Smart Bee. Do Less Make More
Inspiration Saida a Bee farmer in Jasekan, has a bee farm with 20 beehives. Each hive contains 15 comb frames. To check the readiness and quantity of the Combs for honey harvesting, she has to manually lift each wooden bar frame which sometimes yields no results because the honey isn't ready enough for harvesting.This daily routine for Saida is a slow and arduous task.
In comes Smart Bee. We provide sensors that are attached to the beehives which alerts the farmer to know the readiness of the comb for harvesting. Thus, she does less to make more. Consequently is able to increase profitability and expand. The sensor will also make sure her conditions in the hives are condusive for honey production. Smart Bee's Sensor when upgraded will help check the quality of the honey.
The Honey Sensor was built by consulting a hardware developer who designed the sensor to check defined parameters. A software developer was also brought on board to develop an on-site application for the monitoring device to interpret the measurements taken for the bee keeper. When Saida uses our honey sensor, she only needs to open the hive because she is sure the honey is ready for harvest just by seeing the green light which signifies readiness for harvest. Red light of the sensor means it's not ready at all while Yellow signifies the presence of little honey in the comb. With the Sensor, she can also know the temperature and humidity levels of each hive.
Challenges we run into was; the problem of constant internet and mobile network coverage , financing the project, ensuring our applications were user friendly across all demographics.
Smart Bee seems to be the first company ever to develop a device that helps Bee keepers monitor the state of readiness and quality of their honey. Smart Bee is also proud of creating a 100% internet free device.
In the process of bringing our sensor into existence, as a team we learnt how to cooperate among ourselves. Also, we have learnt and researched on bee farming. Finally, one key thing we have all learnt is to realise how powerful our creative capabilities are.
The Vision for Smart Bee is to further design our Honey Sensor into a mobile device that can be bought by individuals who wants to check the quality of honey they buy. Also, Smart Bee envisions her company to becoming the authority in the optimization of honey production. Thank you.


Identified corridors
Zoohackathon-Solution
Monitor animal movement in corridors
The elephant migration patterns in Botswana have resulted in a lot of lives being lost in the country. Our idea involves using drone technology to monitor the paths of these animals. From drones we can learn which corridors the elephants are using to move in the KAZA region and also understand the path their taking. This data can be used to warn people if their are in the elephant path, inform the government which pieces of land to not allocate for civilians if their are possible animal paths (meaning in the future the elephants will most likely use the path and endanger the people settled there) and the drones can be able to identify abnormalities alerting about possible poaching cases.
Why drones? Satellite images can be obtained most likely every two days and can be obscured by clouds. Drones allow monitoring when needed and with updates we can be able to count the number of elephants moving through various corridors.
The solution is aimed at clearing a path for the elephants and allowing safe and efficient co-existence.
Built With
jupyter-notebook
Try it out
GitHub Repo


Story
We've been working in trading in investment banks, hedge funds and large commodity trading houses. For the co-founder Marc, being the only one who could code in his team, he was asked very often to backtest trading ideas using an internal platform. Coding, running the simulations, analysing the results was a time consuming and painful process, especially in a fast paced capital markets environment where testing a trading strategy, and weighting its associated risks, justifies, or at least supports all major trading decisions.
Within a trading team, each one has their own trading ideas that they would like to test very quickly to be able to make the good trading decisions. The strategy design and the approval is very often a team effort. Backtesting and simulating outcomes is the first important step for the valuation of the potential risk and returns.
First steps
A few years back at work, Marc's answer was to automate every single process that was meant to be systematic. He created good old excel files that let his teammates backtest their ideas very easily by importing market data, creating signals with moving averages and linear combinations, and defining entry and exit levels for their positions. The UX, as you can imagine, was made as simple as possible: dropdown menus, automatic recalculation, visualization of results…
This result of this tedious process answered 90% of his colleagues' needs. Building and testing the same strategies, with single amendments to the workflow, over and over again is currently very frequent in trading houses, even coming from "innovation" departments.
The STRATL idea simply hatched out of good old frustration at workl! :)
It was time to try and suggest to all traders or aspiring traders out there something new, initiated by a team, and eventually built and maintained by a larger community, for the community.
STRATL - Your Strategy Lab
STRATL lets you to create investment and trading strategies like a Lego, with pre-coded calculation modules, by building diagrams for analysis and decision. It is two essential diagrams:
an analysis diagram, where every node consists of a quantitative model, taking signals (or series e.g. prices) as inputs and producing signal outputs.
a decision diagram, where every state corresponds to a target portfolio position. The transition between states is a condition based on the value of the analysis signals.
it is built with Angular 8 on the front end, served by Java Spring and Mongodb on the back-end using reactive libraries.
The UX lets the user build strategies in a flexible and intuitive manner and backtest them, "debug" them efficiently. The data produced is both daily and minute data.
The UX experience, with a high level of data and results transparency, adapted for touch screens, is meant to satisfy any passionate trader to design, test and understand the results of their strategies minute by minute at their workplace, or from the comfort of their bed. Money never sleeps ;).
We are very proud of the interface that we coded for building the diagrams, with nice animations and smooth logic, and with the performance of the backend. The technological challenge is two-fold:
bringing "fun" into a very serious sector, but mostly taking the frustration out of a trader's mind. The platform has to be very transparent: to understand quicklly why a strategy is performing well or not. This is the single most demanding request that a trader has.
optimized performance. The process is non-blocking and lets you design multi-asset strategies. Models can be as sophisticated as they can be: sharding and parallelization at every node.
Our vision: a STRATL community
In investment banking, trading houses and hedge funds, we have typically:
quantitative analysts who develop quantitative models for asset management or structure pricing. They still need to convince traders of the sound logic of their models. In other words, they are selling their model to the trading desk so they can actually start to use it. What if you can build your model (node) and effectively sell it to the trading community. It is a quant marketplace.
ITs who work hard on serving data to feed the models in a timely manner. Commodity houses are slowly shifting to cloud based solutions, but what if you were only paying for the usage you need to run a single strategy. Somewhere between a SaaS and a PaaS.
Traders, asset and hedge fund managers who use the produced signals to take investment or trading decisions, and source best execution to seek lower fees. Anyone would like to participate to the best managers performance: this is copy trading friendly, or the crowdfunding version of a hedge fund.
Every desk has a specific function and the full structure as it stands is hardly flexible or scalable, or at least its scalability depends for instance on the trader's ability to perform.
Today, starting a quant hedge fund with $100mio AUMs or less hardly covers the costs. Historical data, IT infrastructure, Research and Development are all necessary to be and stay competitive.
STRATL helps every aspiring trader to build their own flexible, scalable strategies. they can allocate resources efficiently. Quants can build proprietery models, make description, reverse engineering tests available for traders. If convinced, the trader can subscribe to the model with a minimal fee.
We are a team of financial and startup professionals with a lot to give and learn and we are thrilled to see our team of advisors, passionate technologists and traders, expanding.
We started our B2B Go-to-market recently with the first exciting feedbacks from traders.
Built With
angular.js
d3.js
gcp
java
mongodb
spring
Try it out
www.stratl.com


Non available of good and nutritious food and fancy cakes on the market.
Built With
laravel
php
python


Impactful UI
re:Invent 2019 Hackathon: SkyTruth
PROJECT STRUCTURE
High Level
All around the world oil is being spilled into the seas and winding up on the beautiful shorelines of our earth, but no one knows. How do we effectively and quickly get people to see this problem? It's a challenging problem, given that this oil comes from ships which travel on the seas and are always moving. Even if an oil spill can be detected, how do you know which ship, of the thousands on the seas, caused it?
SkyTruth has a process already to deal with this, but it is not as automated and timely as it could be. This solution was improved upon in this project to reach a number of goals:
Expose the data on spill to the world.
More fully automate the process.
Technologies:
We used AWS, with SageMaker, Lambdas to automate hte process which gets ported to an impactful UI which shows the results to the user.
Built With
css
html
javascript
makefile
python
ruby
Try it out
GitHub Repo


Generic idea
Inspiration
SWVL and Careem
What it does
It will provide easy access to transport to day traveling people on long routes.
How I built it
Currently It's an idea, which needs to start. It will be an app on client side (Drivers,Owners,Customers/passengers) and a web portal on server side for admin users and owners.
Challenges I ran into
Finance, Developers Marketing Experts and idea improvement.
Accomplishments that I'm proud of
I have taken my first step and i am sure i will be able to take last step as well.
What I learned
A Team of committed people can do anything that one cannot achieve alone.
What's next for estop
It's an hybrid idea of careem and SWVL and will be known as electronic Bus Stop or in local language (بس اڈہ) specially for the people who travel daily basis from surroundings of big cities like Islamabad,Rawalpindi Lahore etc for their jobs and study. It will be a win win situation for both users and vehicle owners.
Built With
android
ios
laravel
mysql
react-native
Try it out
GitHub Repo


Inspiration
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for Relay Bank
ddd
Built With
android
keras
node.js
python
scikit-learn
tensorflow
Try it out
Google Play Store
GitHub Repo


Inspiration
What it does
Single Open API in FFDC that makes it easy for FinTech apps to retrieve used vehicle valuations from the leading vendors (NADA, Black Book, Kelley Blue Book, Edmunds).
How we built it
Common vehicle valuation methods running in Azure Service Fabric with small individual behaviors handled separately.
Challenges we ran into
Partners granting access to their development and test environments. Only two of the four vendors had test credentials set up by the start of the Hackathon.
Accomplishments that we're proud of
1) Demonstrated multi-tenant, multi-vendor access through an Azure SaaS environment in record time 2) New FFDC API submitted that leverages prior experience with 4 other FFDC API submissions
What we learned
Azure Service Fabric made it clean and straightforward to deliver a streamlined API and accommodate idiosyncratic differences amongst vendors.
What's next for FFDC API: Multi-vendor vehicle valuation service
Immediately/end of December: 1) Incorporate FFDC comments on swagger and modify services to follow suit 2) Hand over API, NADA to DecisionPro development for incorporation in CY 1H2020 DCP release
By end of January: 1) Finish up Black Book gateway, and hand over to DCP to replace ancient manual interface 2) Tweak Total-Lending revenue tracking and reporting to improve monetization 3) Tie into Total-Lending config tool 4) Spin up TRV to generate KBB and Edmunds as Azure Service Fabric gateways Skills-building exercise
Built With
azure
azure-service-fabric
c#
json-dot-net
microsoft-authentication-library
Try it out
open-api.visualstudio.com


Inspiration
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for dev4change_ReFull_Hope
.


Inspiration
Our Customers and relieving their pain point of manually creating their own pipeline reports in excel spreadsheets. As the industry trends to using data and analytics more, we understand that for our customers data is king. However rather than just receiving the data back in a raw form, they are looking to receive this back in a more consumable form, providing them strategic insight or direction. This is where we see the opportunity to apply machine learning for forecasting or efficiency gains and monetizing the data in this format.
What it does
In our proof of concept, we implemented a pipeline in LaserPro and tied in analytics by creating custom events in Application Insights. We took the data from application insights and created a pipeline dashboard using the visualization tool PowerBi, which is intended to be accessed by customers on a webpage (or mobile device) via a API on FFDC.
How we built it
What is finished: We have Application Insights in our On Premise Product. We added pipeline events to that existing Telemetry data. From there this Telemetry data is backed up in a Storage Blob hosted on Azure. The blob data is then sent through an Azure Data Factory, to be placed in a Data Lake which adds ease of use. We then use this data through Power BI to add visualization.
The future: An additional layer of data bricks will be added to the data lake, which will then pipe data to a SQL warehouse. The SQL warehouse will then feed the Power BI piece. That will be done via FFDC, which will also have a pipe in, so a hosted Website will have access to the Power BI visualization. An additional API will be written that feeds the data lake, this will also be accessed via FFDC. -The API is to be used by our 3rd party vendors to add their pipeline data for a holistic view of the process
Challenges we ran into
Getting a consistent ID to track loans across products.
Accomplishments that we're proud of
Digesting a customer pain point, and creating a solution that would help make their lives easier. In addition to delighting the customer, we were able to improve our current data analytics collection process and our understanding of multiple product integrations.
What we learned
How to strategically look at a customer request and turn it into a win for everyone involved.
What's next for What the Fusion
First: Implementing a standardized pipeline with analytics across our Total Lending products, and being able to deliver a One Finastra view of the customers loans in the respective products pipeline.
Second: Implementing machine learning to forecast institution trends comparing to other Total Lending Customer's institution trends, and potentially using an API to connect to national databases (such as the FDIC or SNL) to provide national comparisons to their data.


Inspiration
Preventing cashew apple waste and providing rural women with jobs through out the year.
What it does
Antioxidants Prevent gallstones Healthy skin Aphrodisiac Contains Vitamin B, C, E and K
How I built it
AI derived technologies are used for harvesting, sorting and processing the juice for consumers. Farmers benefit from training sessions on organic farming and farm management oriented by technology.
Challenges I ran into
Access roads to the farms are not good. Mishandling of the cashew fruits during harvest and poor storage facilities.
Accomplishments that I'm proud of
We are able to turn the wasting cashew fruit into juice and other edibles
What I learned
Cashews are nutritious and a great business opportunity for our country.
What's next for VISSIONAIRE
ACTION
Built With
none


Inspiração
Gerenciador de Fundos
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for dev4change_gFM_catsr


Inspiration
We were sick of the outdated centralized exchanges and their monopoly. They require trust and there are lots of security issues that are solved with the DEXes.
What it does
Allow people to exchange one cryptocurrency for another in extremely secure, fast and transparent manner.
How I built it
We were working on that since early 2018 with a full team of developers.
Challenges I ran into
The technology is cutting edge, therefore there were a lot of technical issues and research work
Accomplishments that I'm proud of
We have built a few fully working projects based on ethereum blockchain. Now we are working on cross-chain atomic swaps which is one of the biggest pains in the current blockchain ecosystem
What I learned
You should be patient and keep building!
What's next for weiDex
The cross-chain atomic swap integration and gaining some popularity and users
Built With
ethereum
express.js
mongodb
node.js
python
react
solidity
Try it out
weidex.market


eFootball PES 2020 Triche – Astuce eFootball PES 2020 myClub Pieces et GP Illimite Vous pouvez vous amuser tout de suite avec ce nouveau eFootball PES 2020 Triche Astuce et vous verrez que cela vous plaira. Dans ce guide, nous allons vous dire quelques mots sur le jeu, puis nous expliquerons comment celui-ci fonctionne et comment il peut vous aider à devenir un meilleur joueur du jeu.Vous devez savoir que ce nouvel eFootball PES 2020 Triche Astuce est prêt à être utilisé afin d’obtenir toutes les myClub Pieces et GP que vous souhaitez. Vous réussirez à vous amuser avec celui-ci et vous remarquerez le fait que toutes les fonctionnalités nécessaires seront ajoutées en quelques secondes. Cela signifie que vous n’aurez pas besoin d’attendre longtemps avant que toutes les fonctionnalités soient ajoutées et, comme vous le verrez, vous en profiterez certainement beaucoup. Nous vous encourageons également à tirer pleinement parti de ce nouveau eFootball PES 2020 Triche, car il fonctionne correctement sur tous les appareils que vous utilisez.
Caractéristiques de l’outil eFootball PES 2020 Triche: – Obtenez gratuitement myClub Pieces et GP illimité – Fonctionne sur Android et iOS, les appareils Windows – Pas de téléchargement ou Jailbreak nécessaire – Aucun risque d’interdiction dans le jeu – Utilisez-le à tout moment et n’importe où – Nous mettons à jour le Triche presque quotidiennement
https://efootballpes2020triche.astucejeuxgratuit.com/
https://jeuxtricheastuces.com/efootball-pes-2020-triche/
eFootball PES 2020 triche, eFootball PES 2020 astuce, eFootball PES 2020 pirater, eFootball PES 2020 jeu triche, eFootball PES 2020 truc, eFootball PES 2020 triche et astuce, eFootball PES 2020 triche android, eFootball PES 2020 tricher, eFootball PES 2020 outil de triche, eFootball PES 2020 gratuit myClub Pieces et GP, eFootball PES 2020 illimite myClub Pieces et GP, eFootball PES 2020 astuce android, eFootball PES 2020 tricher jeu, eFootball PES 2020 telecharger triche, eFootball PES 2020 code de triche, eFootball PES 2020 triche france, Comment tricher eFootball PES 2020, eFootball PES 2020 hack, eFootball PES 2020 hack online, eFootball PES 2020 hack apk, eFootball PES 2020 mod online, how to hack eFootball PES 2020 without verification, how to hack eFootball PES 2020 no survey, eFootball PES 2020 cheats codes, eFootball PES 2020 cheats, eFootball PES 2020 Mod apk, eFootball PES 2020 hack myClub Pieces et GP, eFootball PES 2020 unlimited myClub Pieces et GP, eFootball PES 2020 hack android, eFootball PES 2020 cheat myClub Pieces et GP, eFootball PES 2020 tricks, eFootball PES 2020 cheat unlimited myClub Pieces et GP, eFootball PES 2020 free myClub Pieces et GP, eFootball PES 2020 tips, eFootball PES 2020 apk mod, eFootball PES 2020 android hack, eFootball PES 2020 apk cheats, mod eFootball PES 2020, hack eFootball PES 2020, cheats eFootball PES 2020, eFootball PES 2020 hacken, eFootball PES 2020 beschummeln, eFootball PES 2020 betrugen, eFootball PES 2020 betrugen myClub Pieces et GP, eFootball PES 2020 unbegrenzt myClub Pieces et GP, eFootball PES 2020 myClub Pieces et GP frei, eFootball PES 2020 hacken myClub Pieces et GP, eFootball PES 2020 myClub Pieces et GP gratuito, eFootball PES 2020 mod myClub Pieces et GP, eFootball PES 2020 trucchi, eFootball PES 2020 truffare, eFootball PES 2020 enganar, eFootball PES 2020 amaxa pros misthosi, eFootball PES 2020 chakaro, eFootball PES 2020 apati, eFootball PES 2020 dorean myClub Pieces et GP, eFootball PES 2020 hakata, eFootball PES 2020 huijata, eFootball PES 2020 vapaa myClub Pieces et GP, eFootball PES 2020 gratis myClub Pieces et GP, eFootball PES 2020 hacka, eFootball PES 2020 jukse, eFootball PES 2020 hakke, eFootball PES 2020 hakiranje, eFootball PES 2020 varati, eFootball PES 2020 podvadet, eFootball PES 2020 kramp, eFootball PES 2020 plonk listkov, eFootball PES 2020 hile, eFootball PES 2020 ateşe atacaklar, eFootball PES 2020 osidit, eFootball PES 2020 csal, eFootball PES 2020 csapkod, eFootball PES 2020 curang, eFootball PES 2020 snyde, eFootball PES 2020 klove, eFootball PES 2020 האק, eFootball PES 2020 備忘, eFootball PES 2020 哈克, eFootball PES 2020 entrar, eFootball PES 2020 cortar
Built With
2020
astuce
efootball
et
gp
myclub
pes
pieces
triche
Try it out
efootballpes2020triche.astucejeuxgratuit.com


Icon
Inspiration
AWS Hackathon for Public Good 2019 Urban Institute Challenge
What it does
Given two sets of input data: 1: a FOOTPRINT file containing polygons of defined houses 2: one or more LAS files containing LIDAR information.
Annotate the FOOTPRINT file with a new column "ALTITUDE_M", which is the altitude (in meters) of each individual building.
How We built it
Lightweight front end to submit URLs of data location Heavy lifting done by Autoscaled EC2s which listen to a queue of job requests
Challenges we ran into
Provided data was in the wrong projection Suggested Python library was incompatible with LAS 1.4 format Lambda is insufficient (memory and time) for the job execution
Accomplishments that we are proud of
Worked with the customer to verify the provided data set Considered Speed of Execution and Cost in the solution
What we learned
Working with GIS data has a learning curve GIS Coordinate systems need to be aligned Working with very large datasets slows down prototyping
What's next for Hypsometer
Swap UI layer for S3 web hosting, API Gateway and Lambda Containerize the ASG to work in Fargate for on-demand compute
Built With
autoscaling
ec2
gis
lambda
postgresql
s3
Try it out
git-codecommit.us-west-2.amazonaws.com
team23-fe.s3-website.us-east-2.amazonaws.com


Inspiration
The goal of SkyTruth to promote environmental justice was a driving factor in the team selecting this project
What it does
Cerulean helps individuals identify ships responsible for bilge dumps, and empowers users to take action to help hold those responsible accountable.
How I built it
The application is built using a variety of AWS services on the number one public cloud provider.
Challenges I ran into
How to store and query the data were sticking points early on in the process. There were also issues involved with narrowing down the problem scope into something that could be completed in the time of the hackathon.
Accomplishments that I'm proud of
We were able to create a solution that is a stepping stone to solving the larger problem.
What I learned
Before we started on this, we were not aware that bilge dumping was a problem. How to apply AWS technologies to work on a real word solution.
What's next for Table10
Integration of mapping and geocoding services .
Built With
amazon-dynamodb
amazon-lambda
amazon-web-services
api-gateway
google-maps
node.js
react
Try it out
skytruth-slicks.s3-us-west-2.amazonaws.com


Inspiration
I drew inspiration from myself as a beauty queen (Ghana’s Most Beautiful) who also owned a coconut farm and wanted to see how I could draw other young women like myself to get into the field
What it does
Miss Agriculture Ghana capitalizes on the interest of today’s young woman which is fashion, make up to draw them to the pageant and through that train them and boost their interest on the need to get into Agriculture to promote food security in the next coming years
How I built it
I used my influence as a past Queen of one of Ghana’s Most prestigious pageants to begin the whole Agendas
Challenges I ran into
My greatest challenge was getting access to land to support some of these young women who get interested in the project and want to do farming
Accomplishments that I'm proud of
I was able to Speak to the Traditional Ruler of Chief of Adeiso who gave the project a 10acre land to support the project with assist young women to have access to land for their project. Through the project we have also trained 20young women since it’s inception
What I learned
I can do more with perseverance, in a few years my project should get more young women taking Agriculture as a business
What's next for Miss Agriculture Ghana
Forming campus Networks to advocate for the interest of young ladies in Agric before they complete school


This project was bootstrapped with Create React App.
Available Scripts
In the project directory, you can run:
yarn start
Runs the app in the development mode.
Open http://localhost:3000 to view it in the browser.
The page will reload if you make edits.
You will also see any lint errors in the console.
yarn test
Launches the test runner in the interactive watch mode.
See the section about running tests for more information.
yarn build
Builds the app for production to the build folder.
It correctly bundles React in production mode and optimizes the build for the best performance.
The build is minified and the filenames include the hashes.
Your app is ready to be deployed!
See the section about deployment for more information.
yarn eject
Note: this is a one-way operation. Once you eject, you can’t go back!
If you aren’t satisfied with the build tool and configuration choices, you can eject at any time. This command will remove the single build dependency from your project.
Instead, it will copy all the configuration files and the transitive dependencies (Webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except eject will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.
You don’t have to ever use eject. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.
Learn More
You can learn more in the Create React App documentation.
To learn React, check out the React documentation.
Code Splitting
This section has moved here: https://facebook.github.io/create-react-app/docs/code-splitting
Analyzing the Bundle Size
This section has moved here: https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size
Making a Progressive Web App
This section has moved here: https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app
Advanced Configuration
This section has moved here: https://facebook.github.io/create-react-app/docs/advanced-configuration
Deployment
This section has moved here: https://facebook.github.io/create-react-app/docs/deployment
yarn build fails to minify
This section has moved here: https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify
Built With
css
html
javascript
reatjs
Try it out
GitHub Repo


Citrus Zone
Inspiration
On our way to a one-week capacity building training in the Central Region, we came across a heap of oranges for about a 100KM stretch of the road. On our return, these oranges were still there and had started going bad. On questioning residents in the area, they informed us they lacked access to ready market and are forced to sell the produce at cheaper prices than expected.
What it does
Our Company therefore seeks to become the "middle-men" that links these farmers to buyers and vice versa using the USSD model.
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for CITRUS ZONE
Built With
apis


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Organic feed supply
Built With
excel


pulsa paypal
Several customers complain that Best Buy grants reduced credit restricts on their cards, sometimes only only $300. You need to use a Most useful Get card in the store only, limiting your spending power. Applying for pointless credit cards may reduce your general pulsa paypal since it decreases your earnings to accessible credit ratio.
The concentration of any business is to create a profit. The most effective strategy for all corporations is to achieve regular profits while minimizing the risk. There are plenty of unforeseen problems that could affect the earnings of a company and actually influence the bankruptcy position of a company. Thus, any good company strategy needs powerful risk management.
The largest risk a small business looks is if they extend credit to reports and clients. Extending credit is an inescapable concern in the current organization industry. All businesses require access to credit and most must increase credit with their clients. However, if an consideration is compensated late or perhaps a company abruptly moves broke then a quick loss in revenue can have catastrophic consequences. For this reason organizations need to purchase credit reports to be able to evaluate all dangers connected with extending credit whether they are a local or worldwide business operation.
When businesses buy credit studies, they’re going for a essential part of ensuring they’re making a noise organization choice to extend credit. Nevertheless, what is the power behind buying credit reports?
If you’re providing credit to an area company then it is not that difficult to visit their center and talk with the owner. An area company may frequently provide you the data you will need by just asking about or examining the local paper. If you have a trouble with the companies consideration then it is possible to resolve the issue by way of a meeting.
The great print on the Most useful Get credit card software indicates that when you may not qualify because of their card, usually due to a poor credit score, they can automatically offer you yet another credit card, the annual charge Gold MasterCard. This means you must spend an annual charge to have a card with a top fascination rate and a reduced credit limit.
Try it out
gopulsa.co.id


How to Sell your Handmade Packaging & Boxes
Handmade crafts are trendy. Perhaps, this is because the need to save the environment has become more prominent recently; and a lot of people are doing their best to help save it. Buying handmade products such as handmade boxes is one simple way to partake in this cause. If you choose to buy recycled handmade Premium Boxes, you will be saving some trees. Conversely, you can also sell handmade boxes to encourage more people to help save the environment. You can use recycled boxes to make new unique and functional handmade carton boxes. In this way, you will be able to make good money while enhancing your creativity.
Currently, there are companies that buy and sell used carton boxes. However, most of these are for moving purposes. That is why the individuals who want to buy handmade carton boxes for gifts need to look for other sellers. If you start your handmade boxes business now, you can earn good money. You see, there are plenty of people who are in need of your services. You can sell small handmade boxes for soaps, jewelry, and candies. You can also make bigger ones for clothes, wines, and large gifts. Handmade carton boxes make great containers due to their homey look. They are also appreciated for their uniqueness and panache.
Anyway, you can start selling your handmade carton boxes in your neighborhood. You can set up a small stall in front of your house. If you use recycled cardboard, your handmade boxes must not be expensive. On the other hand, if you use acid-free and imported papers, you can raise your prices a little. Then again, recycled materials for your handmade boxes are still better because they are environment-friendly. Once you have earned a good reputation, you can expand your handmade carton boxes business. By that time, you are probably receiving plenty of orders already. Advertising through word of mouth is effective; and your neighbors might have told a lot of other people about your business.
You can make more boxes and sell them at fairs. You can also display your handmade carton boxes in shows and galleries. When you are in these places, do not forget your business cards. Hand them to customers, so they can call you for future orders. You can also give business cards to onlookers, in case they decide to order handmade boxes. Moreover, you can sell your handmade carton boxes online. Building a website is one of your best options. You may sell at sites like eBay or Etsy, but having your own site is still better since you will not need to pay fees. Furthermore, if you have your own website, your customers will be able to view your handmade boxes collection easily. They will also be able to send you a message for requests or suggestions.
Built With
html5
php
Try it out
premiumboxes.com


Phoenix
Inspiration
Operators are responsible for running the back-end batch processing and making sure that it completes. Sometimes they run overnight run on several instances. This is usually performed at night.
What it does
Allows an operator to conversationally query the status of the overnight run in Phoenix.
How I built it
Google Assistant Actions.
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for The Operator is dead. Long live the Operator!
Built With
actions
javascript
soap
sql


Inspiration
We were doing conversational AI for retail banking users and wanted to extend to business banking users too. We wanted to get access to real data, so this was a natural choice to build on top fusion business banking APIs
What it does
It lets business users to chat on different channels and get mundane tasks done like balance check, statement download, checking FX rates, transaction approvals, FAQs etc
How we built it
We integrated with CB APIs on the B2C side to our conversational AI platform to offer seamless experience for the end user
Challenges we ran into
Understanding few of the corporate banking scenarios and designing the login experience for the end user
Accomplishments that we're proud of
We are having good installed base and with FInastra's support we can take this to a wider segment as we can support both on-prem and cloud models
What we learned
Corporate banking entitlements
What's next for Conversational Business Banking
We can start supporting various use cases including trade contract approvals in the future and support handover with Relationship manager or even 3 way chat between bot, RM and client
Built With
conversational
corporate
natural-language-processing
Try it out
democb.active.ai


Inspiration - Payment Systems (e.g. Fusion GPP-SP) testing majorly constitutes validation payment attributes at each transaction/ payment level which are derived by code function or rules & profiles. The core idea of the ‘Payment Testing Platform‘ is to make logical use of the Payment Attributes/ GPP Logical fields across different Testing phases to make all Testing phases inline with GPP architecture.
(At the same time, it is scalable enough to be used for any Payment engine testing)
What it does?
o Automates all major Payment testing phases. o Implements unique Payment testing concept by using a library of Payment Input conditions and Validation Points.
Payment Input Conditions library - It contains a library of all Payment attributes/ logical fields to be used while creating a test case which would help; a. Define/ select the subset of the data setup defined in the System - solution delivered against the requirement, for which test case is being written. For example – Outgoing MT103 to SWIFT will use
Parameter Operator Value Source Equal To SWIFT MT Equal To 103 DR CCY Not Equal To EUR CR CCY Equal To EUR MOP IN EURO1, TARGT2 Instr Amount Less Than 10000
b. Define the payment attributes that would be passed in AI algorithm to generate a payment message (test data) automatically for each test case. Using the same intelligence, define the variations of payment attribute test data to be used across all test cases of a project.
Pre-functioned Validation Points library - It is a library of Validation points covering all Payment/ GPP functionalities. For example – Outgoing MT103 to SWIFT will use following Validation points. E.g. Validate Price Product derived by GPP for a payment message - PB Validate FX Charges derived by GPP for a payment message - 10 EUR Validate Main Dr Transaction code derived by GPP in Accounting leg for a payment message - AAA
The objective is to align Validation point for each GPP/ Payment core function and at the same time, to map it with the logical fields. E.g. In GPP/ Payments, we have identified 1000 core functionalities covering all payment functional areas. Accordingly, we will create/ maintain a library of 1000 Validation Points wherein 1 validation point would be mapped to each core function. At the same time, try to map each Validation point with the Payment attribute or Logical field.
Parallel and Comparison Testing - o It is used for Parallel & Comparison Testing wherein as a part of migration or production release, we do compare the behavior/ processing of each payment at payment attribute/ logical field between; o Old legacy system and GPP version being tested o GPP Classic and GPP SP version being tested o Production env and GPP SP version being tested.
We do this comparison for millions of payments wherein each payment would be compared with the value derived at multiple Payment attribute/ logical field level.
How we built it
We build it by using Java and AI technology.
Challenges we ran into
Challenges to build a library of Validation points to cover all GPP functionalities
AI algorithms to create a MT/ MX payment.
Accomplishments that we're proud of
It does simplify current Payment testing process.
What we learned
We learned that current complex process of Payment Testing can be simplified.
What's next for Payments Testing Platform
In the industry, huge efforts and cost is put by Customer/ Banks for Payment Testing to simplify and automate the Payment testing but still facing multiple challenges & issues. Due to this huge demand of Payment Testing in market, few companies are coming with a Product specially for Payment Testing. As it is a very early days for Payment Testing products hence we strongly believe it could be a Next FINTECH Product that could compete with the existing payment testing product.
It would help Customers/ Banks to save efforts, time and cost. Also, most importantly, it helps Banks to implement GlobalPayPlus or Go Live at much faster rate.
Built With
ai
jave


Reunification App for Pet Owners, Rescuers and Pet Spotters!
The Reunification App creates tools to enable the discovery, matching and ultimately reunification of lost pets and their owners
This solution helps all parties get the data to tools to make the best use of it and enable the reunification process The system can be deployed within AWS to process all the data needed to enable the reunification process. The mobile app can be published and downloaded by user to enable the discovery process.
In the future the team has some features we’d love to get to: Geo fencing: a pet maybe be seen by multiple people, multiple times. If we can correlate that information, it could give rescuers an idea of where the pet is roaming/moving to. Social network enablement: to help make the photo ingest easier for pet owners, have the ability to ingest photos from social platforms
Built With
amazon-web-services
lucidchart
Try it out
git-codecommit.us-west-2.amazonaws.com
GitHub Repo
tinyurl.com


Inspiration
Pending
What it does
Pending
How we built it
Route 53 Angular Single Page App, Hosted in S3, Leveraging Cloudfront for CDN API Gateway Lambda/Serverless Dynamo DB S3 for images Amazon SageMaker
Challenges we ran into
Leveraging existing AWS Services to perform image recognition of new pets against existing records
Accomplishments that we're proud of
Pending
What we learned
Pending
What's next for Best Friends: Saving Noses Is Fundamental
Pending
Built With
angular.js
dynamo
lambda
rekognition
sagemaker
serverless
Try it out
visual-search.notebook.ap-northeast-1.sagemaker.aws
docs.google.com
git-codecommit.us-west-2.amazonaws.com


Inspiration
Poultry production is capital intensive yet the profit margin is small. What are the ways to reduce cost on the farm.
What it does
Capacity building, connectivity
How I built it
Data from my poultry farm
Challenges I ran into
High cost of inputs Labor unavailable
Accomplishments that I'm proud of: produce chicken at 80% productivity
What I learned
What's next for NTAKRA abubro nkosua
Built With
api
iot


Inspiration. I was inspired to go into farming as a results of where I find my self, that is working in a deprived area as a midwife and witnessing series of accidental poisoning at the facility as a results of misuse of agrochemicals.
What it does. We produce vegetables and educate farmers on the precautions during application of chemicals
How I built it. I built it by Consulting farmers from the Community and also collaborated with the agric Extension officers.
Challenges I ran into. My challenge is that as I'm in the deprived area is difficult for those there to understand and follow the instructions.
Accomplishments that I'm proud of. I'm proud that I've been able to collaborate with some NGOs to come on board to educating the farmers.
What I learned. I learnt that wrong application of agrochemicals affects both the farmer and consumer
What's next for duolagro. To produce more vegetables across the Country.


tools to show you the license taht you have in your computer .
Built With
vbscript
Try it out
drive.google.com


Inspiration
Humans are losing their lives to Human –Wildlife Conflicts Poaching incidents are on the rise Communities not Incentivized to Report Incidents Slow Response from wildlife authorities Inaccuracy of Reported information ( Coordinates) No organized incident tracking Insufficient Network Coverage No Distributed Communications Platform
What it does
Anonymous reporting and fast response of wild life incidents
1) An Incident Is Reported Via GSM or Data Network or - OPEN
2) Incident Data Sent To Command Center
3) Command Center Accesses Threat Level - ACKNOWLEDGED
4) Command Center Issues Response and or Ticket to
5) Command Center – Relays Information to Field Troops
6) Issue Updated to CLOSED- After Appropriate Action is Taken
Built With
django
react
twilio


Inspiration: Why Only Youth? Every Pakistani must able leverage technology either educated or uneducated (From Cobbler to top Executives.
What it does: Focus on Digital skills w.r.t Gender, Age, Profession & Other factors to improve productivity and quality of life
How I built it: It is Framework and Program (2030 Vision to Trained 10 Million People in every Sector/Trade) for productivity and contribution to digital economy
Challenges I ran into: Team, Finance and Technology to leverage and support my Idea
Accomplishments that I'm proud: Quite Govt Job and Start my Entrepreneurial Career
What I learned: Nothing can achieve alone, Work Together and achieve more
What's next for Digital Skilled Pakistan: First Program Women Employability and Empowerment through Job Ready Digital Skills
Built With
digital-learning
lms
opensource


eFootball PES 2020 Hack Mod – Cheat eFootball PES 2020 myClub Coins and GP You can have fun with this new eFootball PES 2020 Hack Cheat right away and you will see that you will like it. In this guide we are going to tell you a few things about the game and after that we are going to jump into how this eFootball PES 2020 Cheat works and how it can help you in becoming a better player of the game.You should know that this new eFootball PES 2020 Hack is ready for you to use in order to gain all of the myClub Coins and GP you want. You will manage to have fun with this eFootball PES 2020 Cheat and you will notice the fact that all of the needed features will be added in a matter of seconds. This means that you wont have to wait for a long period of time until all of the features will be added and as you will see, you will certainly enjoy that pretty much. We also encourage you to take full advantage of this new eFootball PES 2020 myClub Coins Hack because of the fact that it works well on any device that you are using. You can use this new tool on any of your desired iOS and also Android that you own, without any problem. You will certainly like the fact that this one works well and you wont have any issues with it.
Features of the eFootball PES 2020 Hack Online Tool: – Get free unlimited myClub Coins and GP – Works on Android and iOS,Windows Devices. – No Download or Jailbreak necessary – No risk of being banned in the game – Use it anytime and anywhere – We update the hack almost daily
https://efootballpes2020hack.cheatonlinemod.com/
https://cheatgamesonline.com/efootball-pes-2020-hack/
eFootball PES 2020 hack, eFootball PES 2020 hack online, eFootball PES 2020 hack apk, eFootball PES 2020 mod online, how to hack eFootball PES 2020 without verification, how to hack eFootball PES 2020 no survey, eFootball PES 2020 cheats codes, eFootball PES 2020 cheats, eFootball PES 2020 Mod apk, eFootball PES 2020 hack myClub Coins and GP, eFootball PES 2020 unlimited myClub Coins and GP, eFootball PES 2020 hack android, eFootball PES 2020 cheat myClub Coins and GP, eFootball PES 2020 tricks, eFootball PES 2020 cheat unlimited myClub Coins and GP, eFootball PES 2020 free myClub Coins and GP, eFootball PES 2020 tips, eFootball PES 2020 apk mod, eFootball PES 2020 android hack, eFootball PES 2020 apk cheats, mod eFootball PES 2020, hack eFootball PES 2020, cheats eFootball PES 2020, eFootball PES 2020 triche, eFootball PES 2020 astuce, eFootball PES 2020 pirater, eFootball PES 2020 jeu triche, eFootball PES 2020 truc, eFootball PES 2020 triche android, eFootball PES 2020 tricher, eFootball PES 2020 outil de triche, eFootball PES 2020 gratuit myClub Coins and GP, eFootball PES 2020 illimite myClub Coins and GP, eFootball PES 2020 astuce android, eFootball PES 2020 tricher jeu, eFootball PES 2020 telecharger triche, eFootball PES 2020 code de triche, eFootball PES 2020 hacken, eFootball PES 2020 beschummeln, eFootball PES 2020 betrugen, eFootball PES 2020 betrugen myClub Coins and GP, eFootball PES 2020 unbegrenzt myClub Coins and GP, eFootball PES 2020 myClub Coins and GP frei, eFootball PES 2020 hacken myClub Coins and GP, eFootball PES 2020 myClub Coins and GP gratuito, eFootball PES 2020 mod myClub Coins and GP, eFootball PES 2020 trucchi, eFootball PES 2020 truffare, eFootball PES 2020 enganar, eFootball PES 2020 amaxa pros misthosi, eFootball PES 2020 chakaro, eFootball PES 2020 apati, eFootball PES 2020 dorean myClub Coins and GP, eFootball PES 2020 hakata, eFootball PES 2020 huijata, eFootball PES 2020 vapaa myClub Coins and GP, eFootball PES 2020 gratis myClub Coins and GP, eFootball PES 2020 hacka, eFootball PES 2020 jukse, eFootball PES 2020 hakke, eFootball PES 2020 hakiranje, eFootball PES 2020 varati, eFootball PES 2020 podvadet, eFootball PES 2020 kramp, eFootball PES 2020 plonk listkov, eFootball PES 2020 hile, eFootball PES 2020 ateşe atacaklar, eFootball PES 2020 osidit, eFootball PES 2020 csal, eFootball PES 2020 csapkod, eFootball PES 2020 curang, eFootball PES 2020 snyde, eFootball PES 2020 klove, eFootball PES 2020 האק, eFootball PES 2020 備忘, eFootball PES 2020 哈克, eFootball PES 2020 entrar, eFootball PES 2020 cortar
Built With
2020
and
cheat
coins
efootball
hack
mod
myclub
pes


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for dev4change_GRAACCapp_vaiNa.sort()


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Science specific goods
ES File Explorer is a great tool for managing files and programs. It comes with a multitude of additional features such as a tool for killing running applications, direct cloud drive storage (via Dropbox, Google Drive, or Skydrive), and an FTP client so you can use it both on your mobile device as well as your PC.
The program allows any Android user to easily manage all of their files, being able to access anything on their mobile device and then share it, if they so want to. Uploading photos, watching movies, and managing your 3G connection is now even easier.
When working with your files, you will have the classic options you are accustomed to on desktop computers, such as copy, paste, cut, create, delete, and rename. But, you can also send files to anybody via email.
You can also decompress ZIP or RAR files, access the contents of documents in many different file types, and even access the content on your computer via a WiFi network.
ES File Explorer is a very useful tool for those more advanced Android users, as it will place tons of possibilities at your fingertips.
Built With
es
Try it out
es-file-explorer.en.uptodown.com


Inspiration
Fintech is booming, we are in the era of new payment methods, cryptocurrencies, and banking latest softwares. But one under-represented institution is lacking which is the Micro-finance institutions. According to the world bank, 1.7 Billion people around the world are financially excluded from the system. Most of them are living in rural areas. The micro-finance institutions target these people to help them integrate in the financial system by giving them small credits to help them start their own projects.
What it does
Our solution Lendster is a 360 full package software designed specifically for Micro-Finance Insitutions (MFI), it helps the agent have a digital way of doing their daily operations and also the client to submit his application automatically online.
How we built it
We are using Spring boot technology for back-end developement and React Js for front-end.
Challenges we ran into
Main challenge was the lack of competitions in the field so we get inspired about the existing software and develop better solutions.
Accomplishments that we're proud of
Obviously winning the Tunis City Hack was the best accomplishement for the team!
What we learned
Learned a lot about the MFI world, their business requirements, their struggles and everything related to these insituttions
What's next for Lendster
Sign letter of intents with potential customers -> Raise an angel round -> finalize our MVP :)
Built With
finastra
jhipster
material
mysql
python
react
spring
Try it out
GitHub Repo
GitHub Repo


portable-manhunt
Inspired originally by the game mechanics of Pacman and the logic of the game manhunt, this game is a 4-player game that involves the hunters chasing prey until one team wins against the other.
Built With
java
Try it out
GitHub Repo


This is a wonderful project to automate the process of detecting and reporting oil contamination in bodies of water.
Project Presentation: https://drive.google.com/file/d/1QSw2Wxy6JFqGaW7JkKljpnoc6zzb1XMZ/view?usp=sharing
Project Documentation: https://github.com/mkohn/skytruth-hackathon
Built With
acm
amazon-dynamodb
amazon-sns
api-gateway
cloudfront
lambda
python
react
route53
s3
slack
terraform
Try it out
skytruthwatchdog.com


Inspiration
Helping save the environment
What it does
Helps to report spills
How I built it
With Collaborations
Challenges I ran into
Not enough time
Accomplishments that I'm proud of
Our team work and results to our problem pitched to us
What I learned
How to code fast
What's next for SPILLTRUTH
Hopes to have this integrated with SKYTRUTH
Built With
alexa
hdml
java
jquery
python
s3
serverles
Try it out
spilltruth-website.s3-website.us-east-2.amazonaws.com
GitHub Repo


Inspiration - We selected SkyTruth because of the potential to positively affect environmental change on a global scale
Built With
aurora
lambda
python


Inspiration
Nossa inspiração como time é de ajudar as pessoas distribuindo o que for arrecadado a partir da aplicação.
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for dev4change_vakinhasolidaria_caldodecana


spill-detect-api demo
uploaded PPT and code is available @https://git-codecommit.us-west-2.amazonaws.com/v1/repos/hack-team-15/
Goals: •Real-time satellite analysis of global shipping traffic to detect bilge dump events •Real-time alerts of bilge dump events to interested parties •Ultimately, reduce pollution events & environmental impactPrimary Challenge: •Today, manual analysis effort limits coverage & timely detection
Built With
amazon-web-services
opencv


We built a serverless satellite image ingestion pipeline that uses Skytruth's machine learning model to find illegal bilge dumps.
Built With
amazon-sns
lambda
python
s3


Mr. Akubi, a banana farmer in Akosombo made a huge lost this year after harvesting his banana because he could not sell all his produce and did not know to preserve the rest, meanwhile a weaned baby need this food to help him/her on her growth journey. our inspiration is to help avoid wastage and provide an all natural food supplement for babies.
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for NUTRIFOOD
Built With
javascript
laravel
php
python


Archery Club Triche – Astuce Archery Club Gemmes et Pieces Illimite Vous pouvez maintenant utiliser ce nouveau Archery Club Triche et, ce faisant, vous verrez que vous vous amuserez avec. Nous vous encourageons à lire le guide ici, mais si vous n’avez pas le temps ou si vous savez déjà tout sur le jeu, vous pouvez ignorer directement comment utiliser cet Archery Club Astuce, en faisant défiler vers le bas. Si vous souhaitez en savoir plus sur le jeu, continuez à lire ce guide.Vous devez savoir que ce nouveau Archery Club Triche Astuce va vous ajouter toutes les Gemmes et Pieces dont vous aurez besoin pour vous amuser avec. Vous réussirez à atteindre tous vos objectifs de jeu avec celui-ci et, à mesure que vous l’utiliserez, vous verrez que vous deviendrez meilleur que la plupart des joueurs. Nous devons vous dire que celui-ci est un générateur en ligne et que vous n’avez rien à télécharger de nous pour l’utiliser. Tout ce que vous avez à faire sera de vous concentrer sur le jeu et, ce faisant, vous verrez que votre gameplay va beaucoup s’améliorer. Nous vous encourageons également à utiliser celui-ci car il fonctionnera sur tous les appareils que vous possédez. Cela signifie que vous pouvez facilement l’utiliser sur n’importe lequel de vos iOS et sur votre Android que vous avez. Vous pouvez également profiter de ce nouveau Archery Club Astuce car il s’agit d’un outil protégé. Cela signifie que vous n’aurez aucun problème avec cela. La fonctionnalité Anti-Ban masquera toutes vos données personnelles et privées, ce qui signifie que vous ne pourrez vous concentrer que sur le jeu.
Caractéristiques de l’outil Archery Club Triche: – Obtenez gratuitement Gemmes et Pieces illimité – Fonctionne sur Android et iOS, les appareils Windows – Pas de téléchargement ou Jailbreak nécessaire – Aucun risque d’interdiction dans le jeu – Utilisez-le à tout moment et n’importe où – Nous mettons à jour le Triche presque quotidiennement
https://archeryclubtriche.astucejeuxgratuit.com/
https://jeuxtricheastuces.com/archery-club-triche/
Archery Club triche, Archery Club astuce, Archery Club pirater, Archery Club jeu triche, Archery Club truc, Archery Club triche et astuce, Archery Club triche android, Archery Club tricher, Archery Club outil de triche, Archery Club gratuit Gemmes et Pieces, Archery Club illimite Gemmes et Pieces, Archery Club astuce android, Archery Club tricher jeu, Archery Club telecharger triche, Archery Club code de triche, Archery Club triche france, Comment tricher Archery Club, Archery Club hack, Archery Club hack online, Archery Club hack apk, Archery Club mod online, how to hack Archery Club without verification, how to hack Archery Club no survey, Archery Club cheats codes, Archery Club cheats, Archery Club Mod apk, Archery Club hack Gemmes et Pieces, Archery Club unlimited Gemmes et Pieces, Archery Club hack android, Archery Club cheat Gemmes et Pieces, Archery Club tricks, Archery Club cheat unlimited Gemmes et Pieces, Archery Club free Gemmes et Pieces, Archery Club tips, Archery Club apk mod, Archery Club android hack, Archery Club apk cheats, mod Archery Club, hack Archery Club, cheats Archery Club, Archery Club hacken, Archery Club beschummeln, Archery Club betrugen, Archery Club betrugen Gemmes et Pieces, Archery Club unbegrenzt Gemmes et Pieces, Archery Club Gemmes et Pieces frei, Archery Club hacken Gemmes et Pieces, Archery Club Gemmes et Pieces gratuito, Archery Club mod Gemmes et Pieces, Archery Club trucchi, Archery Club truffare, Archery Club enganar, Archery Club amaxa pros misthosi, Archery Club chakaro, Archery Club apati, Archery Club dorean Gemmes et Pieces, Archery Club hakata, Archery Club huijata, Archery Club vapaa Gemmes et Pieces, Archery Club gratis Gemmes et Pieces, Archery Club hacka, Archery Club jukse, Archery Club hakke, Archery Club hakiranje, Archery Club varati, Archery Club podvadet, Archery Club kramp, Archery Club plonk listkov, Archery Club hile, Archery Club ateşe atacaklar, Archery Club osidit, Archery Club csal, Archery Club csapkod, Archery Club curang, Archery Club snyde, Archery Club klove, Archery Club האק, Archery Club 備忘, Archery Club 哈克, Archery Club entrar, Archery Club cortar
Built With
archery
astuce
club
et
gemmes
pieces
triche


Inspiration
I wanted to solve my problem of losing track of my saving goals.
What it does
Tracks your money saving goals
How I built it
With node.js and ejs and jQuery
Challenges I ran into
Users don't get a unique ID, so I had to associate money buckets with specific accounts. This isn't going to work if multiple users can access the same account.
Accomplishments that I'm proud of
Finishing the app. Getting it to work on mobile.
What I learned
Single page apps are great and fast and scalable as long as the code is separated to different files and errors are handled properly.
What's next for Money Buckets
Decoupling money buckets with accounts. Allowing multiple accounts to be associated with each money bucket.
Built With
ejs
jquery
node.js
Try it out
money-buckets-app.herokuapp.com


Inspiration
Qui Dat - Aquele que Doa.
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for dev4change_quidat_calangosdigitais


Why we do it
Inspiration
Pets lost in the normal course of things can be very difficult to reunite with their owners. In the case of a disaster, these issues are amplified. The number of pets at the same time in the same area compounded by the issues with communicating with the owners who are often not at their normal homes and phones makes this nearly impossible. Creating a way to report the found and search the ones already found will significantly reduce the number of uses of euthanasia.
What it does
This allows rescuers to photograph the rescued pets in the field and automatically capture the location and time of the sighting. This reduces data entry effort and errors.
How we built it
Cameron wore out 3 keyboards. We ate half of the snack pile.
Challenges we ran into
Our biggest challenges we in understanding the real needs, and building what was needed rather than things that already existed. Basically, we are our biggest problem.
Accomplishments that we're proud of
Native mobile application with meta-data automatically captured, and all data stored in the cloud durably. Coming up with many alternate names, none of which were acceptable to present today.
What we learned
How to read blob from S3 and pass to API as multi-part form data. How to call API's from Python. Eric is likely to be unemployed shortly.
What's next for CompassionateBestFriends
Adding a more specific location of the loss than ZIP+4 code. Much snarkiness and more poor quality humor.
Built With
amazon-web-services
ios
lambda
node.js
swift
Try it out
git-codecommit.us-west-2.amazonaws.com


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for KeyCatch Smart Door Stopper
Built With
adafruit
arduino
nfc
servo


LifePillar
A Repository for the Hackathon team at AWS Reinvent 2019.
Challenge Selected:
We opted for the Vibrant Challenge as the team felt connected to the cause of being able to minimize suicide cases all over the world and Vibrant's approach of providing a phone support.
The team narrowed down on the following guiding principles:
Standardize the safety plan intake process for crisis counselors
Capture and retain records in a central repository for all 170 centers
Anonymous personalized safety planning for callers when desired
Provide opt-in functionality for frequent callers to be identified and notified
Leverage IVR to connect callers and crisis counselors for “at-risk” plans
Try it out
GitHub Repo


responsive
Inspiration
to be more inclusive with friends
What it does
counts the number of high fives you give
How I built it
i built it using javascript to update html
Challenges I ran into
bugs in my javascript
Accomplishments that I'm proud of
it is functional
What I learned
how to increment in javascript
What's next for High Five With Friends
expand globally
Built With
css3
html5
javascript
jquery
Try it out
nicholasyu01.github.io


Our logo
Inspiration: As high schoolers ourselves, it gets harder and harder for us to continue managing all our classes, keeping track of due dates, and keeping track of finances that we spend day to day. The freedom that we obtain becomes a underlining stress for us be on top of everything which results in mental health problems for numerous high schoolers. This motivation yearned for us to create platform where students have the potential to be organized in terms of school work and be able to mange their spend-ages which would prepare them for the future.
What it does: It is an app that manages a virtual binder, a todo list, and financial status. We have a navigation system where we can add classes and in the classes the user can add material. In addition, the user can add due dates to their due list to keep them up to date with their assignments without being in constant worry. In the finance section, the user can calculate money as they can subtract or add from what the had spent on that day to keep track of spendings.
How I built it: The platform that we used for the app is Thunkable, a drag and drop programming platform where Thunkable is an app building website which can make a new app from scratch. Thunkable In addition, we used ATOM to build our website. ATOM is a text editor that we used to run our HTML code for our website and the website contains basic information regarding the app.
Challenges I ran into: At first, our plan was to code with React-Native which is a platform that I personally am fluent in, however due to technical difficulties that my computer ran into, we had to move to Plan B which was Swift and use XCode for the app. Nonetheless, my limited knowledge and the time limit given didn't allow me to full explore the platform and we had to resort to Plan C which was Thunkable.
Accomplishments that I'm proud of: To be honest, we are proud of using Thunkable in one try and completing the app hours before the assignment was due. Despite all the technical difficulties that we faced in the beginning half, we didn't give up and continued to find new and innovate solutions to overcome the obstacles. We were all beneficial to this project because we helped proofread and make sure the code and the design looks simple and well-coded. We also accomplished in creating the project idea within a short amount of time because as high schoolers, we understand the needs and wants in our stressful lives.
What I learned: We learned how to collaborate together as a team because if we did not have all 4 members, we would not have gotten as much done and would not have been as successful as we would have been if there were only 1 or 2 members. We also learned more about Thunkable and its usefulness in creating simple yet fulfilling apps.
What's next for My Finder: The next step for this project would be making it more accessible to users by including QR scanning for material and notifications from the app. In later versions, it could be made for more devices, and also include an added feature of a temporary folder, where it keeps material until the user can sort it into the respective class. After we add these updates, we plan to connect their due date to their calendar and connect it to their reminder feature, making them more organized. Moreover, there are many ways to make this program more user-friendly and widespread.
Built With
atom
css
html5
marvel
thunkable
Try it out
x.thunkable.com
GitHub Repo


Are you looking for JSC Result 2019? Then you have come to the right place. You can easily collect JSC / JDC results from our website. Read our post carefully to get your results.
Junior School Certificate or JSC for short, a public examination applicable to eighth grade students of Bangladesh. The equivalent certificate issued for the students of the madrasa is called the Junior Submission Certificate or JDC. The junior school certificates for those who pass the test are given and they are given admission in ninth grade. In addition, junior scholarships will be awarded based on the results of this exam. For the first time in Bangladesh, Junior School Certificate Examination and Junior Entrance Certificate Examination were held for the students of the common school Omadras.
When will JSC result 2019? The JSC result is usually published on the 5th or 5th of December. However, since the 5th national election this year, the date of release of the JSC result may have changed slightly. The result will be published on December 24, 2018.
Once the result is published, you can easily find your result from our website. Before knowing the result, let us know some information about JSC Exam 2019.
How to know JSC Result 2019: You can find JSC Result in various ways. Below are some of the most popular ways.
From their respective schools By sending an SMS on mobile Visit the official website online
Learn about JSC Result 25 from your school You can collect the results from your own educational institution. Going to your own organization, collecting results is relatively difficult. Because, here you have to know the results by going to your body. After publishing the results, educational institutions collect all the results of their organization. Then print it and hang it on the school notice board.
Students have to find their own roll from the list. It's a lot of hassle and labor. The two methods are easier than the groom are discussed below. Now we will talk about how to know JSC Result through Mobile SMS. JSC Examination Result 2019![] .
Credit- Publishing Website.
Try it out
i-techbd.com


Inspiration
For Consumers: The rising challenge of trustworthiness in the media today. For Business: What is the public opinion of a company, and how does that reflect in the company valuation.
Challenges I ran into
Deciding which information was most useful from the APIs, and presenting this is a productive graph format.
The primary initial challenge was finding a News API that provides whole article content, as most only provide a snippet (especially for Developer accounts) - this content was necessary for the sentiment analysis. Eventually, we settled on using the Guardian API for analysing articles, as they provide full article text.
What's next for NewsWorthy
Eventual deployment to business, in order to help them identify the moments the public's opinion changed, and therefore further improve their company.
As an enterprise application, companies are able to monitor how their appearance in the media and their public opinion affects their value. This means that companies can maximise their value, and conversely are incentivised to act responsibly as there is direct accountability for the articles written about them.


Running a full test suite takes hours and hours...
We can either reduce this time, while preserving coverage, or developers will grow frustrate or, worse, find creative ways to bypass the tests (e.g. run just the subset they think might be impacted).
Zordon will analyze the tests and find out which tests are covering material already validated by other tests. With a large battery of tests, we expect a 30-40% reduction in the time needed to achieve the same test coverage!
Built With
java
python


[image depicting a wise tabby looking thoughtfully at a receipt]
In a Nutshell
TabWise aims to help you split the bill - even faster and simpler than ever before! What we offer that's different from competitors is an end-to-end solution requiring no maths, no user accounts, and promising instant and free payments via card. Interested? Read on to find out more...
How it Works
Imagine you're at a restaurant with a large group of people. One ordered a Carbonara and a glass of Sauvignon Blanc. Another ordered a Flat Iron Steak and a Malbec. Someone else ordered a basket of Chicken Wings and split it with three other people. You shared a bottle of Prosecco with two other people. The list goes on...
How do you split it!?
Here are your options:
A. Just split it equally amongst yourselves.
B. Manually calculate everything and add it into SplitWise or some expenses sharing app.
A is not always going to be fair, and B is tedious.
Enter TabWise, an end-to-end solution to this age-old problem!
With 3 easy steps you can get on with your life and do more important things!
Step 1. Scan it!
One person, let's say you, has paid the bill. Simply navigate to our website, and scan the receipt using your phone. No cropping needed, no messing about - just scan it!
Step 2. Say it!
We'll give you a simple, readable and sayable link. Get your friends to visit the link by simply saying it out loud!
Step 3. Split it!
On the website, everyone selects the receipt items that they were involved in. Once we verify that everything tallies, everyone gets a unique, customised link to pay you exactly what they owe you!
Ideas for Improvements
We are not currently actively developing this, but here are some of our ideas to take this idea further.
Enable more granular splitting (e.g. a bottle of wine being split into 1/3 and 2/3 instead of half-half)
Integrate with and support other banks
Allow for persistent accounts (while continuing to support users who don't have accounts)
Universal payment service that is not dependent on individual banks
Built With
an-orange
bananas
cmder
computer
concentrated-power-of-will
curl
dayjs
devpost
dialup
digital-solution
ecmascript
eslint
express.js
fancy-socks
gatsby
insomnia
intel-inside
microwave-internet-exploder
node.js
now
pizza
protein-bars
surge
truelayer
unicode
vodafone-wifi
whiteboard
whitespace
wsl
Try it out
tabwise.microwavethis.com


Arkanum is a 3D first person action-adventure game in which you control a thief with magical powers of attraction and repulsion.
It's set in a fantasy setting including magicians, goblins, fireballs and a mysterious magic castle. It has a cartoonish graphic style, with very vivid and saturated colors.
The game runs on a custom game engine coded from scratch in C++ using DirectX11 graphics API, and was created by 9 students for our final project of the Master in Creation of Video games, at University Pompeu Fabra, Barcelona, Spain (2018-2019).
Watch the trailer here. Watch the full gameplay here.
Social Networks
Itch.io
Twitter
YouTube
Contact: katanaproductionsupf (at) gmail.com
Credits
Programmers:
Josep Llistosella
Gerard Belenguer
Victor Portabella
Jordi Arús
Dani Garcia
Artists:
Pedro Borrelli
Sergio Jimenez
Clàudia Raventós
Antón Miranda
Music:
Inés Mirás
Edu Collin
Voice Acting:
Sean Kurz as Narrator
Ariadna Rodríguez as Thief
Daniel Lanzas as Spirit
Built With
c
c++
cal3d
detour&recast
directx
hlsl
lua
nvidia-physx
slb
Try it out
katana-productions.itch.io


Our Mission Statement
Helping Hand
The Story
Helping Hand is a full-stack web solution that enables seamless donations to homeless people without smartphones/laptops. Powered by a Node/Express + PostgreSQL backend and a React frontend, Helping Hand utilizes a physical QR code printout that is distributed to the homeless. This QR code is their wallet, and can collect donations simply by having a passerby (a Giver) scan their QR code. Once the homeless person (which we call Receivers) has enough funds, they are able to visit a participating Helping Hands merchant (for food, clothes, etc.) and redeem their donation funds. We are particularly proud of the inclusivity and accessibility that our app provides.
Key Features:
No installation necessary: We use a progressive web-app to avoid the headache of native app installation
Studies show that PWA's are far better for engaging audiences
Automatic and immediate unique QR code generation
Instant transaction and donation updates via PostgreSQL
Elegant React client
Loads of error handling
Async/Await usage
Next Steps:
Integrating Credit Card API and/or PayPal
Implementing QR code recovery system
Links
GitHub
Live Demo
Built With
amazon-web-services
elephant
express.js
git
github
mvc
node.js
postgresql
react
sql
terminal
Try it out
www.kevinchoi.dev


Project progress suffers when Jira is not up to date, blockers surface at the last moment and email notifications are missed in all the noise. Important issue context get lost in chat threads. There is too much asking around for updates.
Features
Automated Reports Jira report builder for periodic automated report graphs delivered directly into Slack
Scheduled Smart Notifications Jira smart reminder builder for complex aggregation rules-based notifications
Paginated Views Fetch a paginated list of Jira issues on-demand with custom filters
Guest access Allow secure authorization of approved Slack users to file and track Jira issues as Guests
Field Discovery Automatic required field discovery during issue creation, issue transition
Custom Field Recognition Automatic custom field recognition and update assistance
Noise-free notifications Group your notifications before delivery for less clutter
Jira Standups Troopr Slack Standup automation runs async standup meetings directly in Slack
Issue Unfurl Auto unfurl issues when mentioned in a chat
✔ OAuth 2.0 3LO authentication for best in class security
Built With
javascript
node.js
react
Try it out
www.jiraslackintegration.com


Inspiration
I was inspired to make this project as during the peak of winter, the last thing I want to do is to go out to check my mailbox and be faced with an empty one.
What it does
When the mailbox is opened, the mailbox sends a signal wirelessly to the server-side unit, which sounds a buzzer, displays "You have snail-mail" on an LCD screen, and sends an email notification to an email of your choice.
How I built it
I built this using two XBee radios, programmed using an XBIB-U-DEV module. Each XBee module was connected to an Arduino Uno, and programmed to interact with different electronic components. A python script was used to handle sending the email out to notify the user upon their snail-mail delivery
Challenges I ran into
It was my first time ever using software-defined radios (SDR), and the learning curve was steep as there was not a lot of documentation available for programming the XBee radios, especially as they were legacy 900 MHz models. However, after some research, I was able to learn the basics of the ZigBee radio protocol and was able to successfully implement my XBee radios with my Arduinos to achieve long-range wireless communication between two Arduino Unos.
Accomplishments that I'm proud of
Making a functional project using software-defined radios and Arduinos.
What I learned
How to use XBee radio modules, basics of SDR, python scripting for Arduino interfacing
What's next for SnailMailer
I want to put everything onto a PCB and actually implement it using a PID sensor for the consumer market.
Built With
arduino
python
sdr
wireless
xbee
Try it out
GitHub Repo


The home page. This is where the user chooses whether they are a patient or a doctor.
Inspiration
In America, the drug abuse issue is only growing in severity. The Pill Pal looks to help drug consumers manage and consume their drugs safely and in appropriate amounts. A group member's aunt is a nurse and deals with patients all the time. A common issue that arises with patients living at home is when patients need to get pills and don't know which ones to take. Instead of setting up an appointment which can take multiple business days to work, patients can quickly interact with doctors through their own pill dispensers at home using Pill Pal's Bluetooth-compatible app.
What it does
When it is time for a patient to take their pills, they can quickly reach out to their doctor for permission to take the pill. Using the Pill Pal app, the patient can send a pill request to the doctor's phone Pill Pal app via a Bluetooth connection on the patient's Pill Pal app. The app allows the doctor to decide whether the patient should or shouldn't take the specific requested medications. After approving of the pill request, the dispenser will automatically shuffle to the correct pill, only allowing access to the doctor-approved pill. This will be followed by a label that displays the name of the patient and the pill type.
How we built it
The creation of Pill Pal was comprised of three main parts. The first part is the creation of the Pill Pal app itself. The app was created through Swift
Hardware: First we wired all the components which included the servo motor, LCD, LED indicator , and the Bluetooth module. After wiring was all correct and the circuit was complete the next step was to program the hardware. Initially we wanted to make sure each component can work independently before putting it all together, so we made sure that was working. Once we knew that everything worked by itself we programmed the Bluetooth module to wait for a connection and once the connection was received we began the process of dispensing a pill.
The final part was the construction of the actual dispenser itself. As a prototype, it was constructed our of primarily cardboard and hot glue. Seven mini-containers were created as well as the spinning-table disk that was attached to a motor. This motor allows for the entire contraption to spin to the correct pill, while a large cover with a small opening was placed on top to prevent access to the unapproved pills.
Challenges we ran into
The biggest problem that occurred during the project was related to the arduino. Midway into the project, the entire circuit began to overheat and eventually short circuited. This led us to restart the circuit on a separate arduino using a servo motor instead. A really strange problem occurred while developing the app through Swift. For some reason, the buttons on the app were unresponsive. We had never seen this seemingly basic issue cause the app to malfunction in this way before. This ended up being a huge obstacle as the entire app failed to operate correctly for a while.
Accomplishments that we're proud of
The aspects of the project that we were most proud of are the ones regarding the challenges we had to overcome. A big obstacle was tackling the Bluetooth connection from the arduino to the phone app. We also spent a lot of time accurately measuring the values required for the servo motor to turn the dispenser to the precise angle. We managed to incorporate the ultrasonic sensor and relay that information back to the app. In terms of coding the app, we already mentioned how we ran into a bizarre coding challenge when the buttons of the app didn't seem to work. After playing around with the code, we managed to return it to a functioning state, which was a significant accomplishment because of how long it took. Also, we had to construct the actual dispenser, measuring the side lengths to ensure even proportions for the servo motor to balance the contraption.
What's next for Pill Pal
In the future, we would like to incorporate radio-frequency identification (RFID) to allow doctors to identify their patients through unique RFID tags. This can help doctors determine exactly which pills can go to which patients. Another identification method can be using fingerprint sensors. With medicine, security is extremely important to ensure that patients receive the correct medicine with the right dosage. Another feature that can be implemented is a way for the pill to actually be dispensed. This way, patients with Alzheimer's don't have to endure the inconvenience of actually reaching in and taking the pill. Also, a 360 degree motor would be more useful than a servo motor, which we had to use to overcome the short circuit mentioned in the challenges section. One last feature we could add is a way for the dispenser to send more than one pill and dispense the exact amount the patient needs.
Built With
arduino
firebase
swift
Try it out
GitHub Repo


Inspiration
We wanted to create a hardware based hack that focused on machine learning.
What it does
It's an automated bin that sorts recyclables into their respective containers.
How I built it
We created the machine using cardboard boxes that were leftover after lunch. We used arduino to control motors and laptop for machine learning part.
Challenges I ran into
Creating the base was pretty challenging, but the hardest task was getting PyTorch to behave correctly.
Accomplishments that I'm proud of
We created an interactive machine and managed to do it on time!
What's next for Smart Trash
It would be great to create public bins that work like this and make it feel like a more polished product.
Built With
arduino
machine-learning
python
pytorch


Home page
Inspiration
Created with inspiration from family's charity, where we try to reach out to those who are isolated and forgotten from the society. We aim to bring up the unfortunate ones, to bring them up together to the society.
What it does
A platform that links the society together and embraces the feeling of being one with the community. It allows people to find charities, participate in their events, and even donate money! It makes the process of donating money completely transparent since the information about who donated how much is open to public. Our platform also enables people to take initiation and create their own charity-related events too!
How we built it
First we discussed what the database schema should look like so that both the front end and the backend people have an idea of the entities and relationships involved in this project and then created it (mysql). Then we discussed the file directory structure and decided one that suits everyone the most while also being scalable.
Challenges we ran into
Most APIs we wanted to use had some sort of fee associated with its use.
Accomplishments that we're proud of
Not only did we make a project that is pure good to the community, we also overcame the common issues that would arise such as lack of transparency
What we learned
We learnt that while working we need to listen more to each other. We learnt that moral and ethics are important, that's why we made a project on charity.
What's next for Charity Link
We aim to one day deploy it online and aim to get users to donate to charities. We aim to raise awareness of the current world situation. We aim to create a better world.
Built With
bootstrap
css
git
github
mysql
php5
Try it out
GitHub Repo


ShallowMind Logo
We are a group of Engineers currently on Master's courses with specialisms in Machine Learning/Artificial Intelligence and have decided to apply what we are learning to help the community make decisions about unclassified data by automating the processing of this.
A general NLP system that trains and adapts using a large dynamic and publically available dataset, and then uses the classifier we have created to apply the sentiments that have been statistically calculated on keywords, phrases and quotes to summarise the sentiment behind the statement - e.g. 1-5 stars for Amazon reviews or investment predictions for Bloomberg articles. The main objective of the system is to provide a flexible and dynamic proof-of-concept of applied sentiment analysis that essentially operates on a spectrum of "positive" to "negative".
We created a front end in Java and a UI in JavaFX, which then processes small amounts of logic and data before calling the NLP system developed in python using substantial libraries and custom classifiers.
One problem we faced was that ML takes substantial time to train when running on local machines and without a hosted cloud architecture and running this code based on a 50%+ probability takes about 2-3 hours.
We are proud that we continued to work well as a team and made new friends from other universities and make links with people who also have a passion for AI and ML as we do.
Built With
java
nltk
python


Kumar Abhishek, a core banking consultant living and working in Singapore at the time, marvelled the level of efficiency at which Singapore as a city would operate. Everything was always on time, largely because digital payments had been embraced for their speed, safety, and ease of use. When he got asked why is it in India that people get candies instead of balance cash, he started to realize that there is a need for a better way to make payment in India.
With a vision to establish the first of such efficiencies in India, Kumar found a way to secure and authenticate payments using nothing more than a wave of sound emitted from a device with the right credentials.
After finishing his spell with Infosys in Singapore and returning to Bangalore, Kumar, along with co-founder Vivek Kumar Singh, established a company in 2013. He further developed sound-based technology and tested its application to suit India’s large population. And they found a way to do it. Thus, ToneTag was born, one of India’s most promising new companies which aims to revolutionize payments.
ToneTag’s technology is basically limitless in the digital space – it has no OS-based compatibility restrictions or device communication issues and it can be used to make quick and secure payments to any merchant terminals (like PoS device, hand-held devices, EDC machines, etc.) or receiver. The payments can be done offline. Any merchant terminal can be upgraded with an SDK (Software Development Kit) to receive and authenticate these payments in a matter of seconds.
A large portion of India’s rural population doesn’t have access to regular internet or smartphones, making ToneTag’s powerful new technology the quickest and most easily deployable digital payments model in India. ToneTag started out the journey with enabling payments and is now spreading to multiple domains with global deployments in countries like Dubai, South East Asia, and Latin America. Currently, the following services are provided: • Big data analytics based real-time loyalty. • In-Store Payments. • Omni-Channel Customer Engagement. • Invisible payments. • Brand and service discovery.
ToneTag is the first company in the world to enable contactless payment acceptance on EDC machine using Sound. Since sound-based technology is completely hardware independent, it’s accessible to anyone. Companies like MasterCard are helping ToneTag grow globally by introducing the technology to their partner banks. In India, ToneTag has partnered with: • Yes Pay • ICICI Pockets • IMS • Freecharge • Airtel Money • Shoppers Stop • Bank of Baroda M-Connect • Infosys Finacle
The ToneTag team is dedicated to building a top-notch proximity technology. The team consists of technical minds with a dedicated research in audio technology and extensive experience in building financial products. ToneTag is mentored and guided by industry veterans who are at leadership roles in the Fintech space. The team currently stands strong at 90 which started out with just 2 members.
Built With
fintech
soundwave
technology


gameplay
Inspiration
We wanted to focus on inclusivity, and we believe that everyone deserves a form of entertainment. Everyone can game!
What it does
A fast-paced reaction game that is controlled by your voice.
How we built it
We used the Unity engine.
Challenges we ran into
Working with Google Cloud Speech and Github.
Accomplishments that we're proud of
Getting the speech recognition to work accurately.
What we learned
C#, Unity, friendships, communication, trust.
What's next for VoiceBox (Gaming with your voice)
Generalizing voice control for different games or consoles.
Built With
c#
unity
Try it out
GitHub Repo


Inspired by the rate at which farmers are cheated in the process of selling their cashew and the fact that they do not get the true value of their products.
What it does
How we built it
Challenges we ran into
Accomplishments that we are proud of
What we learnt
What's next for CASHGENTS
To be in full operation


ChatrMaps
Inspiration
The need to increase inclusivity for people at events inspired as to build ChatrMaps.
What it does
Upon launching, users see a map interface that shows any event chat rooms nearby. Users can then view more event information such as the event description, event time, event duration, and active event attendees. Users can then join the chat anonymously and view a list of other active users.
How I built it
Using React, Google Maps API, Material-UI framework, Git, and Scaledrone.
Challenges I ran into
Debugging and using unfamiliar frameworks/libraries/API.
Accomplishments that I'm proud of
Fixing bugs and implementing a user friendly interface.
What I learned
New technologies such as React and Scaledrone.
What's next for ChatrMaps
Improvements include adding event/chat creation and adding user profiles (optional anonymity)
Pitch
Have you ever been you an event and wanted to talk to others, but have been skeptical to approach a stranger? ChatrMaps aims to solve this by providing a risk free, anonymous method of communication and expression using exclusive location and event based chat rooms that anyone can join
Built With
firebase
git
github
google-maps
javascript
material-ui
react
scaledrone
Try it out
GitHub Repo


The home page of Counsel Connect.
Inspiration
Mental health includes our emotional, psychological, and social well-being. It affects how we think, feel, and act. Not enough safe conversation is conducted around mental health, despite 59.6% of college students feeling at some point each year like things are hopeless (2016 Canadian National College Health Assessment). As UBC students, we recognize the importance of mental health, and strive to create an uplifting community where these harder conversations are accepted, unshamed, and encouraged.
What it does
Many students actively seek guidance but mental health resources on campus are limited. Counsel Connect connects students that want to share and are willing to listen with other students in similar positions. This creates a safe community where students can share problems and advice. Each week, students can sign up to be matched with another student, who they then reach out to and chat with. This allows students to gain different perspectives and advice on their problems. At the same time, they help other students by providing a listening ear.
How I built it
We downloaded Visual Studio Code and imported a basic HTML webpage template. From there, team members worked on different parts of the platform, such as user interface, graphical design and CSS. Github was used to manage workflow and push and pull code.
Challenges I ran into
Initially, the goal was to create a mental health platform with multiple features and services, but the team quickly realized that given the time constraints and lack of previous experience, the website functionality had to be narrowed. Despite this, Counsel Connect retains the original intention by addressing and challenging the issues seen in conversations around mental health.
Accomplishments that I'm proud of
Having a team where none of the members have the previous web developing experience, we are amazed that we were able to create a functional website using HTML. We are also proud that through this website, we were able to challenge a topic that we are passionate about addressing.
What I learned
Skills like cloning a repository and using the terminal. We ran into many merge issues when pushing and pulling from github as some of our team members were very new to this. We were also very excited when we got very comfortable with using the command terminal to push and pull. Additionally coding in HTML, CSS and Javascript was done for the first time today by team members. Having less than 12 hours to learn all these skills and combine them to create a product is a milestone for us.
What's next for Counsel Connect
Counsel Connect can be adapted to include increased services, support, and user experience. A review system of matches can increase trust and security within platform users. Moving forward, AI technology can be incorporated to provide students with tailored advice on their situations. Due to time constraints, we were unable to implement the backend matching algorithm, and this should be done. To maintain diversity and inclusivity, it would be a random matching algorithm, within the constraints of the tailored specifications.
Built With
css
git
github
html
javascript
sketch
Try it out
GitHub Repo


singin
Inspiration
I am a big fan of 2048 game board, im playing that game all the free time. So that is the reason why i choose it is my topic to create in this contest.
What it does
It's a game, board game. You need to merge the same number to make a bigger number. The bigger number, the higher score you will get.
How I built it
I've used Reactjs to create the game, Blockstack for authentication and Gaia storage to store best score for each user.
Challenges I ran into
Create game in reactjs is so painful if comparison with other famous game engine like Unity or Cocos Creator. Furthermore, I've never used blockstack and gaia before.
Accomplishments that I'm proud of
I've solved all above problems. My game works, and fun.
What I learned
Blockstack is a convenience way to authentication integration. Making game with reactjs is also good experience.
What's next for 2048
Im going to build and publish it on more decentralize platform.
Built With
blockstack
gaia
react
Try it out
2048.dotgrid.pro


Happy Face
Inspiration
We like to draw
What it does
You draw on the canvas
How I built it
Android Studio
Challenges I ran into
Sometimes I couldn't draw
Accomplishments that I'm proud of
You can draw
What I learned
How to draw
What's next for Drawing Game
More drawings
Built With
android
java
Try it out
GitHub Repo


For many, searching the internet for the perfect doctor can be frustrating and time-wasting as it can take a various number of clicks on google to find the right one for you. Therefore, we designed Doctor Schmoctor, an app designed to help people find the right doctor for them at the fingertips in just seconds. The app categorizes doctors into categories such as dentists, orthodontists, ophthalmologists, and pediatricians. From there, the user clicks their needed doctor and a list of the best doctors in the area are presented to them. The user can scroll through the names of many renowned doctors without having to open up an unbearable amount of tabs. After the user clicks on the doctor that they wish to look in to, they will be presented with their name, gender, speciality, level of education, office address, office phone number, and a photo of the doctor themselves. In addition, they will be given answers to general questions that are looked into by those doctors themselves. We built the app using a platform called XCode. The language that we used was Swift. A challenge we ran into was linking one view controller to another. However, we were able to do it. It was a learning accomplishment for us. Another challenge we ran into was time. If we had more time, we believe that we would've been able to finish. Some future improvements for Doctor Schmoctor would be to have the user be able to enter in their location and display very results based on the location. In addition, we would include a chat box that would connect the user with the reception desk at the doctor's office, which would allow the user to book appointments online and ask basic questions regarding insurance, fees, and services offered at the doctor's office. Furthermore, adding onto the chatbox, we would have an appointment booking calendar that would allow the user to book appointments with the doctor based on the urgency of the appointment.
Built With
swift
xcode


Inspiration
Ter a possibilidade de fazer parte de uma causa nobre, e através da tecnologia espalhar o bem.
What it does
Já imaginou você na fila de um restaurante e enquanto aguarda o seu pedido, poder tirar uma foto com seu personagem favorito como se ele estivesse ao seu lado, e ainda ajudar outras pessoas fazendo uma doação?
Nosso aplicativo oferece a possibilidade das pessoas escolherem seu personagem favorito para uma foto interativa, ainda contribuir para um mundo melhor.
Nossos módulos podem ser facilmente implantados em um Totem, que estejam em local de grande movimentação e que demandem tempo de espera.
How I built it
Construimos o aplicativo utilizando Unity3D e C# como linguagem de programação, fazendo uma especie de game para deixar a doação mais simples, intuitiva, divertida e sem contar com a premiação que o Game trará.
Challenges I ran into
Utilizar e construir os personagens em 3D e a junção utilizando Realidade Aumentada.
Accomplishments that I'm proud of
Construção de um projeto social utilizando novas tecnologias, aumentando assim o aprendizado e a satisfação em ajudar uma instituição que cuida de Crianças.
What I learned
Aprendemos um pouco a utilizar a Tecnologia voltada para Realidade aumentada e desenvolvimento de jogos, a pensa fora da caixa, em um cenário totalmente diferente do que estamos acostumados no dia a dia.
What's next for dev4change_carequinhasar_devolvs
Iremos fazer novos personagens, contos de historias e inclusão de modelos para empresas dentro do aplicativo.
Built With
ar
augmented-reality
c#
unity
vulforia


Inspiration
Stressfulness with homework, exams and general life in our first year at University.
What it does
An app where users can take a break from their hectic lives and calm down. Mindfulness is an app which makes the user set apart 10 minutes every day for them to calm down and breathe, with an inspiring quote to help.
How we built it
With what learned in the gut and python workshops, we tried to build the application Using python flask to build webapps.
Challenges we ran into
Writing the code in a new language, Not having the technical know-how for building applications, especially in less that 12 hours.
Accomplishments that we're proud of
Thinking of an idea for an app which could help a lot of people, including ourselves. Learning basic programming skills.
What we learned
Basic python scripts. Using gitkraken and GitHub.
What's next for Mindfulness
Fully finishing the app, if not for a competition, to help ourselves in the sure to be stressful years to come.
Built With
flask
git
python


ColorBlUX
Inspiration
Our inspiration for this idea is our family members' daily struggle with color-blindness.
What it does
It provides an Upload Photo or Project button for users to upload their photos or works to the web app. Then when they click "Check", users will be able to see how the photos or projects would look like under various color layers, which stimulates what color-blind people see.
How we built it
We used Django to build our web app from scratch, with the help of CBviz script (https://github.com/wflynny/cbviz).
Challenges we ran into
It's absolutely our first time to use Django, so we encountered a lot of problems during the process of setting up and building the web app from scratch. Also, our first UI draft was too complicated and if it weren't for the UI/UX mentor, we probably would have never gotten even the most basic functionality done.
Accomplishments that I'm proud of
Well we started from having absolute zero knowledge in Django to having a quite decent project in the end!
What we learned
Using Django to build a web app, how to make appropriate UI mock up based on time restraints and user requirements.
What's next for ColorBlUX
We would love to add even more features to the ColorBlUX workspace, such as editing photos/projects, zooming, sharing, etc.
Built With
cbviz
django
Try it out
GitHub Repo


This is what the translated language selection menu looks like
Inspiration
While brainstorming around the theme of "diversity, inclusivity, and accessibility," we were inspired by our personal experience as foreigners with basic language skills trying to make friends in a new country. We then confirmed that the language barrier affects the self confidence of foreigners which in turn deters them from interacting with the locals. Sources
What it does
Our application plays your favorite song while scrolling the English lyrics and the translated lyrics (of your choice) side by side. This allows the user mind to be engaged in something they already enjoy (listening to music!) and engage the English thinking side and chosen language thinking side of their brain. The user is able to pay attention to the correct pronunciation of the words or the stylistic choices made by music genre.
How I built it
Client side: HTML, CSS, JS; Technologies used: git, github, chrome dev tools
Challenges I ran into
Collaboration over github and smooth merges. API setup time.
Accomplishments that I'm proud of
Created an application through collaboration with 5 developers. Applied knowledge gained within the last 12 weeks of our first semester in the FSWD program at BCIT.
What I learned
Mostly practiced git and github collaboration, worked out the kinks the process.
What's next for Lyrically - Learn English your way
After the concept demo, we plan to integrate Spotify API and/or Genius API to pull songs and the lyrics based on user's search or playlist. This will depend on which one will prove to be more reliable during testing. We plan to deploy to Heroku with Docker container as we recently learned the process in class.
Built With
css3
git
github
html5
javascript
Try it out
GitHub Repo


Inspiration
We all strive to be a better person. We all know the world will be a better place if we understand the diversity in each other and stop hating. Unfortunately, it’s easier said than done. We’re just too busy to take care of others. We have priorities; we work, we have school. What’s worse, busy hectic lifestyles make us forget about ourselves sometimes.
Therefore, we came out with this app, “One a Day”. Our app will ask you to do one simple selfless act or self-care practice every day. You’ll learn it only takes a couple of minutes or sometimes a second to brighten up someone’s day.
Once you complete the task, we won’t ask you anything more for a day! Just check off the check box and feel awesome about yourself for doing something good today. You can also check your progress bar under a profile page to see how many good deeds you’ve been performing.
We wish our app would lead people to self-love. We wish our app to make people feel good about themselves and spread love in the community.
What it does
Our web-mobile application will allow the users to receive a set of short, daily tasks to complete each day. Each task consists of prompts for the users to do something nice. It is a fun, motivating way to treat others. After completing a task, depending on the difficulty of the action, the users will gain points that will add to their progress bar. Once the bar has reached its full capacity, the users will level up.
How I built it
We built this application by using javacript, html, css, firebase, and jquery. The javascript carried out our main functions, such as the point incrementing system. The html acted as the front-end template for our application. The css was used to enhance the visual components. The jquery was used to carry out the UX interactions between the users. The firebase was utilised to authenticate the users, and pull from our database.
Challenges I ran into
The challenges that our team faced were found in the initial planning phases of our project. We had multiple ideas that we wanted to construct, but our time and skill restraints forced us to dismiss most of them. Each potential pitches were piled into the junk pile. Eventually, as we discussed about some of the problems that we felt in our current society, we realized how much of our growth and wellbeing is reliant on the kindness we receive. So, after some negotiations and design iterations, we were able to overcome our challenge of indecisiveness through clear research and communication.
Accomplishments that I'm proud of
We are proud that we managed to create a functional, visually pleasing app that incorporated all the tasks that we were hoping to complete. We had never been put into such a strenuous, heavy environment for coding and designing. Just the fact that we have a finished product that encourages kindness, inclusiveness, diversity, and care to others is a feat that we feel very happy about.
What I learned
Despite having no prior experience in any hackathons, we pushed ourselves to communicate, and in turn, this has taught us the importance of management, transparency, and teamwork.
What's next for One a Day
In the future, we hope to bring this web-application as a real application for people to use. We believe that this simple application can be a fun way to track your actions, while making a difference to the world around us.
Built With
.-our-app-will-ask-you-to-do-one-simple-selfless-act-or-self-care-practice-every-day.-you?ll-learn-it-only-takes-a-couple-of-minutes-or-sometimes-a-second-to-brighten-up-someone?s-day.-once-you-complete-the-task
bootstrap
busy-hectic-lifestyles-make-us-forget-about-ourselves-sometimes.-therefore
css
firebase
html5
it?s-easier-said-than-done.-we?re-just-too-busy-to-take-care-of-others.-we-have-priorities;-we-work
javascript
jquery
we-came-out-with-this-app
we-have-school.-what?s-worse
Try it out
GitHub Repo


Mentor Match Swiping
mentr
Our iOS application, Mentr, connects inspired high school students to university-level mentors. It’s implemented through a Tinder-like interface with NodeJS/Express backend serving data to the iOS application through AWS, optimized based on diversity, accessibility, and inclusivity.
Built With
dockerfile
javascript
swift
Try it out
GitHub Repo


Inspiration
While standing in a long queue to deposit cash in the bank. Also wasting time to write my details in the slip provided by the bank. At least half an hour will take for deposit and request for DD.
What it does
Instead of manually filling the slips, we are digitalizing it and enter all the details via mobile app and submitting it with a selected time slot. We will get a response contains a reference ID and QR code. Users can go directly to the bank and show the ID or scan the QR code and the teller will get all the details and just give the cash to deposit or cheque to collect DD.
Also, the app will recognize conversational speech and identify which feature needs to be actioned and it will automatically enter the details too
How we built it
We build it by developed a mobile app using ionic frameworks and angular for UI part and the backend will be handled by .Net and open APIs. The speech recognition will be handled by LUIS, the cognitive service of Microsoft Azure. Also, we are consuming FFDC API to get the account information
Challenges we ran into
Accessing FFDC APIs and implement the NLP
Accomplishments that we're proud of
Achieved to consume FFDC APIs and implement all the factors mentioned in the hackathon
What we learned
How to use the AI part in LUIS and how it is handling the NLP
What's next for Acute Banking Services (ABS)
Add more features like Foreign exchange and other banking activities still using slips to fill.
Built With
.net
ai
angular.js
apis
ionic
natural-language-processing


Inspiration: 100% Release Quality.
What it does: solution for doing the automated validations of feature toggling along with the performance monitoring across multiple software releases
How I built it: Built With Open API's
Challenges I ran into: Software feature Toggling issues
Accomplishments that I'm proud of: Built Prototype.
What I learned: Learned Issues removing in Feature toggling
What's next for RQFT-Release Quality in Feature Toggling :Building Application
Built With
api


Inspiration
Absence of an asset which combines the technologies to give a ONE VIEW for the payment solutions
What it does
Its a Web based application sits on top of Payment Platform as a layer which pull the required information / analyze and visualize then helps to investigate the users.
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for The ONEVIEW - Payments
Built With
api
css
html
j2ee
java
websphere
Try it out
tinyurl.com


This image is currently processing. Please be patient...
Inspiration
I have a friend who used to be in a wheelchair and her persistence inspired me
What it does
Help people with disabilities as well as people with non-binary genders
How we built it
With JavaScript
Challenges we ran into
Working with GitHub
Accomplishments that we're proud of
we pulled through and finished
What we learned
How to collaborate under pressure
What's next for accessibuldings
More features
Built With
javascript
Try it out
hackathon-project-7160d.firebaseapp.com


Inspiration
We want to help those who are visually impaired to be able to complete their budget easily
What it does
It will allow users budget and calculate their monthly total cost spending by simply scanning the receipt
How I built it
We use python to leverage Google vision API and use Android studio to handle the front end for our mobile app
Challenges I ran into
We are having issues with loading things from google vision as well as compiling with Android studio since this is the first time for us to use these platforms
Accomplishments that I'm proud of
Even though we have never used these platforms before, we still manage to create something useful at the end of it
What I learned
How to use Android studio effeclty
What's next for BudgetBuddy
WE WILL SEE
Built With
android-studio
java
python
Try it out
GitHub Repo


Testing out the gesture tracking
Hard to use your fingers? Hard to utilize certain limbs? Have the urge to play Mario and other realtime games instead of slow, boring, turn-based RPGs? Then the Assistive Input Controller is for you! A customizable input controller using body movement and sound, for a small platforming game (created from scratch in Unity). Setup is relatively simple, and presets can be made to swap between body part gestures. Hardware used includes a Microsoft Kinect and audio input devices such as a contact microphone and a clip on microphone. We used Unity and Max, with UDP and OSC protocols to allow the Kinect and two computers to communicate locally. Input methods for controlling the character can be any body part (with a secondary body part to reference position). Other input methods that are integrated include yelling into the clip on microphone, tapping the contact mic like a button, and making a fist shape with a hand.
Figuring out how to develop a game in Unity, using UDP and OSC protocols between Unity and Max, and using skeleton tracking software with the Kinect and turning its output into meaningful control data were some of the challenges that we overcame during this Hackathon.
We'd love to continue to develop this tool and for a broad audience, so input can be customized to be more accessible for certain groups of people. We'd also love to integrate the control scheme with more basic control schemes, such as mouse and keyboard input.
Built With
c#
kicass
kinect
max
osc
udp
unity


Login Page
Inspiration
Too many of us have had professors who were biased toward one gender or ethnic background and we found it intimidating at times to approach professors during office hours because of problems such as having a language barrier. Moreover, some of us were part of the Tri-Mentoring Program at UBC and we definitely had mentors that we couldn't relate to or weren't as approachable as we'd hoped for. To resolve this, we wanted to create this safe online community for students to choose their own mentors based on their personal preferences.
What it does
Our web app is a service that connects Vancouver students in tech with industry professionals. The service enables students to choose their own mentors based on personal preferences such as gender, ethnicity, educational background, etc. This allows students to have a better and more personalized mentoring experience. Also, not only will students be able to learn more but they can further expand their network.
How we built it
We built this web app using React.js, Node.js and Express.js.
Challenges we ran into
We initially encountered problems with styling the web app and picking components to implement for the scope of the hackathon. We were also finding the time constraint difficult to experiment more with cloud services such as Microsoft Azure as we were trying to deploy our entire web app.
Accomplishments that we're proud of
We worked cohesively as a team and we were able to effectively delegate tasks based on skill-set. Also, we were able to complete a working implementation of the features we planned to create. This involved integrating the front-end work with the back-end which none of our team members have done before. Overall, we loved the experience of working in a team and being able to produce something!
What we learned
We learned that effective communication and task delegation is critical during hackathons and any project/company for that matter. It is also important that everyone on the team is clear on what they need to do and what the over-arching project goal/MVP looks like. On top of that, we also fetched further into learning about the tech stack that we worked with and how they can be integrated.
What's next for MentrMatchr
We hope to complete the additional features that we had planned for the web app. Hopefully, institutions such as UBC would use this web app to provide their students with a better mentoring experience. For instance, the Tri-Mentoring Program could pick up this web app.
Built With
azure
express.js
mysql
node.js
react.js
Try it out
GitHub Repo


Volunteerity Logo
Inspiration
Many people have it in their heart to give back to their community, but quickly get discouraged when trying to find the right organization to work with. Finding and initiative to volunteer for can often be difficult, and that's why we've created "Volunteerity" a platform which connects volunteers to organizations that meet their interest, making the process of giving as possible.
What it does
The platform allows user to create either a organization, or volunteer account. Organizations can use the platform to promote for upcoming events, raise awareness about pressing issues, and enlist the help of local community members. Volunteers will be able to search for organizations using keywords pertaining to their interests, and be able to sign-up for upcoming events created by organizations.
How we built it
Front-End Using html we created a basic framework for the website, with a landing page, login page, and search page. We we're hoping to expand into more pages such as feed, and profile pages but ran out of time. The pages discussed above were styled with css to add a minimalistic, friendly look to the website.
Challenges we ran into
We ran into difficulty when trying to integrate our back-end java code, with our front-end html code. Our project had two strong pieces, but we failed to integrate them.
Accomplishments that we're proud of
This being our first hackathon, we are proud of the way that we worked together to create a product (while not complete) that has a solid base, and the potential for future development. This has been a great learning experience, and has given us the knowledge to set ourselves up for success in future hackathons.
What we learned
The notion of mutable/immutable objects was reinforced in this project, as there were many attributes of Users and Organizations that we did not want to be accessible to the user of this program, in order to maintain the rep invariant. As mentioned above, we struggled with integration of front-end and back-end. This taught that more preparation is key, and by expanding our skill set we may have succeeded in the given time.
What's next for Volunteerity
Bridge the gap between the Front and Back-End. Upon doing this, we can continue to develop the software to better suit the users.
Completion of login, profile, and feed pages.
Possible additions include algorithms to find initiatives that a User might be interested in based off of the attributes of their account.
Built With
css
html5
java
Try it out
GitHub Repo


Inspiration
Despite Canada being a wealthy country, food bank use remains at unacceptably high levels. Contrary to popular misconceptions, food banks users span the spectrum of our society. According the Food Banks Canada's Hunger Count 2019 Report, 1 in 8 are currently employed, 34.1% are children, and seniors are the fastest growing user group. We wanted to tackle one aspect of this social issue, which is the availability and accessibility of healthy foods at food banks.
What it does
For donors, our apps gamifies the food donation process. One common hurdle for food banks is the lack of consistent donations - there is usually a rush of donations around the holiday seasons which tapers off quickly. Our goals is that by gamifing the process and "levelling up" users as they donate, it will incentivise consistent donations.
For users, our project provides a way for them to see what's available at different food banks easily. This would help them access what they need more efficiently.
For food banks, this allows them to specify their needs and create a more personal connection to their community.
How we built it
We used Figma to create UI/UX mockups, and then implemented them using React Native.
Challenges we ran into
Our biggest challenge was the time constraint. With only 12-ish hours, we had to ideate at breakneck speed and once we settled on our concept, we were left with not much time to code. Our second challenge is the varying programming experience in our team, with some of our team members with little to no experience with React Native.
Accomplishments that we are proud of
We are proud of the idea we came up with and think it has merit. We are happy with what we accomplished in the little time we had.
What we learned
We learned more about food banks and the societal issues around them, and we learned about working in a diverse team with different skill sets. On a more technical note, we learned more about coding with React Native.
What's next for Banking on Food
Next steps would include moving the app towards a more functional beta version. Right now, we have the bare skeleton prototype, and we are excited to build it out more.
Built With
javascript
react-native
Try it out
GitHub Repo


Inspiration
We were inspired by people who didn’t have access to important info on the internet. Ubique is an attempt to help out those people who aren’t lucky enough to have reliable or consistent access to the internet.
Personally, the wifi where I live gets cut off at 11:30pm, so I needed a solution that would allow me to access info offline.
What it does
Gives you access to important information such as Wikipedia, anywhere!
How we built it
Technology used: Flask (backend) External hard drive Router (MacBook) DNS server (dnsmasq)
We used a MacBook Pro which sends out a local wifi network. The Flask backend is also running on the MacBook, which serves the offline data. Devices that connect to the local wifi network can access the Flask server and see the offline info hosted there.
Challenges we ran into
We had to scrap the original React Native interface for something simpler late into the project. We had issues with downloading and parsing books and wikipedia data
Accomplishments that we’re proud of
We learned how to adapt under stress, as our React Native interface was not working at first. We learned how to build and adapt, only implementing the important and key features while scraping the unnecessary ones.
What we learned
How to work under stress How to work with multiple people on the same project Working with large amounts of data (the entirety of Simple Wikipedia downloaded)
What's next for Ubique
Adding more services to Ubique, like videos, music and maps. Improving the UI to be more user-friendly. Use a framework like React Native to improve code maintainability.
Built With
flask
html5
python
Try it out
GitHub Repo


Useful Student Widget layout
Inspiration
Bloomberg
What it does
How we built it
Python
Challenges we ran into
Accomplishments that we're proud of
Completing it on time and learning an entire new framework
What we learned
What's next for Student terminal
Built With
bootstrap
css3
flask
html5
javascript
python


Inspiration
We wanted to bring people together to share homecooked meals. We thought about the fact that cooking individual portions for one person is costly and inefficient. So people can cook bulk meals with economies of scale and sell the other potions while making connections at the same time.
What it does
Allows people to get together to share healthy meals for cheaper and pay for them all in one app.
How I built it
We made this into a web application using php, html, css, and javascript.
Challenges I ran into
Api integration with to return latitude and longitude values for a given post code. Financial integration, we decided to use our own financial database just to show that the concept works.
Accomplishments that I'm proud of
The look and ease of use of the app. The financial integration in the app.
What I learned
How to use git to maintin version control and allow concurrent work with collegues
What's next for SpiC Chilli
native mobile apps
Built With
ajax
api
css
curl
html
javascript
jquery
mysql
php
Try it out
tution.ddns.net


An example of the Street View functionality
Inspiration
In an increasingly technological world, more and more of our interactions and connections are becoming digital. We wanted to figure out how to bring people together in a way they may not normally see, and at a level that's more personal than curated posts on social media. We imagined being able to walk through an area in the world, and see its history, but on a personal level. To see what others had felt and experienced, with their shoes in the very same place that we stand. The real-world, connected through digital, personal, histories.
What it does
Memory Lane is a webapp, hosted at https://memorylane.website, which allows users to view markers with comments on the map, and add their own markers with their own memories to the map. If a user logs in using Twitter their display name will be shown, otherwise it'll be marked as Anonymous. You can also go into streetview and see rough locations where memories have been placed, and share in their experience.
How we built it
Initially, we split off into frontend and backend development. This allowed us to collaborate on development while minimising the number of conflicts between us during early development, where a mostly functioning product is important to have as soon as possible. After we had a cool design for the frontend, and some working API endpoints on the backend, we began to intergrate the two, with API methods being created as needs present themselves in adding features, and calls from the frontend to the API being added to methods in order to obtain the actual
Challenges I ran into
An early challenge was that of considering the CORS settings of the site. We decided to combine the frontend and backend into a single Flask app, as CORS prevented us from accessing different ports, alongside it being simpler overall for implementation.
As the event went on, we encountered some bugs and issues along the way. Sometimes these were as simple as changing a variable name, but one particularly nasty
Accomplishments that we're proud of
The user-interface that we developed is very clean, easy to use, and nearly a direct translation of our concept idea. The ability to enter street-view, and look around and view markers (memories) in the locations they would appear in the real world. This also works with mobile phones and view tracking, so that the user can actually look around. Another accomplishment was the implementation of a Twitter-based user authentication system.
What we learned
We learned that we're able to focus on a project longer than we initially expected. Also, we learned about separating a project into components, have group members work on different parts independently, and then successfully link these separately developed components into a cohesive product.
What's next for Memory Lane
The next stage of memory lane would involve building the mobile application for users so they would be able to better access the site on mobile. The mobile application would also involve a notification feature. When the user passes a nearby tag they haven’t encountered before, they will be notified so it gives them the opportunity to know someone had a personal experience there and they can interact with the tag if they choose to. Improving the accessibility on mobile would also be apart of the next stage so when users view the website on their mobile devices the graphics will be resized to be optimal for different devices. Implementation of augmented reality may also be a potential future addition so users would be able to look around their location using their phone and they would be able to see the tags. Making the tags searchable would be a useful addition too to allow the users to find memories under certain categories. A filtering system for tags could allow users to search for memories of a specific category in their area if they chose to. Adding custom tags may also be necessary if users find that their memory does not fit under any of the pre-existing tags
Built With
css3
flask
google-maps
html
javascript
Try it out
memorylane.website


Inspiration
We wanted to stick to the theme of the hack while also doing something original. Our initial idea was that whenever a player wants to attack the opponent's pieces that a 2D fighting game would commence including the pieces in play as fighters. As we saw that would be all too much to do in 24 hours we decided that instead of a fight another set of mini-games would commence allowing the players to battle for their piece's survival.
What it does
An average game of chess until a player decides to attack their opponent's pieces upon which a mini-game (checkers, connect 4, tic-tac-toe or game of chess) is launched, winning the mini game can save your piece from being taken or allow you to take your opponent's piece depending on who initiated the mini-game. The goal is to beat your opponent
How We built it
We built it using react and JavaScript while using CSS for our styling for the web-application. We integrated various different board games using JavaScript.
Challenges I ran into
We ran into issues while creating separate game modes, such as AI vs AI and Human vs AI. Their implementations were a challenge and new bugs always seem to be rising up.
Accomplishments that I'm proud of
I found this as great practice with the React library and building JavaScript functions. Also having an aesthetically pleasing implementation is very good.
What I learned
I learned that implementing a basic computer to replace a human player is very hard as we take sub-conscious reasoning very much for granted when we play board games like these.
What's next for Chess With Extra Steps
Chess With Extra Steps plans to internationalise the business of putting things into things that don't necessarily need extra things. The 'Extra Steps' business model is incredibly scale-able and we plan to thoroughly utilise it as such
Built With
css
javascript
react
Try it out
GitHub Repo


Inspiration
ĐÁNH GIÁ PLUS là trang web không thể thiếu khi người dùng muốn mua một món hàng nào đó, tìm hiểu chi tiết về mặt hàng, đồng thời đọc các đánh giá chi tiết từ những người đã mua. ĐÁNH GIÁ PLUS được xây dựng nên nhằm giúp người dùng biết được mặt hàng đó có tốt, có nên mua hay không! Tất nhiên, những đánh giá này đều mang tính khách quan, không thể đúng hoàn toàn 100%, nên người dùng đọc chỉ mang tính tham khảo. Truy cập thêm về DANHGIAPLUS.COM để biết chi tiết hơn.
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for DANHGIAPLUS.COM
Built With
lib
ui


Inspiration
Pets are integral part of family and lot of pets are lost during disaster. Our idea is to build an easy to use application to reunite lost pets with their family using Machine Learning and cloud computing.
What it does
Snif buddy is a fully automated voice enabled real time searching and reporting application for missing pets. Fully automated missing pet report intake process via Alexa. Leveraging Machine Learning to match missing pets images with missing report. Real time notification to the owner of possible match and location. Exposing an API for third party organizations
How I built it
I built it using Amazon alexa, lambda, rekognition, s3, sns, email service
Challenges I ran into
SNS had issues as we reached maximum limit
Accomplishments that I'm proud of
Easy voice based intake process, creates clean and enriched data which enables use of AI and ML to provide real time pet identification system. This will help for faster pet reunions
What I learned
I learned how we can create a personal touch to missing pet report process by using Alexa.
What's next for SNIF Buddy
Building an fully functional mobile application which is Alexa enabled and publish it to Apple store and Google Play
Built With
node.js
python


Inspiration
To help Vibrant save more lives.
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for BeThe1To
Built With
amazon
lambda
lex
lightsail
mysql
s3


okboomer-table37
okboomer-table37
Urban Institue
Affordable housing in cities, we work with federal city and state governments, want to stop pushing out low income families out of homes
To remedy and predict building hights data fushion ML washington DC input data sets polygon footprints lidar data, drone and get lattitude and longittudes, and satellite imagery datafusion we have the polygon and lattitue and longitudue smart data to merge both datas and use ML to expand past DC
Building heights why? Building heights are important tell you about character of the neighborhood and zoning policies
Keeping families together, years of research measuring building heights correlates to quality of life.
Our Approach
Our approach is completely Serverless, to reduce load times you can incorporate a Database for importing data. A formula for Quality of Living vs Building Height to Correlate for analytics Platform AWS QuickSight or Tableau Take satellite imagery out of Google Drive and put into S3 for historical Use AWS app sync to get data back faster with one endpoint and get json format the way you want S3 Folders for Input and Output .geojson to .csv and backend Visualizing and meshing the sources including mapbox Building a Scalable solution by File size Serverless Take File clean up file for data cleansing New Headers and append additional data via Lidar and Satellite
Built With
amazon-web-services
angular.js
apigw
javascript
python
serverless
sls
Try it out
git-codecommit.us-east-1.amazonaws.com
GitHub Repo


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Debt B. Gone
Try it out
www.canva.com


Logo
Inspiration
Impulsive spending on video-games specifically with micro transactions.
What it does
It discourages impulsive spending from consumers and restricts children from using parents bank information without their permission. It sends SMS messages and notifications to both your phone and computer to warn and discourage needless spending.
How I built it
Using a template as a foundation a website was created that displayed the account information of our client as well as a mock-up of how the website version would work. Using the Twilio API we made it so that a SMS message is sent when a user of our software attempts to complete an unnecessary transaction.
Challenges I ran into
.XYZ domain not loading in time (takes up to 24-48 hours to construct website on domain) Flask not working with Twilio
Accomplishments that I'm proud of
We created a functional website that was client-side. Our SMS messaging system was also functional. We have a unique idea with a solid foundation in the real world.
What I learned
How to use APIs (Twilio). How to use githup-pages and node.js.
What's next for BudgetBuddy
Expansion to multiple websites and industries
Built With
css
css3
google-slides
htlml
html5
javascript
node.js
python
twilio
Try it out
GitHub Repo
GitHub Repo
budgetbuddy.xyz
docs.google.com
drive.google.com


Inspiration
It's expensive to pay managers to train front-line workers. There may be bias with feedback that's not data-driven. Managers may not accommodate to disabilities as clearly as going at the worker's own pace would.
What it does
Trains people to assemble parts using mixed reality.
How I built it
Lots of pain.
Challenges I ran into
Took me 6.5 hrs to get the environment set up.
Accomplishments that I'm proud of
Implemented most things in 2 hrs.
What I learned
MRTK is a mess.
What's next for HoloAssemblyTrainer
Sell out to Microsoft Guides.
Built With
mrtk


Inspiration
We live in a super multicultural country and the tech community is super diverse. We see the importance of being able to communicate with all of these different types of people.
What it does
Language learning game. The objective is to correctly identify the english translation for the word being displayed.
How I built it
We used the Yandex translation API for basic fetching of foriegn language words. We presented the words using HTML and CSS on a dynamic webpage and receive user input using Python. It outputs if the user made the correct selection and move on to the next level of words.
Challenges I ran into
Using the Yandex API to retrieve accurate translations.
Accomplishments that I'm proud of
Being able to use Python and Yandex API to interact with users.
What I learned
Our team did not have any Python experience before attending this event. We were able to learn a new language from scratch and build a useful application using it.
What's next for Langle
We will add more multi language support and also add more levels to enable users to learned even more words.
Built With
css
flask
html
python
yandex
yandex-translate
Try it out
GitHub Repo


Consider this, you are some sort of musician, producer, or vocalist who wants to collaborate your work with other artists online, but the problem is that there is no service out there that gives us the accessibility of sharing our music files, audio files, garage band files online with other people from other parts of the world. We decided to create a web-based platform for musicians and producers of diverse music genres, cultures, and expertise to collaborate with each other from across the globe. This allows users to upload their audio tracks or music studio (garage band, FL studio) files, and have other users listen, download and collaborate with the original file to piece together a cohesive piece of music! We created both a rough wireframe for the UI using Adobe XD, and also worked on a rough HTML implementation of the website. The problem we encountered is the time constraint, since we were all new and came from different expertise, but we tried our best to communicate and work through our design of the product.
Built With
adobexd
css
html
Try it out
GitHub Repo


None of us like to wait on hospital lines. Our project was inspired by a member’s experience when her mother was having uncomfortable heart problems. She was hesitant in going to a hospital because she was aware of the long-wait times. In the end, she ended up visiting her local hospital but her family was constantly worried during the long wait time. We realized that this is a common issue due to the lack of easy access to necessary hospital information, but this can be easily resolved through an app that displays hospital wait times. We created this platform to have a stronger control of our own health and the health of those who love. Taking care of our body is a serious matter, and we shouldn’t rely on luck to take care of them. Instead, it is about having a conscientious decision, and that starts on which hospital to go.
Our app identifies the location of the user and renders a list of hospitals that are close to him/her. The list gathers all necessary information, such as address, phone number, website, rating, and most importantly the waiting time. With such information, the user can make a better decision of which hospital to go and get a faster treatment.
There were many challenges in implementing this app, given that we are all second-year undergraduate students with not much knowledge on CS. Retrieving the correct API, as well as carefully constructing the UI, were our biggest challenges. Having said that we were able, as a team, to overcome these obstacles and deliver the goal we set. It has been an incredible journey so far, learning from each other and defying our own expectations.
Our next steps will be to integrate even more personalized features, such as creating a profile, being able to star specific hospitals, get real-time notifications of hospitals with a short line, etc.
Built With
google-maps
intellij-idea
java
Try it out
GitHub Repo


Inspiration
Bridge the gap between deaf people and their peers.
What it does
Translates speech or text to sign language to help users learn sign language and communicate with peers that use sign language.
How we built it
We used Microsoft Azure's Speech SDK in an Android application written in Java and wrote parsing logic on text.
Challenges we ran into
Coming up with an idea and setting up the project uniformly was more than half the battle. Additionally, we had minor difficulties with version control.
Accomplishments that we're proud of
Successfully translating speech to text to sign language.
What we learned
Azure is lit.
What's next for Peace
Peace is easily extendable as long as we add more words to the dictionary.
We can also add context meaning, since not all words are used in the same context all the time.
A history of sentences/translations
Built With
android
android-studio
azure
java
photoshop
Try it out
GitHub Repo


Our idea was to implement an app that simplifies the task of navigating around UBC for all. it was a priority to incorporate features for those who need wheel-chair accessible routes. Additional feature that we have is to help students to stream the live update of certain study and food spots. We wanted to create a user-friendly, interactive, and all-in-one app that routes short-cut routes between the user’s starting location and chosen destination.
Inspiration
We had two major inspirations behind this project. First, we were frustrated with the current UBC Wayfinding site. The site makes it difficult to actually efficiently navigate around campus. Secondly, we were inspired by a friend who was on crutches and needed alternative paths to get around campus. We realized how limited the UBC Wayfinding application was. And so, we wanted to create a more interactive and user-friendly experience for those trying to get their way around campus!
What it does
The application presents the user with a customizable profile where they can select their preferences in food and study location as well as any physical disabilities. You are able to search within the app for locations around UBC and the app will give a route that accommodates for any disabilities that may inhibit movement. You can also search for nearby food locations and filter the results by cuisine and price. In addition, the app gives you live updates on the availability and crowdedness of your destination.
How I built it
We started off by building a framework for the android application using Android Studio. This framework includes the varying pages that the user can navigate to and from. These pages were tailored to the specific features we wanted to supply, namely, the map, and the search filtering page. To actually incorporate the more comprehensive routing feature to the app, we decided to integrate the Google Maps API and utilize it’s built-in features.
Challenges I ran into
The biggest challenge that we ran into was an unfamiliarity with the tools that we were working with. Understanding Android Studio and especially the Google Maps API was time consuming and detracted from time that we could have spent implementing our project. This meant that time was a big constraint and if given more time we are confident that we could have completed a fleshed out version of our application. Another challenge was how we brought our code together as we edited code individually on different project files and attempted to merge it all together. This could have been avoided with better planning in the beginning and a better use of git.
Accomplishments that I'm proud of
We were able to scrape from Google map to our code to make the app functionable. In addition, we created the prototype and user interfaces of our app
What I learned
We learned how to work together in a time constrained environment where you have to implement different sections of code, written by different people. We learned the value of having a concise plan and making sure your idea is reasonable before going out and coding it. We learned how to utilize the Google Maps API to plot markers and routes and began working on sending http requests to retrieve a route from the directions API. We also learned how to utilize wire framing in the design process and creating unique elements in android studio, like a search bar.
What's next for UBC Nav
To implement the actual routes to accommodate any disabilities, including warnings for narrow passages and stairs etc
Built With
android-studio
figma
google-maps
java
Try it out
GitHub Repo


Logo for the project
Inspiration
When Pedram mentioned the troubles his Aunt had with Canada’s tech savy culture, everyone in our group instantly related. Each of us had experience with a relative being unable to return an email or start a video call. This has an isolating effect on those relatives, especially when a person is a new immigrant to Canada as in the case of Pedram’s aunt. We think the internet
What it does
We have compiled a list of everyday tasks using the web, such as checking and sending emails, getting directions to a location, making video calls, etc. Based on their query, the user is directed to the right place on the web and guided throughout the process to achieve the desired task.
How I built it
This is an integration of an IBM Watson Assistant into a chrome extension. We programmed a Watson Assistant so that it could respond to requests about emails, voice-calls, and getting directions. The assistant pattern matches the requests and then assists by providing suggestions and helpful links to the user.
Challenges I ran into
It was a big challenge merging a Cloud based Watson Assistant into a Chrome Extension. Because of the many npm packages required to pull a chatbot off, it was very difficult to merge them all into a chrome extension.
Accomplishments that I'm proud of
It was really neat using the Watson Assistant and seeing how much functionality could be obtained quickly. An accomplishment I was proud of was getting the assistant to ask prompt where the user wanted to go and provide a link to google maps with the response pre-filled. This functionality embodies is the ease of use we want this service to provide.
What I learned
We learned to work with JavaScript and assemble a Chrome extension. We also learned to build our own chatbot AI in Watson Assistant, and used the Watson API to connect it to the chrome interface functionality.
What's next for Dr. Internet
Support for more functionalities (cooking recipes, sales flyers, news and weather…) Even more help with emails. E.g. enter the email address, enter the text you want to send. Then our chatbot can pen the message in gmail for them.
Built With
chrome
html
ibm-watson
javascript
Try it out
GitHub Repo
photos.app.goo.gl


Inspiration
Inspired by color matching games and the difficulties that color blind people are facing.
What it does
It allows the player to cancel out the squares that have the same color as the one you click on and is especially designed for Tritanopes!
How we built it
We used Unity editor and C# to implement the whole game.
Challenges we ran into
Some edge cases are stopping us from removing all the neighbours with the same color.
Accomplishments that we're proud of
It's now working for most of the clicks on the grid!
What we learned
Learnt a lot about making a game from scratch and applying algorithms to it!
What's next for Tritan Fighter
We'll continue on working on removing all the neighbours with the same color and change the colours of their neighbours in some pattern.
Built With
c#
unity
Try it out
GitHub Repo


Sensory Haven is an application where users can input their accessibility needs and find locations that best suit these needs. We have developed both mobile and web prototypes to demo. Users can add in a profile detailing their accessibility needs, such as wheelchair accessibility, light and noise sensitivities, allergies, and more. Based off of these needs, which we use as "tags", we can find locations which have been rated by other users, shown using a Google Maps API. Users are able to read reviews from other people, as well as write their own. We used Figma for the mobile prototype and React for the web version. Problems we ran into include learning the frameworks which we were unfamiliar with, API issues, time limitations, and keeping web accessibility in mind.
Future ideas for this project involve developing a settings menu with options that accommodate different accessibility needs, such as enabling users to increase font size or run a text to speech function. Another idea was to use AI sentiment analysis to see if user-written reviews are more positive or negative and use this data for our rating system. In terms of implementing real-world change, we considered Sensory Haven’s impact on businesses. For example, if a business has a low rating, this may help the owners realize how accessibility issues may be driving away potential customers and encourage them to change their spaces to be more inclusive.
Built With
api
css
figma
google-maps
html
javascript
react
Try it out
www.figma.com
GitHub Repo


An example of the app in action!
Submission for UBC LHD Build Day
The Problem
In the USA, there are 250 000 to 500 000 individuals who know ASL. Out of the total population, that is .2%. Most of these individuals are deaf or hard of hearing, and in order to interact with the world, must rely on observing mouth patterns, which can be difficult due to each individuals unique speech pattern. Furthermore, the rest of the population never realizes that ASL is a learnable and simple language, so it is rarely used except for those close to the hard of hearing.
Our Solution
Our solution is a web app that quickly translates either speech or text to ASL. Users can either type or speak directly to the web app, and in return, are given a translation of their speech in ASL. For common phrases, it returns a picture describing the motion, while other words are directly translated using the ASL alphabet. A Google Cloud Speech-to-Text API that utilizes neural networks is able to translate speech with astounding accuracy. The app is easy to use, and more efficient than searching up commands. This creates a pathway for those hard of hearing and those who have never been introduced to ASL.
How we built it
We used the Flask framework to build a simple back end. Our front-end is coded in CSS and HTML. We also hooked up a Google Cloud Speech to Text API.
Challenges we ran into
The biggest we faced was creating the front end. Both members of the team have never used CSS or HTML, so we were unsure of how components worked together. This lead to a lot of guessing and checking. Eventually, we got a better handle on the language. Another difficulty was linking common ASL phrases into our web app.
Accomplishments we are proud of
We are proud of how our front end turned out, this being the first time we have ever coded in CSS and HTML. Overall, we are proud of being able to create a web app to combat a real life issue.
What we learned
We learned how to send input from the user, to the back end and back to the front end as well as how to communicate with an API. Additionally, we also learned how to design a minimalistic, but functional front end.
Built With
css
flask
google-cloud
google-cloud-speech
google-web-speech-api
html
python
Try it out
GitHub Repo


Dashboard
Why are we spending our valuable weekend to hack? It’s because we are students eager to learn more and work on a fun, interesting project to develop our technical skills. When we’re brainstorming and wrapping our heads around the topic of ‘accessibility, inclusivity, and diversity,’ we thought it would be wonderful to have a platform that enables us to discover hacking opportunities across the world, find a team to hack with, showcase our proof of concept and get recognized by professionals and recruiters. This is why we created MentorMe - a virtual co-working space for programmers and designers.
The two designers in our group worked with Figma to build the visual design and prototype between the pages. By learning to reference UI kits available (such as Material Design), we were able to simplify the design process by representing information efficiently. The challenges we faced were keeping consistency across pages with different assets. In the future, it would be effective to explore a standard style guide before beginning the design process.
The two programmers in our group worked with Javascript, HTML, CSS and Python Flask for web app development. While Python Flask presented an initial learning hurdle, once we were on track to create basic functionality such as rendering pages, we moved on to creating additional features in Javascript. Once we gained more familiarity with the syntax and features of the languages, we shared these insights with each other.
Built With
css
flask
html
javascript
python
Try it out
GitHub Repo
www.figma.com


Inspiration
We would like to begin by acknowledging that our land has a deep history. We take time for "land acknowledgement" statements at many events. What would it take to learn what these really means? We were inspired by our lack of understanding of the First Nations tribes and the land acknowledgement statements we repeatedly hear. Despite often hearing these statements, we acknowledged little understanding of the First Nations Tribes of Canada.
What it does
Our application makes this vital information accessible in a fun, interactive, and non-intrusive way. It is inclusive to the First Nations peoples and their history, and allows people to learn about their traditions and history in our city. Our app celebrates the diversity and culture that they bring to our current landscape.
Birds'eye uses location data and push notifications to alert a user when they are within a given distance of a historical landmark or area, as well as information about the landmark and the First Nations peoples.
How We built it
Android Studio - Kotlin
Google Maps API
Challenges We ran into
Kotlin; none of us had used it
Accomplishments that We're Proud of
Good looking app
What We learned
Use Java since people already knew it
What's next for Birds'eye
better distance calculation
Built With
android
android-studio
kotlin
mobile
Try it out
GitHub Repo


Inspiration
We are a group of meme-lovers. We realized that many memes are in image format and that people who are visually impaired may not be able to enjoy them as we do. Thus, we decided to build a tool to help those people enjoy the same memes that we know and love.
What it does
Meme Reader is a Chrome extension that reads aloud the text in images found on websites. While the user is browsing websites, Meme Reader will look for images on the page and read out any text associated with it.
How we built it
Front-end: We used JavaScript to scrape websites for images, pass image URLs to be processed, and convert the processed text to speech.
Back-end: We used Java with the Spring Boot framework to communicate with the front-end and receive image URLs, as well as the Google Cloud Vision API to produce text from the images.
Challenges we ran into
We had difficulties setting up Spring Boot and Google Cloud Vision API. We also ran into problems with passing information back and forth between the front-end and back-end.
Accomplishments that we're proud of
Learning to use new tools in a limited amount of time, as well as collaborating with others to build a project together.
What we learned
On the technical side, we learned how to use Google Cloud API in our project. Teamwork-wise, we progressively got better at communicating our goals and progress to each other. Sometimes if your program doesn't run, compile it again and maybe it'll be nicer. plz no mad ty O(no), O(my)
What's next for Meme Reader
The next step for Meme Reader is to train our model, such that images, which are categorized as memes, are properly filtered out from the websites and described with more precision.
Built With
google-cloud-vision
html
java
javascript
spring-boot
Try it out
GitHub Repo


Inspiration
We are inspired to make UBC more inclusive. We have friends who are colour vision deficient and we wanted to make academic resources more accessible to them. We then wondered how technology can be used for this purpose.
What it does
UncolouredPDF is a webapp where users can submit PDFs which have graphs or images that may not be very accessible for colour vision deficient people. We then return that PDF with updated colours which are easier to perceive for the users. We then extended it to PPTs and any JPG or PNG image.
How we built it
We used React for our front end to accept a PDF, PPT, JPG or PNG. We then convert it to a Numpy array and use a convolutional filter to change the colours. The algorithm we used is called Daltonization. We then convert it back to the original file format and the user is able to download the modified file. In addition, the users are also able to preview the modified file online after it has been processed.
Challenges we ran into
We were new to React and had some trouble setting up the upload and preview features. We also spent some time supporting the various file formats.
Accomplishments that we're proud of
We were able to successfully implement the file upload feature to allow users to upload a PDF file and view the processed colour-blind-friendly file in the browser through a PDF viewer.
What we learned
We learned how to use React and Flask. We also learned about colour spaces and the need to make resources more accessible.
What's next for UncolouredPDF
Our tool can be made to a Chrome extension for easy colour changes online. It can also be integrated to Google Drive on resources stored on the cloud.
Built With
flask
python
react
Try it out
GitHub Repo


Inspiration
Members of our team have personal experiences with panic attacks and know that when you're in the middle of one, there's not much else you can focus on. We wanted to create an app that could be used hands-free with minimal voice controls, so the Google Home was a perfect match.
What it does
PANda Pause guides the user through a panic attack. It calms anxiety by playing relaxing music, guiding them through deep breathing, or guiding them through relaxing their body.
How we built it
We built it through Google's Dialogflow API which let us configure responses to various phrases.
Challenges we ran into
None of us had used Dialogflow prior to this so we had to learn from scratch. We weren't quite sure of what it was capable of doing or how to execute it, and we don't have the experience necessary to modify the actual back-end code.
Accomplishments that we're proud of
Our app is genuinely useful for people and is easier to use in the middle of a panic attack than a phone app would be. We were able to modify the voice to be more calm and natural.
What we learned
We learned how to quickly find information on a brand new API and apply it. We learned some of the possibilities of Google Home apps and how they could be useful in different ways than phone apps.
What's next for PANda Pause
We want to learn how to include more features like calling loved ones, turning down the brightness on smart lights, and providing distractions to focus on.
Built With
dialogflow


Inspiration
There are millions of people in the world that are blind, while the internet a widespread amount of information inaccessible to the visually impaired. We created an application that would fix this issue. This application not only translates online webpages into braille (currently displayed in a Python GUI). As well, it is very time-consuming to read in braille when compared to other languages, so we implemented an API that condenses long articles into key words according to their relevance for increased literacy. The program can be connected to a Rasperry Pi board and pistons for practical use.
What it does
Braille-ify currently takes a Wikipedia page URL as an entry and displays the contents of the page in a GUI. We have designs and code for connections to a Raspberry Pi board.
Challenges we ran into
We initially tried to implement all the features on Java but we ran into bugs with the GUI and translating library. Parsing webpages in Java was also tedious in that conversion to JSON format is complicated. We switched to Python on the spot to match a text to Braille library in that language. We also attempted a prototype on Arduino, but had trouble with connecting and uploading code, so switched to Raspberry Pi.
What we learned
Python!
Html parsing, making GUIs in Python, working with APIs.
What's next for Braille-ify
Concrete Raspberry Pi hardware that displays webpages in Braille in real-time.
Built With
api
python
Try it out
GitHub Repo


Inspiration
We were thinking of important issues that need to be solved, like climate change, world hunger and rising depression rates and we determined that this was a project within our abilities that addressed one of these issues.
What it does
It gives small tasks that the user can do that make them and other people happier.
How we built it
We coded it on Android Studio and used a physical phone and emulator to test it.
Challenges we ran into
Not knowing some basic things like how to link pressing a button to a new page on the app.
Accomplishments that we're proud of
Constructing a working app in one day, when none of us have ever made one before.
What we learned
We knew almost nothing about android app development going into this, so we learned everything about building a basic application.
What's next for The HappyApp
Add more tasks Adding a calendar that tracks progress Adding notifications (reminders)
Built With
android-studio
github
java
xml
Try it out
GitHub Repo


Profile, People, and Preferences
Inspiration
Eating together is such a small act requiring little of us, yet such a psychologically boosting experience. Whether eating with family, close friends, or a new friend, it could be the happiest part of anybody's day.
What it does
Our user can use the DinerDates to find an eating companion based on each of their cuisine preferences and locations.
How I built it
Originally, we planned to use the skills we learned in the python workshop to implement it as a webapp. However, we ran into many issues and decided to change to a JavaFx application as we have experience is such. We implemented it using Profile classes and a Collection of Profiles, along with a GUI that allows a user to login and see other users with similar food preferences. Our app also uses a Google api to display local food locations based on preferences.
Challenges I ran into
While coding the structure of this webapp, we ran into issues using Python since we did not have prior experience with the language. Eventually we pivoted and switched our language to Java.
Accomplishments that I'm proud of
As this was our team's first full-length hackathon, each of us are proud of ourselves and each other for completing and submitting this project. It was a true team effort and we are looking forward to building future projects.
What I learned
We learned lots about the time and effort involved in making a vision come to life through websites, webapps, and apps in general.
What's next for DinerDates
Further improvements by adding extra features and making touchups as we go.
Built With
apis
intellij-idea
java
json
webflow
Try it out
GitHub Repo


Inspiration
Our inspiration for building an application to mask resume is through the publication of Harvard's metrics on how they evaluate undergraduate applicants to their programs. This lead us down a rabbit hole to find other areas in today's society were racial and gender profiling occur. One of the most prevalent racial profiling areas today is in the hiring process. According to studies, it is said that African Americans who masked their race on their resumes received 25% more interview offers, in comparison to their original resumes with a 10% response rate. This lead us to creating an application that would blackout racial and gender specific information to create a neutral resume screening stage.
What it does
Incognito Jobs allows users to apply to job postings with confidence that they will not be racially profiled. We will automatically detect racial or gender specific information and then blackout this information. This allows for companies to have a more neutral resume screening stage of the hiring process.
How I built it
We built the identification and masking algorithm in Python and implemented a Flask framework to run our web application. If you want more information on how we built it feel free to look at our Github linked below.
Challenges I ran into
Most of our challenges were with connecting the front end of our web application to the python algorithm we built. Our team in general did not have much experience working with Flask or Django and experience with programming the backend. We definitely think in the future we will need to improve our strengths in this area.
Accomplishments that I'm proud of
We are proud of finishing the hackathon today and coming in the top 5 out of 84 teams.
What I learned
Learned alot about collaborating with new individuals and some areas we need to improve on.
What's next for Incognito
Building out the web application, adding in a more robust identification and masking algorithm. We will be working on adding support for all types of document file types. Then from here work on developing our back end to integrate this resume masking into our website.
Built With
css3
flask
html5
javascript
pillow
pytesseract
python
Try it out
GitHub Repo


Inspiration
Data plans in Canada are the most expensive in the world source and some people may not be able to afford them.
Our focus is to help people with limited access to data to find their way back home, or anywhere they want to go.
What it does
DM our phone number and we will give back information on how to get to where you want to go without the use of data!
How we built it
Our backend is a flask app hosted on Azure. We used the Twilio API to receive texts, which is forwarded to our backend. The backend calls the necessary Google Maps API and will return the useful information in a text message. It will also send back a low-cost picture of the route if data is enabled.
Challenges we ran into
Eric
Learning the Twilio API
Vandy
Building and deploying a web app was kind of tricky
Liang
Learning Python and Flask
Accomplishments that we're proud of
we coded something useful and practical in a short amount of time
we all learned a lot about Python, Flask, Azure
What we learned
we learned how to use new APIs, especially Azure, the Twilio API and the Google Maps API
we learned how to code in a team-based environment
we learned to view from different perspectives to build features for
What's next for Direction Message (DM) Us
add natural processing language to make it easier for people texting us and reply back with more humanistic responses
add translation features so people can use it in their preferred languages
save previous locations
Built With
flask
google-maps
python
twilio
Try it out
GitHub Repo


DigiConsent is a new revolution in descrete, safe and fun dating. The DigiConsent App will combine face recognition with facetime, location and Adobe sign.
It will be linked to all the social platforms and carry international audiences on its platform. Our goal is not only to get DigiConsent from both people but to also protect them from any type of sexually transmitted diseases.
Its focus will be the social network of college students and dating scene. Especially those that are highly sexually active. It will also be for people who need extra security or proof that their sexual relationship was consensual and valid at that particular time.
Built With
adobe
dextro-image-recognition
google-maps
sign
Try it out
www.gofundme.com


Inspiration
Wildlife crime has reached a crisis point and we wanted to bring a solution to this problem
What it does
The algorithm detects living objects and distinguishes between animals and humans
How I built it
We used Yolo and Cuda infrastructures
What's next for Syndicate
We want to reduce wildlife crime.
Built With
cuda
yolo


Inspiration
According to Statistics Canada, 1 in 5 Canadians have disabilities, with mobility disabilities being the most prevalent. It is difficult for people to navigate the city, which is filled with construction, ill-maintained roads, and other obstacles. We envision a world where people can explore without limitation, and are making it our mission to design a novel application to help people navigate around these obstacles.
What it does
We are designing an innovative application to help users with disabilities plan and navigate around potential obstacles that would impede travel. Users will be able to access an extensive list of locations, and assign ratings as to the current accessibility of the location. These ratings can be used to assist in travel, providing a reliable, comfortable, and safe route for handicapped individuals. User-submitted descriptions provide a more detailed insight into potential accessibility problems the user may encounter.
How we built it
To create a simple, easy to use interface, we used Figma to design the front end of our project. Despite the twelve hour time limit, our team quickly picked up Figma, as it's easy to use. With Figma, we could collaborate as a team in a real-time environment to create an interface that is responsive, visually appealing, and easy to use.
The back end structure of Project Scout utilized a server, built using Node.js and Express.js. These two powerful packages can accept requests and information from our front end. Once fetched, they can modify and return those results based on the internal representation of our mapping system. With such a simple yet elegant design, we crafted a functional proof of concept of our idea.
Challenges we ran into
Project Scout was an exciting, yet difficult challenge for our team. We used JavaScript to combine our front and back ends, which required the back end subgroup to learn JavaScript in a short time period. Excellent communication between the front end and back end subgroups was vital to the success of this project, and was difficult for the first few hours of the project.
After hours of research, collaboration, and advice from mentors, we managed to transition from design to a working prototype of our project. It wasn't easy, but it was a tremendously fun challenge that I'm sure our team will remember for years to come.
Accomplishments that we're proud of
Our team is proud of the many things we learned and accomplished at Build Day 2019. We're proud that we learned how to use the Google Map API, html, JavaScript, and Figma. With what we learned, we were able to collaborate as a group to bridge our design with our code to form a product that can help millions in Canada navigate and explore freely.
What we learned
We learned how to use the Google Map API, html, JavaScript, and Figma. We also learned how to work effectively as a team, how to share our ideas, and when to ask for help from experienced mentors. Overall, Build Day has been a tremendous learning opportunity, and our team is excited to participate in future hackathons.
What's next for Project Scout
Project Scout has the potential to create tremendous impact in the day to day lives of millions of Canadians. Using the Google Maps API, we will utilize the cloud and advanced algorithms to present the optimal route to users in a clear, informative view.
The Project Scout team will also reach out to the community and engage with stakeholders to craft a product designed for the users, and with the help of the users. We think that by taking this extra step, we can make something truly special.
Built With
express.js
figma
google-maps
javascript
node.js
react
Try it out
GitHub Repo


Logo
Inspiration
Not enough attention is given to accessibility in web development. Many key aspects of accessibility are overlooked by web devs in trying to push their latest build to production. Additionally, developers often opt for aesthetics over accessibility, and this imposes a problem for visually impaired users.
Research is compiled by Sergio Luján-Mora addressing this topic. His work emphatically showed that webpages are frequently missing alt-text, and this can severly limit their usability. Alt-text is often flat forgotten or ignored.
What it does
Take in a website URL and a set of boolean options that concern the users needs (i.e., visual impairedness, color blindness, etc.)
Scrapes the site for header, paragraph, and image data. Reformats data with the same header and paragraph, and adds alt-text to the image(s) according to what Microsoft's Azure Computer Vision library suggests is in the image.
Renders a new, simplified version of the image on the same page with the new alt-text.
How we built it
We used React to develop the front-end user interface. We integrated our web-scraper and Microsoft Azure’s CV library together, with Node.js.
Challenges we ran into
Our team is new to JavaScript development using React.js and Node.js, and we spent a lot of time familiarizing ourselves with the different aspects of it, as we ran into various nasty bugs along the way.
We also faced a lot of difficulty in trying to make the three difficult components of our program talk to eachother. We build a front-end which took form data, a web scraper which formatted data from a URL, and a way of getting suggested alt-text for an image, but taking them all together took the support of Build Day's mentors. We finally got it working in the end and it was quite rewarding.
Accomplishments that we are proud of
We gained solid progress on the idea we brainstormed. Each member worked productively on their respective tasks, and despite this being the first hackathon for most of us, our project came together slowly, with a functional front-end and a back-end that yields satisfactory results.
What we learned
We familiarized ourselves with the general workflow of hackathons along with tools and software required in these kinds of competitions.
We definitely learned a lot regarding web development using Node and React. More importantly, we grasped how to plan the development process effectively so that each module can come together timely.
What's next for Alt-access
-Implementing new features for re-rendering the webpage, such as correcting text for dyslexia.
-Research more into specific types of color-blindness, and develop relevant contrasting options.
-Integrated screen-reader
-Chrome extension
Built With
azure
cv
node.js
react


Inspiration
At one point or another, your phone will run out of battery and you’ll be stuck with no charger. If you’re in a familiar place, you might ask one of your friends. But what if your phone dies and you know nobody around you? Recharge allows everyone to share and recharge their phone, while also recharging themselves by relaxing and connecting with new people. It brings people together through a shared difficulty: a dead phone battery.
What it does
'Recharge' is an app that will help people find a charger when their devices are dying by connecting them with other users who have agreed to share. Recharge encourages community and social interaction while resolving a prevalent problem in our everyday lives. The app will automatically find the device model and the appropriate charger for the device. Using a Google Maps API, it will then show the position of the device holder and others who are willing to lend a compatible charger.
How we built it
We built Recharge using Android Studio, the Google Maps API, and Firebase Firestore and Firebase Authentication. We used the default Google Maps activity to track and mark our position, as well as other users. We used the google maps location api to request and use user location. We used firebase auth and firebase store to manage the coordinates, location, and charger type of each user. We intend to combine these with some activities in android, allowing us to show the chargers of nearby individuals.
Challenges we ran into
Some problems that we ran into include: being unable to test on certain devices, working with a strict time limit, and having little to no experience with Android Studio/java in general. We also ran into several technical difficulties, where the API differed vastly from the documentation we could find online. Lastly, near the end of our project, we faced issues with Firebase authentication; it became slower to log us in and it stopped working despite not having changed any code.
Accomplishments that we're proud of
It was the first-ever hackathon for the majority of our team, so we’re proud of how we created a functional app from our incredibly ambitious idea.
What we learned
We have gained a lot of experience collaborating with others. Jumping into the project, we were able to brainstorm a lot of ideas, but quickly learned we would have to prioritize certain features over others. Working with a deadline, productivity and time management was essential to creating a product we were satisfied with.
Built With
android-studio
firebase
java
Try it out
GitHub Repo


ERRATUM: we weren't able to pitch because we forgot to submit the Google Form. So thats a big fat L. Nevertheless, we still think this is a pretty cool project so enjoy.
Inspiration
One of our team members has an older family relative with hearing impairments and found through his interactions with her how difficult some simple tasks and conversations could be due to the fact that she couldn't hear well. Though she has a hearing aid, she often finds it uncomfortable to wear and would prefer to learn a better way to facilitate communication. Upon doing further research, we found that around 466 million people worldwide have disabling hearing loss, and 34 million are children (according to the WHO). Despite this large number, only about 70 million people around the world use sign language to communicate (according to the World Federation of the Deaf). Given that sign language is the primary means for people with hearing loss or deafness to communicate on a day-to-day basis, we wanted to develop a tool that would help people (both those with and without hearing loss) learn and practice American Sign Language.
What it does
A user can select from 27 ASL hand signs (the letters in the alphabet and space) and imitate the corresponding image on-screen in front of their webcam. The web app will read the image from the webcam and indicate whether the user's hand sign matches the chosen hand sign. Additional insight is provided through a list of possible hand signs that the user's hand sign could be misidentified as. Ultimately, Sign Lingo helps bridge the gap of communication that is experienced daily by those with mild-to-severe hearing loss by serving as an educational tool to learn ASL, hand sign by hand sign.
How we built it
The model is being trained through the use of Azure's Custom Vision AI. Through this model, we are able to export it as a Docker Container which makes use of Tensorflow. Thus, our React App mainly communicates with this Tensorflow Application in order to parse the images using the backend.
Challenges we ran into
One of the challenges we ran into was training the model. All of us didn't have prior experience with the use of Tensorflow and other Machine Learning Libraries and we all wanted to explore about Machine Learning in a little span of time.
Accomplishments that I'm proud of
Nevertheless, we're ultimately proud of being able to build such an idea. We hope that through ideas like these, we will be able to make the world a better place one step at a time.
What we learned
CHECK THE SLACK NEXT TIME AND REMEMBER TO SUBMIT THE GOOGLE FORMS SFJSAOJFAOI;FJA;OSDFJAS;JDFASDJDFAO;DFJA;DFJAS;JDASO;JFAS;ODJADS;DFNA;DFNAS;FHALEHFALUFHALIUHFA;HFA;FEHAEFUHALEUFHD
Through today's event, we mainly explored the horizons on what we could do through the use of Machine Learning. We also learned how to implement Tensorflow Applications in a Virtual Private Server setting while also integrating the use of a system webcam with a web application.
What's next for Sign Lingo
The immediate next step we want to take is to refine the app's webcam reader and ensure higher accuracy when reading users' hand signs. This way, we will give more precise and correct feedback to users wishing to learn and practice ASL. Eventually, a mobile app could be developed, increasing the ease with which users can access the tool and learn on the spot. Furthermore, we could aim to make Sign Lingo capable of not only reading individual characters but also entire strings that can be formed into words and sentences.
Built With
azure-custom-vision
python
react
tensorflow
Try it out
GitHub Repo
signlingo.jackhe.codes
signlingo.phillytan.xyz


Mockups
Inspiration
Since most lectures in university are at least 40 minutes long, students with attention deficit and dyslexia often find lack of support to excel at school. Shockingly, one in five students suffer from some form of dyslexia, and will face difficulties reading extended pieces of text. In an effort to increase their success in schoolwork, we have created Inky- an app that summarizes long lectures into short, easy to read summaries.
Inky can also help students with hearing problems to visualize the text of the lecture in real time.
What it does
Using Inky is easy! Simply open the app, and hit record. As soon as you start recording, Inky transforms the sound into text that appears on your phone screen in real time-- this is very useful for students that face hearing problems.
When the lecture is over, you can stop the recording and hit _ summarize _ -- Inky will start processing the long text file and convert into a condensed summary that you can export. You'll have an easier time reviewing for finals!
How we built it
Our product is developed on Xcode and everything is programmed in Swift. Speech recognition and transcription were executed through Swift’s foundation library and SF Speech Recognizer function. The summarization was implemented through an external Swift library, Reductio. Together, we made an action handler at interface that triggers each function chronologically.
Challenges we ran into
We struggled to import external libraries for many reasons. To import an external library we had to install and use Carthage, a dependency builder for binary frameworks, and move the Reductio’s framework over to Inky’s environment variables. After much struggling, we further realized that Carthage was not applicable for the following library we were trying to import. Thus, we installed and use another dependency manager Cocoapods, to import Reductio’s library. Eventually we were able to import Reductio using Cocoapods, but we still wasted a lot of time trying to just import a library.
Accomplishments that we're proud of
What we’re most proud of is our ability to make decision making based on a goal-orientated mindset. Our idea stemmed from the hacakthon’s theme: accessibility, and our decision to give up Python or writing original algorithms to summarize texts were discarded because of time shortage. We had idealistic goals, yet very practical.
What we learned
Time management and strategies for next hackathons. We realized that sticking to one programming language and one framework is best for hackathons. Our initial attempt to use Python for text summarization failed because we realized Xcode could not import Python code. We believe the best strategy for hackathons is to pick a programming language everybody is most fluent at, and perfect a simple concept.
What's next for Inky
Talky will be a great addition to existing Learning Management Systems such as Canvas, and Blackboard. This integration would allow the distribution of the lecture for all students in the class even if only one person records the lecture. For universities striving to achieve their inclusion support for students with disabilities, this integration is a significant step.
Built With
azure
cocoapods
foundationdb
reductio
swift
xcode
Try it out
GitHub Repo


Inspiration
Our parents often have trouble pronouncing words in English, making it difficult for them to feel included in their work environment. Moreover, having children who can speak English compels them to rely on them to speak for them rather than trying to themselves. We want to help not only our parents but other immigrants build a better sense of belonging and relief in a foreign area. Not only this but with the number of immigrants rapidly increasing in Canada, an easy to use and accessible application becomes more necessary.
What it does
Our application offers a free platform for non-English speakers to practice proper pronunciation, serving as a 24-hour teaching assistant that fits in your pocket. A pocket buddy that creates a safe space for you to make mistakes and grow. We take the user’s pronunciation and display any errors. Our ai displays what it believes the user is mispronouncing and shows what it heard, compared to what should’ve been said.
We differentiate from generic translation software like Google Translate, by offering not only translation but accurate cues on where you need to enunciate.
How we built it
We built this program HTML and CSS and served it with React Native webview. With accessibility in mind, we focused more on the mobile applications of our program. We are also implementing SpeechAce’s API as they have a well developed audio recognition and visual displays. We are also demoing the application on expo.
Challenges we ran into
Initially, we tried working with Wavesurfer.js, but we ran into many compatibility issues. Mid-way into the hackathon, we had to make the quick decision to pivot and use a new API -- SpeechAce. Even though we weren’t able to get access to SpeechAce’s API, we got around this by wrapping their demo website in an iframe and incorporated into our application. This way we could express our vision with the demo.
Accomplishments that we're proud of
As this is our first hackathon, we’re proud of how we were able to efficiently plan out the direction we were going to take, and delegate the work based on each person’s strengths. Compared to our experience in LiteHacks 2018, which did not require any coding experience, we have definitely improved our time management together.
What we learned
We learned the importance of goal setting and planning. With a solid schedule, we stayed on top of our goals and were able to finish with time left to improve. While working on our application, we gained a more in-depth view on how APIs function when we incorporated them into our project. Also, using Figma for early prototyping was a new experience for all of us.
What's next for Talkative
Our main vision for Talkative is to have a “language buddy”. We plan on making this happen by adding more complex features such as AI to allow for dialogue as opposed to just confirming pronunciation. In terms of short term goals, we hope to properly implement SpeechAce’s API into our program and expand our functionality to a wider array of languages.
Built With
css
expo.io
html5
javascript
react-native
speechace
Try it out
GitHub Repo


Inspiration
As experienced by our teammate Majka, pharmacies may not always recommend you the best over-the-counter drugs - if you already have a disease, they might sell you drug that is actually supposed to prevent it, not heal it, etc. On the other hand, patients often require their doctors to prescribe them with antibiotics, even when they are completely unnecessary (e.g. viral infections), which leads to drug-resistant superbugs. Our goal was to tackle these issues in an easy and accessible form.
What it does
Artemis is a chat bot that asks you a series of questions regarding your health and transforms them into your symptoms. Once finished, it will send them to the backend where the magic happens - symptoms are mapped to diagnose, diagnose is mapped to active substances and active substances are mapped to medicines. Those are sorted by relevancy and top 3 are then shown to the user as recommended treatment to their issues.
Naturally, shall we detect that symptoms are pointing to a more severe disease, we will immediately endorse seeking professional medical assistance.
How we built it
Our project is divided into 3 large parts - data gathering and analysis, frontend and backend.
The first and most important step was to gather data from various sources and process them to a more suitable form. Translation of symptoms to diseases was provided by Infermedica API. Unfortunately, we failed to obtain an application key in time, so we had to mock their servers. After specifying the disease, we searched through databases of European Medicines Agency and Medical Subject Headings of U.S. National Library of Medicine to determine which active substances are used to treat it. At last, we matched this list of substances with available medicines from ADC database of drugs in Slovakia.
We aimed not only for features, but usability as well. This is where our frontend shined - we have created a simple chat bot that asked you a tree of questions (starting with general one and asking more specific later on) and based on your answers built a list of your symptoms. To make our application more friendly, we also made our chat bot read questions loudly, hopefully making this experience a bit more personal.
Backend was where the magic happened. It glued all databases and services together and provided a list of medicines for given symptoms. One important thing was to make sure we were recommending only the best and most suitable ones. For that purpose, backend also had a scoring function that could tell whether given medicine is more or less suitable for a given person.
Challenges we ran into
Because not all databases provided APIs or developer-accessible formats, we had to write spider bots (web crawlers) to scan pages and transform raw HTML data into small and nice JSONs. This took a lot of effort as nobody on our team had any previous experience from it.
Another big challenge was chat bot. We could have used Google Dialog Flow, but it is not available for slovak language. Therefore, we had to design our simple bot from scratch. We ended up using simple tree structure so that we can ask simply questions first and complex ones later if necessary. As this was config driven, it was extremely easy to modify and add new options.
Accomplishments that we're proud of
Despite being inexperienced in both of the challenges we faced, we have managed to solve them not only in time, but with satisfying results.
What we learned
During the course of hackathon, we have learnt how web crawlers work and what it takes to convert raw HTML to valuable data. We also expanded our knowledge in data analysis and in interconnecting several unrelated sources of data to create a bigger and more powerful one. Last but not least, we have discovered an easy and lightweight way for creating simple decision-based chat bots.
What's next for Artemis
We want to enhance our chat bot with Google Text-To-Speech and Speech-To-Text to enable natural-like conversation and also make it much more easier for elderly and handicapped people to use it.
Built With
axios
express.js
google-cloud
infermedica
javascript
lowdb
node.js
vue


bible-4-devs
Bible Utility for use on the commandline by developers, hackers and terminal lovers in general. Built using Javascript and runs on Node. Blessed Hacking ;)
Usage
$ git clone https://github.com/oyamoh-brian/bible-4-devs.git [folder]
$ cd [folder]
$ node bible.js
Usage:
node bible.js [options]
Used Commands
```
--help, -h, --usage, -u : Show usage manual e.g node bible.js --help
--read, -r: Read a particular bible verse. node --read [options] 
    e.g node bible.js --read john --chapter 3 --verse 16
--read/-r usage example : --read john --chapter 3 --verse 16`

``` 
(The order does not matter)
Built With
javascript
Try it out
GitHub Repo


A picture of what our game would have looked like.
Inspiration
We wanted to make a financial simulation of life so young adults would be introduced to some important financial decisions that they will have to face in their future life.
What it does
Our simulation features a person walking through a screen going through life. This is the person making the decision and as time progress they will have to
How I built it
We built it using java.
Challenges I ran into
We ran into a big challenge which was time. We had a lot of great ideas and weren't able to execute of all them because of the short amount of time. However, we did the best of our ability and managed to get a lot of the algorithm and analysis down.
Accomplishments that I'm proud of
We were proud of having a really good idea and the fact that we were able to make a decent simulation.
What I learned
How important time management is.
What's next for Fin Sim
We hope to improve the visuals.
Built With
java
Try it out
repl.it


We have 2 university students in our team, and 2 grade 11 students.
Our Problem
We have been told that finding scholarships nowadays could be both difficult and discouraging due to scholarships being scattered everywhere and just simply have no motivation to apply. There has also been an issue where most scholarships are only available to Americans and not a lot available to Canadians thus the reason why our target audience are Canadians. We're aware that when most people are searching for scholarships, it's very difficult to find one that suits them (some scholarships asks for things like females only, religion, etc.)
Our Solution
We decided to create an app, where users are able to create their own customizable profile, and based on their profiles, we will send them all the scholarships that are available to them. That way, the scholarships will not be scattered everywhere and will just be in one place. We decided to make an app and not the website because we want the consumers to be able to access the app anywhere and anytime on their phones. We also realized that most people won't be able to keep track of how many scholarships they would like to apply and when they'll be due, and so we have a favorites feature, in which, they'll be able to click on the tab and apply for those that they have favorited, that way it'll be easier for the consumer to access instead of having to scroll through all the different scholarships. We will also be giving out notifications at least once a day reminding the applicants that there are an x about of days to apply for those that have not applied to the scholarships that they have favorited because we know as students, it can get really busy and hectic due to all the schoolwork and extracurriculars we would have to do. In order to motivate and encouraged the students to apply and use our apps, we will be creating a points system, in which for every 4 essays they have written, they'll earn 100 points which is equivalent to a dollar. However, the applicants are only able to withdraw the money once they have reached 1500 points. We understand that it is a long way, so we decided to put ads in our app to promote some companies, and in return, they'll provide the applicants with swags in between the 0-1500 points. That way, they'll be applying for scholarships while earning some money. Towards the end, we'll be congratulating those that have got accepted to the scholarships they have applied and to those that have written their application.
Built With
adobexd
Try it out
drive.google.com
docs.google.com


What it does
Tradize is an application to teach aspiring investors in a direct, effective and enjoyable manner. It provides a platform for both people looking to invest and people who are proficient at investing and wish to expand their outreach. Tradize uses a simulated investment system using "trade points," which can be used to unlock new courses and to demonstrate your proficiency and skill in investing.
Our choice of using the points you invest to unlock new courses stems from the belief that points reflect on how proficient you are with investing. Instead of learning at the same pace as everybody else in a typical class, where the speed and the quantity of the lessons may demotivate you, Tradize presents a new and innovative approach to learning about investing. Tradize assures that you don't feel overwhelmed by the amount of content yet to learn, while still always providing you with a solid set of courses at every level to help evolve your investment skills.
.xyz Domain
http://www.tradize.xyz
Built With
html5
Try it out
tradize.xyz
GitHub Repo


Main app builder flow
Why we chose this idea? We had numerous companies reaching out to Freshdesk to build their custom apps that often do very basic tasks. We wanted to change this and democratize the whole marketplace app development. Also more often than not the support admins are not exposed to coding and hence when they want to build an app they would have to reach out to developers. This will encourage more people to build apps and also provide an easy interface to do so.
How we built it? We built the frontend as a marketplace full-page app. The frontend component is built as a conversational flow so that everyone can understand the flow of the app they are building. The frontend component constructs a data structure and sends it to the backend. The ruby on rails backend has a parser that parses this data structure to develop and build the code. This code is written in the specified file structure, zipped and sent back to the app to download.
Challenges: The idea as a whole itself is a complex one. We had to write a parser that is modular and can handle multiple types of marketplace APIs and also make the framework easily scaleable across products. Also building the data structure in the frontend app components using jquery was a tedious task.
What does it do? It allows users to build their own apps using interactive UI and eliminates coding.
Accomplishments that we're proud of? Building such a complex app in time constraint of 36 hours
What's next for Scratch? This can be an important feature for the marketplace itself. Being a major differentiator for us. This will urge more apps being created and utilized which is a big win for us in terms of support for huge customers. Hence scratch can be extended to full capacity in the future.
Built With
javascript
jquery
ruby-on-rails
Try it out
GitHub Repo
GitHub Repo


Gadai BPKB Mobil Cepat Aman Terpercaya
Gadai bpkb
Gadai bpkb mobil
Gadai bpkb mobil cepat
Take over bpkb mobil
Simulasi gadai bpkb mobil
Built With
host
Try it out
pembiayaanbpkb.com


Inspiration
Humans tend to forget
What it does
Cues the user with reminders in the form of notifications. This extends to multiple FW products with different use cases and through different media of reachability, to ensure that the user is reminded.
How we built it
Timer can be configured in ticket details sidebar Timers are triggered (and also removed) globally via cti-widget A Backend express server which will send sms or WhatsApp when the timer ends.
Challenges we ran into
Restricted API, locators, Uniqueness of the application.
Accomplishments that we're proud of
Team-work, compassion & self-motivation.
What we learned
Learning a new language isn't an unsurmountable task.
What's next for Que
Advanced real-time integrations. Ticket Urgency suggestion using sentiment analysis.
Built With
express.js
jquery
twilio
Try it out
GitHub Repo


The app is available at the bottom of the left navigation pane.
Not kind of inspiration but why some products in freshworks do not have the features when compared to others. Anyway, the established product has more features than the new ones. So, we planned to build an existing feature to a new product. At first, we have a different idea, then we didn't know about the boundaries that each product has. So it is really challenging to build an app within the boundaries. So after changing our plan, we choose fresh sales without any idea about the product like how it works and features it has we choose to build certain features in it. At first, it took time for us to collect the resources and thereby we face many challenges to build it. What our app does is similar to a dashboard where the logged user can easily view certain activities. It displays the overdue tasks, completed tasks with name and link to the tasks of the particular week. It also has a reminder feature which will trigger an email to the logged user. Yeah, we finally built it successfully. All the members of our team are first time participants for the appathon/hackathon. The main reason we participated is not to win a prize but to learn something new so that next time we can win. We planned to represent details in charts and to create a todo list but became impossible because of the time constraint.
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for Task Manager
Built With
fdk
freshsales
javascript
Try it out
GitHub Repo


Projeto da equipe Sooouro para o Hackathon Solidário 2019
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for dev4change_easymoneycatch_sooouro


Inspiration
The need for instant credit scoring for an individual/ institution (SME) in Kenya (based on Machine learning) and give lower interest rates on loans and overdrafts as compared to digital lenders. Some banks and Saccos in Kenya that use traditional credit scoring techniques which is time consuming hence most people opt for more expensive but instant loans of the digital lenders
What it does
The machine learning algorithm predicts the probability that the applicant will pay back a loan based on a pre-trained model.
How I built it
The API is built using python programming language, XGB classifier algorithm and Flask
Challenges I ran into
The biggest challenge I had was in acquiring the data I used to train the model. Highly imbalanced data that lead to a highly biased model
Accomplishments that I'm proud of
I am proud that I was able to build the app despite the lack of data
What I learned
To be patient How to work with highly imbalanced data
What's next for KopaPap
I hope to expand this API to other East African countries within the next two years, and to other African countries within the next 5 years
Built With
flask
python
xgbclassifier


App home screen.
Inspiration
For Freshdesk or Freshservice customers, having a portal page is a must-have need. But currently, the default portal page offers only basic customisations. To edit something you either need to have deep knowledge of html,css and javascript or have to have to go to and fro with a third party to build your portal site. Waisting your time and money. We have a better way of building your portal page.
What sol do we have?
We have build a WYSIWYG GUI builder with which freshdesk admins can build, customize their own company portal themes portal pages on their very own without the knowledge of html,css or javascript.
How we built it
We used javascript with ember.js framework.
Challenges we ran into
Freshdesk used liquid html format to show dynamic content. It was a good challenge implementing a renderer engine that compiles liquid to html and vice verse.
Implementing dynamic preview to users interaction to the portal was also challenging.
What's next for Freshdesk Portal Builder
more custom components
javascript modules like one-click google analytics setup
support for freshservice
wizard-style Q&A theme builder
analyse a company website and build support page
Built With
ember.js
javascript
Try it out
GitHub Repo


Mr. Maulik Shah is the founder & CEO of CRMJetty, hub of innovative customer relationship solutions, provides ready to CMS integrate portal solutions for SuiteCRM, Sugar CRM, Salesforce, and Dynamics CRM. Maulik is a tech enthusiast and writes about the various aspects of ecommerce technology.
Try it out
www.crmjetty.com


Authentication page where you provide source and destination credentials
Inspiration
A single application for all sync use cases.
What it does
The app does the following in sequence:
Listens product events from source account
When an event is received it converts the source object to destination object.
The app checks if the destination object already exists in the destination account. If the object already exists then the app updates the destination object with the changes else a new item is created in the destination in near REAL TIME.
For this the app requires the following:
Source account details ie., domain, api key
Source object details ie., source object name, schema url, endpoint url etc.,
Destination account details ie., domain, api key
Destination object details ie., object name, schema url, endpoint url etc.,
How I built it
Created app using fdk cli tool that used the IPaaS backend service to transform the entities and create the entities in the destination
Challenges I ran into
Constrains defined by fdk platform. For example only https urls are allowed in client.
Adding multi select drop down. Had to search for a lot of bootstrap items that was compatible with marketplace. Further, the bootstrap must be hosted in cdn to access it from marketplace.
No .html is allowed other than iparams.html. This made creating multiple tabs tabs difficult and we had to go ahead with multiple divs.
Initially thought of having a endpoint URL from which schema can be fetched however, several entities had no endpoint for schema so had to put a text area to read the schema in platform specific format.
Accomplishments that I'm proud of
1.Creating the almost 3/4th of the platform service in 2 days.
What I learned
To some extent how marketplace works and what are its limitations.
How marketplace can be leveraged for sync use cases.
What's next for Simple Sync Service (s3)
Currently only a single item can be synched, it can be extended to multiple items
Also, only one single integration can be created. However, allowing multiple integrations to be created as part of the app will make it extremely useful.
Webhooks support from marketplace can be used to allow third party applications to sync to freshworks products.
Built With
css3
fdk
html5
javascript
jquery
node.js
Try it out
GitHub Repo


Demo
Inspiration
Enhancing Sales Agent productivity and making a day in the life of sales agent easy, one day at a time. One-stop point for the sales agent to start his day with a boom.
What it does
What does a Sales Agent do when he logs in for the day on freshsales?
Answer - He looks at leads, contacts, deals, calendar, tasks, phone calls and maybe a whole lot of conversations. Ain't this too much information for breakfast? Tired and confused, already? This tedious process of decision-making eats precious selling-hours which could have been used productively. To help save these precious-hours and help sales-agent focus on sales and not on decision-making, we are trying to have a positive impact on the sales cycle. Our smart day-planner solution provides a sales agent with a unified view of things to be done or review on a particular day. It will provide priority-based help to the sales team by suggesting to them which leads or deals needs immediate attention and which can be delayed.
How we built it
Using APIs from Freshsales and fullcalendar.io plugin
Challenges we ran into
Creating free time slots for work assignment
Dividing work entities into prioritized balanced buckets
Limitations of I-frame and dealing with fullcalendar.io
Accomplishments that we're proud of
Helping the sales agents plan their day and impacting their day to day life, so that they can focus on sales, and leave the enablement to us.
What we learned
Teamwork, collaboration, and delivering moments of wow.
What's next for Day Planner
Ability to add: mark as completed for each item
Provide daily digest email and feedback to the agent at the end of the day, so that he can plan better
Adding Machine Learning capabilities that learn from sales-agent actions during the day and provide him with ad-hoc items or suggests that he's wasting his time
Weekly, daily, monthly averages and historical data for the below parameters and a time-series graphical reporting dashboard for individuals
Work-Life Balance
Sales team most active hours
Heat maps of activities
Rolling average of activities completed by team vs individual sales agent's percentile
Time spent on each module of the CRM

Project the most productive hours for a sales agent.
Track analytics and metrics which can provide insights on the CRM usage on a user level (Sales-Agent)
Spillage of todo-items from buckets previous days and weeks
Configuring what they want in buckets and how do items get in buckets.
Try it out
GitHub Repo


Parent Allowance Setup and Review
Inspiration
As parents, as our children grow older, we open bank accounts for them. And we notice some challenges:
We don't carry cash anymore. How does a parent handle "quick" problems like a child asking: "I need $20 for the movies"?
When we do give our children cash, we don't know where they spend it, or how much cash our spouses have already provided
As our children enter their teens, do we want them carrying cash as they go out the door to buy clothes?
In a low interest environment, how can we help our children build the habit of saving money
What it does
Through a mobile Xamarin app that runs on Android, with some backend services:
It allows a child to request money from their parents, triggering a notification for approval for the parent
It allows a parent to transfer money to their child's account
Parents and children can view account balances
The functionality is built for financial institutions which support Finastra's FusionFabric.cloud US Retail APIs
Some features are currently mocked up, and not fully functional
It allows a child to setup savings
It allows both parent and child to track requests, transfers, and spending
It allows a parent incentivize the child to save by paying interest on savings
How we built it
We first mocked up screens on paper, and then built wireframes in Invision
We then developed what we could with the time available
Challenges we ran into
No knowledge of Retail banking, or the US Retail APIs
What does a transfer look like from parent to child
Accomplishments that we're proud of
Developing a PoC for an idea that, from our research so far, looks promising from a business perspective, and solves some of our own pain points in our own day-to-day banking.
What we learned
Our team has no exposure to Retail banking, apart from being consumers. We learned the FFDC US Retail APIs
The business. Some of us have children, and have these money/cash/allowance exchange issues, but we were not aware that others had developed solutions in other countries - to our knowledge, nothing like this is available in Canada.
One of us used C# for the first time
What's next for Yallo - A Youth Allowance Service
We need to assess interest and market. There are existing players who have demonstrated some success in the UK. Before building this out, we need to better understand the needs of the customers served by financial institutions who support Finastra's FusionFabric.cloud US Retail APIs
Confirm some assumptions about how we'd structure the accounts
Develop a sign-up process
Complete MVP
In terms of build, we would want to do more research into competing services, and define a model
We need to work with some prospective customers to determine how some features might work best, such as how to implement the child's savings feature (for example, do parents want to "enforce" savings?)
Built With
.net
android
appcenter.ms
azure
ffdc
fusionfabric.cloud
xamarin


We are a Singapore Fintech startup with innovation lab in Bengaluru and office in the US. Our artificial intelligence (AI) delivers conversational banking services that help banks and other financial institutions redefine their future digital strategy. The technology uses advanced NLP and machine intelligence to enable customers to have natural dialogues over messaging, voice or IOT devices.
At Active.Ai, we are taking the conversational experience to a deeper level of customer engagement for financial services institutions through our AI platform that are making the conversations beyond transactional. We are moving the conversations from reactive to proactive and predictive and from just a bot based conversation to a bot and human agents / relationship manager based collaboration. Our financial services industry expertise and attention to accuracy rates, particularly when dealing with a multiple-language, multiple-dialect environment, omni-channel presence and customer insight based on machine learning leads to a customer experience that is much more than what an application or portal can provide. We believe when customers communicate in a natural, conversational way they reveal more about their preferences, opinions, feelings and inclinations and our AI engine understands that and the bots act based on that learning.
There are several financial services institutions that are live with our products like Axis Bank, IndusInd Bank, Kotak Mahindra Bank, HDFC securities, Tata Capital, FWD (Singapore), NTUC Income (Singapore). We have several more which are under implementation across India, South East Asia, US, ME region and Australia.
Links for details / demo videos:
· One.Active - https://active.ai/one (Platform) One.Active available on Finastra Fusion Fabric Cloud - https://store.fusionfabric.cloud/details/one/
One.active.ai provides a self-service conversational AI platform for banks and credit unions with pre-built workflows, pre-trained datasets and pre-certified integration with Finastra.
Banks and credit unions can select features such as balance queries, funds transfers and others, configure business rules quickly, customize responses and branding and deploy to end users in a matter of weeks.
ONE by Active.ai provides full flexibility and control for creating retail banking conversational AI use cases.
· Axis Bank Aha: https://www.youtube.com/watch?v=WB36VDH1bnk
· FWD Faith: https://www.youtube.com/watch?v=f2-CpBFBo-E
· IndusInd Bank Alexa: https://www.youtube.com/watch?v=Z50PYYxd7aM
· HDFC Securities Arya: https://www.youtube.com/watch?v=wiy1uW5ymIE
· Kotak Mahindra Bank Keya: https://www.youtube.com/watch?v=a5axbmt36Gw
· NTUC Income IncomeShield: https://www.youtube.com/watch?v=Ul3xa2tNkXA
· APIX - Axis Bank and Active.ai: https://www.youtube.com/watch?v=OF86pHAhfPM
· Triniti.ai: https://www.youtube.com/watch?v=3Yysq43aesk
Built With
ai
bfsi
conversational
natural-language-processing
Try it out
flow-us.active.ai


Spatial Intelligence for Businesses
Inspiration
We often come across a situation where a person interrupts you to ask one of these questions:
"Bro, any idea where the meeting room Santa Maria is?" "Does the Mt Everest conference room have a TV?” "Ji, is there a printer somewhere nearby?" "Hey, on which floor does the Freshreports team sit?" "Do you know where Caleb’s place is?" "மச்சா, “டைட்டானிக் ” மீட்டிங் ரூம் எங்க டா இருக்கு?
Do you find a pattern in all of the above scenarios?
People are looking for important context when it comes to assets and spaces, i.e. “SPATIAL AWARENESS”
What it does
To help people get spatial awareness easily, we are bringing “SPATIAL INTELLIGENCE” to Freshservice by making use of assets and the relationship between them.
How we built it
Our appathon project will cover three important parts.
1. Creating and mapping spaces
PERSONA:
IT Admin
PROBLEM STATEMENT:
As an IT admin, I want to facilitate IT service agents to quickly locate where the assets are in the office.
TOUCHPOINT:
Spaces (Newly suggested module) In order to provide spatial awareness to the employees and IT service agents, they will have to create a digital replica of their office setup and map the assets to them. The IT admins can now just upload a floor plan (in the form of a png/jpeg image file) into the system, and create hotspots for spaces on top of them as required. Then these hotspots can be directly tied to assets (be it the employee/a device,etc.) This will come handy especially in organizations that span across different floors or buildings.
2. Locate assets in space
PERSONA 1:
IT Agent
PROBLEM STATEMENT:
As an IT agent I need to quickly lookup employee or asset locations and resolve issues faster.
TOUCHPOINT:
Tickets/assets details page The IT agent can now view any associated asset’s location from the “ticket detail page” or the “asset details page” directly.
PERSONA 2:
Requester
PROBLEM STATEMENT:
As a requester, I swiftly need to find people or teams within my organization. Or quickly find that meeting room without roaming around the office or getting frustrated.
TOUCHPOINT:
Spaces module from the self-service portal The requester can now login to his organization’s self-service portal and access the information from the module “spaces”.
3. Get spatial insights
PERSONA:
IT operations
PROBLEM STATEMENT:
As a person from IT operations, I would want to get a bird’s eye view on the status of the assets in my organization so I can take necessary measures.
TOUCHPOINT:
Spaces module Assets that are associated with any open tickets will be highlighted.
Business Impact:
Freshservice:
20% of Freshservice’s paying customers use Asset Management exclusively. By adding spatial intelligence to the existing list/relationship view, we can add more value to HR teams and Facilities teams of ESM.
HR TEAMS:
Locate employees and teams.
FACILITIES:
Achieve operational efficiency with insights from spatial intelligence.
According to ResearchAndMarkets.com, the global facility management market was valued at nearly $35 billion in 2018, with the expectation to grow to $59.3 billion by 2023. At a Compound Annual Growth Rate (CAGR) of 11.4 percent, this makes it one of the fastest-growing industries in the world.
Freshworks:
The same solution can be tweaked based on the domain and can be easily integrated into Freshdesk and Freshteam.
What's next for Spatial intelligence
Mobile app:
A persona focused mobile app which facilitates handy access to quick information on assets/employees/spaces.
Educational Institutions:
Self-service portal logins can be created for each student when they onboard with the spaces module enabled. They can use this module to search for classrooms, labs, auditorium or even where their professors sit.
Freshdesk:
For use cases like field service management. Just like how we map assets to space in Freshservice, we can map customers to space in Freshdesk’s FSM.
Freshteam:
Spatial intelligence can be scaled to HRMS vertical for managing locations of employees and teams. Represent org charts and employee time-off visually on space.
Challenges we ran into
Findings proper app locations for our project was a major concern as Freshservice didn't support full page app locations.
Accomplishments that we're proud of
Creating space and mapping assets to them, Insights from spaces.
What we learned
How to Iterate and brainstorm fast. And most importantly team work.
Links
Mocks: https://invis.io/ECV1Z2FK6NF
Presentation: https://docs.google.com/presentation/d/1OPoXPS2FtXSzUfm9gSx-ayOceTC6QivRw329ceIeLQc/edit#slide=id.p
Built With
css
html5
javascript
react
Try it out
GitHub Repo
invis.io
docs.google.com


Monthly View
Inspiration
The shorter way to do many things is to do one thing at a time and to do proper time management, what do you need? Do you need a PA? You just need an app for tracking your schedule. When it comes to hours in a day, we all have 24 hours.
What it does
Fresh Calendar App helps you to track the meetings, appointments, sales activities like traveling to customer's location, phone calls, marketing campaigns.
How we built it
We have used API exposed by Freshsales to collect tasks, appointments, and sales activity information for a user. Once we will fetch the data for all the users in a team, we will populate that data in the calendar.
Challenges we ran into
All three of us are backend developers and there was a major part that needs to be added in the frontend i.e. a full page calendar, and yes we wrote code in javascript for the first time. We learned new frameworks and utilities that are used in the frontend.
Accomplishments that we're proud of
Learning the basics and coming up with a working model on the same day was a big challenge. During the first 12 hrs hours, we lost all our hopes. We took help from multiple Frontend developers but nothing was working out. Finally, when we did it on our own, it was a proud moment for us.
What we learned
With teamwork, hard work, and a positive attitude everything is possible.
What's next for FreshCalendar
What's next -> FreshCalendar should have the capability to push notifications to the mobile phone and the browser.
Built With
css
html5
javascript
rest
Try it out
GitHub Repo


Customer starts chat asking about residential properties.
Inspiration
We were inspired by the Canned Forms feature in Freshdesk and not to mention the post in Ideation Platform about implementing it for Freshchat :)
What it does
In many scenarios, a fixed list of information is needed before an agent can help a customer. And doing this over chat can get cumbersome and inefficient with a lot of to and fro between the agent and customer. This can be solved by providing the agents with a set of canned forms to gather the information.
Canned Forms app allows the agents to create and save form templates in freshchat. Whenever needed, they can send across the form to the customer in a click and get back the consolidated response inside the chat window.
How I built it
We used the fdk to build an app that can allow the agents to create and save form templates and also list the available templates for use. We built a node js application to serve the form templates and to send the response back into freshchat.
What's next for Canned Forms for Freshchat
1) Maintain lists of personal forms and org-wide forms 2) Integrate the form to be rendered inside the freshchat window 3) Integrate freshdesk canned forms into freshchat if available 4) Allow form previews and easier editing options 5) Allow more field type options
Built With
node.js
Try it out
GitHub Repo


Inspiration: While I was running a digital marketing agency, I found that my clients always wanted my account managers to visit them and personally explain the campaign performance even though we used to send out a nice report with beautiful charts. On digging, I found that the clients used to get overwhelmed with the reports and found it difficult to understand them. That is when I started wondering what changes do I need to make to the report to ensure anyone reading it is able to understand it. What is it that my account managers do which solves this problem of understanding? Well, they interpret those charts and explain the insights in words that the clients quickly understand. How could I automate this process of interpretation of data and communication of insights in words? That is when the idea of building a product was born. And when I started thinking of the product I realized the enormous potential it had to change the way data was understood not just in digital marketing but in every other place where data was being presented, which was literally in every company.
What it does: Our product takes in any structured data, analyses it and then communicates the insights in words, as human beings do. Our clients use our product to prepare personalized narrative reports for their employees and in some cases for their customers as well. Ours is a SAAS platform where we integrate with the client systems via an API but in exceptional cases, we provide an on-premise installation as well. The personalized narratives which we generate can be customized to match the client organization's style of communication. The tone, diction, and style of the narrative are configurable. The analysis which gets done is also configurable. From the same data set, we prepare personalized reports, with the right metrics, for people at all levels in the hierarchy.
How we built it: We built the product using Python.
Challenges we ran into 1) Marrying data with language when NLP was not so evolved.
2) Client acquisition due to unawareness of such technology.
Accomplishments that we're proud of: Winning the - 1) CIO Choice for the best BI Platform,
2) India FinTech Award for the most innovative FinTech among numerous other awards.
What we learned: There's an immediate and profound need for insights in words as opposed to plain charts and graphs based reports since visualization based reports are prone to misinterpretation.
What's next for Insights from data in words - vPhrase: We have worked with any industry leaders in India and now we are aiming to expand globally.
Built With
natural-language-processing
pandas
python


Do-Do in action :)
Three backend developers wanted to experience appathon with one intention "I am still learning". Why Do do: 1. Free up your mental space 2. Organize it all. 3. Aligns with Freshworks culture "Take Ownership", "Happy work environment" by better planning.
Do Do
This app let freshservice agents login to their Google account and then let them create, read, delete tasks andc tasklists.
Pre-requisities
fdk - Freshworks Developer Kit
How to run the app?
Clone this app with git client. Add the client_id, client_key, key of your google app in the sample_oauth_config.json and add the contents in it to config/oauth_config.json. Start the app using the command,
fdk run
Testing the app
Then login to your domain https://domain.freshservice.com/helpdesk/tickets/1?dev=true. Test the app as mentioned here.
Technologies
Javascript
HTML
css
Google Tasks api (of-course)
Built With
css
google-tasks
html
javascript
oauth
Try it out
GitHub Repo


Inspiration
After using Siri for iPhone, google assistant on android, how about introducing an interactive voice assistant for Freshsales.
What it does
Makes life easy for sales representatives. "God Mode" is meant to give super power capabilities to freshsales. Freshsales will be able to interact to its users with the voice of "Zeus - God of sky and thunder". Users can perform handsfree functionalities like opening list pages, going to landing pages, creating LCAD, opening create forms, and many more. Currently commands are not enriched using ML and NLP but works like Alexa skills which are activated with specific words.
How we built it
Javascript, Css, Html. Native browser apis.
Challenges we ran into
Finding a simple speech to text converter and implementing same. Finding text to speech converter in voice of Zeus. Due to some issue in freshsales and fdk connector, post requests were hard to make with front-end apps.
Accomplishments that we're proud of
Well the assistant itself and whoever tried our product has one word in common for it "Wowwwww".
What we learned
Team-work beats one man army.
What's next for freshsales-AI.
With the help of more interface APIS, control the entire freshsales only through voice. Bring ML model for getting the user intent. And unlock unlimited possibilities.
Built With
css
html
javascript
Try it out
GitHub Repo


• We designed and created an phone app to connect philanthropical chefs to restaurants to host pop up events. Mainly during restaurants’ off hours, the restaurant owner can provide space for the chef. The profit will be split between the venue, chef, and to a charity of their choice.
• The app sets a limit so that at least more than half of the profit have to be for philanthropy and the actual percentage and the charity will be decided by the chef. The chef can apply to restaurants to host events and the general users will be able to pick established events to attend. Each established events will contain the information of the restaurant, the chef, and the charity it is for.
Built With
firebase
javascript
react-native


Everyone knows that Family Island Farm game adventure hack is important in getting free Rubies. Thanks to it is easier to get more xp and higher level. It isn’t a secret that spending your own cash on buying Rubies in game! Today we propose you to use our newest generator: Family Island Farm game adventure Cheats. Getting unlimited amounts of Rubies and Cash is now very simple. There is no need to describe more. We wrote down whole proccess in just few steps below. No one should have any problems using it. Simple build and intuitive interface will allow you comfortable use in only few minutes. Remember to have active internet connection. Our Family Island Farm game adventure hack works online, you aren’t downloading anything. Read the steps and use it!
LINK Here : http://bit.ly/33Aoq82
Trouble is brewing all over the country if you are not using Family Island Farm game adventure hack in game. DISCOVER A MASSIVE STORY CAMPAIGN Explore a massive world, gather warriors, creatures, resources, treasures, artifacts, and glory. Fight for justice and glory by leading massive armies into real-time ranged and siege battles. Choose the best formation ahead of battle and use your hero spells to turn the tide in your favor.
OUTPLAY YOUR OPPONENTS IN FAST-PACED PVP DUELS Order your units carefully on the battlefield and enter the PvP arena. Test your army’s strength and show off your strategic skills against other players with both asynchronous and real time multiplayer modes.
TEAM UP IN GUILD ADVENTURES & GUILD WARS True heroes never fight alone. Join a guild and fight alongside friends and other players from all around the world. Rush castles and take over ennemies' strongholds in epic PVP battles. Join the guild quests to reach the top of the guild leaderboard and collect rare loots.
COLLECT AND TRAIN MYTHICAL HEROES & UNITS Recruit various heroes from Might and Magic universe, each with their unique powers, weapons and artifacts. Collect, train and upgrade 40+ dreadful troops and creatures: Knights, Griffins, Archangels, Dragons, Orcs and many more.
IMMERSE YOURSELF IN A FANTASTIC WORLD Discover beloved heroes and foes, creatures and environments, in all-new colorful, anime-inspired 2D art style.
TAKE PART IN LIVE EVENTS & WEEKLY CHALLENGES Take part in a range of challenging Live Events to grind rare items. To help you reclaim the kingdom of Erathia, Queen Catherine has prepared many special bonuses, including super units, rare items and much more.


Inspiration
We wanted to give back to the small communities of animals shelters. We were also inspired by our collective love for animals.
What it does
It is a website that you can search for animals to adopt at your local animal shelters, find events in your local community to raise money for the shelters to support and take care of the animals, pair yourself up to an animal that matches your lifestyle and be able to make your own profile.
How I built it
Using html, javascript and Gatsby React
Challenges I ran into
Using Gatsby for the first time and learning React.
Accomplishments that I'm proud of
Learning to use to React.
What I learned
Learning to use React, javascript, HTML.
What's next for RescU
Develop it further so the user can create an account and work with Google Maps' API to implement the location feature.
Built With
html5
javascript
json
react
vscode


Reducify is an app created to reduce food waste from households. The app lets you input what items you have in your fridge, and it lets you scan your receipts to automatically add items to the app. The app keeps track of how old the food items are and when they will expire. Based on what food items you have and when they expire, the app suggests recipes you can make to ensure that you use all items before they expire. In addition it allows you to upload items that are about to expire to a sharing platform to allow other users to pick up the food for free.
Built With
jupyter-notebook
python
sqlite
swift
Try it out
GitHub Repo


Inspiration
A GRAAC.
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for dev4change_graacfy_leaodonorte


nodejs.org Website
This is the legacy repository for the previous version of the nodejs.org website.
To file issues against the current website, please use http://github.com/nodejs/new.nodejs.org/issues instead.
If you were looking for the source code repository for the Node.js open source software project you can find that at http://github.com/nodejs/node
Built With
makefile
nginx
Try it out
GitHub Repo


Loopbomb - Perpetual Art Machine
Inspiration
The intersection of Art & Gaming
Digital Collectibles
What it does
Loopbomb is a dynamically evolving artwork, an art mixing engine cycling through visual elements pulled from an ever expanding image bank. It's a game of luck, taste & timing where players can freeze & claim a temporal, unique art piece that's then registered to the blockchain as a digital collectible.
Images used in Loopbomb are either newly created or sourced & modified. All sourced images adhere to intellectual property & “fair use” guidelines relating to Collage art.
How We built it
Loopbomb was built by a small team of dedicated art lovers and technologists to promote the use of bitcoin & blockstack technology. Primarily it's a javascript SPA built using the Vue js. User data is stored in the users gaia storage, it also has a small websocket enabled server side spring boot java 11 micro-service that watches the bitcoin blockchain for payments for the loopbomb service. The service is hosted over https from a Debian VM on a linode cloud server.
Challenges
Retaining image quality on final render
Cross-Browser & Cross-device consistency
What We learned
There's always more than meets the eye.
What's next for Loopbomb
R&D on robust blockchain solution for digital collectibles
Streamline performance, UX & UI
More payment options
Promotions drive
Build team
Continually expand visual content
Integrate global gallery/secondary market for buying, selling & a ranking system
Port to iOS & Android app stores
Physical limited edition collectible cards
Built With
blockchain
canvas
cryptography
css
debian
gaia
html5
javascript
smartcontracts
vue-js
Try it out
loopbomb.com


Inspiration
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for Credit Sense
Creditsense is a relational Blockchain systems where database veracity is controlled by complicated cryptography, analyzing SME's repayment attitude with the use of structural and graphical approach, encouraging online individual and group system of lending and use credit scoring as a model tools to build individual credit power.


This is a Freshsales Marketplace app built during Appathon.
Goal: To build an voice assist system for agent.
Current Implementation: We have build an agent facing widget via marketplace, which can be installed on any of the freshworks product which have integration with marketplace. Widget is able to perform both on text as well as voice input.
WorkFlow:
Widget will collect the agent query, forward it to System42 via an API call, which will further be routed to ML to tokenize it and extract entities and send the response back to system42.
System42 here is a decision making system, which will do phonetic match, cleaning the response, adding the default operator, verify the confidence, etc.
Post that System42 will send the response back to widget. Marketplace app will forward the request to specific route and apply the filters as well.
ML role.
We have used RASA as infrastructure level to build our ML models. We have used only the NLU part for intent detection.
Entities for which we trained on
type (model_name / table name on product)
Operand (Attribute_name / field name on product)
Operator (operation that need to be perfomed)
values (Actual data) (could be name/date/number/currency)
We also have smalltalk intent
SYSTEM42 role.
We have used system42 as the decision making system. We are exposing an api to the marketplace app.Through this we will collect the customer query and proxy it to ml to identify the entities. Once the entities are collected, System42 will take certain decisions.
In the query the type should always be there. If not it will give unknown intent.
If Operand is there, then value should also be there.
If operator is not there, but operand and values are there, then it will insert the default value of operator if we have, otherwise mark it as unknown intent.
It will also take decision on confidence. System42 can tune intent confidence to get more better result.
Built With
css
html
javascript
Try it out
GitHub Repo


Inspiration
Life is more than just updating properties over and over again. That's why we built recent actions - the fastest way for agents to quickly repeat their recent actions.
What it does
The app eliminates mundane clicks, helping agents get closer to making the next customer in the queue, happy!
How we built it
We've built on Freshdesk using Marketplace sdk.
Challenges we ran into
Marketplace APIs
What's next for Replay actions
Support liquids in replies and notes.
Bulk select assigned tickets and bulk apply actions.
Search in the list of recent actions.
Quick actions for Merge ticket and Execute scenarios.
Automatically apply actions to similar tickets
Add liquids to quick actions
Allow choosing flows in quick actions
Undo most recent action (Reply, Note, Forward, Property updates)
Ability to Add Ticket reminders.
Just replay? Why not undo? - Build something that will undo anything in the product
Not just Freshdesk. Build it across products.
Built With
css
html
javascript
Try it out
GitHub Repo


Title
Inspiration
Why spending a lot of time in resolving the tickets??? When Machine Learning is here:) One of the major place where the agents spend a lot of time relies in reading the tickets. What if we use our Machine Learning model to summarise all the text present in the ticket body?? We strongly believe that it would reduce the resolution time of the agents.
What it does
Our machine learning technique would roll out a summary of each conversation in the text(every note or reply) . The text could be from any one - either the agent, or the end-user. No worries- our machine learning algorithm will roll out a summary for every conversation. We would also give out the overall summary of the entire conversation. If the agent likes the answer by our algorithm ,he can use the summary and update the ticket, or he could write out his own summary. Remember humans are intelligent than machines . :)
How I built it
We have trained an tensorflow model using CNN/Daily mail dataset- which contains millions of data. Since we faced a lot of challenges in the loading of the final ML model.(which requires a lot of processing) in marketplace., We have created an flask API which would load the model and serve requests and give out predictions for the text. We have hosted this external service using Ngrok to serve requests from the market place app. Coming to UI and UX, We have used technologies like javascript,html and cssto build the app. We have added an exclusive timeline for agents to know when the conversation has started and when an new event is updated in the conversation.
Challenges I ran into
Training the model - Had to use CPU to finish the training, would be better if we had GPU.
Dataset - We didn't have freshdesk data to train the model and give the real time summary.
Accomplishments that I'm proud of
Was able to train a tensor-flow model without the support of GPU I am sure that if we fine tune the model with a better Dataset and with a support of GPU it would create a moment of WOW for everyone. Was able to build something that would add a lot of value to the business and save a lot of time. Cleaning the dataset.
What I learned
How word embeddings works. How Freshdesk marketplace works. Tensorflow serving
What's next for Text Summarization Using Machine Learning - Data Pirates
We are planning to fine tune the model using our freshdesk data which would result in better accuracy and results.
Built With
bootstrap
css
flask
html
javascript
natural-language-processing
ngrok
python
tensorflow
wordembeddings
Try it out
GitHub Repo


Having 32 conversations
Inspiration
Text summarization is a hard problem to solve. It will be useful in a lot of use cases like summarizing a support ticket or interviewer feedback or an email. In Freshdesk, we have to read all conversations to understand a support ticket. In Freshteam we have to read all interviewer feedback to understand a candidate. How can we reduce an agent's effort to understand a support ticket or interviewer feedback quickly?
based on the above pain point we started thinking through it and started building a text summarization engine.
What it does
Text summarizer is a small microservice which will take input as text and summarize it. Frontend-app will be sending text as input summarizer will be summarizing the given text and send as output to the frontend-app.
How we built it
We wrote a LDA(Latent Dirichlet Allocation) algorithm which will give top N words from a topic, based on this top N words we will calculate clustering score for the sentences. Sentences will be sorted based on the clustering score.
 # tokenize all the data into sentences
 sentences = [s for s in nltk.tokenize.sent_tokenize(data)]
 # run LDA algorithm to get top N words
 top_n_words = LDA(data)
 # run clustering score algorithm to get top n sentences
 scored_sentences = score_sentences(sentences, top_n_words)
 # return only the top N ranked sentences
 top_n_scored = sorted(scored_sentences, key=lambda s: s[1])
 return dict(top_n_summary=[sentences[idx] for (idx, score) in top_n_scored])
Example: In the case of the Freshdesk ticket summarization, we separated the ticket summary into 3 parts.
Ticket description
Agent responses summary
Customer/requester replies summary
Challenges we ran into
Bringing the accurate text summarization for a support domain(freshdesk product) with the existing algorithms. Designing a proper frontend app UI which will imply to proper UX Learning new python libraries related to NLP
Accomplishments that we're proud of
We were able to make it work for the freshdesk and the freshserivce products with almost meaningful summaries : )
What we learned
We learned topic modeling, LDA(Latent Dirichlet Allocation), writing an app on the Marketplace platform.
What's next for Summarizer
Today we are doing only extractive text summarization. We have to extend this to abstractive summarization which will give a more semantic accurate summary.
Built With
javascript
lda-algorithm
nltk
python


Inspiration
When an employee joins a team, today, we're adding the new employee to mailing groups manually. Eg. When an employee joins as a Software Engineer in Freshteam, he must be added to mails groups like freshteam@freshworks.com, freshteam-engineering@freshworks.com, etc. This is not followed as a process too, that the employees are unaware that they should be added by someone in the team to the team group. So, the newly joined employee misses out any important notification that is sent to the team. We ourselves have experienced this when we joined freshworks.
What it does
We can configure a workflow which can assign google-groups to new joining employees automatically based on team, department or any other category. It also updates in google groups when an employee gets transferred internally, eg. When an employee gets transferred from Freshsales and Freshteam, they will be removed from Freshsales related groups and added to Freshteam related groups.
How we built it
We checked for APIs available by Google to do the necessary operations. Freshteam supports events on employee create and employee update. We utilized those triggers to add/remove from google groups. We use oauth to authorize the Gsuite admin. We use custom API params to get all the necessary workflows, and we store it in installation params of the marketplace app. It started as Freshteam - Google Group sync, but we were also able to do the creation of user on the google Suite, which reduces the manual process of creating email id for each employee who is joining the company. And that's how, our app is evolved.
Challenges we ran into
At first, we were not even aware that we can get custom installation params. It took us some time to understand the flow.
Well documented instructions for creating marketplace app and well-organized sample apps for marketplace helped us a lot. We were able to find solutions for our code struggles within our app if we spend some time on documentation and sample apps.
With very minimal pre-experience on js, and both of our team members are backend devs, we had a struggle to cope up with the marketplace serverless app which was completely dependent on js.
Accomplishments that we're proud of
We're able to do POC of Google groups at a fast pace and was able to do a minimum viable app.
Automating the user creation which will help reducing the burden of IT support people.
What we learned
Creating a marketplace app - This is our first marketplace app.
What's next for FreshTeam - Google group Sync
Based on Designation, we can make the new joining employee as an admin of the google group.
This idea can be extended to any other social channel like slack, etc. where the user would want to add new employees to groups/chat rooms based on condition.
Video links
For Employee Flow - https://youtu.be/l2OANfruFZQ
For New Hire Flow - https://youtu.be/9CoRj7jaBUk
Built With
css
fdk
html5
javascript
Try it out
GitHub Repo


Food Delivery App Development
A Young Entrepreneur and his Journey of establishing the Food delivery chain.
What Did He Do?
He partnered with all the local restaurants and hotels and built a multi-vendor food delivery chain; Foodiss. It converted the most common online food delivery solution into a unique and successful business.
Try it out
www.excellentwebworld.com


Automated Employee campaigns (Shown timeline screenshot from FM)
What Inspired us?
Putting ourself in customer shoes, 1000’s of candidates apply for our company every month and for every person who is offered a job, 100’s of them might be rejected. In which, quite a lot of those rejected candidates might be talented enough to be added to the Talent Pool for future opportunities. How do we keep those candidates engaged to make sure they are available for the right job in the future? Currently, Freshteam does not support such candidate engagement. What’s the right solution?
Solution and What we learnt?
We already have a solution called Freshmarketer, our in-house product. So, whenever a candidate is being added to the talent pool we can schedule regular campaigns such as newsletter etc., to keep the candidate engaged. Developing an app using the marketplace was awesome. The architecture and the way the marketplace was built to support various cases among multiple products just wow's us. It's completely a new chill experience which we gained and sure it will be useful to solve more ad-hoc problems among the Web apps :)
Challenges you face
As the problem statement says, Freshteam as a great product has very few support with its API's and support events. With what we have in the account, achieving our idea was really challenging and interesting in exploring various loops and new stuff.
About People Engage and Installation Steps
People Engage Project
Complete People engagement app which is used for sending out campaigns based on Freshteam events.
Description
Stay on the right top with candidate engagement with the right app on your web app. Schedule regular campaigns from your Freshmarketer based on the activity you perform on your Freshteam HRMS. What can we do for you?
1) Send out an automated Newsletter, Events etc., to your passive candidates.
2) On addition of new hire, send an automated notification on the onboarding process and etc.,
3) Automated grouping of employees based on your field preferences and with one touch fields sync between Freshteam and FreshMarketer. Send automated campaigns or events based on employee groups.
Instructions
1) Make sure you have a valid Freshteam and FreshMarketer Account.
2) Make sure you have proper API keys, for the respective app on the installation.
Installation Steps:
1) Login to your Freshteam Account and navigate to "Settings ---> App --> Custom Apps ---> People Engage".
2) Click Install.
3) Fill the domain and API key from your Freshmarketer. (For more information on where to find your API key please visit: https://support.freshmarketer.com/support/solutions/articles/8000076186-how-to-find-my-freshmarketer-api-key-)
4) Similarly, fill your domain and API key for the Freshteam account. (For more information on where to find your API key. Login to your freshteam. Click your profile picture at the top right corner. Click API Settings --> Copy Key to clipboard).
5) Click "Proceed" under your settings to Map the Fields to sync with your Freshteam and Freshmarketer. If you don't want to map any fields. Click "Skip and Submit" to proceed further.
6) After you are done with the above steps. Click Install. Hurrah :D !!! Happy Engaging !!
Built With
css
html
javascript
Try it out
GitHub Repo


Image recognition brings the deal details to the mobile app in real time
Inspiration
Deals are the most important module for any Freshsales user and it is vital to help them gather information about their deals quickly and easily in order to maximise productivity.
What it does
The app allows the Freshsales users to link their deals to the AR experience from the Freshsales webpage which in turn stores the deal data in our cloud database. Upon scanning their deal/product using our app, the corresponding deal information appears in the mobile screen. This saves the user time and effort to scroll through their numerous deal records in Freshsales page to obtain the desired information of the corresponding deal.
How we built it
We used the fdk to enable the Deals-AR integration within the Freshsales app. The server was built in Python using Flask framework for the deal data to be stored and in turn retrieved by the mobile app. We built the frontend for the mobile app using the Unity engine coding mainly in C#.
Challenges we ran into
We found it challenging to establish communication between the freshsales app and the mobile app and had to learn the basics of Flask overnight.
Accomplishments that we're proud of
We managed to set up a local Flask server which accepts and delivers data using REST calls, and then further hosted it in an online platform called pythonanywhere.
What we learned
We learned how to communicate between JS - Python and Python - C# using REST calls
What's next for FreshDealAR
We can allow the users to customise the fields they would like to see in the quick view of our mobile app.
Built With
c#
flask
html
javascript
python
unity
vuforia
Try it out
GitHub Repo


Top Lottery Management App
We were approached by the client to make an app that addresses the problem of the hustle happens while managing the lottery ticket number in Florida state. His thought was to combine all the lottery ticket numbers of the whole Florida state lottery at one place.
Gator lotto is a beautifully designed Lottery app that manages your winning numbers, informs you about the dates of the upcoming draw, and alerts you to jackpots worth playing.
Try it out
www.excellentwebworld.com


Car Rental App Like Tesluxe
Tesluxe is the luxury startup developed from the concept of luxury travelling.
Some very unique features were developed specially for Tesluxe. Every addition to the app and website was a planned move to improve either user experience or speed up the whole working. Sustainability was an integral part of our app and web development for Tesluxe. Just like the Tesla car, our app is also sustainable for every scenario.
Built With
android
codeigniter
ios
Try it out
www.excellentwebworld.com


Inspiration
Due to certain limitations in the discovery probe in Freshservice, it's difficult to automate the process of adding relationships to any asset. Hence, generally, users prefer doing a manual job. But this manual job process alone is little hectic when they have to add more than one relationship to different assets (it involves a lot of navigational operation and time).
What it does
Asset Relationship Builder - allows the user to manage the asset relationships from one commonplace rather than going to different asset pages and doing it manually for independent relations
How we built it
Brick by brick through our tears and sweat (from Pizzas and Redbull).
Challenges we ran into
We did not have a front-end dedicated person. We are a few backend developers and designers who don't have any idea about front-end coding. So that coding front-end was a challenge
Accomplishments that we're proud of
We were able to successfully complete the project
What we learned
Front-end coding
What's next for Asset Relationship Builder
Showing the impacts over any affected asset in any change or tickets
Built With
html5
javascript
Try it out
GitHub Repo


What's next for How can you get affordable translation?
Online affordable translation services let your translations be performed by professional translators thus ensuring quality. In comparison to traditional methods of translation (traditional being offline) online translations services always help you meet your deadlines because voluminous work can be divided up into professional translators (or can be performed by one depending on the content of work, and what client demands). Also, online translation services balance out the cost between translations of esoteric language and languages that are rifer. An online translation service is synonymous with low cost translation.
Now, how exactly do translations become affordable? Let online affordable translation services provide an answer for you:
The holy trinity of translations – Cost, quality, and time: Let’s discuss quality and time before discussing cost. When dealing with translations quality matters. Bad translations (usually done with automated translators) can cost you money – accounting for legal issues, loss of clientele, and thus reputation. Translations done by expert translators save you all these troubles and thus money.
The cost of translations from one language to another, as described before, depends on supply and demand. For example, translation from English to Arabic or Bulgarian runs cheaper than the other way round. However, this is where online cheap translation services help. It balances out the holy trinity of translation.
Good translators run a busy schedule – because of the paucity of what accounts as “good”. They do so because they have to meet their deadlines however, this also enables YOU to meet YOUR deadlines. Meeting targets leads to better rapport building with clients and customers while your decision making becomes easier, quicker, and regular. This invariably saves and makes you money.
However, with recent advances in machine learning and online automated translations “bulkiness” in translations has been made possible but the quality of translated output remains quite low. Phrases aren’t translated fully, colloquialism and cultural references are omitted, and let’s not discuss misappropriation of slangs.
balance out the cost between translations of esoteric language and languages that are rifer. An online translation service is synonymous with low cost translation.
In addition: Searching affordable translation in UK (or any other locations)” in Google? UK, US, Germany, or India quality translations in this day and age equates to online translation. This is also because of confidentiality, transparency, 24x7 services and accuracy they guarantee.
Easy to use: Online translation services are easy to use. All you need is to upload your documents, videos, or audios and the process begins. The files to be translated are sent to professional translators and they will ensure that the output in terms of quality is out of this world. Also, if you require a certificate of accuracy, and an attested copy of your documents online translations can easily provide them for you. Let us reiterate cheap certified translation services save you time, and money ensuring excellent quality. visit: https://vanantranslation.com/Kinyarwanda-Translation-Services.php
Built With
affordable
services
translation


Inspiration
learning evereywheree and fast and sure
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for takecare
Built With
javascript
react
tensor


Astrology Books in India
Shree Maharshi College of Vedic Astrology is situated in India, one of the most popular Institutes for Astrology, Palmistry, Face Reading, Tarot Reading, Palm Reading, Numerology and many related courses. We are offering the best astrology courses to the students at affordable fees. Our main objective is to provide quality astrology knowledge to our students.
Astrology Books helps much to get idea about basic knowledge of Astrology. We can provide Astrology Books in India for Beginners to help them to achieve success in their astrology career. Making career in Astrology is highly in trend these days. There are many courses available for the students according to their interests but Astrology is one where many students are getting admissions.
We offer Astrology Books for Beginners to get started to know basic theory about Astrology. We have various well known and famous authors of Astrology Books in India. Astrology books are written in simple terms with some basic concepts about astrology. We can offer you Astrology Books in English and Hindi for the students.
Contact: Website: https://www.mcvudaipur.com/ Address: 306, Arihant Plaza, Udaipole, Udaipur-313001 (Rajasthan) INDIA Phone: +91 2942427211 Mobile: +91 9829243211 Fax: +91 294 5102145 Email: mcvaadmission@gmail.com mcvaadmission@rediffmail.com
Social Links: https://twitter.com/mcvudaipur https://www.linkedin.com/in/vikas-chouhan-816a2816b/ https://www.facebook.com/maharshicollegemcva/ https://mcvudaipur.tumblr.com/ https://www.pinterest.com/mcvudaipur/ https://www.instagram.com/mcvudaipur/


Inspiration
70% of the Kenyan Population are farmers and most of these farmers do not have access to bank loans as most of them are in rural parts of the country.
What it does
connect farmers with banks and allow them to access instant loans on their mobile phones and decrease interest rates almost 10 times
How we built it
we used django framework and the finastra customer details api
Accomplishments that we're proud of
we were able to come up with an idea that can better our community
What we learned
we learned to collaborate with each other
What's next for PESA SHAMBANI
We plan to market our app through FFDC and pilot it in Kenya with a Finastra customer ahead of a global deployment in phase two
Built With
django
finastra
fusion
Try it out
GitHub Repo


Sample window that shows the ticket life cycle
Inspiration
C4L - Pillars of Customer for life theme
What it does
Solving one of the major problem in C4L called contextual engagement which provides contexts across Freshworks suite of products
How I built it
Challenges I ran into
Here you can visualize the entire journey or lifecycle of the ticket and proactively collaborate among the agents involved in the journey.
Accomplishments that I'm proud of
Able to run Freshconnect adapters inside marketplace-app
Proud that we solved one of the major pain points today with the customers who are using multiple Freshworks products.
What I learned
What's next for Eagle Eye
Leveraging this idea to capture collaborative contexts and Ticket contexts in chat widget powered by Freshconnect.
Built With
freshconnect
marketplace
Try it out
GitHub Repo


Inspiration
We thought this was a great idea to have a one-step solution that would integrate all the applications that are internally used in Freshworks.
What it does
When an employee is added in Freshteam then the employee account automatically gets created in Workplace and Fyle. On updating and Terminating the employee the respective accounts get deleted.
How we built it
It was built using FDK and the event triggers provided by Freshteam. When any change event occurs then the APIs to add, update or delete in Workplace or Fyle are triggered.
Challenges we ran into
Finding and working with the REST APIs for Workplace and Fyle was a challenge because they don't have proper documentation.
Accomplishments that we're proud of
Our App works :')
What we learned
We learnt that a lot can happen over 36 hours.
What's next for FreshTeam Sync
It can be integrated with other Org level applications like AllSec, Freshservice or any payroll applications.
Built With
api
fdk
freshteam
fyle
javascript
workplace
Try it out
ramyasathyamurthy-org.freshteam.com


Inspiration suksess
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for DethNote
gamer of money
Built With
chrome
facebook
gamercv
google
instagram
twitter


Inspiration
When I was in university I use to go to school every day but because course was in English it was not easy for me to under stand the what lecture was talking about so I change my minds and then I started to follow my friends who were software developer the teaches me how to code explaining in my language and finally I started to develope in android JavaScript php and python embedded c programming and finally I started yanjye website
What it does
What it does we write content of programming in language compared to the country like python in kinyarwanda in English in kigadanda
How I built it
The way how it bult there part of student and instruct and admin
Challenges I ran into
Challenge is if programming is explained in the language people understand very well it is not hard to them to learn
Accomplishments that I'm proud of
Now I have plate form and I have 100 student who are interested and learning with my plateform and 70% are ladies
What I learned
Passionate is the key of success when have passionate about what you want you can achieve every thing second iam trying to see how I can make language that can be used by blind person
What's next for Yanjye
Next of yanjye is to open branches in EAC
Built With
javascript
php
Try it out
www.yanjye.com


Inspiration
When an employee joins a team, today, we're adding the new employee to mailing groups manually. Eg. When an employee joins as a Software Engineer in Freshteam, he must be added to mails groups like freshteam@freshworks.com, freshteam-engineering@freshworks.com, etc. This is not followed as a process too, that the employees are unaware that they should be added by someone in the team to the team group. So, the newly joined employee misses out any important notification that is sent to the team. We ourselves have experienced this when we joined freshworks.
What it does
We can configure a workflow which can assign google-groups to new joining employees automatically based on team, department or any other category. It also updates in google groups when an employee gets transferred internally, eg. When an employee gets transferred from Freshsales and Freshteam, they will be removed from Freshsales related groups and added to Freshteam related groups.
How we built it
We checked for APIs available by Google to do the necessary operations. Freshteam supports events on employee create and employee update. We utilized those triggers to add/remove from google groups. We use oauth to authorize the Gsuite admin. We use custom API params to get all the necessary workflows, and we store it in installation params of the marketplace app. It started as Freshteam - Google Group sync, but we were also able to do the creation of user on the google Suite, which reduces the manual process of creating email id for each employee who is joining the company. And that's how, our app is evolved.
Challenges we ran into
At first, we were not even aware that we can get custom installation params. It took us some time to understand the flow.
Well documented instructions for creating marketplace app and well-organized sample apps for marketplace helped us a lot. We were able to find solutions for our code struggles within our app if we spend some time on documentation and sample apps.
With very minimal pre-experience on js, and both of our team members are backend devs, we had a struggle to cope up with the marketplace serverless app which was completely dependent on js.
Accomplishments that we're proud of
We're able to do POC of Google groups at a fast pace and was able to do a minimum viable app.
Automating the user creation which will help reducing the burden of IT support people.
What we learned
Creating a marketplace app - This is our first marketplace app.
What's next for FreshTeam - Google group Sync
Based on Designation, we can make the new joining employee as an admin of the google group.
This idea can be extended to any other social channel like slack, etc. where the user would want to add new employees to groups/chat rooms based on condition.
Video links
For Employee Flow - https://youtu.be/l2OANfruFZQ
For New Hire Flow - https://youtu.be/9CoRj7jaBUk
Built With
css
fdk
html5
javascript
Try it out
GitHub Repo


Inspiration
One of our friends was misled into believing that Apple Card had a low-interest rate and amazing benefits because they did not read the terms and conditions text. We decided to help solve this important issue by using NLP to automatically simplify and obtain the main points of terms and conditions texts.
What it does
TalkMoney uses NLP to read + analyze the terms of services of companies that offer financial services and summarizes it for people to understand
How we built it
Challenges we ran into
Training the model was incredibly hard as we only had a couple of hours. We had to constantly watch over it while we were training it. We also had to do some manual work to differentiate between "important" and "less important" information.
Accomplishments that we're proud of
What we learned
What's next for TalkMoney
TalkMoney was only trained on 1 PDF. For now, we can train TalkMoney with more PDFs and in the future, we can possibly use TalkMoney for financial documents such as the quarterly earnings of public companies
Built With
keras
numpy
pandas
python
pytorch


Inspiration
Many people around the world do not have the proper financial literacy skills to keep track of their own expenses. Seven personally, spent over $65 on Coco's bubble tea without any clue of how big of a hole he made in his wallet. This is why, we decided to come up with a product to encourage users to properly manage their spending habits.
What it does
Stacktrack utilises inputs from the user to track and analyze the statistics revolving around the user's spending.
How we built it
Using html5, bootstrap templates and github repositories.
Challenges we ran into
Resizing images, formatting, organisation, time constraints
Accomplishments that we're proud of
Finishing the website on time
What we learned
Time management, proper use of HTML5
What's next for Stacktrack
Receipt scanner, habit tracker, reward/punishment program
Built With
bootstrap
css
html5
javascript
visual-studio
Try it out
GitHub Repo


UI
When a lead is created in a territory, the lead will be assigned in a round-robin manner to the salespersons in the territory. Some sales person will be more experienced in that territory and can handle a lot of leads, some will be new and may find it difficult to handle the same level of leads. So we thought there is a need for load balancing. So we created an app which will get the skill level from the customer and will assign the leads to the sales person in such a manner that more experienced sales person will handle higher number of leads.
Built With
javascript
Try it out
GitHub Repo


Inspiration
When the value for a deal we were working on changed out of the blue, it made us think about how can we track these changes or give the power to the Account Admins to track changes and execute their own Actions on these changes.
We always maintain the current state of the record but using the historical states we can have more possibilities like change detection, more report insight and have more customisable workflows.
We are not having anything like app script to have easy reusable functions and scripts during the updation of record and easy access the scope without writing much things.
What it does
Hi-Story is having two components
1) Datastore for historical data 2) Script runner for running Action Group scripts
DataStore is having a historical track of data in a queryable and
The Global User History page gives an option to track User history on a filtered date range per module.
Hi-Story tracks User actions on a record, giving intuitive inputs on the actions performed by Users. The "Action Group" function allows Users to execute their own actions like trigger emails, SMS and custom scripts execution and sharing when a change takes place.
How we built it
We created Data Storage using elastic search and events for storing and retrieving data.
ES was used because it is more scalable and used for performing functions like sorting, search aggregation like count average and more advanced filter criteria.
For the script, we have used Node.js and Marketplace Datastore and wrote our own Dependency Manager and Executor. Context will be set for each run and having current user, Record context.
Challenges we ran into
Query construction in the elastic search based on the dynamic criteria selected
Full page apps are not supported currently for Freshsales which proved as a challenge to load all the UI components
Dependency management was complicated than expected.
Accomplishments that we're proud of
We could implement all the UI components in the small widget available
Built the app runner along with package manager and sharing in a single day
Datastore to have historical data
What's next for Hi-Story
More API kind of interface for datastore
Script runner to have more utilities and security mechanism
Built With
css3
elasticsearch
html5
javascript
node.js
Try it out
vaidhy-freshworks.freshsales.io


Inspiration
Reseller doesn't have any portal and unified management inside Freshsales
What it does
Respo calculates the commissions for each deal the reseller closes and generates the invoice and makes resellers to manage their own deals and fetch reports.
How we built it
Market place Application
Challenges we ran into
Limitations in the Market place application
Accomplishments that we're proud of
Unified Portal for reseller and generates an invoice through Sage Intacct (a portal for all finance-related payouts)
What we learned
Extensive integration support for all freshworks suite of products by Market place Application
What's next for Respo
LMS and Training material inclusion for the resellers and rewards for their completed certifications.
Built With
api
Try it out
GitHub Repo


Inspiration
The difficult journey of a customer to get their own data from Zendesk
No mechanism to export tickets for lower plans - (SMB)
Export is available only for higher plans
Even for higher plans, data export is disabled by default for the customers
Accounts with more than 1 million tickets are downloaded in JSON format only in 31-day increments. - No csv
CSV export doesn't have ticket description
XML export supports only 200k tickets
Zendesk community threads on the issue: https://support.zendesk.com/hc/en-us/community/posts/203437096-Ticket-export-tool-for-End-users-Export-tickets-by-organization-?page=2
In the rest of the doc, ZD refers to Zendesk and FD refers to freshdesk.
How can FD make use of this?
Build an ZD export App for all the customers
move their data from ZD to FD
Most of the customers expect a backup of their data before moving from ZD to FD, which turns out to be a nightmare with ZD
Act as the only platform available to easily export ZD data, thus providing a much asked ZD feature in FD - piquing the ZD customers' interest on FD.
What it does
The app accepts ZD domain, user_email, api token and exports ZD tickets as csv files and uploads to s3 and provides the s3 url to the user. It will also track from which freshdesk account, this export was initiated and ensures that a given account's data cannot be accessed by another account. The backend api server will run the export in background, thus enabling the server to manage multiple exports for different accounts at the same time.
How I built it
Ruby On Rails - backend Bootstrap components for the marketplace app localstack to mock aws s3 sqlite as db
Challenges I ran into
AWS S3 SDK for ruby does not have good documentation. This made it difficult for us to configure localstack with aws.
Zendesk SDK had dependency issues
We were new to marketplace apps and their constraints. We did not realise we had to build our app as a backend app for almost first half of the hackathon, realised it much later.
Accomplishments that I'm proud of
Configuring AWS SDK for localstack by going through AWS S3 SDk
Fixing Zendesk SDK by going through their source code.
Quickly realising we had to build a backend app and finally capable of finishing it within the timeline
What I learned
Building marketplace apps
What's next for Zendesk Account Exporter
Support authorisation for the export files generated
Support exporting all other entities.
Support time range
Built With
amazon-web-services
bootstrap
javascript
localstack
node.js
ruby-on-rails
s3
Try it out
GitHub Repo
GitHub Repo


Inspiration
Lead insights's business value is under-estimated
What it does
Makes the world easy for the sales people to know the deep understanding of the prospect whom he is dealing with in a single place.
How we built it
We build it with the help from the api provided from vendors like insideview, clearbit, uplead.
Challenges we ran into
We almost looked into as many as 30 lead insights provider, while we just had to narrow down to use only 2 as most of the api are paid.
Accomplishments that we're proud of
Most of our time, we spent on getting the right api. The fruit of the effort is great as the apis we have selected provides a information with an edge. Moreover, though we spent a huge time in api docs we were able to accomplish a completed / working project.
What we learned
There is a huge scope for Lead insights
Bad API Docs can eat your time
What's next for InSights Inside
Leverage API of paid partner will be a huge addition
Built With
freshmarketplace
node.js
sdk
Try it out
GitHub Repo


Employee Onboarding Parent Ticket View
Inspiration
To learn about fw marketplace app building.
What it does
When an Employee Onboarding request is raised, there will always be a parent ticket created and possibility of one or more child tickets associated to parent ticket that needs to be created. Freshservice currently creates all the child tickets parallel with the parent ticket at a time. This App allows agent to either let all the child tickets to get created parallel with the parent ticket or sequentialise the order of child tickets to be created one at a time such that the next child ticket in the preset sequence only gets created once the current open child ticket gets closed or resolved in order to prevent the SLA and handle dependancies.
How we built it
Using the fdk and freshservice ticket APIs.
Challenges we ran into
The existing freshservice API for tickets doesn't store any information related to child tickets and Employee Onboarding based tickets which if was present it could've made our job easier.
Accomplishments that we're proud of
It's the feature we tried to build which Freshservice hasn't explored yet in Employee Onboarding. We introduced sequentiality for child tickets of employee onboarding.
What we learned
How to build a marketplace app for any FW product. How to make best use of available FW APIs for building a productive app.
What's next for Employee Onboarding Sequential Child Tickets
1) Right now our app will allow to open a single ticket at a time according to the sequence set by the agent, We can also add creation of two or more child tickets at a time in the sequence. Example: {ticket1, ticket2}, {ticket3}, {ticket4, ticket5, ticket6}. Here first set of ticket gets opened first and following set of tickets will open when all the tickets in previous set are closed or resolved.
2) We are opening the next ticket in the sequence only when currently open child ticket gets resolved or closed, we can also add a condition such that the next ticket in the sequence will be opened when current child ticket goes into pending state. We can provide agent with the customisable conditions for opening next ticket in the sequence.
3) The App integration can be extended to a bigger view instead of having it in the ticket sidebar.
Built With
api
fdk
freshservice
javascript
json


Template Engine Screenshot
Inspiration
We drew the inspiration from an issue where the user wasn't able to change the page structure or layout ,because of inadequate knowledge about the CSS, HTML and also the cost of hiring developers just to do some minor changes to the existing page . We came across some websites (Support Portal ) which looks like a mess or broken page because of the improper change done (customising page) manually.And we also came across situations where user wants a page to display some additional information or to display a video content .
What it does
Template engine will provide you with an option of choosing the layout and styles for the Support Portal Page. The template engine will add an extra look and feel to your existing support portal page. It helps you makes the support portal page more interesting to the customer. The template engine also let you to create custom pages when you need an extra page . Template engine also let you add widgets to your pages and even to custom pages you've created . Let's say you need a video spiral in a page, Schrodinger's Cat (a.k.a. Template Engine) have got you covered !
How we built it
We built the app using the sdk provided by the Freshdesk. Template Engine was built on top of vue and jquery
What's next for Schrodinger's Cat : Template Engine
A thought for future:
Provide more customisation features changing position of elements
Drag and drop of widgets to exact location and position
Directly manipulate the portal pages using APIs
Create a bookmark for solution articles for agent
and much more ..
Built With
jquery
vue


Problems to solve
Struggle of tracking and paying invoices
Automate customer on-boarding for banks
Problem Statement - 1: Struggle of tracking and paying invoices
Operational overhead for corporations of manually tracking and paying the invoices from various suppliers
Incur late payment charges
Damage their supply chain relationships due to late payments
Resources are occupied due to manual processes and as a result couldn’t focus on their core functions like optimizing working capital
Problem Statement - 2: Automate Customer On-boarding for banks
Manual paper based processes for customer on-boarding resulting in lengthy time-to-cash cycles
Higher on-boarding cost for the bank
Loss of revenue for the bank
Excessive on-boarding turn-around time prompting customers to go to other competitors
What the solution does
The solutions scans the invoice images to map the input parameters of FFDC APIs with invoice information using AI (NLP) techniques and present the suggestions to the users for their review before calling the FFDC API to create payment
If required, users can also correct the suggested mapping before calling the FFDC API to create payment
The same solution is also extended to scan customer on-boarding forms to map the input parameters of FFDC APIs with on-boarding form information and present the suggestions to the users for their review before calling the FFDC API to push customer data into FFDC APIs.
Value proposition for corporations
End to end processing of invoices right from scanning different formats of invoices to scheduling payments using FFDC Payment Initiation Open APIs
Avoid late payments and charges
Streamline corporates’ payables operations
Reduce burden of manually tracking and paying the invoices so that freed up resources can focus on core functions
Value proposition for banks
Allowing banks to improve efficiency of customer on-boarding process
Reduces on-boarding turn-around time
Reduces cost by automating slow paper based process
Improved customer satisfaction
What's next for Manual to Automation
Multi-lingual support for input feeds
Store user corrections for future uploads
Extend the solution for handwritten invoices and forms
Extension of the solution to other pain areas and use cases
Built With
ffdcopenapis
java
natural-language-processing
python
springboot


Inspiration - Victim of fraudulent transaction
What it does - Validates Transaction using GPS location
How I built it - Using REST API, Android App and various online payment systems
Challenges I ran into - Getting exact locations of User and Fraud person and we overcame it in our application (FusionTrack)
Accomplishments that I'm proud of - Bank can provide additional security feature to all their customers for Online banking, ATM, POS, UPI transactions to avoid any fraud activities
What I learned - CyberSecurity is a mission critical part for our day to day transactions and providing this feature with FusionTrack will help to improve customer satisfaction.
What's next for FusionTrack - Integrate this API with FusionFabric.cloud so that it can be provided to bank as a one soultion.
Built With
android
j2ee
rest
spring


What it does
It's a workflow automations app that can do just about anything that Freshchat offers with its Webhook and APIs. A sample set of worksflows it can do:
Assign to first responder
Send first response
Send response on agent assignment
Send response on group assignment
Send response on resolution
Reopen on agent engagement on a resolved conversation
Auto respond based on user message ... and a limitless number of possibilities.
How I built it
It's a serverless app that processes a set of rules that are configurable in the Marketplace Apps settings page. While the settings page is built using Ember, the serverless component is built using nodejs. We split the job of building the app into 3, each of us handling independently testable modules. But for that, we needed to have a solid contract, and that is what took the longest time to agree upon. In the end, the Frontend was completely handled by Imthihas. And the nodejs code was split between Ajay and myself (Arun).
Challenges I ran into
We had to figure out how to load an Ember app in the custom iparams page. It was a challenge to build the complex UI that allowed a multitude of customizations in a short duration of just a few hours. It was a challenge all the way to figure out the hidden/buggy capabilities of Markeplace APIs and Freshchat APIs.
Accomplishments that I'm proud of
Super proud of my teammates for having stuck together and stayed up all night to see it working. In the process, we got help from a bunch of folks and offered help to a few.
What I learned
Nothing is impossible.
What's next for Amma - The mother of all apps
Conditions are currently limited to messaging events and can be extended to time and user events Actions are limited to sending a message (extended to sending quick replies- actions), private notes.
Built With
ember.js
node.js
Try it out
GitHub Repo
GitHub Repo


Inspiration
Inspired by solidarity to help a hospital that saves so many lives.
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for dev4change_graaccp_AmDevOps


Mock for the unassigned tickets queues
Inspiration
Current auto-assignments (LBRR and SBRR) happen based on incoming time of tickets. Urgent and High priority tickets coming in late suffer SLA breaches due to late assignment in a long queue!
What it does
Admin creates custom Ticket Views using the filters and sort options and configures these views in the app. This app auto-assigns the tickets of this view in the same order.
Challenges we ran into
Real-time assignments, agent availability management, assignment only for tickets with group assigned
What's next for Q Priority
Single place to view the unassigned tickets queue in multiple views, option for the agent to pick up next ticket in the queue explicitly, assignment for non-group tickets.
Built With
javascript


Inspiration
Children have very limited possibilities of cashless payments. They need to have cash.
What it does
Our solution allows cashless payments, which are accepted (or not) remotely by parents. It also allows to make and control savings.
How I built it
Solution works in cloud - children and parents are communicating through it by get/post requests. All payments and accounting are made through FFDC.
Challenges I ran into
It was challenging to prepare whole workflow with exact communication schema and scenarios.
Accomplishments that I'm proud of
We have managed to prepare also iot button for children which (for any reason - for example school regulations) cannot have (or use) their mobile phones.
What I learned
We have learned how to write programs for iot buttons and also some other tips regarding working with http requests
What's next for FusionFabric.child
It can be expanded by adding new features like selecting a toy (or other target for savings) from e-store using ebay or amazon api. AI can be used to estimate time after which child will save for each product - it can vary in time depending on inflows and outflows.
Built With
ffdc
iot
java
javascript
pwa
python
socket.io


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for MODPLAY.iO - TOP 1 Website Download MOD APK Games and Apps
Website: https://modplay.io/
Fanpage: https://www.facebook.com/modplay.io/
Youtube: https://www.youtube.com/channel/UCXPNDfp6p4iBSCK-NFXbgow?view_as=subscriber
Twitter: https://twitter.com/MODPLAY_IO
Built With
apks
html


Inspiration
We have been inspired by day to day work on customer implementation projects. There is a lack of predictability for a project status in different project phases.
What it does
The pilot helps to predict when project becomes "red", based on the historical data of defects from previous projects, and suggests potential actions to prevent the crisis.
How I built it
Provide feed from the following sources to ML: from Jira with extraction of defects' backlog from closed and live projects. PowerBI to provide a dashboard with project statuses WIX to present the idea and flow
Challenges I ran into
Data collection process and how to define indicators for the model creation
Accomplishments that I'm proud of
TBD
What I learned
TBD
What's next for Project success prediction
Model extension to take into account the following parameters/inputs/indicators: 1.Prioritization of customers according to customer profile/ranking
Use test packs and automation ratio of Finastra and customers
Use OpenAir resource time allocation
Use Salesforce escalation indications
Built With
jira
ml
openair
powerbi
wix


Inspiration
Currently available payment apps do not provide a platform for users to split a bill and pay immediately. One person needs to pay first and keep a track of all the dues. This leads to petty arguments and headaches about who owes what to whom.
What it does
PAYSAP is a real time smart app which is designed to split the bills and make payment in real time. The bill is shared and paid in real time from multiple users to a single recipient. The application possesses its own E-wallet which can consolidate the transactions made from all the users and convert that into a single payment. This wallet amount is then credited in the recipient’s E-wallet. This application’s payment gateway can be linked to any other payment mode. With PAYSAP, you’ll be able to keep the peace between friends by cutting down on squabbles.
How we built it
We built the User interface using microsoft powerapps and integrated it with multiple APIs. The API sources were power app's push notification API which sends a notification to user's phone and asks to accept/reject payment request. We have incorporated two FFDC APIs -
FFDC Payment Request (PSD2, STET) (1.3.0) API for Initiating Payment Request
FFDC Payment Request-Pay Now, Pay Later, Reject (1.0.0) API to respond to real time creditor payment request
Challenges we ran into
We are all from testing background so developing a new app from scratch was the major challenge. Secondly understanding and connecting all API's with UI was complex but it git solved wiih help of mentors and tutorials. Also we had to squeeze out time out of our normal working hours.
Accomplishments that we're proud of
We built a successful prototype and were able to execute all we thought of doing.
What we learned
Working in Team Thinking out of box solutions for daily life challenges Learnt new technologies
What's next for ASAP
Credit Card Bill payments Uneven bill splitting Connectivity with applications such as Big basket, BookMyShow, MakeMyTrip, Oyo etc. can be incorporated. Transaction tracking
Built With
api
mobile-java-push
ui
Try it out
letusknowyourmsid.com


FASILITAS TRANSAKSI YANG DISEDIAKAN OLEH SITUS JUDI ONLINE
Permainan Judi Online di Indonesia telah mengalami kemajuan yang cukup drastis. Saat ini berbagai macam situs judi yang menyediakan berbagai macam permainan seperti judi bola, poker online, bandar ceme, domino qq, judi togel, judi casino, live casino, judi dingdong online, tembak ikan, judi slot online dan masih banyak lagi permainan judi lainnya yang ditampilkan. Berbagai macam bandar judi telah membuat segala sesuatunya sebaik mungkin supaya para member dapat merasakan bermain judi layaknya di casino darat pada umumnya. Untuk itu para bandar judi dan developer games judi selalu memiliki kepanjangan yaitu agen judi online yang akan berguna untuk memberikan pelayanan yang terbaik bagi para member yang ingin bermain judi secara online. Bermain judi casino yang dulunya hanya bisa dinikmati oleh orang-orang kaya saat ini sudah bukan mustahil lagi seluruh lapisan masyarakat dapat juga merasakan permainan judi dan dapat menggandakan uang mereka.
Tertarik bermain judi online, tapi takut sulit melakukan deposit ternyata tidak juga karena sekarang melakukan deposit di situs judi online sangat mudah dan telah diberikan berbagai fasilitas untuk melakukannya. Memang belum semua situs judi online memberikan kesempatan yang sama bagi setiap membernya untuk melakukan deposit dengan berbagai pilihan. Namun saat ini sudah banyak juga situs judi online yang menawarkan deposit melalui fasilitas berikut:
Via ATM / Banking Pastinya anda sudah mengetahui metode yang satu ini. Umumnya, para pemain judi online melakukan transkasi dengan metode transfer dari bank ATM ataupun internet / moble banking. Seperti yang kita ketahui bahwa sangat mudah bertransksi menggunakan mobile banking. Selain itu juga cepat dan praktis. Melakuan deposit via ATM, internet Banking dan Mobile Banking adalah hal yang paling umum dilakukan karena dinilai paling dipercaya dan sudah pasti nilai yang diberikan akan sama dengan nilai uang yang di transfer. Tentunya hal ini juga berpengaruh karena Deposit dengan uang asli masih merupakan alat pembayaran yang paling sah.
Via Pulsa Metode melakukan deposit dengan menggunakan pulsa smartphone yang anda miliki menjadi salah satu alternatif bagi para pemain judi online. Jadi, bagi kalian yang tidak memiliki mobile / internet banking namun pulsa di dalam handphone anda banyak, maka anda dapat memanfaatkannya untuk bermain judi online. Caranya sangat mudah, anda cukup menanyakan hal tersebut ke Livechat dari penyedia situs judi online tersebut. Tentunya deposit dengan pulsa tidak berlaku untuk rate satu banding satu. Oleh karena itu akan ada rate yang berlaku untuk mengubah pulsa menjadi kredit judi online. Namun, untuk proses penarikkan / withdraw tetap akan di transferkan ke rekening yang telah anda daftarkan.
Via Aplikasi Nah, baru – baru ini situs judi online mulai mengikuti perkembang zaman yang ada dan metode transaksi dengan lebih mudah. Seperti menggunakan DANA, OVO, GO-Pay atau aplikasi apapun itu yang berbasis untuk bertransaksi. Sangat praktis sekali tentunya, jadi anda dapat bermain dengan mudah, cepat, dan proses transaksi juga lebih efektif dan efesien.
Dengan banyaknya pilihan bagi anda untuk melakukan transaksi deposit, sudah pasti kemudahan dalam bermain judi online menjadi semakin terlihat. Apalagi saat ini untuk bermain judi online hanya membutuhkan modal yang sangat kecil. Maka jangan takut lagi untuk bermain judi secara online karena semuanya sudah dibuat sedemikian mudah dan sederhana.


Inspiration
Tedious process of getting a loan online requires providing a lot of information which our banks already have. PSD2 kind of APIs can ease the process much giving a possibility to autmate it. After filling all of the required fields it takes time for the Bank to judge what is the customer's current situation and decide if he can get the loan. This process includes validation of the provided information, check with 3rd party vendors about credit history and such. In case when the loan submission will be rejected, the customer is put into situation where he must repeat the same process once again from the very begining but at other bank or online store.
What it does
Open's new opportunities for cooperation between Banks and stores. Introduces the SPI which can be implemented by a store to provide recomendations. Those recomendations are fetched with some criteria to find alternative products for which a customer can take a loan. AI engine matches recomendations with customer expectations defined by the initial product he wanted to buy. Together with rejection the bank can respond with new pre-processed options of loans or alternative products with a lower price. By doing this the store can keep the customer and the bank still have a chance to sell a loan. Offered alternative products are already pre-processed so it is guaranteed that a loan will be given what improves customer experience who isn't required to repeat the whole process one again.
How we built it
Our solution consist of few elements.
Store which offers some goods
Front-end in Angular and back-end in Java (Spring Boot). The store exposes an API which is complient with a SPI we defined. Thanks to this SPI other vendors could integrate very easily. The SPI defines a way to fetch recommended products when the customer is not able to complete a process of getting a loan successfully.
Bank which offers loans online
We have developed a sample bank application with a front-end written in Angular and back-end in Java based on SpringBoot framework. The app allows a customer to get a loan online. Filling a form has been automated with a usage of APIs exposed in FFDC. Summary page, displayed to the user after the loan submission rejection, contains a list of pre-processed alternative products which user can buy, taking a loan, with a single mouse click.
3rd praty bank which authorize the customer
A front-end application which represents another bank where our customer has an account and from which we can fetch a customer profile. By doing this our application automates the process of gathering information from the customer, who doesn't need to provide them manually anymore. The only thing he needs to do is to login to his bank, and consent the access to his sensitive data. To impement that we've used Account Information (US) and Customer Profile APIs which are exposed by FusionFabric.cloud platform.
Challenges we ran into
Access to customer's sensitive data requires his consent. PSD2 APIs exposed by FFDC have implemented a consenting mechanism, but due to the lack of some priviledges it was eaiser to use US alternatives.
Accomplishments that we're proud of
We have delivered running software, with decent visible business value, giving understandable presentation, starting the hackathon without a clear idea of what we gonna do, enjoying the event!
What we learned
With a tight time constraint we had to cooperate efficiently to deliver that much stuff. This nicely integrates a team of people who are technology enthusiasts.
Built With
angular.js
finastradesignsystem
fusionfabric.cloud
fuzzywuzzy
java
psd2
springboot


Inspiration - The recent versions of Google Chrome support offline browsing though the option to easily access the cached version of any web page in hidden deep inside the settings. So this inspired us to build an offline version of Freshdesk
What it does - The agents will be able to view his/her open tickets inside our full-page app. Along with it, the agent can view all necessary ticket details and all its conversations. The agent can reply to the customer and add a private note in offline mode. And that's it! The agent can deliver uninterrupted service with our app!!
How I built it - When the app is initialized, we store all the agent's tickets and its conversations in Browser storage. And when the network connection is intermittent or completely offline, the agent will be able to view all his/her open tickets inside our full-page app. We render a ticket list page in the full-page app. Clicking on a ticket will load a modal which contains the necessary ticket details.
                       The modal has an input area that allows the user to reply to the customer or add a private note. When the agent replies or adds a private note, we store the content in the browser storage, when the app goes online and the agent accesses the app page during that time the failed requests stored will be retried.
Challenges I ran into - Did a lot of study on offline mode apps. We had to think of workarounds when a few things didn't work in platforms
Accomplishments that I'm proud of - We are really proud of the amount of effort and learning happened when building this app
What I learned - Progressive Web Apps, Cache API, Service Workers
What's next for Offline Support - Turn into a complete PWA and add more functionality in offline mode. Make use of IndexedDB to store large chunks of data
Built With
javascript
vanilla
Try it out
GitHub Repo


tamminhduong-logo
tamminhduong
Built With
fluid-ui


What it doeOn 18th January, 2020 we're organizing Hackathon on Indic Languages in partnership with Nasscom - #RevHacks- a day long event of fun challenges.
The event will include certain challenges to be brainstormed by all product makers who love building innovative products to provide solutions for Indian language internet users and help to bring language equality on the internet.
Join RevHacks at Nasscom Bangalore, as we work through a series of challenges, learning and having some fun! competing in teams of up to 4 people. We'll supply the food, fun diversions, prizes, and some expert guidance in the form of our engineers.
This event is open to Startups, IT professionals, Makers, Growth Hackers, Innovation experts and students studying in the Bangalore and select nearby cities.
Winners of this Hackathon will walk away with Rs 1 Lac cash at the end of the day. There are other perks provided to all participants.


Inspiration - Avoid unnecessary stimulation when we want to focus-on something
What it does - Engage the agents to be in HYPER Focus mode which will help to reduce distraction time which in turn increases productive time.
How we built it - Built full page marketplace app to have clone of ticket and ticket details page to enable hyper focus mode.
Challenges we ran into - Main purpose of doing the app is to provide focus mode for FD Tickets and Ticket details page. And that is not technically feasible to access DOM of FD page, created clone of above mentioned pages to meet the goal.
What's next for Focus-On App - To make it as full fledged paid feature for all products of Freshworks
Built With
bootstrap
css3
html5
javascript


Inspiration
การหาที่จอดรถเป็นเรื่องยาก
What it does
สร้าง Application สำหรับดูว่า ณ ตอนนี้เหลือที่จอดรถช่องไหนบ้างในอาคาร
How I built it
API Gateway, Lambda, DynamoDB
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Smart Parking Application
Built With
amazon-web-services
node.js


Built With
css
html
javascript
Try it out
GitHub Repo


Inspiration - This project was inspired by the poor quality education system in Nigeria
What it does - This will be a monitoring and evaluation system that will serve as an intermediary system between Parents, Teachers, and Governing bodies to enhance quality and up to standard education for students. This project is geared to improve the quality of the educational system in Nigeria.
How we built it - Our system is built with HTML, CSS and PHP as the scripting language. Also, the bootstrap framework technology is used to get an awesome user interface.
Challenges we ran into - Resources, getting firsthand information on the school system.
Accomplishments that we're proud of - We were able to enlighten the audience about our idea.
What we learned - We learnt about the core of Nigeria education system
What's next for Monitoring and Evaluation System - Proposing the system to the federal government to use, in other words growing our education system.
Built With
bootstrap
css3
html5
javascript
Try it out
GitHub Repo


Weather forecast result for Miami, Florida
Inspiration
I like what Blockstack is doing, and I feel I can make a difference here
What it does
Search for local weather anywhere in the US
Draws forecasted area on the map
Displays scrollable 5 day forecast
NEW! Mappit! automatically searches the same forecasted area for any severe weather alerts and will display them before the standard weather forecast. This includes any special instructions issued by the National Weather Service.
View the locations of major wildfires in the US
Displays the technical name of the wildfire and draws its boundaries on the map - this data is updated on a regular basis.
Search local restaurants with Zomato (domestic and international)
Get contact information, overall restaurant rating, see the menu and more!
Create custom map pins
Pin data saved to Gaia - not Google
Categorize your pins so you can view only the pins you want to see
Add a title and some notes to each pin (optional)
Drag the pin anywhere on the map before saving to have a more exact location
Get Directions
Pins & Restaurants
Get custom weather with the click of a button (Custom pins have weather buttons automatically added)
Get directions to or from any pin (including to or from any other pins) with the click of a button (Custom pins have directions buttons automatically added)
STACKABLE
All data points (weather, custom pins, fire, restaurants, etc) will stack on the map one after the other. You have a button that allows you to clear the map at any time. This allows you to stack data points on top of your map so you can gain more insightful information about your targeted area.
For example, if you're going on vacation, you can create some custom pins for those must-see tourist attractions. Search the area for restaurants, then create custom restaurant pins to mark those gotta-try restaurants. Curious about the weather in those locations? Just click the weather button on any of your pins, or go to the weather menu and search for weather in that area. Your forecasted area will be drawn on the map so you can see where your pins are in relation to any forecast!
How I built it
I just sat down and wrote it
Challenges I ran into
I think user education on the way Mappit! interacts with various APIs - especially coming from Google - is the toughest challenge with this. The app is easy and straight forward to use, but obtaining the level of faith from the user to know that, without question, their information and usage is not being tracked, is another deal altogether.
For that reason, I built an FAQ section that explains how these processes work in a way that hopefully both novice and more advanced users can understand.
Accomplishments that I'm proud of
I did all this in 15 days. I would have gone further this month but its holiday season so my time is a bit more limited. I plan to do more though.. no worries :)
What I learned
It is possible to write a decentralized application around Google Maps
What's next for Mappit!
Lots.. International Weather Hurricane / Severe Weather Tracking More data around wildfires if possible (The US wildfire data I'm looking for is almost impossible to find) Australian Fire Data Add more restaurant data providers so information is not biased to just Zomato Create your own categories for custom pins Public transit routes worldwide ...and more!
Built With
google-directions
google-geocoding
google-maps
national-weather-service
zomato
Try it out
mappit.guru


Inspiration- the constant lack of communication between people and wildlife.
What it does- provides a platform for both the public and officials to communicate on issues concerning wildlife.
How we built it- combination of java and css5 to create a website
Challenges we ran into- time is always a challenge.
Accomplishments that I'm proud of- actually participating in the event.
What I learned- critical and out of the box thinking literally.
What's next for Team Exploit-learn more and hack more
Built With
css
javascript


Explore projects from Portfolios and hackathons


TEST whole story
Built With
testsdk


Inspiration
Make our life more easy while testing REST APIs
Help create ready to use test and demo templates (BAs and clients)
Use pre-configured test workflows to create your keywords for automation in 1 step
What it does
Enables you to create your test workflow templates and avoid navigating each time through different specs and filling mandatory parameters
How we built it
HTML5,CSS, javascript
Challenges we ran into
Using internal Finastra APIs and datasets
Accomplishments that we're proud of
Save up to 50% of your time spent on running your REST APIs
Templates can be re-used by other teams or in demos
Easy to configure - out of the box solution can be easily configured to any REST CALL.
Can be used on top of FusionOne REST APIs but also for all Fusion Solutions which use REST FWK
Re-use pre-configured test workflows to create your keywords for automation in 1 step
What's next for Keeler
Extend it for Fusion Pricing and Analytics tests and automation
Use Keeler templates during demos for products where Swagger is the main interface (eg: Fusion Quant Pricing, Fusion Pricing, Fusion Calibration Engine & Curves)
Built With
css
html5
javascript


Inspiration
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for Stand Buy
..
Built With
angular.js
asp.net
c#
javascript
Try it out
GitHub Repo


Inspiration
We are a group of people with different backgrounds and diverse mindsets with one thing in common, the goal to revolutionize the e-commerce world into a simpler world, as simple as having a chat with a friend, only a very helpful, extremely intelligent, and an always available friend, the one we all favor. We offer a solution for the complexity of the modern shopping experience and the difficulty that faces the unsophisticated to participate in the e-commerce world, we offer this through Yara, the middle east's first online shopping assistant.
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for Yara


Inspiration
The first and second sustainable development goals are our primary inspiration. We want to help create financial wealth through investment. By this intention, we building a platform that offers the opportunity to individuals, households or organizations to create financial wealth as well as investing in sustainable food security.
What it does
stocklyft crowdsources funds from its users. Invests the funds into farming and pays back the users with returns on investment over an agreed period of time.
How we built it
Currently, the platform is a web app.
Challenges we ran into
Earning public trust as an early company is our primary challenge at the moment.
Accomplishments that we're proud of
Partnered with our first farmers.
What we learned
People know the importance of agriculture and when given the opportunity in ways that they can easily adapt to, they invest their best into it.
What's next for stocklyft
Improving our users' standard of living financially and increasing food production to zero hunger in the next ten years.
Built With
java
javascript
node.js
php


Inspiration
One stop service for sales and consumption
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for Any...POS
Built With
.netcore
c#
webapi
Try it out
drive.google.com


Purpose
To display descriptive statistic of London crime rate.
Dataset:
https://www.kaggle.com/LondonDataStore/london-crime https://data.london.gov.uk/dataset/statistical-gis-boundary-files-london https://data.gov.uk/dataset/759f6fcb-934a-464e-a45c-eced2f5fcf67/local-authority-districts-december-2016-full-clipped-boundaries-in-the-uk-wgs84
Shiny Apps:
https://mazhalini07.shinyapps.io/CrimeRate/ https://rpubs.com/mazhalini07/datapolice
Github:
https://github.com/ami-sm/London-Shinyapps
This project is done in group during Introduction to Data Science


Inspiration
Data collection on stock list and prices
What it does
Goes to https://www.thestar.com.my/Business/Marketwatch/Stock-List/?alphabet=**X** to collect stock list. Then, it goes to each of the stock index https://www.thestar.com.my/Business/Marketwatch/Stocks?qcounter=**X** to collect stock data (board, stock code, open, high, low, last, change, change%, and volume)
How I built it
I used beautiful soup to crawl and pgAdmin to store data.
Challenges I ran into
The website coding structure keep changing, so the crawler must be keep updated. Crawling in dynamic table and dynamic page. To understand which data is important for data collection process Run the crawler everyday.
Accomplishments that I'm proud of
Completed within one week
What I learned
Understanding of stock data
What's next for Crawler: TheStar Stock-List
Data analysis on stock data
This project is under active development.
Built With
python


Công ty nội thất Aline tự hào là đơn vị thi công nội thất văn phòng được nhiều doanh nghiệp lựa chọn nhất năm 2019. Chúng tôi với đội ngũ nhân viên thiết kế, chuyên gia thi công nội thất văn phòng có nhiều năm kinh nghiệm sẽ giúp bạn có những không gian làm việc tốt nhất.Với sự phát triển không ngừng, hiện nay ngày càng có nhiều doanh nghiệp trú trọng đến không gian làm việc của nhân viên nhằm nâng cao năng xuất lao động cũng như kéo tài lộc về cho công ty.
Tham khảo: https://aline.vn/bao-gia-tu-van-thiet-ke-noi-that.html 
Chúng tôi nhận thiết kế, thi công nội thất văn phòng uy tín, chuyên nghiệp ở các quận, huyện trong khu vực Hà nội với mức giá rẻ nhất thị trường.Đội ngũ kỹ sư, thiết kế nội thất chúng tôi với tay nghề nhiều năm kinh nghiệm chuyên thiết kế nội thất, thi công văn phòng công ty, xử lý cải tạo nội thất văn phòng làm việc đẹp, thi công nhanh chóng và bảo hành sau khi bàn giao.
Tư vấn, thiết kế và tính toán chi phí chính xác. quan trọng hơn cả là mang lại hiệu quả cùng lợi ích cao nhất cho mọi Doanh nghiệp thông qua việc cung cấp ý tưởng & giải pháp tốt nhất.ALine cung cấp dịch vụ thiết kế phòng giám đốc, văn phòng nhân viên, công sở.- Thiết kế nội thất phòng giám đốc.
- Thiết kế nội thất tiền sảnh.
- Thi công lắp đặt nội thất văn phòng.
- Cải tạo nội thất văn phòng làm việc.
- Cung cấp bàn ghế văn phòng chất lượng cao.
- Sửa chữa tôn tạo nội thất văn phòng.
Chính vì vậy, Công ty Aline chuyên cung cấp các giải pháp như: thiết kế văn phòng tại Hà Nội trọn gói, thiết kế văn phòng tại tphcm giá rẻ.Hãy cùng Aline tham khảo 50 mẫu thiết kế nội thất văn phòng tại: https://aline.vn/ để cập nhật xu hướng thiết kế mới và có thêm những ý tưởng giúp hoàn thiện không gian văn phòng của mình. 
Built With
caitaovanphong
noithat
phong
thicongvanphong
thietkevanphong
van
Try it out
aline.vn
aline.vn


Modernst is one of the best office suppliers products in Dubai. we are providing best quality products at the reasonable rate. our comprehensive products is being used in offices as daily needs. we arranged a wide variety of office accessories and stationary products to the clients office equipment suppliers in uae and you can choose the better one. Our sop is hvaing all the basic products needed in the office as like the furnitures and the other equipments. The customers come to our shop is treat as our family member and we are giving them best products. We have various brands and varietys of products as with different budgets. Then we are providing online shopping also for the clients and we will reach your products as safely and with as a guaranteed products.


We have a project for ALPR parking system Learn more at https://www.sztigerwong.com
Try it out
www.sztigerwong.com


A short break on new posts due to an important work project. Would be really exhausting, overwhelming! Appreciate understanding. Will try my best to put my effort, at the earliest. Thanks for support.
I would complete my Prototype.
Accomplishments that I'm proud of participating in this Hackathon event.
SMART SECURITY
Built With
arduino
c


A short break on new posts due to an important work project. Would be really exhausting, overwhelming! Appreciate understanding. Will try my best to put my effort, at the earliest. Thanks for support.
I would complete my Prototype.
Accomplishments that I'm proud of participating in this Hackathon event.
SMART SECURITY
Built With
arduino
c


Inspiration
[TBA]
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Triwizard Tournament
Built With
c#
unity
Try it out
GitHub Repo


I am a student who loves to program. My last site was made to find various anagram combinations in just a few seconds. You just type the word and wait for it to be unsrambled.
The project works by inserting any word and then selecting the number of words we want to get. In less than 1 sec you get over 100 tell which anagrams are the initial ones.
Built With
mysql
php5
phpmyadmin
Try it out
word-unscrambler.online


Inspiration: exposed the wealth of date functionality we already have to other applications
What it does: currently it:
adds periods to a date
finds if a date is a holiday
finds if a bank is open on a certain date
finds when the rescission date occurs after a specific date
How we built it: using C#, asp.net, swagger, and Swashbuckle
Challenges I ran into: Couldn't get onto FFDC due to short time-frame and requiring help from people in Europe, no experience in the area we worked in
Accomplishments that I'm proud of: We got the app with the functionality listed above and quite a bit of additional functionality build in the short time-frame, we successfully posted the service on Azure, and got the ball rolling to put it on FFDC
What I learned - How to work with controllers, integrating with Swagger, the architecture for front-ends, API, FFDC, and back-end services
What's next for DateMagic: expose more date functionality and add time functionality, add models for the endpoints, get it on FFDC,create a simple front-end to exercise the API so it is available in an easy-to use format anywhere.
Built With
api
asp.net
c#
swagger
swashbuckle
Try it out
datetimemanagercoreserver20191204013129.azurewebsites.net


Inspiration
YouTube does not allow you listen to videos on background. And this is a real pain for me. I often find a lecture or a talk on YouTube that I’d like to listen to while I’m walking somewhere. All other YouTube to MP3 converters are not mobile friendly at all. You need to do acrobatic tricks, copy-pasting the link, finding the website, walking through the mine-field of ad banners and waste 15 minutes of your life just to listen to YouTube on the background.
What it does
I’ve built a Telegram bot, that is always pinned to the top of my chat list. I can share a YouTube link directly from the YouTube app and get it converted in a few minutes. It’s way more convenient and easy to use than any other app I could find.
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for YouPod
Built With
dokku
next
node.js
Try it out
youpod.app


Inspirationggg
What it doesggg
How I built itggg
Challenges I ran intoggg
Accomplishments that I'm proud ofggg
What I learnedggg
What's next for Ghost Riderggg
Built With
appian


This project was bootstrapped with Create React App.
Available Scripts
In the project directory, you can run:
npm start
Runs the app in the development mode.
Open http://localhost:3000 to view it in the browser.
The page will reload if you make edits.
You will also see any lint errors in the console.
npm test
Launches the test runner in the interactive watch mode.
See the section about running tests for more information.
npm run build
Builds the app for production to the build folder.
It correctly bundles React in production mode and optimizes the build for the best performance.
The build is minified and the filenames include the hashes.
Your app is ready to be deployed!
See the section about deployment for more information.
npm run eject
Note: this is a one-way operation. Once you eject, you can’t go back!
If you aren’t satisfied with the build tool and configuration choices, you can eject at any time. This command will remove the single build dependency from your project.
Instead, it will copy all the configuration files and the transitive dependencies (Webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except eject will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.
You don’t have to ever use eject. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.
Learn More
You can learn more in the Create React App documentation.
To learn React, check out the React documentation.
Code Splitting
This section has moved here: https://facebook.github.io/create-react-app/docs/code-splitting
Analyzing the Bundle Size
This section has moved here: https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size
Making a Progressive Web App
This section has moved here: https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app
Advanced Configuration
This section has moved here: https://facebook.github.io/create-react-app/docs/advanced-configuration
Deployment
This section has moved here: https://facebook.github.io/create-react-app/docs/deployment
npm run build fails to minify
This section has moved here: https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify
Built With
css
html
javascript
Try it out
GitHub Repo


Restaurant Profile Application
This is a simple React Native Application for Restaurant Profile.
How to run
Clone the repo and Run the following commands
npm install
npm install json-server -g
Open a command window or Terminal and type
json-server --watch db.json --host 0.0.0.0 -p 3001 -d 2000
Download the expo app from App Store or Play Store
Open another Command window or Terminal and type
npm start
a QR code will appear in the browser scan it using the smart phone, this will open the app in the expo
Built With
java
javascript
objective-c
python
ruby
Try it out
GitHub Repo


Inspiration
In many countries specially-abled individuals are requested with assistants to go in person to bank for physical identification and perform basic banking operation. In a world with much advanced technologies there is no unified solution help them to perform basic banking operation. The main objective for FinVA is to provide a platform where we can build banking application which are fully specially-abled friendly and create an inclusive environment. Voice interaction is a gateway to help improve personalization and the digital experience Voice technology has reached a stage where it started to disrupting the existing way of working. With technology companies applying for banking license and launching payment products they become clear competitors for traditional banking products. AI should be able to elevate customer experience.
80% consumers are satisfied with voice shopping experience 20% - 30% of mobile phone search are done by voice Voice shopping is expected to be around 10% of all mobile e-commerce. Make consumer experience convenient i.e) should not search for Sort code, Bill Payment due. It should be accessible by asking for it. It is not about answering basic customer support activities using chat bot instead doing all branch and customer transactional activities with voice. Preference towards voice technology is due to convenience and ability to engage hands free! Cost rationalization Reference: Pwc-voice-banking. • Free up front line branch staff • Reduce call center call volume • Minimize mid-/back-office operations
What it does
FINVA provides the platform based on ML & AI to enable voice assistance to any product. The user will be able to instruct the system using natural language to perform most of the operation. The transactions can be secured using additional authentication using any modes I.e) Face ID, Finger print, OTP or password. As a proof of concept for the platform few scenarios from customer retail banking are explained. Integrate next gen technology without much change to the core product.
How we built it
Started visualizing the concept based on one market demo. Built from scratch on iOS tech stack but can be easily moved to open tech stack like Python. Created a data based on the requirements of the FinVA. Converted the data to ML model and trained the model using python/CoreML, with accuracy of 80%.
Challenges we ran into
There are many challenges even small things like text to speech, speech to text, Natural language processing using ML and providing a chat like look and feel and many other challenges :-) Creating a seamless, user friendly chat like experience to consumers like their digital voice assistants ex: Siri/Alexa/Google
Accomplishments that I'm proud of
Using NLP to convert the natural language used by the user into a command specific to the application.
What I learned
Learning about ML the subset of AI Usage of NLP (natural language processing) Making sense of users language to a meaning full command and be able to execute it.
What's next for FinVA
FinVA is a platform using which the voice banking concept was explained. But the potential for this product is huge as it can be easily extended to other Essence suite of products and beyond. Voice technology will extend for both front and back office results in more efficiency which translate into competitive pricing for customer.
Built With
avfoundation
coreml
ios
json
sirikit
swift


Inspiration
I wanted to build a game that incorporated newly acquired skills for ISP.
What it does
This is a game of strategy where the user is in charge of an army. The user chooses the direction that the army moves and at each direction choice, there is a group of enemy soldiers. The user then chooses how many soldiers to fight with. There is a randomized modifier added to the battle party so it is possible for a smaller party to win a battle, it just has a smaller chance.
How I built it
This is an Alexa hosted skill written in javascript. It utilizes ISP for a one time purchase as well as consumables.
Challenges I ran into
I have previously written a skill that had consumables, but have not done a one time purchase skill. It was interesting to see how they can be implemented.
Accomplishments that I'm proud of
I am proud of the time frame it took to build the game. It was done over the course of a few weeks.
What I learned
I learned how to implement one time purchase ISP.
What's next for War Path
I would like to modify the skill to store personal high score and possible create a public leader board.
Built With
alexa
ask
javascript
json
node.js


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for CreatexStudio
I got inspired by learning and practicing what i learned, being a develop tho is one of the coolest jobs. yeah i said it.
It's an e-commerce store where sales of gadgets, electronics, wears are being sold online. still in the process of finishing it tho. i fix a countdown timer with pure JavaScript tho, cool UI too.
Challenges i encountered; in building the dropdown, yeah!. it came tough.
Getting to the point i'm in my project. yeah that's my accomplishment.
I learned alot.
Finishing it to an e-commerce store.
Built With
css
html
javascript
Try it out
GitHub Repo


Inspiration:
3 years ago, some friends and I attended our first hackathon, and made a strange little game called Waluigi Dating Simulator as a joke about how much of a meme Waluigi is. We ended up having a lot of fun making the game, and received a lot of positive feedback, so we decided to make a 2nd version the following year, with a new story and improved graphics. Unfortunately, my friends couldn't make it to help this year, but I didn't want to let the legacy die. So I present Waluigi Dating Sim 3 :)
What it does:
This game takes place at Western with you playing as a Western first year attempting to win the affections of Waluigi, your residence soph. However, there are rival suitors who are also attempting to win Waluigi's heart, so be careful! You must completely and properly vibe with Waluigi in order to win his heart!
How I built it:
I built it using Renpy, a visual novel engine. The code is done in python with all sprites being hand drawn by myself.
Challenges I ran into :
I was on my own coding and making the hack, meaning that it was difficult with time management and getting everything done on my own. As a result, I had to make some cuts to things I originally wanted to add, such as more details and design features.
Accomplishments that I'm proud of:
I made a working game in 36 hours on my own, with it running smoothly with no major bugs or errors.
What I learned:
In the future, if I'm doing such a hack on my own, I'll be sure to downsize on my original plans and manage my time better.
What's next for Waluigi Dating Simulator 3: WAH Takes On WESTERN:
There's potential for some improvement and the lengthening of the game. I was really hoping to add mini-games, more characters and more possible endings. Furthermore, I will definitely be making a Waluigi Dating Sim 4 at the next hackathon I attend! :)
Built With
python
renpy


Inspiration
Problem Statement
Transactional duration while Shopping in Retail malls can be time consuming as it involves large queues – all for a unified purpose: Invoicing. ‘Scan & Bill’ for each product at counters constitutes an important part of the Invoicing process.   Solution :
As a part of mitigating the underlying issue – we are designing Mobile App that provides user options to select the Outlet being shopped in as well as centralized payment gateway benefiting users & countering the problem at the same time.
Users can: Get billed through application by scanning the product Bar code code while shopping. Pay via methods - UPI, Credit/Debit cards, Reward points & generate invoice for the purchase. On completion of payment, users will be awarded with points that can be redeemed for future purchases.
Advantages :
Saving time of customers & crew by eliminating the concept of Counters at outlets. Saving money & man-power for the Outlet vendors by lessening the queue at counters. Unified Reward Points System - a centralized system where customers can redeem at will for any transactions done at Outlet.
Built With
ffdc
powerapps


Download Spool Query
Problem Faced Bank Urgency and priority TAT for issue analysis is increased Waiting period for Spool of database Dependency on environment Time Difference
This Project Provides below information This is a web application to download the sql output in the .csv file. User Enter the Query in the application and click the submit button. Spool of the query download in the csv file.
Feature Web Application User Friendly web Portal 24/7 Information available Reduce dependency TAT will reduce
Built With
j2ee
java


Business Monitoring Dashboard
Problem Faced Real time information of application not available Not able to monitor application at runtime by operations/Management Difficulty in decision making
This Project Provides below information Application details like Application date, Eod in process, Previous application date Processing Status of file upload, download ,Event Count of Transactions Yearly and monthly Search information like Account description, Mandate description after entering the Key Count of master like client, Mandate, Account Features Web based API application User Friendly web application 24/7 Information available Real time information
Built With
j2ee
java
restful-web-services-financial


Inspiration
We always try to automate common day today activities which are repeatative in nature to save the time.
What it does
Liquibase is a tool which used to deploy database release changes. Liquibase has a predefined XML file format for each type of database object. For a developer its a challenge to create these scripts manually and takes significant time.The utility will reduce the time from 3-4 minutes per script to 30-40 seconds over for 130 objects release we can save 3+ hours.
How I built it
I myself faced the time challenge in script generation so build a tool using Visual Basic.
Challenges I ran into
Not much
Accomplishments that I'm proud of
Many of the Finastra team mates are using this tool and they are very happy and look at the utility as a life saver.
What I learned
Learned the end to end functionality of Liquibase tool which was new to me.
What's next for UTILITY TOOL
Currently its a desktop base application. We will be enhancing the utility to work as web based portal so that everyone can access it from around the globe within my company and start using the same.
Built With
visual-basic


Family Island Hack Mod – Cheat Family Island Rubies You were probably looking for this new Family Island Hack Cheat and starting from today, you can use it. In this guide, we are going to give you some info regarding the game, and after that we will tell you why is it so important to take advantage of this Family Island Cheat. We hope that this guide is going to help you a lot and we are confident to tell you that you will be able to use this tool, every time you want.You should firstly know that this new Family Island Hack Cheat is going to add all of the needed Rubies you would like. As you will be playing through the game, you will manage to have fun with this Family Island Mod apk right away. We really hope that you start using this one also because it will be available for free.Have you been wondering if you could find a working Family Island cheats online? Over time we have noticed a lot of searches coming through, people looking for Family Island hack for android or iOS, Family Island cheats on windows mobile. It will provide you with unlimited Rubies in the game with little to no efforts.
Features of the Family Island Hack Online Tool: – Get free unlimited Rubies – Works on Android and iOS,Windows Devices. – No Download or Jailbreak necessary – No risk of being banned in the game – Use it anytime and anywhere – We update the hack almost daily
https://familyislandhack.cheatonlinemod.com/
https://cheatgamesonline.com/family-island-hack/
Family Island hack, Family Island hack online, Family Island hack apk, Family Island mod online, how to hack Family Island without verification, how to hack Family Island no survey, Family Island cheats codes, Family Island cheats, Family Island Mod apk, Family Island hack Rubies, Family Island unlimited Rubies, Family Island hack android, Family Island cheat Rubies, Family Island tricks, Family Island cheat unlimited Rubies, Family Island free Rubies, Family Island tips, Family Island apk mod, Family Island android hack, Family Island apk cheats, mod Family Island, hack Family Island, cheats Family Island, Family Island triche, Family Island astuce, Family Island pirater, Family Island jeu triche, Family Island truc, Family Island triche android, Family Island tricher, Family Island outil de triche, Family Island gratuit Rubies, Family Island illimite Rubies, Family Island astuce android, Family Island tricher jeu, Family Island telecharger triche, Family Island code de triche, Family Island hacken, Family Island beschummeln, Family Island betrugen, Family Island betrugen Rubies, Family Island unbegrenzt Rubies, Family Island Rubies frei, Family Island hacken Rubies, Family Island Rubies gratuito, Family Island mod Rubies, Family Island trucchi, Family Island truffare, Family Island enganar, Family Island amaxa pros misthosi, Family Island chakaro, Family Island apati, Family Island dorean Rubies, Family Island hakata, Family Island huijata, Family Island vapaa Rubies, Family Island gratis Rubies, Family Island hacka, Family Island jukse, Family Island hakke, Family Island hakiranje, Family Island varati, Family Island podvadet, Family Island kramp, Family Island plonk listkov, Family Island hile, Family Island ateşe atacaklar, Family Island osidit, Family Island csal, Family Island csapkod, Family Island curang, Family Island snyde, Family Island klove, Family Island האק, Family Island 備忘, Family Island 哈克, Family Island entrar, Family Island cortar
Try it out
familyislandhack.cheatonlinemod.com


Inspiration
day to day difficulties in reducing the debt and no ways to increase the wealth which we earn.
What it does
It reduces the debt automatically and increases the wealth with the end user's debit transactions with minimum preferences.
Challenges we ran into
connectivity between the APIs Building the App from the scratch
Accomplishments that we're proud of
Penny wise, provides the best opportunity to reduce the debt
What's next for Penny-Wise
Using AI for the better analyzing on customers transactions pattern.
Built With
bootstrap
jquery
oauth
postgresql
ruby-on-rails


Inspiration
After experiencing that more and more trash cans are overfilled in the city center, we thought there should be done something about that. Processes executing the organization of waste disposal personnel are still very static and oldschool. We are going to change that!
What it does
Via a ultrasonic sensors in the garbage cans we are able to receive the current filling level and send that information to our AWS hosted backend. Here the AI is calculating a dynamically optimized route for the personnel to follow for most efficient waste disposal based on the location and filling level of the trash cans. This data may be accessed with the TrashX App for iOS and Android.
How I built it
Using Arduino Uno with Groove Ultrasonic, GPS Sensor and lorawan antenna. Those components are built into a small package that is placed inside the trashcan on the bottom of the cover. Initially the sensor has to be placed in a empty trash can to get the "empty depth". Every 10 minutes the sensors measure the current depth of the garbace can and send it to the backand, which will notify of the treshold of 90 % is exceeded to enable on demand cleaning requests. When the grabage disposal personnel is starting their workday they access their current route via the app or website after authenticating.
Challenges I ran into
Arduino connection to other components and lorawan. TTGO sensor connection and ultrasonic sensor were finnicky.
What I learned
How to handle the arduino components and how to connect those to work properly with each other
What's next for TrashX
Distributing the sensor in all smart cities in bavaria. Introducing the public available TrashX app for reporting problems with garbage disposal.
Built With
amazon-dynamodb
amazon-web-services
arduino
lambda
lorawan
react
react-native
ttgo
ultrasonic
Try it out
cloud.protopie.io
GitHub Repo


Inspiration
Having grown up in developing countries, our team understands that there are many people who simply cannot afford to visit doctors frequently (distance, money, etc.), even when regular check-ups are required. This brings forth the problem - patients in developing countries often have the money to buy medicine but not enough money to visit the doctor every time. Not only does this disparity lead to lower mortality rates for citizens and children but makes it difficult to seek help when you truly need it.
Our team aims to bridge that gap and provide patients with the healthcare they deserve by implementing "Pillar" stations in settings of need.
What it does
Patients visit the pillar stations for at least one of three purposes:
Update doctor with medical symptoms
Get updates from doctors regarding their past symptoms and progress
Get medicine prescribed by doctors
For the first purpose, patients activate the Pillar stations (Amazon Echo) and are called on a secure, private line to discuss symptoms and describe how they've been feeling. Pillar's algorithm processes that audio and summarizes it through machine learning APIs and sends it to the remote doctor in batches. Our reason for choosing phone calls is to increase privacy, accessibility and feasibility. The summarized information which includes sentiment analysis, key word detection and entity identification is stored in the doctor's dashboard and the doctor can update fields as required such as new notes, medicine to dispense, specific instructions etc. The purpose of this action is to inform the doctor of any updates so the doctor is briefed and well-prepared to speak to the patient next time they visit the village. There are also emergency update features that allow the doctor to still be connected with patients he sees less often.
For the second purpose, patients receive updates and diagnosis from the doctor regarding the symptoms they explained during their last Pillar visit. This diagnosis is not based purely on a patient's described symptoms, it is an aggregation of in-person checkups and collected data on the patient that can be sent at any time. This mitigates the worry and uncertainty patients may have of not knowing whether their symptoms are trivial or severe. Most importantly it provides a sense of connection and comfort knowing knowledgable guidance is always by their side.
Finally, for the third purpose, patients receive medicine prescribed by doctors instantly (given the Pillar station has been loaded). This prevents patients' conditions from worsening early-on. The hardware dispenses exactly the prescribed amount while also reciting instructions from the doctor and sends SMS notifications along with it. The Pillar prototype dispenses one type of pill but there is evident potential for more complicated systems.
How we built it
We built this project using a number of different software and hardware programs that were seamlessly integrated to provide maximum accessibility and feasibility. To begin, the entry point to the Pillar stations is through a complex Voiceflow schema connected to Amazon Echo that connects to our servers to process what patients describe and need. Voiceflow gives us the ability to easily make API calls and integrate voice, something we believe is more accessible than text or writing for the less-educated populations of developing countries. The audio is summarized by Meaning Cloud API and a custom algorithm and is sent to the Doctor's dashboard to evaluate. The dashboard uses MongoDB Altas to store patients' information, it allows for high scalability and flexibility for our document oriented model. The front-end of the the dashboard is built using jQuery, HTML5, CSS (Bootstrap) and JavaScript. It provides a visual model for doctors to easily analyze patient data. Doctors can also provide updates and prescriptions for the customer through the dashboard. The Pillar station can dispense prescription pills through the use of Arduino (programmed with C). The pill dispense mechanism is triggered through a Voiceflow trigger and a Python script that polls for that trigger. This makes sense for areas with weak wi-fi. Finally, everything is connected through a Flask server which creates a host of endpoints and is deployed on Heroku for other components to communicate. Another key aspect is that patients can also be reminded of periodic visits to local Pillar stations using Avaya's SMS & Call Transcription services. Again, for individuals surviving more than living, often appointments and prescriptions are forgotten.
Through this low-cost and convenient service, we hope to create a world of more accessible healthcare for everyone.
Challenges and What We Learned
Hardware issues, we had a lot of difficulties getting the Raspberry Pi to work with the SD card. We are proud that we resolved this hardware issue by switching to Arduino. This was a risk but our problem solving abilities endured.
The heavy theme of voice throughout our hack was new to most of the team and was a hurdle at first to adapt to non-text data analysis
For all of us, we also found it to be a huge learning curve to connect both hardware and software for this project. We are proud that we got the project to work after hours on end of Google searches, Stack Overflow Forums and YouTube tutorials.
What's next for Pillar
We originally integrated Amazon Web Services (Facial Recognition) login for our project but did not have enough time to polish it. For added security reasons, we would polish and implement this feature in the future. This would also be used to provide annotated and analyzed images for doctors to go with symptom descriptions.
We also wanted to visualize a lot of the patient's information in their profile dashboard to demonstrate change over time and save that information to the database
Hardware improvements are boundless and complex pill dispensary systems would be the end goal
Built With
amazon-web-services
arduino
avaya
bootstrap
c
css
flask
hardware
heroku
html5
javascript
jquery
meaningcloud
mongodb
python
voiceflow
Try it out
GitHub Repo


WalkingBuddy
Where did the idea come from?
Durham University spans across a large area across the city, there are many areas without streetlights and are surrounded by woodlands, particularly around the Hill Colleges and Maiden Castle, which may discourage students from participating events taking place in the evenings. We have built on this idea and have decided to make it available to be used at any time of the day.
Target users
We are making this app available for all Durham University students, they will need to sign up and verify their account with their durham.ac.uk email. We believe this app will be especially useful for freshers, as it could help them socialise with new people. We are aware that some students would avoid going to college for food because they are conscious of sitting by themselves and this app could potentially help with this issue. For example, students can arrange to walk back to college together during mealtime.
What does it do?
The app allows students to meet up with others to walk together as a group. For example, student A sends a request for someone to walk with from Bill Bryson Library to St. Hild and St. Bede college at 18:00, and student B has also requested for someone to walk with from Bill Bryson Library to St. Hild and St. Bede College at 18:00, these two students will match automatically and they will be notified of this. They will be given the other person’s name and the college they are in. This information should then be checked when the two students meet up. At the end of the journey, they will need to confirm on the app to say they have arrived safely.
Challenges
We have originally planned to have the option to automatically send SMS to the emergency contact once the journey has completed as an extra safety measure, however in the end we were unable to integrate Twilio with Android Studio. We would like to research the API further and eventually add this function to the app. PLUS, everything else, including database, Google Calendar API, Android Studio, time management
What we are proud of
This was the first hackathon that any of us have contended in. While we did not manage to finish the project to a completely usable state, we know we tried our best. All of us worked all night to deliver our vision for the app, and we continued to keep our morales high and concentration focused, despite having to go through 5 different database backends, and a complete pivot from our original task 5 hours in, we worked hard to submit a project that we all felt very passionate about. We hope that we can one day bring this project forward, as we believe that it would have a positive impact on the most vulnerable members of the student community.
Built With
android-studio
firebase
google
java


Skill to help improve your vocabulary.
Built With
javascript


Main Landing Page
https://durhack2019hackerbyname.appspot.com/

Inspiration
As students who all have different approaches to handling their finances, all of which come with their own difficulties, we decided to make a project that help solve this issue by providing a platform, where transactions and balances cacn be seen clearly.
What it Does
Our web-app provides a set of tools to help students keep track of their expenditures and incoming funds, allowing them to set budgets and see how they have stuck to them. The main dashboard clearly shows the balance, and the history of your balance based upon transactions, as well as other graphs for showing the distributions of contributors to the transactions. There is the ability to view transactions history as well as a tool to calculate the remaining spare money based upon university and personal prediction costs.
How we Made it
We started by dividing up tasks until they were all in a position to be combined. Max setup the MongoDB Atlas database system and configured how python is able to communicate to the cloud based database. Fin implemented a flask framework, handling webpage get and post requests. Ben setup the Google Cloud Platform and Github to automatically sync, to provide online hosting. We used Atom that communicated to Git making pull/push requests so that we could all work on the project simultaneously. We clearly communicated throughout, ensuring everyone was heading in the right direction, in order to produce a fully functioning website.
Problems we Faced
None of our group had used python for back-end webserver development before, let alone the flask framework. Neither had any of us used MongoDB to host a database in the cloud. The same was also true for hosting with Google Cloud Platform, so all of these combined resulted in a lot of research being necessary to get all components working together smoothly. Whilst constructing the flask framework, we had to handle user sessions and cookies as well as ensuring connections to the server were secure, especially when creating a new account, so we had to implement bCrypt hashing algorithm.
Accomplishments that we're Proud of
We're proud that our web-app is as interactive and responsive as it is, and are happy that the hard work we put into it has paid off.
What we Learned
We learned a lot of technical skills while dealing with the frameworks and services. For example, we improved our research and communication skills, since most of the concepts were learned completely from scratch.
What's Next for Cash It!
We're going to try to add in the extended functionality it deserves to have, such as the ability to track multiple accounts!
Built With
bootstrap
django
flask
google-cloud
html
mongodb
python
Try it out
durhack2019hackerbyname.appspot.com
GitHub Repo


Faça uma doação de forma rápida e segura
walle
somosindra
somosvoluntarios
hackathonindra
devforachange
Built With
java
javascript


a## Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Task Factory
Built With
java
javascript


Inspiration
Color deficiency is when the photoreceptors in the retina of the eye are slightly deformed such that they cannot see certain wavelengths. People with color deficiency struggle to see either red-green wavelengths or blue-yellow wavelengths. While color deficiency does not typically impact lives severely, it deprives those with it of seeing the world in the same light that others do. Solutions have already been created in the form of special ‘sunglasses’ that modify incoming light to more closely map to what an actual person would see; however, these glasses can end up being hundreds of dollars.
What it does
Our app uses a simple filter that modifies the images it takes in from the camera in real time so that a user with color deficiency can see what a normal person would see. For instance, if you climbed to the peak of a mountain and you want to see exactly what it would look like, you could pull out your phone and see it.
How we built it
We built our application using the Unity engine in C# with the corresponding AR frameworks. We used canvas elements to create a filter to overlay over the main camera, creating better contrast for problematic colors, making them easier to differentiate.
Challenges we ran into
Capturing the input from the camera to produce a filtered image was a challenge, especially in trying to use render textures to apply a filter. We pivoted towards modifying specific pixels, proved to be too time consuming to deliver a functional product in time. Finally, we were able to switch to using canvas elements to produce a filter overlay for the feed from the camera to the screen.
Accomplishments that we're proud of
Delivering a functional product, especially after running into issues with our initial development plan.
What we learned
We learned that render textures are very difficult to operate with.
What's next for ColorDeficiencyAR
We plan to add specific modes for a variety of color deficiencies.
Built With
android
ar
c#
shaderlab
unity
Try it out
GitHub Repo


Inspiration
A few days ago, I was at a local restaurant and our waiter took too long to take our orders. We waited for almost 30 minutes! We realized that there may be apps like Uber Eats and Door Dash that bring food for you, but what about the amount of time it takes to go to the restaurant?
What it does
Panini is a unique website that designates a QR code for every table in a restaurant and allows a customer to skip long lines, save time, and still be able to eat inside. The paper laminated QR codes are on each table and link to the menu online. It takes less than 1 minute to order a few drinks that would originally take 10 minutes of waiting. This also makes it easier for the restaurant to hire fewer waiters and have the capacity to care for more customers. Managers can check customer's orders online and visually see which tables are vacant/ occupied.
How I built it
We used Javascript, HTML5, CSS, and Selz to create the application. Which the 3 programming languages were used for the web application, Selz was used to implement the UI.
Challenges I ran into
We changed our ideas a variety of times and didn't rest on one until 5 pm. But once we knew that we had a good idea, we went straight for it!
Accomplishments that I'm proud of
We're proud of working as a team towards a common goal and overall enjoying this hackathon experience.
What I learned
My group learned how QR codes and Web Apps can make everyone's life easier. Not only is the app's UI sleek and unique, but it also works on both Android and Apple products.
What's next for Panini
We want to expand our app to a few locations to prototype it. We are specifically targetting larger restaurants like BJs that take a long time. We also want to implement a ringer that rings your phone and notifies you when your food is ready.
Built With
css
html5
javascript
selz
Try it out
fishberry.net


CitINsight
Inspiration, What it does, Business Model Canvas, Use Cases & Business Opportunities
Please check out our detailed presentation at https://www.beautiful.ai/player/-LuRxQueFMq_UZMP1xKn
Here is our short slide-deck for the pitch (preview):Pitch slides
How we built it
Verbaute Hardware
Im Prototypen ist die folgende Hardware verbaut:
Controller & Erweiterungsplatinen ⦁ Arduino Uno R3 ⦁ Base Shield for Arduino
Sensoren ⦁ Erweiterungsplatine TTL Port GPS für Einplatinencomputer ⦁ DHT 22-Modul (Temperatur und Luftfeuchtigkeit) ⦁ Grove - Sound Sensor ⦁ Grove - Dust Sensor ⦁ Grove - Multichannel Gas Sensor ⦁ TTGO ESP32-Paxcounter LoRa32 T3_V1.6 ⦁ GY-521 (3-Achsen Beschleunigungs- und Gyro-Sensor) ⦁ Weather2-Board ⦁ SI1132 (UV Ambient Light Sensor) ⦁ BME 280 (Sensoren für Temperatur, Luftfeuchtigkeit, Luftdruck)
Antenne
Schutzcase Das selbst designte Case aus 6mm dickem Schichtholz ist mit Luftschlitzen und einer Kabelöffnung versehen und wurde in SketchUp entworfen. Die im Makerspace lasergecutteten Einzelteile wurden über Steck-/Schraub-Verbindung zusammengeführt und auf die Gegebenheiten der Sensoren angepasst. Zur zerstörungsfreien Montage und Demontage auf Fahrzeugen dient eine mit Neodym-Magneten bestückte Metallplatte als Basis. Sowohl zur Abschirmung der Sensoren vor den Magneten als auch zur Holz-Holz-Verbindung mit dem Schutzcase wurde eine 15mm dicke Holzplatte auf der Metallplatte mit Kabelbindern aufgebracht. Um Autolacke vor Beschädigungen durch die Magnete zu bewahren und zur leichteren Demontage wurde eine dünne Anti-Rutsch-Matte eingebracht und durch Kabelbinder und Schrauben befestigt.
Challenges we ran into & Accomplishments that we are proud of
Solved Technical Difficulties
-> 19 verschiedene Messwerte, die vom Gerät erfasst und über LoRaWAN übertragen werden
-> Vielzahl von Schnittstellen zu den Sensoren (Serial/PWM/Analog/I2C)
-> Konfiguration Backend (Node-RED, InfluxDB und Grafana in Azure Cloud)
-> Kommunikation zwischen LoRa-Device und Arduino
-> Abstimmung Box-Design auf Sensoren (Belüftungsschlitz, Kabelführung)
-> Leichte, zerstörungsfreie Montage/Demontage an Fahrzeugen
What I learned & What's next for CitINsight
Bekannte Optimierungsbedarfe von Architektur und Design:
-> Aufbau eines eigenen LoRaWAN-Gateway-Netzes Aktuell hoher Air-Time-Konsum bedingt durch (im Verhältnis) hohe Sendefrequenz (alle 10 Sekunden) und hohen Payload (46Byte). Lösungsansatz: Aufbau eigener LoRaWAN-Gateways im Stadtgebiet und - sofern möglich - Zusammenschluss zu einem privaten Netzwerk.
-> Umsetzung einer regenerativen Stromversorgung Aktuell ist eine Powerbank zur Stromversorgung vorgesehen. Neben dem dadurch entstehenden Wechsel- bzw. Recharge-Bedarf ergeben sich Schwierigkeiten beim Einschalten durch Verbau im Schutzcase. Lösungsansatz: Integration einer regenerativen Stromversorgung. Solar und Wind (Fahrtwind!) stellen denkbare Optionen dar.
-> Wetterresistentes Design Aktuell ist das Schutzcase aus Holz. Lösungsansatz: Umsetzung in wetterresistenten Materialien.
-> Umfangreiche Analysen und automatisierte Reports Aktuell sind noch keine Tools im Einsatz, um einem Kunden gegenüber die Analyseergebnisse attraktiv darzustellen. Da Übertragbarkeit der Use Cases zwischen Städten zu erwarten ist, birgt Automatisierung gegenüber der manuellen Reporterstellung Optimierungspotential. Lösungsansatz: Design Thinking Workshop, um die Report-Bedarfe und Report-Tiefe einiger Kunden zu erarbeiten und Umsetzung in Software.
Built With
arduino
azure
grafana
iflux
node-red
passion
pax
platformio
ttn


Sample Output
Overview
A console program to display a snakes and ladders board based on a text file. This was coded using C with the aim to gain an understanding of pointers.
This project used pointers in the form of nodes to form a doubly-linked list to traverse of _ O (n) _ time and space complexity.
Each node is formed as a _ complex_node _ which contains a unique identifier in the form of an integer to represent each square on the board as well as pointers to other nodes which are before or after it in the list. Each snake or ladder is added as a pointer called _ transition _.
This project was managed using BitBucket to track version changes and write documentation through the CodeBlocks IDE.
Built With
bitbucket
c


Inspiration
Life is busy. Make your decisions faster with stylist.ai. We built this app to keep you fashionable while staying on the go.
What it does
stylist.ai provides you with styling options on the fly using deep neural networks.
How I built it
Backend: Django, Python, tensorflow Infrastructure: Google Cloud SQL, Google Compute Engine Frontend: Android, Java
Built With
android-studio
deep-neural-networks
django
google-cloud-sql
google-compute-engine
java
machine-learning
mysql
python
regression
restapi
sql
tensorflow
Try it out
GitHub Repo


Inspiration
Only 57% of the US population identify as financially literate (2015 Standard & Poor's Global Financial Literacy Survey) while approximately 39% of Canadian millennial men said they were concerned about their level of literacy compared to 29% of Canadian women said they were worried (GlobalNews). Indicating that overall, there may be a disconnect between an individual's financial health and their
FIFI, the Voice-Activated Financial Advisor/Corgi, looks to empower every individual with access to advance analytics and easily available financial data. FIFI will help make financial information and advice more accessible, provide tools to make informed decisions, anywhere and anytime you need it.
What it does
FIFI can predict future stock prices, provide portfolios recommendations, get your current balance, find stocks and provide current prices, calculate risk (beta) of stock, calculate risk (Beta) of your portfolio, purchase and unload shares.
How we built it
It uses DiologFlow for the user-facing side. We use a node API to send data about stocks to it. There is R code to analyze stocks and make predictions which is exposed by a Python API.
What we learned
It was the first time we used DiologFlow. We also learned how to integrate many different API structures. The finance side of things was also new to some of our team.
What's next for Fifi: Voice Activated Financial Advisor
FIFI will be able to:
Leverage ML to Optimize Portfolio Returns
Analyze All International Stocks across Exchanges
Execute Complex Trades (Futures, Options, Limits, Shorts, etc.)
Use ML to Develop Proprietary Financial Products
Train AI to Better Identify Intent behind Survey Answers
Financial Encyclopedia to help Improve User Financial Literacy
Built With
dialogflow
gcp
node.js
python
r
Try it out
GitHub Repo
GitHub Repo


Inspiration
Unhealthy diet is the leading cause of death in the U.S., contributing to approximately 678,000 deaths each year, due to nutrition and obesity-related diseases, such as heart disease, cancer, and type 2 diabetes. Let that sink in; the leading cause of death in the U.S. could be completely nullified if only more people cared to monitor their daily nutrition and made better decisions as a result. But who has the time to meticulously track every thing they eat down to the individual almond, figure out how much sugar, dietary fiber, and cholesterol is really in their meals, and of course, keep track of their macros! In addition, how would somebody with accessibility problems, say blindness for example, even go about using an existing app to track their intake? Wouldn't it be amazing to be able to get the full nutritional breakdown of a meal consisting of a cup of grapes, 12 almonds, 5 peanuts, 46 grams of white rice, 250 mL of milk, a glass of red wine, and a big mac, all in a matter of seconds, and furthermore, if that really is your lunch for the day, be able to log it and view rich visualizations of what you're eating compared to your custom nutrition goals?? We set out to find the answer by developing macroS.
What it does
macroS integrates seamlessly with the Google Assistant on your smartphone and let's you query for a full nutritional breakdown of any combination of foods that you can think of. Making a query is so easy, you can literally do it while closing your eyes. Users can also make a macroS account to log the meals they're eating everyday conveniently and without hassle with the powerful built-in natural language processing model. They can view their account on a browser to set nutrition goals and view rich visualizations of their nutrition habits to help them outline the steps they need to take to improve.
How we built it
DialogFlow and the Google Action Console were used to build a realistic voice assistant that responds to user queries for nutritional data and food logging. We trained a natural language processing model to identify the difference between a call to log a food eaten entry and simply a request for a nutritional breakdown. We deployed our functions written in node.js to the Firebase Cloud, from where they process user input to the Google Assistant when the test app is started. When a request for nutritional information is made, the cloud function makes an external API call to nutrionix that provides nlp for querying from a database of over 900k grocery and restaurant foods. A mongo database is to be used to store user accounts and pass data from the cloud function API calls to the frontend of the web application, developed using HTML/CSS/Javascript.
Challenges we ran into
Learning how to use the different APIs and the Google Action Console to create intents, contexts, and fulfillment was challenging on it's own, but the challenges amplified when we introduced the ambitious goal of training the voice agent to differentiate between a request to log a meal and a simple request for nutritional information. In addition, actually finding the data we needed to make the queries to nutrionix were often nested deep within various JSON objects that were being thrown all over the place between the voice assistant and cloud functions. The team was finally able to find what they were looking for after spending a lot of time in the firebase logs.In addition, the entire team lacked any experience using Natural Language Processing and voice enabled technologies, and 3 out of the 4 members had never even used an API before, so there was certainly a steep learning curve in getting comfortable with it all.
Accomplishments that we're proud of
We are proud to tackle such a prominent issue with a very practical and convenient solution that really nobody would have any excuse not to use; by making something so important, self-monitoring of your health and nutrition, much more convenient and even more accessible, we're confident that we can help large amounts of people finally start making sense of what they're consuming on a daily basis. We're literally able to get full nutritional breakdowns of combinations of foods in a matter of seconds, that would otherwise take upwards of 30 minutes of tedious google searching and calculating. In addition, we're confident that this has never been done before to this extent with voice enabled technology. Finally, we're incredibly proud of ourselves for learning so much and for actually delivering on a product in the short amount of time that we had with the levels of experience we came into this hackathon with.
What we learned
We made and deployed the cloud functions that integrated with our Google Action Console and trained the nlp model to differentiate between a food log and nutritional data request. In addition, we learned how to use DialogFlow to develop really nice conversations and gained a much greater appreciation to the power of voice enabled technologies. Team members who were interested in honing their front end skills also got the opportunity to do that by working on the actual web application. This was also most team members first hackathon ever, and nobody had ever used any of the APIs or tools that we used in this project but we were able to figure out how everything works by staying focused and dedicated to our work, which makes us really proud. We're all coming out of this hackathon with a lot more confidence in our own abilities.
What's next for macroS
We want to finish building out the user database and integrating the voice application with the actual frontend. The technology is really scalable and once a database is complete, it can be made so valuable to really anybody who would like to monitor their health and nutrition more closely. Being able to, as a user, identify my own age, gender, weight, height, and possible dietary diseases could help us as macroS give users suggestions on what their goals should be, and in addition, we could build custom queries for certain profiles of individuals; for example, if a diabetic person asks macroS if they can eat a chocolate bar for lunch, macroS would tell them no because they should be monitoring their sugar levels more closely. There's really no end to where we can go with this!
Built With
chart.js
css
css3
firebase
google-actions
google-assistant
google-cloud
html
html5
javascript
json
mongodb
natural-language-processing
node.js
nutritionix
Try it out
GitHub Repo


We were inspired by accounts such as @bbcbweaking to create a bot and website that would parody a public figure's tweets and publish them to a bot account. There is quite a high demand for accounts like this, as many in the past have gone viral amongst teens on twitter. One of the most challenging tasks in today's society is getting people involved in politics, as it is oftentimes negative and detrimental to their mental health in large doses. We hope that, in creating this account, we have created a way for people to view the news in a more comedic light, and that this form of news is easier to interact with in a positive way.
In this task, we have learned how to: interact with the Twitter API; create an appealing front-end; interact with the GitHub API; host and schedule tasks on HEROKU; and create a REST API using Flask. In using the Twitter API, we pulled data from twitter accounts to modify and post to our own bot account. Using the GitHub API involved using patch requests and get requests to modify and read a persistent storage of data. The front-end development was accomplished using html and bootstrap, while the back-end used tweepy to fetch tweets and exposed a REST API to allow the front-end to retrieve tweets and display them. Some basic caching was implemented in the API to limit the number of times the twitter API was called.
We built mainly in a PyCharm IDE, using python, js, html, and some css and php from an open source website. We also used VSCode at some points. We used GitHub as our VCS so that we could track our progress and easily coordinate our work. It also helped to solve bugs as we could see all the differences between working code and non-functional code.
In our development, we experienced many challenges, such as: the API wrappers we used not being fully documented; returning the wrong data from the REST API, which was also difficult to debug due to python scripts being run slightly differently than in the localhost as they are imported rather than being run as is; and also the formatting for the front-end was challenging due to some of the elements not being suitable for mobile browsers without modification.
The files that were used from an open-source website template:
all the files in the css, img, js, mail, node_modules, scss folders
index.html and about.html were adapted from the source
durhack2019
Built With
css
html
javascript
php
python
Try it out
amb1plasma.github.io
twitter.com


Logo
Inspiration
Software engineering and development have been among the most dynamically changing fields over the years. Our voice is one of our most powerful tools, and one which we often take for granted - we share ideas and inspiration and can communicate instantly on a global scale. However, according to recent statistics, 3 out of 1000 children are born with a detectable level of hearing loss in one or both ears. While many developers have pursued methods of converting sign language to English, we identified a need for increased accessibility in the opposite way. In an effort to propel forth the innovators of tomorrow, we wanted to develop a learning tool for children with hearing impairments to accelerate their ability to find their own voice.
What it does
Our Sign Language Trainer is primarily designed to teach children sign language by introducing them to the ASL alphabet with simple words and effective visuals. Additionally, the application implements voice-to-text to provide feedback on word pronunciation to allow children with a hearing impairment to practice speaking from a young age.
How we built it
The program was built using node.js as well as HTML. We also made a version of the web app for Android using Java.
Challenges we ran into
The majority of our team was not familiar with HTML nor node.js, which caused many roadblocks during the majority of the hack. Throughout the competition, although we had an idea of what we wanted to accomplish, our plans continued to change as we learned new things about the available software. The main challenge that we dealt with was the large amount of learning involved with creating a website from scratch as we kept running into new problems that we had never seen before. We also had to overcome issues with hosting the domain using Firebase.
Accomplishments that we proud of
While also our largest challenge, the amount of content we had to learn about web development was our favorite accomplishment. We were really happy to have completed a product from scratch with almost no prior knowledge of the tools we used to build it. The addition of creating a phone app for our project was the cherry on top.
What I learned
Learned about node.js, HTML, and CSS
The ability to understand and structure code through analysis and documentation
How to cooperate as a team and brainstorm effectively
GitHub was new for some members of the team, but by the end, we were all using it like a pro
How to implement android applications with android studio
How to fully develop our own website
What's next for floraisigne
If we were to continue this project, we would try and add additional hardware to exponentially increase the accuracy of the solution. We would also implement a neural network system to allow the product to convert sign language into English Language.
Built With
android-studio
css
google-web-speech-api
html
java
javascript
Try it out
GitHub Repo


In late September, in partnership with the Joint Artificial Intelligence Center (JAIC) and the University of Michigan, NSIN hosted Michigan-area innovators at the University of Michigan for a three-day hackathon event. The hackathon, “Into the Dataverse”, was held September 20-22, 2019, at the FXB Building at the University of Michigan North Campus, in Ann Arbor, MI.
The event gathered entrepreneurs, developers, designers, members of the military and venture communities as well as student hackers from the University of Michigan, Michigan State, Wayne State, and Lawrence Tech for the weekend to explore innovative methods to support data collection through the development of an AI-enabling user interface to produce more accurate maintenance logs. Prizes totaling $45,000 were awarded to the top three teams.
https://www.nsin.us/
Try it out
www.nsin.us


The London Bridge's Citizen Portal for Streetlight Repair
Inspiration
We were intriguied by the City of London's Open Data portal and wanted to see what we could do with it. We also wanted to give back to the city, which houses UWO and Hack Western, as well as many of our friends. With The London Bridge, we aim to enable communication between the community and its citizens, highlight the most important points of infrastructure to maintain/build upon, and to ultimately make London citizens feel involved and proud of their city.
What it does
The London Bridge is a web app aiming to bridge communication between changemakers and passionate residents in the city of London. Citizens can submit requests for the construction/maintenance of public infrastructure, including street lights, bike lanes, traffic lights, and parks. Using our specially designed algorithm, The London Bridge uses a variety of criteria such as public demand, proximity to similar infrastructure, and proximity to critical social services to determine the most important issues to bring to the attention of city employees, so that they may focus their efforts on what the city truly needs.
How we built it
First and foremost, we consulted City of London booth sponsors, the City of London Open Data portal, colleagues studying urban planning, and the 2019 edition of the London Plan to determine the most important criteria that would be used in our algorithm. We created a simple citizen portal where one can submit requests using PugJS templates. We stored geotagged photos in Google Cloud Storage, and relevant geographical/statistical data in MongoDB Atlas, to be used in our score calculating algorithm. Finally, we used Nodejs to implement our algorithm, calculating scores for certain requests, and sending an email to Ward Councellors upon meeting a threshold score.
Challenges we ran into
Integrating and picking up a variety of new technologies proved to be a difficult challenge, as we had never used any of these technologies before. We also discussed and revised our algorithm many times throughout the hackathon, in hopes of creating a scoring system that would truly reflect London's needs.
Accomplishments that we're proud of
We're proud of our team's commitment to our hack's vision and goals, especially when things looked hairy.
What we learned
We learned more about a variety of the aforementioned web technologies, as well as the struggles of integrating them together.
What's next for The London Bridge
In the future, we'd hope to:
Refine and add to our algorithm
Implement additional request types
Enhance data visualization and add workflow integration
Add a web interface for city employees
Create a user login system and impact tracking
Built With
express.js
google-cloud
mongodb
node.js
pug
Try it out
GitHub Repo


Vhysio: AI Physio for the Visually Impaired
By Alisa Hussain, AJ Sung & Ben Harries
1st Place Winners of DurHack 2019
Access the live application at: https://vhysio.herokuapp.com/
View our presentation slides at: http://bit.ly/2OEQrWv
Our code is available on Github: https://github.com/BenHarries/Durhack2019
Vhysio is a web app utilising cutting edge Machine Learning library, tensorflow.js to enable accessible physiotherapy for the Visually Impaired, talking through exercises by responding to users' postures in real-time.
Vhysio makes it easier for users to not only complete but to improve their techniques independently.
Technology
Vhysio utilises AI Machine Learning technology to learn what makes a particular position correct and incorrect. It has learnt off a dataset of images to predict whether the position is correct, or incorrect - and what makes it so.
We have used 'TeachableMachine' A web-based AI Machine Learning tool to train our models in the various physiotherapy poses.
Google's Speech-to-Text API was also used to enable the application to be accessible by the visually impaired. The user can start their exercises via speech remotely this is more convenient and easier to use for our target audience.
The application utilises Windows WebKit Speech Recognition, for text-to-speech. This is useful for the visually impaired as they can hear if they are in the right position as the application will tell them to adjust their posture if incorrect.
We also use the webcam to track the user's movement which is fed as input to the machine learning model and outputs a status on the user's posture.
Supportability
This is fully supported on Desktop/Android Google Chrome. However, from our research, IOS and Safari are unsupported.
For best results it is advised to use Google Chrome on a desktop.
Development
During our software development cycle, we used Notion for allocating work segments and dividing the workload into easy to use sizable chunks.
Main files
Index.html
Index.js
app.js
micWork
Client Folder
The web application is located in the clients folder. The web application consists of two files: index.html and index.js.
Index.html
The index.html contains all the HTML that forms the backbone of the website.
We have used the bootstrap open-source CSS framework for our front-end development.
Index.js
index.js contains the Javascript code for the web application. This works with HTML to add functionality to the site.
Loads the model and metadata and handles image data.
app.js
The app.js is the server-side back-end code. This serves the web application using express on a node.js server.
We have decided to use Heroku as the hosting platform which can be accessed from the link above.
micWork
(Deprecated due to ease of use of in-browser 'Windows WebKit Speech Recognition' alternative)
Uses Google Cloud SDK to utilise Google Cloud Speech-To-Text, so visually impaired users can communicate with the application.
MicrophoneStream.js: Listens and transcribes text. Performs functions based on input received
Built With
bootstrap
css
express.js
google-web-speech-api
html
javascript
node.js
tensorflow.js
Try it out
vhysio.herokuapp.com
GitHub Repo
bit.ly


Logo/Title
Inspiration
As students, we have the sensation of what it feels like to be stumbling every day because of time wasted. We knew that this was one of the major problems that occurred to almost every single high school and/or college student. This was the beginning of our inspiration for what we are going to do to try to help students in society.
What it does
Our software is Timanager. This software has multiple different aspects that make it different, unique, and non-time consuming program that helps students preserve and manage their time well. It basically asks you for a few things: event name, start time, end time, and importance. After you’ve entered these 4 things, it’ll appear in the calendar saying the time. The calendar is basically a simple schedule showing every event that you need to finish in chronological order, and the importance in color: green, orange, and red.
We purposely make it simple so that it is easy to access your schedule and it will not be time consuming because you don’t have to enter too many requirements.
How we built it
We used python to code this software. In python, we used the pygame module to create graphics. We coded as much as we could from scratch. We coded the user interface, made the images for buttons, and created our own ringtone sounds by ourselves. We used the gimp software to create custom buttons for our program, and the music maker to make our own uplifting ringtones. These were the steps we took to create the code:
we worked on the logic of the organization of the schedule.
we created a graphical user interface using pygame to let the user enter the data and events.
we worked on the notification system, such that, when an event ends, our system notifies you with the music that we created.
we made the user interface more fancier by adding better fonts, colors, backgrounds etc.
Challenges we ran into
Pygame’s user interface was a big challenge that we had to face with.
Accomplishments that we're proud of
We are all proud of what we have made. Our schedule could save students so much time and it would also make students more efficient. Not only is it simple and convenient, it is also super easy to understand and easy to access. We are also proud of the code and the process of how the event, time, and importance is stored and moved into calendar and displays everything there. We learned many things and we are very happy to have written this project.
What we learned
We learned many things in this short hackathon, like how to quickly use pygmame to make executable software to make apps, how to use GIMP to make good looking UI for the user to interact with, and how to use Music Maker to make soundtrack that activates when the timers are finished, etc.
What's next for Timanager
We have decided that we will port Timanager for android and iOS. This will have many special integrations like notifications, and more ease of access. For example, we will be able to view the days in the past and what the person has done in the past. We also want to be able to save the calendar and add multiple accounts to the calendar.
Our main goal is to try to make this calendar as efficient and convenient as possible.
Built With
gimp
musicmaker
os
pygame
python
random
sys
time
Try it out
GitHub Repo


Inspiration
Augmented Reality is the future that will allow us to have more union between the real and virtual world, this project is the start our journey.
What it does
We created 3 cool miniprojects:
Cool rule: Measure objects: AR application that measure objects by setting 2 points on the space. Selecting 8 points the measures are volumes.
DrawWall: Painting walls: AR application that detects walls and allows it to change the color. The colors you can paint the wall are Blue, Orange and Green.
Gran Hermano: Counting people in a room: OpenCV api that counts the people in the room and the time they stay in there. Additionaly the api shows the people that are in the room at the same time.
How we built it
For the Cool rule and DrawWall projects we've used Unity with the ARCore sdk. So we've used C# as the developing lenguage. For the Gran Hermano project we've used Flask and openCV library. So we've used python as the developing lenguage.
Challenges we ran into
We've had some problems creating the enviroments and learning how to use ARcore and openCV libraries. Also for one of us was the first time using python. A non-technical challenge we also run into was that one of us has become ill during the saturday night.
Accomplishments that we're proud of
Developing 3 cool applications in 24 hours beeing 2 people and a half is a thing we can be proud of!!
What we learned
We've learned how to use ARCore and openCV libraries, also for one of us was the first time developing with python, also the experience with unity wasn't so extend and we have deepened knowledge in it
What's next for this projects
All these projects can have better versions with all the enhanced features
Built With
ar
arcore
flask
opencv
python
unity
Try it out
GitHub Repo


Homepage for the application
Inspiration
Mental health has become one of the most prominent issues today that has impacted a high percentage of people. This has taken a negative toll on their lives and have made people feel like they do not belong anywhere. Due to this, our group decided to assist these people by creating a phone application that minimizes these negative feeling by providing a helping hand and guiding them to additional aid if necessary.
What it does
Our application utilizes a chat bot using voice recognition to communicate with users while responding accordingly to their mood. It strives to help their overall mentality and guide them to a greater overall personal satisfaction.
How we built it
We used Android Studio to create an android application that incorporates Firebase for user authentication and data management using their database. In addition, the chat bot uses Dialogflow's machine learning capabilities and dialog intents to simulate a real life conversation while providing the option for anonymity. In conjunction to Dialogflow, Avaya's API was utilized for its voice recognition and connection to emergency situation through SMS and phone calling.
Challenges we ran into
It was very challenging for us to implement the Avaya API because of its compatibility with Java DK, making it difficult to get the correct HTTP connection needed. This required specific Java versions as well as maven to be able to integrate it in conjunction with the data output from Avaya's API. In addition, the Firebase implementation provided difficulties because of it is NoSQL database which made it tough to retrieve and interact with the data.
Accomplishments that we're proud of
Despite the challenges faced, we were still able to implement both the Avaya API, which is now able to both call and sent text messages, and the Firebase database to store all the user data. This all came together with our final product where the chat bot is able to interact with, call, and send text messages when required.
What we learned
The biggest takeaway from this is learning to think outside the box and understand that there is always another way around a seemingly unsolvable goal. For example, the Avaya API library was difficult to implement because it required downloading a library and using an intermediary such as maven to access the library. However, despite this obstacle, our team was still able to find an alternative in accessing the API through Curl calls and access the needed data. A similar obstacle happened for Firebase database where the pull requests would not process as required, but we were able to find an alternative way to connect to the Firebase and still retrieve the needed data.
What's next for ASAP Assistance
The more the chat bot is utilized, the better the communication will be between the user and the bot. Further training will improve the the bot's capabilities which means it could use many more intents to improve overall user experience. With continued contribution to the logical capabilities of the bot, a wider range of communication can be supported between the user and the bot.
Built With
android
android-studio
avaya
dialogflow
firebase
zang-api
Try it out
GitHub Repo


A preview of the report generated by the Cracke.
Inspiration
Crack Identification is an important challenge in estimating the reason for the cause of the failure. Onboarding of a defective machine into the insurance ecosystem leads to big losses being incurred. Most of the heavy machinery susceptible to fatigue loading is located in remote locations, where the connectivity may be poor.
What it does?
The Cracke is an end-to-end automatic report generation tool that identifies cracks to pixel-level accuracy. It is computationally inexpensive and so can be deployed on even a Raspberry Pi. Cracke leverages the Paris Equation for crack propagation to estimate the number of cycles of load applied. The tool compares the number of cycles of load with a standard loading condition for the material to identify the root cause of the defect. Then a report is generated in an HTML format.
How We built?
Cracke has 3 main components:
Image Processing Pipeline
Median Blur Filtering
Canny Edge Detection
Morphological Segmentation
Bounding Box Generation
Crack Estimation Pipeline
Approximate Crack Length
Use Paris Equation for crack propagation
Compare with standard loading for a given material
Report Generation Pipeline
Status of the material
Analysis of the image
Estimate crack start and cause
Generate report
Hurdles we overcame?
Integration of the pipelines with the frontend for the app
Deploying the pipelines on the Raspberry Pi
What we learned?
That the Occam's Razor is still valid, that a simple solution can be very effective in solving huge problems and saving a ton of money.
What's next for cracke?
Improve material database
Incorporate more domain knowledge
Built With
flask
ionic
javascript
opencv
pandas
python
Try it out
GitHub Repo


Project homepage
Inspiration
I'm a huge fan of the Google APIs, especially the Google Sheets one. But it's always a bit tricky to setup. So I've created a project that lets you push data to any Google Sheets in a few seconds.
What it does
It gives you a code-snippet to push data into one of your Google Sheets.
How I built it
It's build using Vue.js and Bearer.sh the company that I work for.
Challenges I ran into
The Google APIs OAuth scopes are always tricky. Google should definitely give some more granularity on that.
Accomplishments that I'm proud of
To that day, the project has runned over 10K API Calls!
Built With
google
javascript
vue.js
Try it out
community.bearer.sh


Inspiration
We wanted to create a project that would challenge both our front end and back end skills.
What it does
It finds the safest path between two points in London.
How I built it
It uses the Google Maps API, data from the city of London, and statistical analysis to make recommendations.
Challenges I ran into
React was a challenge as we couldn't pass props to our maps components. Challenges with Python packages and getting statistically significant results.
Accomplishments that I'm proud of
We got this done.
What I learned
In future front end projects, we shouldn't use React.
What's next for SafeWay
A possible sale to Google ;)
Built With
css
flask
html
javascript
numpy
pandas
python
react
scikit-learn
Try it out
GitHub Repo


Inspiration
People with hearing impairment are safe and capable drivers, although there remains some environmental cues which they cannot detect while on the road. We developed a tool that creates a safer driving experience by alerting hearing impaired drivers of other incoming vehicles.
What it does
Three microphones are set up around a vehicle so that it samples sound from the environment in 360 degrees. If our machine-learning SVM algorithm detects an ambulance or honking car in the nearby area, it localizes the object based on the difference in amplitude of sound detected by each microphone and the time of delay between each microphone.
How we built
We connected three microphones to an Arduino Uno for sound detection. The amplitude of sound and the time of sound detection was read from the Arduino and channeled into a raspberry-pi for further processing. In Python, we used supervised learning with a support vector machine to detect whether a nearby sound was the siren of an ambulance or the persistent honk of a nearby car. Taking into account which microphone was persistently detecting the loudest sound, and the position of the microphone in relation to the driver, a dynamic GUI displays an arrow that tracks the position of the incoming vehicle to alert the driver.
Difficulties encountered
Adjusting the sensitivity of the microphones so that they were providing rich enough data for training our machine learning algorithm. Interfacing the Arduino Uno with the Raspberry-Pi. Controlling our data flow so that our tool could support alerting from real-time data.
What we're proud of
Setting up the hardware so that we could sensitively detect sounds in the environment, feeding that data into a raspberry-pi, and performing processing and supervised machine-learning in real-time.
What we learned
We all started the project with zero experience in using Raspberry Pis or Arduinos so there was quite a learning curve for all of us. We also had never worked with triangulation, python GUIs or classifying sound data. We learned quite a bit about each topic through the course of the weekend.
Next steps
Integrating more microphones for more sensitive and accurate 360 degree sound detection. Implementing microphones into vehicles in an effective but non-intrusive way. Training our algorithm on more environmental threats so that we may alert drivers.
Built With
arduino
c
circuitry
machine-learning
python
raspberry-pi
Try it out
GitHub Repo


Inspiration
We do not know enough about the future. It is scary and unknown, yet we try to fight the irregularities that happen in our everyday lives.
Thus we must predict it.
Predicting the failing rates would help a lot in decreasing measurement time.
What it does
It predicts the breakdown probability and the best measurements to do in order to reject the device as early as possible. This model learns from the past device measurements and uses the currently known characteristic to predict the value of each measurement to be done and order them, failing probability ascending order.
How I built it
We wrote lines of python code, and used our great machine learning knowledge to create model of the device's measurements.
During this project we used different libraries from sklearn and pandas model using different machine learning algorithms to create proof of concepts.
Challenges I ran into
Time and Money, for some reason we ran out of both too soon.
We had some challenges when trying to run our algorithms on our machines as we would have preferred more extensive tests. We also believe that in real data correlation could be a lot more visible and would improve the use of PCA in our model.
Accomplishments that I'm proud of
We are proud to announce that the future is now as known as the past.
What I learned
We learned that breakdowns are rare but present.
What's next for breakdown_prediction
There will be no more breakdowns so we will be jobless.
We hope to test our algorithms on real data and improve our implementation to not only be used as a POC but also as an actual predictive algorithm.
Built With
python


Inspiration
The prominence of cardiovascular disorders has only gotten worse resulting in 30% of deaths worldwide according to the World Health Organization [1]. Therefore, it is crucial to detect patients at risk earlier and better understand the mechanism of disease to prevent the onset of cardiac arrest. A common routine used in hospitals is the acquisition of electrocardiograms (ECG) to capture the cardiac electrophysiology propagation in the heart using a non-invasive method [2]. Our team wanted to find a convenient way to assess the electrophysiology of patients at risk and detect cardiac arrhythmias to alert caregivers or medical aid of the arrhythmic state and risk of cardiac arrest.
What it does
We developed Rhythm, a wearable device that routinely evaluates a patient’s ECG and inputs it into a model generated by a machine learning algorithm. If the model predicts that the patient is experiencing a state of arrhythmia, it immediately calls a caregiver who can talk to a bot that has access to the patient data.
How We built it
The Hardware We used an Arduino Pro Mini with an FTDI basic breakout as for microcontroller communication. The ECG signals are measured by a single lead AD8232 and sent to the PC as an analog signal.
The team built a convolutional neural network in the tyhoe VGG16 to process these 1-d signals into a single value which is stored in a csv file. This single value was obtained through the complex analysis of the P, R, S and T values associated with each heartbeat.
The convolutional neural network uses artificial intelligence and deep learning to train a model that can use the values in the csv file to accurately predict when and what type of heart arrhythmia will occur. The group designed a algorithm that when fed testing data, generates a .h5 model that can be indefinitely trained to further the accuracy in diagnosing possible heart abnormalities.
The group used over half a million different patient data sets to train the neural network to become more and more accurate as time goes on. After training our model for 100 epochs, we have achieved an accuracy rating of over 99.7%.
It should be noted that the group did indeed discuss another simpler path to success which included transposing the 1-D ECG signals to a 2-d grayscale image and then using a neural network to identify what type of heart beat was occurring through image recognition with the help of ImageNet. However, the group decided that said path would be vulnerable to scaling issues and run-time efficiency.
Once the model detects with a high degree of certainty that a the patient is experiencing cardiac arrhythmia, and there is potential for entry into cardiac arrest, it uses the Twilio API to call a caregiver at least twice, in the event that the caregiver does not respond, 911 will be dispatched immediately.
Through the use of Twilio API, we have created a voicebot that relays important information to the caregiver such as location of the patient, their heartbeat and the diagnosis.
Challenges we ran into
When we first built the hardware to analyze the ECG, there was a huge learning curve. By the time we finally got it to work, we had already begun working on the machine learning model and incorporating the different aspects of the program together. At some point Saturday evening, the hardware stopped working and we could not get it to work despite hours of troubleshooting. Thankfully, we had a backup of each of our hardware elements and so we re-built the hardware from scratch.
We got it working only to find out that our Twilio account that we used to contact the caregivers got suspended as we uploaded our code to GitHub. Turns out that our Authentication ID and token were not allowed to be made public as it is a security breach risk.
Accomplishments that we’re proud of
** That the project works **. This was all of our first time using any machine learning software. We spent dedicated hours learning how to train models and how to use the models to predict the outcome of new data. We were really amazed and proud of how accurate the model is given the publically available dataset.
What we learned
Each of us learned something new while working on this project. To begin, we all learned the fundamentals of neural networks and how to build our own. We also learned how to develop a project from scratch. This was one of our first opportunity to work on a extensive project with a group. Over the 36 hours, we improved our ability to delegate tasks and organize the workflow to ensure efficiency and quality was met.
What's next for Rhythm
There is a lot of potential for Rhythm's future. To begin, we want to obtain higher resolution ECG data as well as more data for the Arrhythmias that were not included in the MIT data set. We also want to transform the ECG hardware into a convenient, portable device that is less intrusive as well as less noticeable (i.e an apple watch or fitbit).
References
[1] Kelly, B. B., & Fuster, V. (Eds.). (2010). Promoting cardiovascular health in the developing world: a critical challenge to achieve global health. National Academies Press.
[2] Chiarugi, F., Trypakis, D., Kontogiannis, V., Lees, P. J., Chronaki, C. E., Zeaki, M., ... & Orphanoudakis, S. C. (2003, September). Continuous ECG monitoring in the management of pre-hospital health emergencies. In Computers in Cardiology, 2003 (pp. 205-208). IEEE.
Built With
arduino
keras
numpy
pandas
python
tensorflow
tkinter
twilio
Try it out
GitHub Repo


Main Page
Inspiration
Our team believes that development of technology should benefit all communities. We happened to come across an interesting technology, IBM Watson, and we wanted to create a solution that might benefit the community as a whole.
What it does
A-Eye is meant to assist people with visual impairment, lessen the daily life struggles that people of visually imapaired community encounters in regular basis. A-Eye achieves this goal by providing a voice user interface that allow visually impaired individuals to easily locate objects around their environment.
How we built it
We builts our user interface and front-end using Android Studio, stored business logic and handled server request in the backend using node-js and express framework, the final model of our server is hosted publicly on AWS C9 to be accessible by public, and utilized IBM watson's visual recognition API to implment object recognition.
Challenges we ran into
During our production, we wanted to utilize the dialog flow to analyze the voice and generate a response that is more robust. However, we had difficuties connecting to the dialog flow and could not use it.
Accomplishments that we're proud of
Learned Android mobile application frameworks and features and created easy-to-use mobile application. Being able to manage multiple subsystems Using a structured software stack to build working front/back-end points Analyzing customer data using an unsupervised learning algorithm and applying knowledge gained from the analysis in real application Designed a simplistic UI that is intuitive and easy to interact.
What we learned
Features that are provided by the various APIs and how to implement them
What's next for A-Eye
Learn more in depth about different machine learning algorithms, evaluation techniques, and analyzing/visualizing methods. Research more APIs that are accessible to incorporate them into future events. Building more scalable mobile application accessible by various platforms (Android, iOS, etc.)
Built With
amazon-web-services
android
ayava
express.js
ibm-watson
java
javascript
mongodb
node.js
object-detection
Try it out
GitHub Repo


Inspiration
Each of our group members have been affected by Type 2 Diabetes as it runs in our families. From personal experience, we understand that diabetes can be a demanding condition to manage and affect our lives in many ways. Everyone wants to have the best possible quality of life. It just feels good to be satisfied and happy. However, there is another reason, as well. Just as diabetes can affect your quality of life, your quality of life can affect your diabetes. This notion inspired our application: Sugr Rush, a mobile application for identification of Type 2 diabetes and voice-enabled workout routines to prevent further severity of the condition.
What it does
Sugr Rush is a mobile application which identifies whether a female individual has Type 2 diabetes or not. It suggests workout routines with voice-enabled dialogue to guide patients through specified level workouts as per their health conditions related to diabetes. The application has a physician/doctor login and patient login.
On the patient side, the individual can request a diagnosis from their doctor at their clinic on the interface.
On the doctor side, the physician can login to his/her database and select new diagnoses to complete as per health care records. a) The doctor fills out patient information on the input parameters pertaining to Type 2 diabetes. b) The interface will output whether the individual is at low risk or high risk for Type 2 Diabetes. c) Information gets relayed to patient side
On the patient side, the individual views diagnosis and obtains workout routines tailored to their specific level of severity for diabetes. a) Voice-enabled workouts help the individual complete routines based on their frequency and time preferences b) Individuals may keep track of their workouts on interface and request updated diagnosis from doctor after completion of workouts in a set duration of time.
How we built it
The model is built using python’s machine learning libraries (tensorflow, Keras) by incorporating deep neural networks to predict whether a patient has type 2 diabetes or not. The model uses the K-fold Cross Validation(CV) technique by dividing the data into folds and ensuring that each fold is used as a testing set at some point. The data set consists of some medical distinct variables, such as pregnancy record, BMI, insulin level, age, glucose concentration, diastolic blood pressure, triceps skin fold thickness, diabetes pedigree function etc. The data set has 768 patient’s data where all the patients are female and at least 21 years old.
The front-end application interface was built on Sketch and Android Studio with the server hosted on the Internet. In addition, the voice-enabled, NLP technology was integrated with Dialogflow, an API on Google Cloud.
Challenges we ran into
Coming up with a solid idea that we are all passionate about
Connectivity issues related to integrating functionality of the back-end, front-end and speech into one application
Dialogflow challenges with voice integration
Learning curve in understanding new languages from scratch (JavaScript)
Accomplishments that we're proud of and what we learned
Learning more about the implications of Type 2 Diabetes
Working with the Dialogflow API for the first time
Communication between an application and a server hosted on the internet
Leveraging our skill-sets while learning new skills (whether it's a new coding language or constructing an interface)
What's next for Sugr Rush
Applying the solution across different demographics (males, children, individuals across different populations around the world)
Learning to diagnosis more specific problems related to diabetes (identification of Type 1 vs. Type 2, early detection, and hearing loss prevention from diabetes)
Integrating a communication network between doctor-side and patient-side for other conditions outside of diabetes on the application itself
Built With
android-studio
dialogflow
flask
google-web-speech-api
gridsearchcv
java
javascript
json
keras
kfoldcv
ngrok
numpy
okhttp3
pandas
python
sketch
sklearn
tensorflow
Try it out
GitHub Repo


The Working app - Conversation #choccyMilk
Inspiration
We were looking for a hack to really address the need for quick and easy access to mental health help.
What it does
Happy Thoughts is a companion service. Whenever in need or desiring a pick-me-up a user can text the app.
How we built it
Using a React-made webclient we accepted user inputted preferences. Via a Google Firebase realtime database we transmitted the preference data to a Node.js web server hosted on Google App Engine. From there the server (using Twilio) can text, and receive texts from the user to have valuable conversations and send happy thoughts to the user.
Also made with courage, focus, determination, and a gross amount of puffy style Cheetos.
Challenges we ran into
We didn't React well. None of us knew React. But we improvised, adapted, and overcame the challenge
Accomplishments that we're proud of
A team that pushed through, and made a hack that we're proud of. We stacked cups, learned juggling, and had an overall great time. The team bonded and came through with an impactful project.
What we learned
That a weekend is a short time when you're trying to make in impact on mental health.
What's next for Happy Thoughts
Happier Thoughts :)
Enjoy these happy thoughts
https://www.youtube.com/watch?v=DOWbvYYzAzQ
Built With
firebase
google-app-engine
javascript
node.js
react
twilio
Try it out
GitHub Repo


LOGO
Inspiration
Nowadays It´s very difficult to find a parking place downtown, specially in big cities. And meanwhile many private parking places are empty for a long time as they go to work somewhere else. So we want to create a service which can help citizens to offer their private parking places to those who need it and make some profit.
What it does
This service will help the parking place owner to offer their places and help the leaser to find the place and park the car.
How I built it
We connect the sensors like Raspberry Pi, Pi camera and Ultrasonic distance sensor with backend through LoRaWAN. We are using openalpr for recognizing car plates. The Backend can check if the parking car is authorized.
Challenges I ran into
Connecting Arduino with LoRaWAN
Building the Application in Backend
Accomplishments that I'm proud of
Development of with a very valuable and practical business model and cases.
We use low cost sensors set.
We addressed the society topic with the parking difficulty.
What I learned
I learned about LoRaWAN protocol and the practical usage of it. I have also learnt how to develop a business model.
What's next for Here2Park
We want to refine our technical solutions and provide a real product.
Built With
arduino
lorawan
raspberry-pi
Try it out
bitbucket.org


Inspiration
We were inspired to create a safe and supportive environment targeted towards individuals with ADHD/autism to practice and improve upon their social skills. As many struggle having weak communication skills and may not have the opportunity to work on them regularly, we wanted our web application to be an opportunity for conversation.
What it does
LettuceTalk allows the user to select a category of their choice to have a conversation on. The app then calculates a rating for the user’s response in real time, giving them feedback as they continue to speak. The algorithm encourages conversational depth and complexity by analyzing the length of the reply and keeping a count of certain keywords. After the user has finished their response, LettuceTalk exports their conversation data to a Google spreadsheet for later personal reference. This data can then be used to monitor progress, and target areas of improvement for the individual. We also included a feature to have the option of conversing in other languages.
How I built it
LettuceTalk was built using Javascript and HTML/CSS. We incorporated the use of Google Text-to-speech and Speech-to-text APIs and used Standard Library to connect the data collected by the web application with Google Sheets. We built a web application for an intuitive user friendly UI that can be easily accessed.
Challenges I ran into
There were multiple challenges associated with the production of LettuceTalk. The first was a matter of scope; originally, we intended to make use of data from Google Photos in order to tailor questions specific to the user’s experiences. However, Google Photos integration was too much to implement for our team in our short amount of time at the Hackathon. Additionally, prior to the hackathon, none of the team members had extensive experience with Web development; the project was a learning experience for each team member.
Accomplishments that I'm proud of
We were proud to have created a functional prototype of the web app we were envisioning. We were able to put our strengths together and work through our weaknesses in order to overcome the challenges along the way.
What I learned
Javascript, HTML & CSS, Google Speech to Text API, API implementation, Standard Library
What's next for LettuceTalk
In order for LettuceTalk to become an application that can provide more educational and medical purposes for users(mostly with ADHD/autism), visual functions should be added to the program that can trigger past memories of individuals selecting the specified topics. This is so to provide the user experience with more personally customized way. Additionally, the scoring system would be made more comprehensive in the future as the database of keywords grows. More complex facets of language could be analyzed as well, such as tone of voice and clarity of speech.
Built With
css
google-spreadsheets-api
google-web-speech-api
html5
javascript
standard-library
Try it out
GitHub Repo


unbiasMe
An AI based search engine capable of identifying bias in news articles and promoting sources that are unbiased.
STORY BEHIND THE PROJECT
University student environments are filled with passionate discussion and debates of controversial topics. The recent Canadian federal election was the first election that many current university students, including ourselves, were eligible to vote in. We both found it very difficult to learn about each party's platform objectively; it seems like every Google search result is trying to persuade you to think one way or another. It's extremely difficult for someone trying to learn about politics for the first, or any contraversial topic for that matter, time to comb through Google and find unbiased articles. The current media landscape does not allow for individuals to easily access unbiased information and form their own opinions. This limits meaningful conversation and causes people to be easily offended without first being thoroughly informed.
WHAT IS UNBIASME?
unbiasMe aims to target the above problem; it is a search engine that uses machine learning to determine which articles in a Google search contain the least amount of bias. It then displays those articles to the user first. It also displays a percent confidence for each article, which is simply how confident our machine learning model is that the article is unbiased.
When you enter a query into unbiasMe, a number of the results returned by Google are scraped to retrieve the text data in the article. For each result we convert this text data into numerical features that can be used by a machine learning algorithm. Intensive research was done to determine important features that can be extracted from the text data 1.
IMPLEMENTATION
The back-end is written in Python using Flask, and the front-end in HTML and CSS with a tiny bit of JavaScript. We use Google Custom Search API to Google the users query and extract URLs for our scraper. It was deployed using Google App Engine.
CHALLENGES ENCOUNTERED
Front-end development
That's it, we suck at HTML and CSS (don't even get us started on JavaScript).
PROUD ACCOMPLISHMENTS
Implementing Google Cloud APIs and deploying a website for the first time for both of us
Development of a web-app that actually runs and almost as good as we could have hoped
Development of a service that impacts many like-minded individuals
Networking with hackers from all around the world
WHAT WE LEARNED
That we suck at front-end web development.
How to deploy a website
It was some of our first times using sklearn and pandas instead of MatLab for machine learning
Sleep is important
WHAT'S NEXT FOR UNBIASME?
Our hope is to continue to develop the application by implementing more features to provide users with the best experience. One thing we'd really like to include is a recent news tab where users could go to get stories on current events that are unbiased. Also, the machine learning pipeline could probably be improved to provide users with more accurate results (though we are pretty happy with our 78% test accuracy). The code is not exactly the cleanest, and could probably be cleaned up to increase the speed of the search engine significantly.
MEET THE TEAM
MEMBER POSITION
Miriam Naim Ibrahim Biomedical Engineer
Rylee Thompson Electrical Engineer
[1] Horne, Benjamin D., Sara Khedr, and Sibel Adali. "Sampling the news producers: A large news and feature data set for the study of the complex media landscape." Twelfth International AAAI Conference on Web and Social Media. 2018.
Built With
flask
google-app-engine
google-custom-search
python
sklearn
Try it out
GitHub Repo


Imitation of banking app
Inspiration
We think improving cybersecurity does not always entail passively anticipating possible attacks. It is an equally valid strategy to go on the offensive against the transgressors. Hence, we employed the strategy of the aggressors against themselves --- by making what's basically a phishing bank app that allows us to gather information about potentially stolen phones.
What it does
Our main app, Bait Master, is a cloud application linked to Firebase. Once the user finishes the initial setup, the app will disguise itself as a banking application with fairly convincing UI/UX with fake bank account information. Should the phone be ever stolen or password-cracked, the aggressor will likely be tempted to take a look at the obvious bank information. When they open the app, they fall for the phishing bait. The app will discreetly take several pictures of the aggressor's face from the front camera, as well as uploading location/time information periodically in the background to Firebase. The user can then check these information (also please contact local police) by logging in to our companion app, Bait Master Tracker, where we use Google Cloud services such as Map API to display the said information.
How we built it
Both the main app and the companion app are developed in native Android using Android Studio. We used Google's Firebase to store user information, pictures, and location data. For our companion app, we also used Firebase and Google Cloud services to retrieve and display the information.
Challenges we ran into
1) The camera2 library of Android is incredibly difficult to use. Taking a picture is one thing --- but taking one discreetly without using the native camera intent and to save it took us a long time to figure out. Even now, the front camera configuration sometimes fails in older phones --- we are still trying to figure that out. 2) The original idea was to use Twilio to send SMS messages to the back-up phone number of the owner of the stolen phone. However, we could not find an easy way to implement Twilio in Android Studio without hosting another server, which we think will hinder maintainability. We eventually decided to opt out of this idea.
Accomplishments that we're proud of
I think we really pushed the boundary of our Android dev abilities by using features of Android that we did not even know existed. For instance, the main Bait Master app is capable of morphing its own launcher to acquire a new icon as well as app name to disguise itself as a banking app. Furthermore, discreetly taking pictures without any form of notification and uploading them is very technically challenging, but we pulled it off nonetheless. We are really proud of the product that we built at the end of this weekend.
What we learned
Appearances can be misleading. Don't trust everything that you see. Be careful when apps ask for access permission that it shouldn't use (such as camera and location).
What's next for Bait Master
We want to add more system-level mobile device management feature such as remote password reset, wiping sensitive data, etc. We also want to make the app more accessible by adding more disguise variance options, as well as improving our client support by making the app more easy to understand.
Built With
android
android-studio
firebase
google-cloud
google-maps
java
Try it out
GitHub Repo
GitHub Repo


Login screen
Inspiration
After reading a study that stated $62 million in pennies are accidentally thrown out each year, we were curious about how this money could have instead been used to benefit society. As such, we decided to create an app that allows users to use their leftover change to make an actual change for others.
What it does
change4change promotes charitable contributions through each of your purchases. All your transactions are rounded to the nearest dollar, with the difference going towards a charity of your choice. In case you’re uncertain of which charity to support, the app has built-in search capabilities that allow you to either search for charities by name or by category.
How we built it
Through Android Studio, Google Firebase, and the CapitalOne Hackathon API, we created our functional mobile app. Firebase provided a secure database for storing user credentials, while the CapitalOne Hackathon API enabled easy access to banking simulations to power our features. Android’s handy native UI elements allows us to create a sleek front-end to present to the user.
Challenges we ran into
As first-time developers on Android, we spent some time learning to work within the platform’s limitations. Obtaining a database of charities was also a challenge which we solved by scraping websites and processing data using custom python scripts to generate the database. Another challenge was configuring Firebase for Android to allow for authorization and data-storing.
Accomplishments that we're proud of
We are proud of our app’s functionalities since they are modularized and well-designed; as such, user experience is streamlined and simple. Additionally, we are satisfied with having developed a pragmatic charity search functionality by applying data science concepts and overcoming certain Android limitations. Additionally, we are happy with our ability to develop a sleek interface design that is appealing to users.
What we learned
Since many of us were new to Android development, we learnt the fundamentals of Android Studio and Java. Additionally, we had to learn how to use Firebase to authenticate user credentials and store user information securely.
What's next for change4change
We plan on implementing functionality for real banking institutions and potentially releasing this product to the Google Play Store. Additionally, we are looking into possibly rebuilding the app to be more scalable for larger operations.
Built With
android-studio
firebase
java
python
Try it out
GitHub Repo


Inspiration
Tax Simulator 2019 takes inspiration from a variety of different games, such as the multitude of simulator games that have gained popularity in recent years, the board game Life, and the video game Pokemon.
What it does
Tax Simulator is a video game designed to introduce students to taxes and benefits.
How we built it
Tax Simulator was built in Unity using C#.
Challenges we ran into
The biggest challenge that we had to overcome was time. Creating the tax calculation system, designing and building the game's levels, implementing the narrative text elements, and debugging every single area of the program were all tedious and demanding tasks, and as a result, there are several features of the game that have not yet been fully implemented, such as the home-purchasing system.
Learning how to use the Unity game engine also proved to be a challenge as not all of us had past experience with the software, so picking up the skills to implement our ideas into our creation and develop a fleshed-out product was an essential yet difficult task.
Accomplishments that we're proud of
Although simple, Tax Simulator incorporates concepts such as common tax deductions and two savings vehicles in a fun and interactive game. The game makes use of a charming visual aesthetic, simple mechanics, and an engaging narrative that makes it fun to play through, and we're very proud of our ability to portray learning and education in an appealing way.
What we learned
We learned that although it is tempting to try and incorporate as many features as possible in our project, a simple game that is easy to understand and fun to play will keep players engaged better than a game with many complex features and options that ultimately contribute to confusion and clutter.
What's next for Tax Simulator 2019
Although it is a great start for learning about taxes, Tax Simulator could benefit from incorporating more life events such, purchasing a house with the First-Time Home Buyer Incentive or having kids, and saving for college with RESPs. The game could also suggest ways for players to improve their gameplay based on how the decisions they made regarding their taxes.
Built With
c#
unity
Try it out
ryanaird.com


SwitchIt Logo
Inspiration
A lot of the time we receive vouchers and gift cards that we don't want or will never use. They gather dust, we forget about them and then they expire. You can't do anything with it, can't get it exchanged with anything else, it's useless to you. But what if someone else a voucher that they don't want either however you'd like one another's, or if someone wants it off from you?
What it does
That's where SwitchIt comes in!
Exchange unwanted vouchers and/or gift cards to strangers on the Internet for their vouchers and/or gift cards or sell/buy one.
A user can post an ad for a voucher/gift card that they do not need, once it has passed checks for being a valid voucher/coupon the ad goes live! Other users can then offer you to exchange it for one of their vouchers/gift cards and the seller can accept or decline the offer, the same applies to when wanting to buy a voucher, you make an offer and the person can accept or decline.
How we built it
We initially brainstormed a couple of ideas. After which we identified which idea would be a viable option to follow through. We decided with the idea of gift voucher exchange (the web app was called “GiftSwitch” at this point). From there, we designed the basic structure of the application as well as a basic flowchart of what pages would be there.
At this point, we delegate the tasks equally amongst the three of us. Rabarb designed the layout of the pages as well as the flowchart while Fahad started searching for an api to verify voucher codes. Kaleem started creating the front end by programming the design for the main page. We all worked in parallel achieving efficient results within a small amount of time.
Once Rabarb had completed her designs she started working on the front end along with Kaleem, creating the login page. This was Rabarb’s first time using React and the React workshop was very helpful to her. Meanwhile, Kaleem was stilling working on the front end, although at that moment he was working on the view voucher list page (the page where the voucher listings are shown). Furthermore, Fahad had started his painful journey learning how to set up the database until he realised that the WiFi was blocking everything. He then decided to hotspot his own WiFi and progressed further into the world of database creation.
Challenges we ran into
Setting up the database was a bit tedious at first due to multiple network issues, but after multiple attempts we managed to host the database on Google Cloud.
Accomplishments that we're proud of
Our team managed to create a project from scratch that is relevant to everyday life, as uni students we find ways of saving money and living the best broke life, vouchers and gift cards are some ways to save money for less. We've been able to create a proof-of-concept that can built and implemented into our daily lives, allowing others to use our platform to make money and help others save money in a different way, think BitCoin but really it's just... McDonald Vouchers...
We set up a working database and server, created a UI template for the front-end and have managed to start implementing functionalities and conversations between the front and back-end.
What I learned
The challenges that can be faced in such a time constricted time, working under that pressure and for some of us in our group it has been one of the first times to even use react.js.
What's next for SwitchIt
We want to make SwitchIt happen!
Our group of friends already sell, buy and swap vouchers and gift cards in person when we don't want it, so let's make it real! We plan on continuing to develop the project and hopefully make it go live. An app version of the product will also be created for ease of use too, and implementation of more sophisticated web-app altogether to make a product for the ages!
Built With
blueprint
css
db
domain.com
express.js
google-cloud
ios
macbook
macbookpro
mariadb
react.js
sql
Try it out
GitHub Repo


Our Team!
Inspiration
In our world of digital development, accessibility is vastly improving. However, with the newly started online banking system, we still have plenty of spaces to work on in terms of providing the same convenience to people with special needs.
What it does
Providing banks with data from special-need end-users, such as type(s) of disability, incident severity, spending value and frequency etc, as these are risks factors for big changes in their bank accounts. By analysing the financial information as well as health information, it is possible to ascertain both the degree to which such a person would need support and how quickly they need it.
How we built it
We built a deep learning neural net, with the aim of analyzing the financial information of those affected by accessibility issues and disabilities in finance. Such a model has the capability to uncover the links between various factors within a person life. By focussing on those who may be more at risk, we can specialise and allow customers to be catered to in a more tailored way than has previously been possible. This also allows banks to quickly adapt to changing customer focus, and ensure a more personalised and empathetic banking experience. #dontbeabanker
Challenges we ran into
We found difficulties obtaining legitimate databases to use as data for our neural network. This meant that a database of our own had to be created, using Gaussian distributions for random variables, and uniform and Poisson distributions to generate noise. Unfortunately, there was a misunderstanding in our team, leading to the guy who was doing the neural network to tear his hair out for 8 hours.
Accomplishments that we're proud of
Overcoming all the difficulties we've faced. And we came up with awesome names for our projects. We're proud of the breadth of what our algorithm has achieved as well
What we learned
We've learned how to use Bootstrap and connect a webpage to a domain using Domain.com. We learned to generate a deep learning multi-branch neural network with support for both categorical and continuous variables, and to learn the basics of natural language processing to analyse customer feedback.
What's next for AccessiBank
We're excited to combine both our ability to analyse the needs of the customer through deep learning neural networks and our ability to see in near real time the change of customer opinion by using natural language processing.
Built With
bootstrap
css
domain.com
google-cloud
html
ibm-watson
python
sklearn
tensorflow
Try it out
accessibank.space
GitHub Repo


Domain.com entry: PleaseGiveUsAGoogleHomeMiniForMoreCool.Tech
Inspiration/Background
Over ten million people worldwide are diagnosed with Parkinson’s Disease (PD), with studies suggesting that there are many more people who are not diagnosed due to the low accuracy of modern day testing methods, which are only 53% accurate. Recent studies have shown that Voice can play a strong role in detecting early PD symptoms, and so we set out to develop a tool to help doctors leverage this advance in technology to assist them to more accurately diagnose PD patients.
What it does
Our app works as a tool for doctors to aid them to detect early signs of Parkinson’s Disease in Patients. It does so by taking an audio file of someone speaking and passing it through to our custom Machine Learning Model, there it computes the discrete Fourier transform of the audio file, and analyses the patient’s speech based on 22 features. The ML instance returns the probability of the user showing early sings of the Parkinson’s Disease. It also returns the scores of each of the 22 features so that the doctor can have a detailed explanation as to how the probability was calculated. All of this is displayed in the Dashboard that the doctor would be able to access.
How we built it
At first we went through dozens of scholarly articles and read up about the relation between Voice and Parkinson’s Disease. Through our research we were able to find 22 features and their mathematical algorithms, from which we were able to recreate 15. We then trained a neural network to predict Parkinson’s from those 15 features. We used a data set from the University of Oxford to train our model. We set up our neural network on the Google Cloud Platform through a Flask server. Finally, we pass back the results from the neural network to the Dashboard for a clean Data visualization.
Challenges we ran into
Engineering the extraction methods for each individual feature was especially tough, since none of us had prior experience in the physics behind acoustics and tonality. Using Fourier Fast Transform, we determined the metrics related to the fundamental frequencies. Using Parselmouth, a Python library for the Praat software, we calculated metrics of jitter and shimmer. Each of the 15 features we found took extensive research and obscure Python libraries to compute.
Another challenge we faced was deploying the model to Google Cloud. A huge array of problems arised when deploying the back-end API for the neural network to be inferenced. (i.e. Cross-origin resource sharing (CORS) issues in Google Cloud when making requests from the front-end, Bugs in programmatic uploads & downloads in Google Cloud, Client-Server Architecture challenges, and many more...)
Git issues :P
Accomplishments that we're proud of
Our model achieved 92% accuracy on a withheld test set and 82% accuracy on the cross validation set! To see what can be accomplished using such little data is incredibly exciting, especially since we only recreated 15 of the 22 features! We're sure that with more effort into this project it can be developed into a real world solution that can save the lives of many people around the world.
What we learned
Deploying to Google Cloud can be really difficult when using machine learning models because instances tend to run out of memory.
A great team dynamic can make a hackathon a lot more fun!
Built With
css3
flask
google-cloud
html5
javascript
keras
python
react
tensorflow
Try it out
GitHub Repo


Inspiration
It sucks when you have vehicles double parked.
What it does
The smart camera capture images of double parked cars and create standardized lightweight packages for processing the fine centrally
How I built it
Currently tinkering on it
Challenges I ran into
I have limited tech skills
Accomplishments that I'm proud of
Got the Coral board to run inferences
What I learned
I need support ;)
What's next for Smart camera for vehicle fleets
Building a MVP
Built With
coral-dev-board
tensorflow-lite


Inspiration
Starting to work on a larger project is often intimidating. We developed this powerful tool to make it easier for programmers to get familiar with a new project.
What it does
Disastrous bugs could often be avoided, if a programmer would understand the codebase better. The best way to understand somebody else's code is to talk directly to the author. But in huge projects it is very hard to find out who wrote a specific component. This tool makes it extremely easy for everyone to find out who wrote a specific part of the source code. "Codeowners" returns a list of authors ranked by how often he changed the component. We started by identifying what distinct components we would need for a complete implementation of our vision. In order to make this large project feasible in such a short timeframe, we decided to limit our efforts during the weekend to implementing the command line interface that would form the backbone to our components hierarchy. We then developed an algorithm that identifies the code-owners for a given file and declaration in the context of the Git version control system. Then we further divided the algorithm into all the functions that we're necessary to implement. On Saturday morning we already had a first working implementation. We then spent some time looking into how we could implement an IntelliJ plugin that would make our project readily available from an IDE, but then decided to spent the remaining time to further polish and expand the application domain of our CLI backbone.
Throughout our development process, we put a huge focus on extensibility. Our Codeowners project is now extensible on multiple levels:
It is built on tree-sitter parsers, thus it is incredibly easy to add support for new languages.
It provides a CLI that was purposefully crafted to work well as a data-source to applications built on top and to also be nice to interact with directly.
Challenges we ran into
Initially, we decided to implement our CLI program in Python, but after messing around with relative imports for a while we quickly moved-on to Node tech stack. We compile our TypeScript source with Babel to standard ES5 JavaScript.
Due to a bug, we had some trouble to write a general purpose solution for traversing abstract syntax trees with the goal of finding a declarations given line numbers and vice versa. We were able to figure it out in the end.
What's next for Who Wrote That S**t
plugins for various code editors (e. g. IntelliJ)
support for all languages parseable by tree-sitter
Built With
bash
es6
git
javascript
node.js
tree-sitter
Try it out
GitHub Repo


Inspiration
Our team came up with this project while searching for a fintech solution. We concluded that budgeting appeared to be one of the primary concerns among students like ourselves. One of the pain points we drew upon was that it is currently very difficult to log every single expense that occurs. We all have expenses that are shared by a group of friends e.g. ordering pizza for dinner, paying off monthly utilities, etc. Upon this discovery, we noted that there were individual apps for budgeting and individual apps for sharing expenses. Our team sought to make a solution that is capable of providing the benefits of both budgeting and sharing expenses.
What it does
Splitz helps students manage their budgets. Users are able to log all their various expenses. Expenses can be personal or shared. Payments on shared expenses will update the user's budget accordingly. Splitz differentiates itself from other personal finance tools with it's capability to split expenses proportionately as not all shared expenses must be divided equally. Moreover, Splitz provides great analytics and insights on group spending habits which can further help students with budget management.
How we built it
We split up the work as follows: Dan developed the backend and created our databases using mongoDB. Ridvan and Michael worked together to form the frontend with Python. Albert sketched and designed the structural framework.
Challenges we ran into
Major challenges include: database creation, frontend development/GUI design, displaying insights for friends and groups, logic problems involving friends appearing in multiple groups.
Accomplishments that we're proud of
Extensive use of mongoDB Atlas, creating a GUI with Python that incorporates all the necessary functions, great teamwork with beginner hackers
What we learned
Identifying social problems and how they could be potentially solved, solutions architecture, proper use of Git, integrating the backend with the frontend and ensuring they align
What's next for Splitz
With Splitz, our team plans to revamp the current UI and create more accessibility for its users by scaling the platform up to a web and mobile app. We would also like to include mobile payments in our solution and allow users to quickly log their expenses. In addition, we are working towards incorporating payments into our solution via Interac e-Transfer. This will allow users to instantaneously pay off shared expenses, further simplifying the budget management process.
Built With
matlib
mongodb
python
tkinter
Try it out
GitHub Repo


Inspiration
68% of the universe is dark matter. Even within a day, almost 12 hours have low to no visibility in many areas of the world. This is also when most of the notorious activites happen. Despite the improvement in infrared cameras and computer vision systems in visible light, there is still a gaping hole in intelligence and automation for infrared camera footage which operate in low light or hazy conditions (Visible light systems have very poor, sometimes unusable accuracy). Customers, especially in private security companies and resource constrained police officers (like those at UCPD) are in dire need of a solution that reduces the manual labor of looking at video footage, much like it has been done for the day time. However, the lack of labelled training data makes this a hard task. We wanted to use our background in Artificial Intelligence and Cloud Computing to tackle this challenge.
What it does
Our system provides Artificial Intelligence on Infrared and Thermal Imagery as a cloud computing and an on-the-edge service. Officers, Security Providers,Disaster Response agencies, Intelligence Community and Army Troops can use this intelligence on both existing or new infrastructure in order to detect, identify, track and easily search for people or objects of interest. This makes existing infrastructure smart, people more effective and reduces costs to businesses by reducing manpower needed to watch video. By making the data richer, we can also enable advanced analytics on video data, while parallely providing peace of mind. Once our solution starts operating in real time, it could provide high amount of visibility for autonomous cars as well.
Accomplishments that we're proud of
We were able to start and complete some major parts of the development of the Demo MVP to show to possible customers, Cloud Machine Learning Infrastructure and Edge Compute transformations. In addition, we are done with a considerable chunk of the training of the data augmentation tools. We were also able to verify multiple existing cloud tools and their poor accuracy on Infrared Images.
What we learned
The problem space we have chosen is very challenging, but has a very high impact in terms of business value. The lack of data also supplements the lack of research in the field, thus making it a very niche field for exploration. We got to learn about some very deep challenges in image processing and boons and banes of serverless cloud compute. We also got to learn about each other as teammates, and how we can complement each other's skills in crunch times.
Built With
ai
amazon-web-services
pytorch
tensorflow
vision


Inspiration
As university students, we often find that we have groceries in the fridge but we end up eating out and the groceries end up going bad.
What It Does
After you buy groceries from supermarkets, you can use our app to take a picture of your receipt. Our app will parse through the items in the receipts and add the items into the database representing your fridge. Using the items you have in your fridge, our app will be able to recommend recipes for dishes for you to make.
How We Built It
On the back-end, we have a Flask server that receives the image from the front-end through ngrok and then sends the image of the receipt to Google Cloud Vision to get the text extracted. We then post-process the data we receive to filter out any unwanted noise in the data.
On the front-end, our app is built using react-native, using axios to query from the recipe API, and then stores data into Firebase.
Challenges We Ran Into
Some of the challenges we ran into included deploying our Flask to Google App Engine, and styling in react. We found that it was not possible to write into Google App Engine storage, instead we had to write into Firestore and have that interact with Google App Engine.
On the frontend, we had trouble designing the UI to be responsive across platforms, especially since we were relatively inexperienced with React Native development. We also had trouble finding a recipe API that suited our needs and had sufficient documentation.
Built With
firebase
flask
google-cloud-vision
node.js
opencv
python
react-native
Try it out
GitHub Repo


SMS Interface with user
InstaQuote
InstaQuote is an SMS based service that allows users to get a new car insurance quote without the hassle of calling their insurance provider and waiting in a long queue.
What Inspired You
We wanted a more convenient way to get a quote on auto-insurance in the event of a change within your driver profile (i.e. demerit point change, license class increase, new car make, etc...) Since insurance rates are not something that change often we found it appropriate to create an SMS based service, thus saving the hassle of installing an app that would rarely be used as well as the time of calling your insurance provider to get a simple quote. As a company, this service would be useful for clients because it gives them peace of mind that there is an overarching service which can be texted anytime for an instant quote.
What We Learned
We learned how to connect API's using Standard Library and we also learned JavaScript. Additionally, we learned how to use backend databases to store information and manipulate that data within the database.
Challenges We Faced
We had some trouble with understanding and getting used to JavaScript syntax
Built With
airtable
javascript
json
std-lib
twilio
Try it out
GitHub Repo


Wahyupoker ialah situs agen judi poker uang asli yang menyediakan permainan terbaik seperti bandarq dan domino qq online terpercaya di indonesia.https://wahyuqqonline.com/
Built With
bandarq
dominoqq
pokerqq
qqonline


What's next for Heading back in touch
Built With
libraries


Smart Glasses
Inspiration
The 2016 Fort McMurray wildfires were the worst in Albertan history. It was a transformational moment for the lives of thousands of Albertans, including us. The impact that this event had on us, combined with our passion for technology, inspired us to come up with novel approaches to disaster response — a field that is relatively lacking in new technology.
What it does
OnSight is a fully integrated end-to-end solution that connects first responders, coordinators, and citizens into one centralized disaster response coordination system. As citizens make 911 calls, the Google Assistant or Amazon Alexa can extract important details which are transmitted to a Realtime Database in the cloud. These reports are processed using the Google Places API to obtain the exact location of the issue. The details of these reports, along with a map showing their locations, are displayed on a web portal. Control Centre personnel can monitor these reports in realtime and relay them to first responders. First responders are equipped with IoT smart glasses, which connect to nearby Wi-Fi networks and pull new data from the database in real time. The data is processed on the edge, where it is intelligently parsed and displayed according to priority.
How I built it
Voice recognition: The conversational functionality of this component was built using Voiceflow and integrated into the Google Assistant and Amazon Alexa. The Google Places API and Firebase Database were integrated into Voiceflow using the REST protocol.
Dashboard: We built the dashboard using Vue.js. It pulls data from the database in realtime and dynamically populates the page with the newest and highest priority reports. Along with these reports, a interactive map of the location of the report is displayed.
Smart Glasses: The brain of the smart glasses is a NodeMCU ESP8266, which is an IoT-enabled development board that runs on the Arduino framework. The board is connected to an SSD1306 OLED screen, which is reflected and magnified using a series of mirrors and lenses such that it appears in the wearer's field of view.
Challenges I ran into
The biggest challenge we ran into with this project was getting the right magnification for the optics system. Despite our high-school level of optics education, we did not calculated the required lens parameters correctly. As a result, we had to mount our system farther forward on the glasses than we anticipated. Had we chosen a more appropriate magnification, the system could be mounted much farther back, resulting in a slimmer profile. Parsing JSON objects from the Firebase Database on the glasses also proved to be quite difficult, due to the low-level nature of the C programming language used on the NodeMCU.
Accomplishments that I'm proud of
Each member of our team worked to develop separate parts of the system. Not only were we able to get all three parts working, but we were also able to integrate them through various handshake protocols. The planning and coordination of this project is something that we are very proud of.
What I learned
-Various API calls -We got to do all kinds of development, ranging from web all the way to hardware -Optics is hard
What's next for OnSight
-Fix magnification -Natural language processing to streamline the speech recognition process into fewer steps -Location pinging on the glasses to prioritize reports by proximity to the wearer
Built With
adafruit
arduino
c
css
esp8266
firebase
google-cloud
html
i2c
iot
javascript
nodemcu
ssd1306
voiceflow
vue.js
Try it out
GitHub Repo
creator.voiceflow.com


Inspiration
https://www.youtube.com/watch?v=lxuOxQzDN3Y Robbie's story stuck out to me at the endless limitations of technology. He was diagnosed with muscular dystrophy which prevented him from having full control of his arms and legs. He was gifted with a Google home that crafted his home into a voice controlled machine. We wanted to take this a step further and make computers more accessible for people such as Robbie.
What it does
We use a Google Cloud based API that helps us detect words and phrases captured from the microphone input. We then convert those phrases into commands for the computer to execute. Since the python script is run in the terminal it can be used across the computer and all its applications.
How I built it
The first (and hardest) step was figuring out how to leverage Google's API to our advantage. We knew it was able to detect words from an audio file but there was more to this project than that. We started piecing libraries to get access to the microphone, file system, keyboard and mouse events, cursor x,y coordinates, and so much more. We build a large (~30) function library that could be used to control almost anything in the computer
Challenges I ran into
Configuring the many libraries took a lot of time. Especially with compatibility issues with mac vs. windows, python2 vs. 3, etc. Many of our challenges were solved by either thinking of a better solution or asking people on forums like StackOverflow. For example, we wanted to change the volume of the computer using the fn+arrow key shortcut, but python is not allowed to access that key.
Accomplishments that I'm proud of
We are proud of the fact that we had built an alpha version of an application we intend to keep developing, because we believe in its real-world applications. From a technical perspective, I was also proud of the fact that we were able to successfully use a Google Cloud API.
What I learned
We learned a lot about how the machine interacts with different events in the computer and the time dependencies involved. We also learned about the ease of use of a Google API which encourages us to use more, and encourage others to do so, too. Also we learned about the different nuances of speech detection like how to tell the API to pick the word "one" over "won" in certain context, or how to change a "one" to a "1", or how to reduce ambient noise.
What's next for Speech Computer Control
At the moment we are manually running this script through the command line but ideally we would want a more user friendly experience (GUI). Additionally, we had developed a chrome extension that numbers off each link on a page after a Google or Youtube search query, so that we would be able to say something like "jump to link 4". We were unable to get the web-to-python code just right, but we plan on implementing it in the near future.
Built With
google-cloud
python
speech-recognition
Try it out
GitHub Repo


Logo/PresentationFirstPage
Inspiration
Many programmers use the "rubberduck-debbuging" technique, to keep their work simple and understandable. Being able to explain your code line by line to a complete outstander (e.g. a rubber duck) requires deep understanding of the sourcecode and helps you structure your code in a simple and understandable way. But...
What if the rubberduck listended to what you explain to it, all the way through your debugging process?
What if it wrote everything down?
What it does
The application provides a graphical rubberduck to explain your code to. It's not only the perfect listener and keeps you motivated with little comments...
...it also protocols everything you explained, directly to your documentation of choice.
Through a graphical interface the developer can choose the file that he is working on. His file will then be parsed, and "typical" positions where documentation is needed (e.g. methods, classes) will be be suggested to him. He can then -with one click- start rubberduck debuggig and documenting in one go.
His language is Processed via Speech To Text and automatically saved; either to a documentation file, or directly as comments to the sourcecode.
How I built it
we built the application iteratively starting with a simple MVP with only a core feature and adding new features over time.
We use Microsoft Azure for speech to text and java fx for gui. The software uses general design patterns like "Model-View-Controller" and "Bridge" in it's architecture.
For simplicitiy reasons the App supports only one source language, for which we chose Java.
Challenges I ran into
pre-trained speech recognition models have to be retrained for specific purposes. Functionality vs. usability tradeoff. All of us were unexperienced with UI development in Java, so everything had to start from scratch. Since we wanted to make the program as user friendly as possible we had to stick to one supported programming language (in this case Java)
Accomplishments that I'm proud of
Being able to create a working app with no previous knowledge about speech recognition and with no front end developer on the team.
What I learned
Using Speech recognition and machine learning can be easy and fun :)
What's next for rubberDocs
RubberDocs as IntelliJ Plugin Retrained speech keyword model, to detect specific coding terms more easily. Nicely reworked UI. Use MS Azure API to track the developers' mood while debugging, and keep him posted with motivating messages. Support for other programming languages other than Java.
Built With
azure
intellij-idea
java
speech-to-text
speechapi
Try it out
GitHub Repo


The landing page
Empower
We are living in times of incredible change and activism as millions of people around the world strive to make the world a better place by utilizing the strength of community to come together and stand up for themselves and what they believe in in organized rallies. However, it can be incredibly difficult to find ways to participate in these events due to a lack of solid information about the protests in your area. Empower is a web app that allows users to post ongoing and upcoming protests to our platform where their information will be stored with MongoDB Atlas. That information is immediately placed as a pin on a dynamic map using google maps. It is very easy for users to quickly find and identify rallies taking place in their area. Additionally, Empower has a global outreach tab where you can recieve centralized, reliable information about major rallies taking place around the world. On this page is located helpful links so that users can aid the protestors from the comfort of their home.
Hosting
Empower is hosted on an MS Azure VM which can be accessed at: http://empower.eastus.cloudapp.azure.com:5000/
Getting Started
1) clone the repository 2) install the following dependencies: - Flask - pymongo - googlemaps - dnspython 3) run python3 app.py 4) Run localhost address given in terminal
Built With
Flask - Used for the backend.
MongoDB Atlas - Stores information about protests both geographical and informational.
googlemaps API - Used to generate a map and pin protest locations on said map.
Images
Authors
Kareem El Assad
Alois Clerc
Gabriel Elkadiki
Subhrodeep Ghose
License
This project is licensed under the MIT License - see the LICENSE.md file for details
Acknowledgments
Thank you so much to the Hack Western team for putting on such an amazing hackathon!
Built With
azure
css
flask
html
javascript
mongodb
python
Try it out
GitHub Repo


Motivation
Part of Durham County Council’s adult social care services includes improving the daily living of elderly residents who have either mobility issues or mental health problems. However, the cost of these social care projects and personal care assistants is ever-increasing, due to an ageing population. In the year 2018/19, more than 840 000 people received publicly funded long-term adult social care. Clearly, the demand is huge, and so assistive technology is implemented to combat these issues while keeping costs to a minimum. This relieves pressure on adult social care budgets. An estimated 1.1-1.7 million people in the UK are currently supported by assistive technology, solving a variety of problems.
What we wanted to achieve
Our idea is to create a communication-focused companion to combat loneliness in the elderly, especially those showing early signs of dementia. Many individuals in this category live alone, and therefore have little opportunity to have a conversation. Age UK report that over a million older people say they go over a month without talking to a friend, neighbour, or family member. It is possible that this lack of conversation could lead to a deterioration of their memory. Our device should promote a daily conversation that forces the user to interact with the toy, by recounting their activities throughout the day, for example. The Alzheimer’s Society claims that keeping the brain active by doing these sorts of exercises can improve memory and retain information for longer.
The device should follow some fundamental aims:
• It should be easy to use
• It should be follow some basic word triggers to execute commands and respond with one of a list of phrases.
• It should detect a cry for help, to trigger a correspondence between the user and a family member / emergency services
• Give reassurance to family members that their loved one can find comfort with this assistive technology
How we achieved this
Alex and Matt resourced a cuddly puppy toy from a local charity shop. Matt and Ross proceeded to tear apart said toy and insert various components into its stuffing, including servos controlled by a Raspberry API. Meanwhile, Tom created a speech-to-text (STT) as well as a TTS protocol for conversation between the user and the toy. This used a web-scraped API for the Mitsuku chatbot. Alfi looked at how we can store the data in the cloud and Ross investigated how to relay information to the front end via Twilio, which Alex looked into.
Eventually, the device should address the aims via the following:
• Being a verbal diary and conversationalist
• Detecting when user says trigger word (“sad”, “lonely”, “depressed”, etc.) and prompts user to decide whether they want the bot to contact family members
• Encouraging user to recount more details of anecdotes, etc.
• Dancing every now and then
• 5% chance of reminding user to drink more water
Technologies used
• Twilio: To send SMS messages to family members, including daily updates. These updates are short, but will contain a link to further information hosted on the website that will show how many times the user has interacted with the toy, outlier times, and average mood based off a score that the bot assigns the user each day
• Google Cloud Platform: The server and database are held in the cloud
• Google’s Text-To-Speech API: Used in the hard-coding of the bot
• Domain.com: Got the domain for the website here
Challenges we ran into
Initially, we thought we could use the Google Home Mini for the microphone / speakers. However, we realised this would involve using Google’s own speech recognition software, and thus requiring the user to say Google’s start-up command (“OK Google”). This would then go against one of our key aims which is to make the technology as easy to use as possible, given the target audience.
Another problem we found was that the version of Python that the Raspberry Pi was running didn’t support some of the code, so some updates needed to be made.
Trying to fit the servos into the stuffed toy proved problematic, so a supportive frame had to be fitted inside so that the arms could be made to move. We built the frame out of chopsticks and zip ties.
We also abandoned the idea of implementing mongoDB into our database structure in favour of Google’s Cloud platform.
The microphone / speakers we had available to us either wouldn’t connect via Bluetooth or used a 3.5mm jack input which also wasn’t supported on the Raspberry Pi. So, for the purposes of the demonstration, we will just use a laptop for the peripherals to hook up to.
Background noise was also an issue the team had to resolve in order for the voice recognition software to work correctly.
Finally, the lag between speech detection and response was initially too large for the interaction to be considered a conversation. Hence, some tweaking was necessary in how the components communicated with each other. This sped up the process dramatically.
Hacker was originally supposed to be a bear, but the only stuffed toy available at Oxfam was a husky puppy. We prefer it this way anyway...
What's next for Hacker the Husky
There is clearly room for machine learning implementation in the design. This would improve performance and reliability, especially in reading moods taking appropriate courses of action. We will also create a more robust physical product, whose movements are more realistic.
We hope...
That in the future this type of assistive technology can be used by older people to comfort them and act as a verbal diary, possibly lowering the risk of developing types of dementia, and thus lowering the emotional and financial pressures on families and carers.
Built With
google-cloud
google-text-to-speech
json
mitsuku-api
python
raspberry-pi
servomechanisms
twilio
Try it out
GitHub Repo
GitHub Repo


hurdles base (correct, one middle frame)
Student athletes often have a hard time affording the time and money it requires to attend classes in order to maintain their skill. TRACKer aims to solve this issue. TRACKer uses CMU's open pose to compare an individual's form with that of someone who they aspire to be like (a pro, for example). We built TRACKer using tensorflow-gpu and NVIDIA's CUDA and CUDnn driver libraries with a deep neural net based off CMU’s openpose for accelerated pose estimation on frames of a video. The most difficult part of the project was getting the flask call for python to work, as transferring the results from a python file to our website was a severe headache. We are proud of successfully implementing not only flask but also CMU's openpose, the latter of which was only possible due to prior experience in tensorflow-gpu use. We learned about the various different ways of storing data on a website and the limitless applications of tensorflow. In the future, we hope to host TRACKer on a public site and share our product to the masses, as it is currently limited only to a local host.
Built With
css3
html5
javascript
opencv
php
python
tensor-flow
Try it out
GitHub Repo


Inspiration
Personal experiences such as waiting in queue at places like Rathaus, Gym, Klinikum, Banks etc insipired us to come up with a solution that can help people use their time efficiently and digitalize the whole process of queueing.
What it does
Digitalize queuing system via LoRaWan communication protocol.
How I built it
Used LoRaWan node which reads RFID tag and further sends to Gateway. Further Gateways sends information such as queue information.
Challenges I ran into
Model to replicate Treadmill LoRaWan bidirectional communication Arduino hardware not responding
Accomplishments that I'm proud of
Working prototype Team collaboration
What I learned
LoRaWan communication How to build a working prototype
What's next for wait@ease
Use the collected data for analysis such as Calorie burner, usage of machines, better workout plans by trainers Business model Building miniature prototype Integrating to Smart watches
Built With
arduino
c++
led
lorawan
mqtt
python
ttn


Inspiration
Two years ago, an especially eventful "fake homecoming" left an 89-year-old Broughdale avenue resident with a front yard garden planted by her late husband completely destroyed by a portion of the 11,000 students who attended the event. A GoFundMe campaign was set up by a group of students and funds were raised to support the replanting of the garden. Even with widespread support online, only a handful of students showed up to help, most only because they had passed by on their way to class.
The Problem:
In the past 20 years, massive leaps in technological innovation have revolutionized the way work, play, and interact with each other. The prevalence of technology in our everyday lives has created a number of challenges for younger generations, most of whom haven’t known a life without computers. Media consumption is at an all-time high with most adolescents spending nearly 8 hours a day consuming media, with 95% of teens and young adults owning a smartphone. Along with an increased dependency on electronic devices and social media comes a notable rise in mental health issues alongside a decrease in social and community involvement, especially with the high-school and college-aged population.
What it does
Connect London is a mobile app that connects London youth with their community, with a focus on social responsibility, community participation, and active lifestyle events. Anything from volunteering opportunities to last-minute pickup soccer games around the city will be made available with a proximity-based map and list. Connect London will also support a voice-activated search, offering a turn by turn navigation tool for hands-free use when on the road.
How we built it
We built our app using Java, The London Open Data API and Google Cloud Speech to text
Challenges we ran into
The first challenge we faced was pinpointing the right solution to address the lack of community involvement in today’s youth. We also faced challenges in implementing the mapping and navigation in our app.
Accomplishments that we're proud of
We are proud to have a functional application with all the main features that we had envisioned.
What we learned
This project helped us with further developing our app development skills and helped us realize the challenges that come with it.
What's next for Connect London
For our Connect London app, we plan on implementing authentication and user login, safety and security measures as well as showing the number of people attending events.
Built With
android-studio
java
photoshop
Try it out
GitHub Repo


Game Drive: Logo
Game Drive – By Lukate Games
During last year myself and Luka created Lukate Games, a name to operate under whilst we coded and created games for both Android and IOS. Our most recent production was a space themed level-based game called ‘Space Ark’. Unlike Luka who has been coding for 10 years and worked as software developer I have no prior coding experience. We split the tasks up mainly with me designing the sprites and overall layout of the game, whilst Luka completed the coding. Throughout the process I got extremely interested in programming and wanted to be able to contribute to that side of the project. Luka taught me the basics and I managed to progress, however the tools out there like libgdx and Unity were too advanced for a newcomer to understand. Upon hearing the theme of ‘Accessibility and Inclusivity’ it sparked my memory of this struggle and after consideration we decided to build ‘Game Drive’.
Game Drive is a game development, cross platform software that provides users with the ability to bring their ideas to life and develop their own games. Unlike Unity and other tools on the market it is an entry level tool, inclusive of all abilities. Providing anyone that wants to create a game the ability to do so, free of charge. The idea is to streamline the game making process in one easy to use click and drag tool. The end goal being that the user when using default settings only needs to upload imagery.
Building Process: • Developed an API using Libgdx and GSON. The API takes a set of JSON files and initialises the game. The API fully re-sizes and scales to any phone based of an initial phone size. • Developed API functionality to provide users with necessary functions to implement functionality into their game. • Began developing a GUI using swing. Created features to upload and preview images. Unfinished sadly 
Problems: • Developing the API and GUI was a lot more work than we anticipated. There is so much functionality we could include with collision detection, developing the physics library, implementing graphical features with fonts and animation etc. We also wish to link the API to google cloud to create an online repository with pre-existing game features and code.
Doodle Jump: • As a demo we developed a basic version of doodle jump. Combined the JSON and code files were around 400-500 lines of code. Comparatively without our API and structure realistically making this basic game could be up to 10-20 times more code.
We as a team of 2 that like sleep have had only a small amount of time to create this huge task but in terms of future developments and the scope of this tool, we believe that Game Drive could utilise google cloud to create a repository of pre-existing actions, triggers and events. From the online repository the API would inject precompiled classes ready for use on runtime. With more time we would increase the functionality, we have currently created a physics library with functionality for acceleration, impulses and gravity. Our API also includes animation features to allow users to produce different features such as fades, shakes and basic movement. The goal is that as the popularity of the tool increases the cloud will enable expansion, constantly making Game Drive even more efficient.
Built With
gson
java
json
libgdx
Try it out
GitHub Repo


Web browser displaying analytics
Baby Whisperer
The Baby Whisperer is a revamped baby monitor that uses voice enabled technology to identify variable crying patterns for infants. TensorFlow was used to process convolutional neural networks of the Mel Frequency Cepstral Coefficient of the infant cries audio files, and categorize them with a predictive reason of crying. The baby's cries can be recorded from a device that will associate the crying to a reason with the help of the neural network. The caregiver will also receive an SMS message with the reason at the time of recording. Additionally, a web browser is used to display the analytics of this data including most common reason as well as how many times a day the child has cried.
Built With
bootstrap
css
html
javascript
node.js
python
tensorflow
typescript
Try it out
GitHub Repo


Baby Signs
Inspiration
Language is important and useful—but for some of us, it's not as easy as it sounds:
Out of every 1000 newborn babies, about 1 or 2 suffer from severe hearing loss.
Over 96% of congenitally deaf children worldwide are born to hearing parents, who are unfamiliar with sign language and have trouble communicating with their babies.
(WHO data on deafness and hearing loss, March 2019)
We wanted to create an app that helps deaf children communicate better with the world, but sign language is more than just a tool for communication. Scientists found that learning sign language at an early age also helps with brain development and general intelligence in congenitally deaf infants.
Through sign language education, we're providing a chance for them to develop into brilliant minds of the future, one Baby Sign at a time.
What it does
Baby Signs listens as the user speaks, and searches for the sign language translation in its sign language dictionary. The video "translation" is played after the user finishes talking.
Baby Signs can be used mainly as an educational tool for children with hearing loss to learn sign language from their daily environment, or for parents to pick up sign language alongside their children. However, we also encourage people with normal hearing to learn sign language with Baby Signs. On the other hand, people who already know sign language can use the app as a way to understand spoken information (when other skills, such as lip reading aren't feasible).
What's new about Baby Signs
This is not the first speech-to-sign language project. However, Baby Signs is better:
Hand Talk is an app that converts Portuguese to Libras (Brazilian Sign Language) with cartoon animation.
Baby Signs translates English to American Sign Language, which is likely the most widely used sign language. For teaching purposes, we chose real-person recordings, which are more vivid and demonstrate digit movements more clearly.
Speech-to-Sign-Language-Translator translates recorded speech files to American Sign Language, but it is buggy and only has 159 words plus 26 English letters in its dictionary.
Baby Signs has a dictionary of over 8800 most commonly used words and phrases and works offline with real-time microphone input, so that parents can communicate with their children whenever and wherever they want.
How we built it
We acquired our text-to-sign dictionary from SigningSavvy.com and Handspeak.com, which in total contains more than 8800 words and phrases recorded in American Sign Language. We used PyAudio to stream microphone input and pass it on to Google Cloud Speech-to-Text API, which converts user speech to text. The text output is then fed into a python script that finds a good match in sign language: if the speech contains a phrase that exists in the dictionary, the phrase is preferred to its components; in this way we can avoid nonsense direct translations to a degree. Finally, the corresponding "translation" is played with a PyQt media player.
Challenges we ran into
We had problems deploying the Azure (microphone-)speech-to-text service (Speech SDK) on our laptops, even though the wav-to-text function works fine. After considering the alternative options, for example saving the user speech input as a .wav recording every time, we decided to use PyAudio to stream real-time microphone input and parse it with Google Cloud Speech-to-Text API.
Accomplishments that we're proud of
We came up with this idea, which we believe can actually benefit a large community and bridge the gap between individuals with and without normal hearing.
What's next for Baby Signs
What we have so far is a functioning prototype. Next, we want to enlarge our dictionary of sign language recordings, either by finding additional resources or by allowing uploads from sign language users. Second, our current method of generating sign language translations is still far from perfect. We might employ natural language processing techniques to create more accurate, context-dependent translations with linguistic nuances; an alternative would be to recruit fluent sign language users who could "proofread" the content. Finally, we might include illustrations and animations of cartoon characters (in addition to real person recordings) to make the app more appealing to our young users.
Built With
google-cloud
pyaudio
pyqt
python
Try it out
GitHub Repo


Inspiration
In this day and age, a lot of people are worried and conscience of their effect on the environment. However, this topic is full of misinformation and conflicting data which can lead to this being a difficult process. Showcasing carbon-bank: a financial planner that automatically calculates a user's carbon footprint and gives them the option to offset it by a percentage of their choosing. This makes environmentalism convenient, eco-friendly and financially responsible.
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for Carbon Bank
Built With
cloudsql
express.js
javascript
node.js
python
Try it out
GitHub Repo


Inspiration
We, the team, have had friends who were utterly brilliant, always smiling, being the light in friend groups while sadly silently suffering away and the only time we got to know about their suffering was when it was already too late for us to act.
What we have experienced in our lives has pushed us to participate in this very challenge because people should know that there is help out there for them, that they deserve the help, that they are not a burden to society and that they are deeply loved.
There is this big stigma in society about mental health issues and people, specially students like us, are scared or not aware of how to reach out for help. This invisible disability, Depression, is one that keeps taking people away from us without us being able to do much about it.
We think we are fine, we think that it is just a phase but in reality a huge percentage of students are silently suffering from Depression without anyone in their surroundings knowing about it. These people live with a mask in society while they are silently dying inside. Depression affects their lives massively without them realising it. Their studies, their relationships with friends and families, their mental and physical health are heavily impacted from it and people are still afraid of reaching out and talking about it because they are so scared of being categorised as weak or of being treated as an outcast.
If you google around about suicide attempts, you'll notice that the most common thoughts of those people before attempting it is that they feel that nobody cares.
This is where we step in. We want to tackle this mental illness by helping people before they are driven to a point of no return. We want to use the idea of frequent positive reinforcements through an app to keep up with a users' emotions and to keep up with their mental health and to encourage them to reach out when matters are getting too tough.
What it does
We are in no way creating an app to replace professional help, but rather an app that acts as a bridge towards getting help. For the moment, we are just writing this app to help students because this is what we are. The app uses the idea of positive reinforcements on a regular basis to help the user feel a bit better. At the very beginning we use a short normal survey to find out a bit about the user and then we follow up with bigger questions to go a bit more in depth and all this info is fed up into a mini database on which the APIs from the cognitive services from Azure act on to get a very clear idea of how the situation is and we base that on a scale of 0-10.
The app has default settings of sending a small notification every 4 hours to the person to check if they are doing okay and it also send a small positive message to hopefully improve their mood. The user can go into settings and change a lot of things such as, they can change the time interval at which they get those messages. We also added a special feature where the user can select some of his favorite animals and choose if they want to get pictures and videos. What this exactly does is that, whenever the user taps on the notification message, they are greeted into the app with a cute image of a small animal or a short funny video of the animal. We all love small fuzzy dogs or cats doing funny, innocent things. So our plan with this feature was to just bring a little smile on the person's face.
We also implemented some more serious features- voice recording and notes. We encourage the user to write a little note about how they felt recently, but as we all know- writing on a smartphone can be very draining sometimes and for a depressed person, this might feel too big of a step to take. So we added the ability to record short voice notes of their feelings. Here, we implemented an API provided by the cognitive services by Azure which is Speech-to-text so that the person could choose if they wanted to have their voice notes converted into text afterwards.
We now have the data of how the person is feeling, but what do we do with it? We just use another API from Azure ;) Here, we used the text analytics. So what it does is pretty simple, it goes through the text and pretty much finds out how the person is doing based on what he wrote or recorded. In the end, we get a result based on a scale of 1-10 about how good or bad the person is feeling.
We are also implementing a small selfie feature where the user can take a small selfie of their face in the app and it runs the emotion recognition API from the cognitive services to find out how the person is doing.
During the bad times, we also encourage them to reach out to friends and families. We added a small feature where you can select contacts that you can call during those bad times.
All this information about the text, the recordings and the selfies are saved into a mini database and we run an AI on it to find out how good or bad the person is doing.
Depending on the answer, we send more/less positive reinforcing messages, show more/less pictures/videos and ask often/less times if they are doing fine. Since we know that it is hard to dial a friend during a depressed phase and talk about it, we implemented another feature that ask if you want to talk to a friend and then the app shows the list of friends that the user previously marked. All the user has to do then is to tap on a name and the app will dial that person. This might not seem like such a big feature but for a depressed person, it might just be what they need- to be shown that they have friends who they can Reach out to.
Like we said before, the app is not a replacement for professional help. When the app finds out that the person is doing really bad or have intentions of hurting themselves in any way- an alert pops up on the screen and it shows "Do you want to call the Krisendienst?". If the user taps on yes, a call to the krisendienst is immediately placed so that the person is a step further to getting professional help.
This is why we say that our app acts like a bridge to get professional help.
How I built it
We started coding the app with very simple loops until we realised that the API provided by the cognitive services of Azure fit perfectly for what we are tackling. So we downloaded Xcode and started making the interfaces for the app which was quite easy to complete and then we just downloaded the APIs from Azure and implemented them in the app.
Challenges I ran into
Well, none of us in the group had any experience with Xcode so we took quite some while learning how to use it with the help of youtube. We got a lot of troubles with the APIs because we are still trying to make everything work perfectly with the data bank. We have had bugs/errors pretty much everywhere and our knowledge of frameworks is very low, so to implement everything is still a huge challenge because we started with basically no real knowledge of anything apart from knowing a bit of Swift.
Accomplishments that I'm proud of
Group work. It's amazing how we were able to work as a team since we did not know each other beforehand. We had no idea that such APIs on AI are available to us freely and we were completely amazed at how powerful and accurate they are. Having had friends who went through major phases of depression, we felt like we were really making a step forward to changing so many lives.
What I learned
Group work. Working with APIs. Working with Azure and AI. Learning to use Xcode at a very amateur level. Just making everything work together.
Coffee is golden liquid.
What's next for Reach Out
Finish the app completely and make it work without bugs. Reach out to a wider audience and be able to help them. Add more features to make the users feel like they are being taken care of. Publish it. Save lives.
Built With
azure
emotion-recognition
face-api
swift
xcode
Try it out
docs.google.com


Splash
Solves the pain of candidates getting their foot in the door, while decreasing the noise in hiring process for competitive companies. Users take an initial coding assessment of Leetcode medium to hard rated questions. Those who exceed our internal score threshold are given the opportunity to purchase mock interviews with software engineers at top tier Silicon Valley companies for around $50 USD. Those who perform well on these mock interviews are given heavily weighted referrals to the companies represented by the software engineers, thus expediting the interview process and cutting down on time and money spent on recruiting and validating talent in a saturated industry. Moreover, the software engineers benefit from recruiting top tier talent to a company that they have vested interest in and collect on lucrative internal referral bounties.
Built With
angular.js
heroku
typescript
Try it out
refmark.herokuapp.com


Inspiration
T
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for TF2.2


Detecting mood.
What it does
Uses facial recognition and sentiment analysis to recommend music, movies and gifs.
Why it's cool
Helps the user cope with their emotion. For ex, if someone is feeling sad, they would probably want to watch movies or hear songs that fall under the same genre.
Likewise, if someone was feeling happy and wanted to maintain that feeling, they could use our application to prevent themselves from accidentally watching something sad
Fast movie recommendations along with detailed descriptions of each, ensuring less time searching and more time watching.
Song play and GIFs provide the user with an added immersion into their feelings. Psychologists agree that denying one's emotions is harmful and prevents one from understanding important psychological clues about themselves.
How we made it
Uses nodeJS and Standard Library to make API calls to the Spotify, Youtube, TMDB, and Giphy APIs. FaceAPI for sentiment analysis.
Built With
giphy
javascript
node.js
spotify
standard-library
tmdb
youtube
Try it out
GitHub Repo


Business Model
Inspiration
Within times of rapid digitalization, it has become increasingly hard for small and medium-sized enterprises (SMEs) to adapt to technological changes. Even though SMEs could profit from cloud-based services, adoption has been slow due to the complexity of the transformation of their business model. We want to change that!
What it does
First and foremost, our web app makes it easy for SMEs to register and experience the advantages of cloud-based services. We aggregated live data such as weather conditions and traffic to predict the number of visitors and therefore the load for SMEs in the area of winter tourism. Full integration of the outdooractive map which allows our users to give detailed recommendations based on the current environmental circumstances.
How we built it
We decided to build a web app around a combination of cloud services. To achieve the modularity needed for this we decided on a frontend built-in angular, supported by a python/flask backend that stores the needed data in a MongoDB. The integrated services are used in many places in the app, be it simple readouts of useful data or detailed analysis of data that allows us to predict their impact on the business. Our GitHub.
Challenges we ran into
Fortunately, the region of Allgäu has a lot of digital services for its tourism industry with two fully functional GIS applications. The API for one of these services turned out to be highly informative but restricted us from implementing their data into our own mapping solution. This digital infrastructure presented us with a general challenge on how to create valuable and unique services.
Accomplishments that we are proud of
We are especially proud of the number of APIs that were included for our prediction (see figure 'Tech Stack'), since they were integral to creating meaningful value. Also we think that we achieved our goal of a simple to use user friendly design, which is focused on aiding enterprises in their decisions.
What we learned
How to successfully distribute work all team members and keep team morale up.
What's next for Alpenlytics
Inspire SMEs to share data in order to make the predictions more reliable and create a digital network for innovation in a time period of transformation of the Winter tourism due to climate change. Integration with the BayernCloud. Real time data collection from SMEs.
Built With
angular.js
flask
mongodb
python
Try it out
GitHub Repo


Inspiration
Entering university, we all get shiny new debit/credit cards made but no proper guidance on how to be smart while using it. Spending can go unchecked and as college students, we can suffer greatly from this.
While many of us spend hours a day on our phones, and multiple applications exist, few of us take the time to monitor our financial records.
What it does
Enter Budget.SMS. We help you budget your finances and thus be more financially aware. You sign up for our service using a simple SMS message. Once registered, we help you stay on budget, notify you when any purchase is made and on request give you a record of all transactions you made that month. We do this by looking over the transactions that are safely recorded on a MongoDB Atlas instance and notifying you with our services over SMS using the Twilio API.
The benefit of using Budget.SMS is that any payment issuer, or financial institution can quickly and efficiently connect to our service and provide their customers with real-time updates into their financial history, without having to build their own complicated messaging services, or risk exposing sensitive data through APIs. Instead, these companies can simply send a quick HTTP request to our services with information about a specific customers behaviour (e.g. a recent purchase) and we take care of the rest.
Best of all, all that is required for a customer to get started is their phone number. Budget.SMS simply records the transaction history associated with each phone number provided, and then users can simply text to our services to obtain information about their history, or have our services notify them of any recent activities.
How we built it
We build this primarily using Standard Library which simplified our workflow for making API calls. The backend here is written in node.js and we used MongoDB Atlas as our database.
Challenges we ran into
We had trouble connecting to MongoDB Atlas on standard library but were eventually able to figure it out.
What we learned
We learned how to better delegate tasks in a team environment and improved our proficiency working with API calls, database queries and HTTP requests.
We got to explore new technologies such as Standard Library
We got to solve a real world problem that we ourselves face on a regular basis using some of the latest and greatest technology
What's next for Budget.SMS
Integrating payment processors and or financial institutions into our services.
Expanding our services to include more rich features such as "query specific date ranges"
Built With
bootstrap
css3
html5
mongodb
node.js
stdlib
twilio
typeform
Try it out
stdlib.com


Inspiration
Food is an important part of our daily lives. With the assistance of machine learning, the ability to identify unknown foods through image recognition opens new doors for culinary enthusiasts who desire to seek out new local restaurants and recipes, expanding their world of food, one picture at a time.
What it does
The user is allowed to take a picture of a complete dish or specify a list of basics ingredients. Alternatively, a user may also input a keyword. Utilizing machine learning using Convolutional Neural Network, the program will first identify the picture sent. For complete dishes, the program will display local restaurants that serve the item, or recipes to make the dish. On the other hand for ingredients, the program will analyze what ingredients you have, and return a recipe which caters best to what is available in your kitchen.
How we built it
As a team, we decided to create an iOS and cross platform Android mainly via react-native. API calls were made using the google-places API for restaurant locations, and the Spoonacular API for recipes based on either dishes or given ingredients.
Challenges we ran into
Early on, during the project, we ran into issues connecting the mobile app to our own server's API.
Accomplishments that We're proud of
An accomplishment that we can be proud of is that we managed to finish the project for the Western Hackathon within the designated time frame.
What we learned
During the endeavor, we learned to manage time and follow group protocol in order to have every individual member on the same page. We also learned the importance of understanding each other's strengths and weakness because a team is only as strong as its weakest link. Knowing each other's weaknesses mitigates this fact as teammates can cover for each other's weaknesses and work together to further enhance the group's overall strength.
What's next for ChowDown!
Integrating additional data sets into machine learning for the image recognition algorithm in order to increase its success rate of identifying certain types of foods.
Built With
android-studio
flask
google-places
javascript
keras
python
react-native
spoonacular
tensorflow
Try it out
GitHub Repo
GitHub Repo


The Plan
Noting the huge rise in smart scales to provide a more interactive healthy lifestyle experience for people of means, and also the unfortunate abandonment of 22 million copies of Wii Fit everywhere. We see an ability to make the most of those dusty balance boards to be repurposed into something much more meaningful.
Track It Too aims to do two things:
1) Provide a cheap equivalent to open market smart scale equivalents - rough technical equivalents costing ~£100 per unit compared to £6 for a Wii balance board. This opens up much more interactive, analytical ways to engage with your own healthy living - something we want to make much more accessible.
2) Help realise those health goals for people who don't have bags of time for extra exercise, or are constrained by a budget. Track It Too combines financial data to provide a set of 7 meals (every week) with an exciting set of healthy meals to match a calorie plan built around the weight data from the Balance Board! With full recipes being sent to you every day and a shopping list every week it's sure to cut down on the wasted time that many individuals fear they can't afford to lose.
The Tech
Data-driven engine to determine the ideal on-a-budget set of 7 meals for a given user (including predicting whether the base metabolic rate predictions are inaccurate, and adjusting accordingly) is built on a Google Cloud Platform MongoDB Atlas deployment with a front end built in flask, javascript, and jQuery hosted similarly entirely on the GCP.
Obviously the actual Balance Board is the only real spot of hardware required with the receiver (client which posts to our GCP hosted centralised server) being simple straight python capable of being run from something as slow as the original raspberry pi.
BMR estimation confidence grows with time, unlike usual fitness apps which don't mix food and exercise with actual results measurement.
# The Run-Of-The-Mill Pre-Error-Correction Base Metabolic Rate calc.
def getUserRecommendedCalories(userData):
    activityMultiplier = [1.2, 1.37, 1.55, 1.725, 1.9]
    if (userData.sex == "m"):
        bmr = 66 + (6.2 * userData.currentWeight) + (12.7 * userData.height) + (6.76 * userData.age)
    else:
        bmr = 655.1 + (4.35 * userData.currentWeight) + (4.7 * userData.height) + (4.7 * age)
    return bmr
Built With
bootstrap
chart.js
flask
gcloud
github
javascript
pandas
python
twilio
wii-balance-board
Try it out
www.trackit-too.tech


logo
Inspiration
Dynamic Calendar
What it does
Given a certain time interval (certain day or week) our app will find all the best times for you to schedule a meeting.
How I built it
The project uses bootstrap and vanilla HTML for the front-end and python (flask) for the back-end. In addition, we our utilizing the google calendar api and the google speech to text api.
Challenges I ran into
We wanted the app to be voice-controlled through something like google assistant but many of the programs to do so like Dialogflow and Twilio caused unknown issues that even our mentors could not solve.
Accomplishments that I'm proud of
Despite all odds, our team was still able to buckle down and achieve a MVP
What I learned
I learned many of the ways you can deploy apps to smart-home devices like the google home.
What's next for timely
I would like to see this project properly using one of the previously mentioned services, Dialogflow.


Inspiration
Our Inspiration was based on the recent push for more content exclusivity, and lack of knowledge to use that content.
What it does
Our website takes your document and tells you plagiarized phrases, combined with where they came from, and a shortcut to citing them instantly. Secondly, we built a companion app that allows users to track their essays and content over time.
How we built it
We built it using HTML5, Php, Bootstrap4, and Swift
Challenges we ran into
We ran into challenges when converting the file uploads, into searchable text
Accomplishments that we're proud of
We are proud that we were able to implement, plagiarism checking, citation creation, and a companion app
What we learned
We pulled a lot from this project. One of the biggest things we learned was working with Bootstrap 4.
What's next for Essay Buddy
We plan to implement a machine learning algorithm, using our current feedback form, to better identify plagiarism, and create more accurate inline citations.
Built With
css3
html5
javascript
json
php
swift
Try it out
schoolloop.ga
www.beautiful.ai
GitHub Repo
GitHub Repo


Inspiration
Cyberbullying and hate speech is a huge problem in teens and can lead to decreased mental health and worsened school performance.
What it does
This app is an app that maintains student anonymity by acting as a third party to transport messages. It uses deep learning to analyze the toxicity of each message and determines if it is offensive or not. If it is deemed offensive, it is then sent for review for friends that the user adds, or squad, who then evaluate whether it is safe or not. No censorship while maintaining safety.
How I built it
Flask, Firebase, Javascript webapp, python, and dapp (decentralized app) The architecture of the network: convolutional neural networks trained on text vectors (text represented by digits). Trained on https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973 Decentralized voting for the safety of messages in squads.
Challenges I ran into
Flask and Firebase were pretty difficult to connect since we couldn't use Node.js which we were comfortable with since we needed to use Python for Machine Learning. Dapps with Solidity and Ethereum for a decentralized voting system (squad votes on if message should be approved) was finished and running on localhost, but we didn't have enough time to integrate it with the final project.
Accomplishments that I'm proud of
A fully functional prototype with a clean frontend and an efficient backend.
What I learned
Flask and firebase Especially Solidity and Ethereum for the decentralized voting system.
What's next for SquadTalk
Add on to chat apps, email, social media sites, and deployment to more functional websites. This is a proof of concept example.
Built With
ai
css
dapp
firebase
flask
html
javascript
machine-learning
ml
python
Try it out
GitHub Repo
GitHub Repo
squadtalk.tech


Arduino and breadboard with sensors and breadboard wires.
Inspiration
India and China are two of the world’s largest countries with one big problem: air pollution. People with asthma in these countries will have a difficult time living here because of the changing air quality. California also has had so many fires, and we wanted to build something to notify people of a fire. We developed an Arduino sensor that detects air quality, temperature, humidity and infrared radiation.
What it does
It is able to detect humidity, temperature, gases in the air, and infrared radiation. It puts information from each one of these sensors into some conditions so that it can finally determine if there is a fire or not.
How I built it
There are three sensors, the MQ-135, a gas sensor that detects ammonia nitrogen, oxygen, sulfide and smoke. The DH22 sensor detects the temperature and humidity in the air. The infrared sensor can detect any infrared radiation. The software puts the information taken in by the sensors into a couple of conditions to determine if there truly is a fire.
Challenges I ran into
We tried to incorporate a Geolocation API to find the location of our sensor; however, we did not have a crucial component that helps connect to the API, an antenna. I was going to find the exact location of the place the fire started, but the google cloud platform wasn't connecting to the Arduino because we didn't have the part we needed. I was also going to find nearby hospitals but without geo location, this wasn't possible.
Accomplishments that I'm proud of
An accomplishment that I'm proud of was when I established the connection with Adafruit IO, the server where I post the data. I also figured out the hardware part which was a bit difficult due to the fact that I'm more of a software programmer than hardware.
What I learned
I learned that some API's require more work to connect to the cloud. I also learned how to use GPI pins and how to establish a connection with servers like Adafruit IO. In addition, I figured out how to take in data from each sensor through analog and digital output and input.
What's next for A Breath of Purity
The website should be able to display the location of the sensor and display what else is near that sensor such as hospitals, senior homes, and shelters. We also want to be able to check if there were any power lines near a fire or factories near the place of air pollution that could have caused or worsened the existing conditions in that place. Another update would be the capability of detecting high winds that could worsen a fire.
Built With
adafruit-mqtt
adafruit-mqtt-client
adafruitio
arduino
dht
wifi101
Try it out
GitHub Repo


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for dev4change_gecap_graacolis
Social


mokka
Inspiration
The rates of depression are increasing year by year, having more effect in the young people as never before. We wanted to create a solution that helps people with disabilities giving the proper tools to psychologist to understand the behavior and progress of their patient on a daily basis. Talking with contacts that practices psychology we received an invaluable feedback that motivated and inspired us to make this happen.
What it does
It gives support to psychologists, not only to diagnose but also to prevent, marking a great impact in improving the mood of the patient. It collects data from the patient smartphone with his/her previous authorization, in order to rate their behavior and display that information both to the patient itself and the psychologist. In case of a extreme crisis, it will send an email in order to shorten the time of reaction. The patient can stop the data collection and any time but the psychologist will receive an email. This information can be useful for the sessions, to analyze what happened, when and how.
How I built it
We have developed a mobile application (with Android Studio) for the patient that records all searches and messages, send them to a server hosted in Microsoft Azure, analyzes this information (using a model trained with python) classifying it according to its depressive tendencies and a webpage for the psychologist to recover and analyze the data. For this, we have used the sentiment140 dataset, that provides 1.6 million tagged tweets with the emotional background of it. This dataset is vectorized using word2vec which makes possible converting words into vectors so we can compute the semantic similarity of different words. Then these vectors are used to train a Random Forest Machine Learning model which is finally able to difference between positive and negative phrases. In turn, the psychologist receives through a web application the evolution of each patient, if someone if in a critical condition, the psychologist will receive an alert (developed with Azure Web App and Azure database)
Challenges I ran into
We knew from the beginning that we wanted to help people with depression by analyzing their behavior and giving a evaluation of their progress. But the biggest challenge was to figure out how to make them feel comfortable sharing a information so sensitive and private. Also, how to use it for making their life betters, and after a lot of brainstorming and iterations we find out that the best way of helping them, was helping the people that are making their life better.
Accomplishments that I'm proud of
We honestly think that this can help people with a disability like depression. We're also proud that we didn't die developing it.
What I learned
We have learned that not all disabilities are understood despite the evolution of the world of medicine. We learnt to work hand to hand, integrating many languages and supporting all team members, and we have also found interesting all the things that can be developed with Azure.
What's next for Mokka
Distribute our application to psychologists to help know and treat their patients, giving a more objective point of view and deeper. Later we also want to provide it in hospitals, thus reducing the number of suicides.
Built With
android-studio
azure
java
php
python
sql


Home Page
Inspiration
Making travel plans suck
What it does
Plans trips for you by first calculating the cheapest overall trip to visit every location, and then plans events for that day
How we built it
Built using Vue.js
Challenges we ran into
Integration of API with Vue
Accomplishments that we're proud of
Front-end
What we learned
Integration of API with Vue
What's next for Tripify
Startup in San Francisco
Built With
and
apis
hardware
hosts
languages
libraries
ui-kits
vue
Try it out
GitHub Repo


Upload Page
Inspiration
The talk at the opening ceremony. We wanted to try ourselves at a hard problem with real world application.
What it does
It analyses a microscopic picture of a crack and determines several key factors about it. These key factors are used to estimate the damage caused by the crack.
How I built it
We used python to analyse the picture and locate the crack. Then we used the convex hull algorithm to estimate the original borders and calculate the crack's key properties. For usability, we also added a Web Interface.
Challenges I ran into
Distinguishing between separate bodies, indicating that the object has broken into two and little pieces left in the crack.
Accomplishments that I'm proud of
Being able to correctly identify the crack as a polygon in the image and the hard work invested in this project.
What I learned
We learned about convex hulls and how much work an UI is.
What's next for ¿hasCrack?
Improve the adaptability for different materials.
Built With
html5
node.js
numpy
python
shapely
typescript
Try it out
GitHub Repo


Inspiration
We were interested in the concept of the Bayesian Spam Filter and decided to implement a similar approach to detect and remove movie spoilers instead of spam emails from different webpages.
What it does
The program takes in two separate inputs: a website's URL and movie title and scrapes the said website to obtain the required information from its source file. It then removes words or phrases based on a spoiler library made by analyzing movie-related webpages like IMDB or Wikipedia and updates the source file. The program then returns it and the chrome extension refreshes the webpage with the new source file. The machine learning program uses "multinomialNB()", a function in Scikit-learn that is similar to the Bayesian Spam Filter to identify if a certain webpage contains spoilers or not by being trained through text files stored in the main directory.
How we built it
Frontend: -> we used paint3D to create the background and the icon for the extension -> buttons and input box were created using HTML forms -> the main google extension was created using HTML and also a manifest.json file
Backend: -> we used Scikit-learn to create a machine learning program and the text files used to train the program are scripts from Star Wars (spoilers) and other movies (non-spoilers)/articles. We are currently just using Star Wars scripts for testing as we intend to give the user the ability to enter the movie of his/her choice to improve the usability of the program as the user will have more control over what movies he/she would like to have blocked. -> the web-scraping program was done by creating a personalized Python toolkit
Challenges we ran into
linking all three components (machine learning program, google extension and web scraping program) together
making the AI smarter
implementing javascript in a google extension
Accomplishments that we are proud of
able to create a program that is capable of web scraping
able to create a google extension
able to train a program to identify a spoiler
What we learned
how to use Scikit-learn
improving the accuracy of machine learning is difficult
chrome extensions do not like javascript in HTML forms
how to use paint3D
how to make a working Chrome extension
how to use Django and Flask for web dev
What's next for Hapocrates
more test files i.e different movie categories for the program to learn
using databases to store spoiler content redacted from the webpages to improve memory management in the program
*we did not manage to link all the three components of the program but we have three separate working parts of it which we would like to show *the github repo contains these components
Built With
css
django
html
python
scikit-learn
Try it out
GitHub Repo


Notification about photos I took today that are reward worthy !
Inspiration
Smartphones now have professional grade cameras and there is an increase in great photos captured by amateurs. Phonix powers such users with the ability to monetize such photos with ease.
What it does
It identifies the most valuable photos and provides an easy way for users to publish these photos to an online marketplace. This unlocks the kudos worthy photos that would have otherwise just end up in their social feeds and might have been soon forgotten. The iOS app runs on the user’s devices in background and once Phonix’s advanced Image recognition engine identifies the right candidates, the user is notified. Each photo has a potential dollar value and a list of relevant tags. Once the user approves the selected photos, it is uploaded to the marketplace. The user gets their share of revenue whenever their photo is bought.
How we built it
Seller platform (iOS application) - Generated scores for images using a simple algorithm in conjunction with Firebase ML SDK to identify image features. These images were then assigned a potential dollar value based on a score to dollar relationship model. The photos can be reviewed, selected and published to firebase realtime datastore backend. Backend - Using firebase realtime datastore as the backend to store the published image information and the number of items sold. Buyer platform (web application) - Built with JAM stack and used Firebase SDK for the real-time data exchange.
Challenges we ran into
*We wanted to integrate with the APIs of existing Stock Photography services. But most of them only support manual uploads and Adobe Stock has such an interface but the adobe account requires a review and approval, so we ended up creating our own web marketplace. *We did not find big enough labeled photography data to train the scoring and pricing models, so the algorithm at this point is simple and intuition based.
Accomplishments that we're proud of
*Built a privacy-conscious app by performing all the image recognition tasks on the device *The Seller-Buyer experience is real-time and showcases the power of this idea effectively
What we learned
*Image recognition technique and tools *Standard image related metadata like EXIF
What's next for Phonix
*Quick high-value feature identification in images like a blur, focus, histogram analysis. Also, training the scoring algorithm based on these new features. *Image filtering to remove repeating images. *Photography project creation based on assigned theme and tags, this will improve the quality of suggestions and will also keep the users engaged.
Built With
firebase
ios
web


Teste


IntelliJ Plugin shows what is being worked on by whom
Inspiration
"Can't Touch This" is a tool that aims to minimize the number of merge conflicts by preventing them from happening in the first place. We want to build an application that supports communication and collaboration within the team and boost overall productivity. Several clean frontends and a robust backend will ensure that every member of the team, no matter which development tools, will all get to be a part of the collaborative network.
What it does
Can't Touch This informs users about which parts of the code are being worked on in real time. Line-by-Line Highlighting is only of the many features that tighten the connection between Version Control Software (VCS) and Integrated Development Environments (IDEs)
Our approach
As a team with prior experience in Hackathons, we knew that we had to tackle the challenge differently this time. Our main goal was to be able to complete a project that not only brings something new to the table, but also helps us grow as developers. We split our workload into four seperate workspaces: the server backend, the web frontend, the desktop backend, and the desktop frontend. With everyone becoming an expert in their own area, conflicting implementations and ideas were kept to a minimum.
Challenges we ran into
As the smart folks over at JetBrains have warned us about, creating a JetBrains plugin with no prior experience is not easy. And while one of us had to reverse engineer IntelliJ, another one of us had to the architecture of Browser Extensions and Website Manipulation from scratch. And debugging, as always, was the final Boss.
Accomplishments that we are proud of
When all the components first started connecting and reading information off of each other, we immediately started using them on the project itself. The moment a team mate asked another "Hey, why are you touching my files?", we all knew that we were on the right track!
What we learned
Don't shy away from a project that seems to be outside your realm of abilities. The hardest challenges can teach the most. Not to forget the relief we get from defeating them.
What's next for Can't Touch This
Our flexible backend allows for all kinds of frontends to really make sure that all team mates can take part. In the future, we are thinking to further analyze the changes and detect possible causes of errors. For example, we could tell the developers that the changes are there because they did not pull. Or automatically detect how likely a change is to be severe. Or to add support for the most popular programming languages to also analyze the program structure that is being changed and potentially affected files. And add an easy way to contact the people that are making the changes. Either way, the possibilities are endless.
Built With
azure
django
firefox
git
github
gitlab
intellij-idea
java
javascript
jetbrains
microsoft
python
Try it out
gitlab.com


Inspiration
Newest research with GANs shows that you can not only generate completely new faces, but also vectorize the input space so that features of the face can be influenced. We wanted to use this new technology for something useful. One field where generating faces with very specific features is important is police sketches/ criminal face composition. The current state of the art is far from satisfactory, given that a good sketch can lead to a criminal offender being arrested.
What it does
Our interface first generates a random face. The user can then use a selection of sliders to alter certain features of the face to get closer to the face they have in mind. We built a MVP solution to show that the generation can be done in high resolution and almost real-time.
How we built it
Based on cutting edge research, we utilized transfer learning on cloud based tesla volta 100 to optimize a pretrained GAN network and its hyperparameters for our specific use case. With regards to hosting the model, we decided to use python sanic with redis as session store. The frontend is built in angular.
Challenges we ran into
Finding the sweet spot for our hyperparameters, highly computationally intensive training task with only 36 hours to hack.
Accomplishments that we're proud of
During the limited time we had, we were not only able to build what we had invisioned, but implemented and evaluated different GAN models to find the best one (GLOW by OpenAI, StyleGAN by NVIDIA and other VAI-based models). We are proud to say that we leveraged cutting edge research from papers only published a few months ago and use it for good.
What we learned
Working effectively in a team under pressure and with limited (computational) resources.
What's next for AIDENTIFY
We really had fun with this project and would like to keep working on it. Through this event we formed a great team and we plan on turning AIDENTIFY into an actual application that can make a difference.
Built With
angular.js
pytorch
sanic
tensorflow
Try it out
GitHub Repo


Inspiration
Scientists say that the lion's share of communication is nonverbal. People suffering from disabilities like Autism or Aspergers can have difficulties with applying and interpreting facial expressions correctly. We set out to help those people improve on those skills in a gamified manner.
What it does
Emojoy allows players to practice facial expressions while playing games with rising difficulty. Starting from basic transitions between a neutral expression and an emotional one up to playing pong controlled with facial expressions with a human opponent online.
How we built it
Detect faces and their expressions using machine learning locally in the browser
Implement the UI and different games with TypeScript & React
Use canvas based animations for playing pong
Implement a server which assings two players for live PvP-Pong action while enjoying the video stream of the opponent.
Challenges we ran into
Setting up the facial expression detection was difficult, as was connecting it to the game. Learning about WebRTC was also not trivial. Some of us have just started learning react.
Accomplishments that we're proud of
We are very proud of our working and running prototype. Also this app is very exciting for non-disabled people, too. So we were able to play a lot and enjoy our own game.
What we learned
We learned a lot about face detection using AI, WebRTC and polished our React skills.
What's next for Emojoy
The user guidance can be further improved, allowing the user to assign facial expressions to the controls of the games individually. This way users can focus on their weaknesses. Also a more sophisticated expression detection model could add more emotions and then increase the value of our app.
Multiplayer demo
https://youtu.be/h5XiGQn7GGc
Built With
ai
face-api.js
javascript
machine-learning
react
typescript
webrtc
Try it out
emojoyy.web.app
GitHub Repo


Inspiration
Indoor bouldering is a form of climbing sport that is performed on small artificial rock walls without the use of ropes or harnesses for safety. A bouldering route consists of a set of multiple holds with a defined start and end hold. Walls in indoor gyms are set with different boulders in varying difficulties at the same time. To distinguish between the individual routes, holds that are part of the same route have the same color.
A frequent problem which arose in our team's past bouldering sessions was the inability of one color-blind team member to recognize which holds are part of which route. Especially between red and green routes or variations of these colors, color-blind people can have difficulties to tell the holds of different routes apart.
What it does
Our app provides a solution by using augmented reality to enhance the live camera feed of a smart phone. The app recognizes boulder holds in the camera feed and augments them with a bounding box and a color label.
How I built it
Using Cognitive Services in Microsoft Azure, we used photos of boulder walls with colored routes (mostly from our TUM bouldering egg) to train a neural network for detecting bouldering holds and their colors.
Challenges I ran into
Obtaining good training data
Tagging our own data was some effort
Using the trained network in Android proved to be challenging
Achieving reasonable performance with the live augmentation of the camera feed
Accomplishments that I'm proud of
Our approach works even in unseen situations, enabling usage on images from various bouldering facilities.
What I learned
Utilizing Microsoft Azure for computer vision tasks and machine learning
Augmented Reality
App development
What's next for BoulderChroma
We should expand the amount of training data to obtain improved results also under difficult and artificial lighting conditions. Furthermore, the app can be extended to provide advice for the climber.
Built With
android
azure
python
tensorflow
Try it out
GitHub Repo
GitHub Repo


Inspiration
To predict/prevent errors and make gadgets more reliable for all humans
What it does
Oraclum is an optimized device tester. It saves the customer time and money.
How we built it
We've used simulator provided and improve upon on it. Then created oraclum as a component tester with basic AI techniques and statistical approach. Oraclum dynamically learns optimal action it should perform.
Challenges we ran into
Lack of real world data
Simulating a test behaviour close to real world applications
Trying to apply novel AI techniques to a statistical problem
Accomplishments that we're proud of
Improvement of the throughput on %94 of the cases.
Throughput is doubled on average on said cases. (Total time dropped by %51 percent on average)
What we learned
We've learned the importance of creating a good simulator with realistic approach.
What's next for Oraclum
With real world data and prior knowledge on component models, we wish to implement novel AI techniques
Increase the complexity of the simulator for customer benefit.
Built With
python
Try it out
GitHub Repo


Inspiration
Nossa inspiração parte da expectativa de nos envolvermos numa causa solidária principalmente e nos evoluirmos como seres humanos, tornando-nos pessoas e profissionais melhores.
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for dev4change_OSSAvanti_BondeDoSigrao


Inspiration
Use Data provided by the city of munich to help tourists and locals get to know the city better or discover hidden places
What it does
Depending on available time by the group and their startpoint, a custom track with restaurants, museums, bars and churches will be generated.
How I built it
We built it in two different ways, just to be sure it works.
Challenges I ran into
Finding an algorithm to match the time requirements with different stations
Accomplishments that I'm proud of
What I learned
A lot about maps
What's next for MUChToSee
Fix everything that doesn't work. Integrate with other Munich services, like the Radroutenplaner
Built With
css
html
javascript
Try it out
GitHub Repo
lholz.de


Program written in Python 3 (+PyGame)
Generates a database of 1,000 flights throughout North America
Creates map that shows exact location of each flight at given time
Creates search engine to search by flight number or destination
Built With
pygame
python
Try it out
GitHub Repo


Business Name
Inspiration
The problem that inspired this solution is universal: what do I throw in the trash and what can be recycled and/or composted? It is nearly certain that you have deliberated over whether something is recyclable or not and ended up throwing it in the garbage.
What it does
In order to address this problem, Ecovio will analyze the material of the object before further categorizing in order to inform the user whether something is recyclable, compostable, or other. The main function of aiding waste disposal is made easier with the integration of a voice experience that allows for a more seamless and natural exchange between human and machine when determining how to dispose of waste appropriately. The voice experience is hosted on Google Assistant, allowing users to access it via their phones with the utterance of a simple invocation phrase, such as “Ok Google, talk to Ecovio”. Ecovio ensures that users are using the voice experience appropriately by using a QR code scanner at waste disposal sites to claim rewards. Aside from just waste disposal, Ecovio also comes equipped with a transportation and food section which again encourages sustainability through a rewards system.
How we built it
Built using Voiceflow, Ecovio was originally designed in a system flow model style that allowed us to easily follow each step and the logic behind preceding and succeeding steps. Each user input section includes a number of possible synonyms to prevent as much confusion as possible. Each response from the voice experience also clarifies any information that was previously spoken by the user and includes a clear call-to-action for the next step from the user.
Challenges we ran into
Some challenges we ran into including the initial ideation of the project as it took some time to properly define a problem space and design an appropriate solution that we could feasibly build in the given time period. We also encountered technical challenges, specifically with learning the different softwares for creating voice experience (ex: VoiceFlow & Dialogflow) and how to deploy the voice experience successfully.
Accomplishments that we're proud of
As a team of first-time hackers, we're incredibly proud to have produced a working prototype of our solution by the end of the hacking period.
What we learned
Over the course of this hackathon, as a team, we were able to grow in both technical knowledge and soft skills. The ability to speak to mentors on site definitely improved our understanding of different programs we used and how to build a successful voice experience. Learning how to design and construct a voice experience in VoiceFlow as well as taking a look at the javascript behind voice experiences in DialogFlow significantly contributed to our overall learning and future understanding of voice.
What's next for Ecovio
To take this project even further, we could complete the Transportation and Food sections of the Ecovio app, complete with voice interaction when appropriate. The Food section would encourage local produce purchases through scanning applicable barcodes which then has returns in the rewards section. Similarly, the Transportation section encourages the use of more sustainable forms of transportation across campus and, if possible, outside of campus to students’ everyday lives.
Built With
figma
google-assisstant
voiceflow


Inspiration
Improve the security and visibility of Vulnerable Road Users.
What it does
Allow data based deep analysis of individual traffic streams to extend the Digital Twin of Ingolstadt with data of Vunerable Road Users with the ability to discern different types.
How we built it
Arduino based collection of ultra-sound distance sensor data. Aggregation based on signal processing algorithms on a Raspberry Pi. Data delivery to the cloud through a LoRa Shield.
Challenges we ran into
Getting reliable sensor data from cheap sensors.
Accomplishments that we're proud of
Stable detection different VRU types (Bike, e-Scooter, Pedestrian).
What we learned
Cool new Team. Coding & Engineering on a LoRa based system
What's next for VRUdetection
Use more sensor types (Lidar, Radar) to improve detection rates Use more sensors on different height levels to distinguish better (i.e. Adults/Children)
Built With
c
python


100% confidence on post-its
Inspiration
We wanted to make an app to let colorblind people be able to tell the difference between different colors.
What it does
You take a picture with your phone camera. It tells you what color it was matched to.
How we built it
Use createML to build a machine learning model to identify colors.
Challenges we ran into
Non-solid and textured colors weren't always correct. If the light level was wrong, it would pick a different, similar color.
Accomplishments that we're proud of
We were able to make this work with good accuracy.
What we learned
How to use machine learning models.
What's next for ColorAid
Getting higher accuracy and more specific colors.
Built With
coreml
createml
ios
swift
vision
xcode


Logo
Inspiration
This project was inspired by Leon's father's first-hand experience with a lack of electronic medical records and realizing the need for more accessible patient experience.
What it does
The system stores patients' medical records. it also allows patients to fill out medical forms using their voice, as well as electronically sign using their voice as well. Our theme while building it was accessibility, hence the voice control integration, simple and easy to understand UI, and big, bold colours.
How I built it
The front end is built on react-native, while the background is built in node.js using MongoDB Atlas as our database. For our speed to text processing, we used the Google Cloud Platform. We also used Twilio for our SMS reminder component.
Challenges We ran into
There are three distinct challenges that we ran into. The first was trying to get Twilio to function correctly within the app. We were trying to use it on the frontend but due to the nature of react native, and some node.js libraries that were being used, it was not working. We solved the problem by deploying to a Heroku serving and making REST calls.
A second challenge was trying to get the database queries to work from our backend. Although everything seems right it still did not work but to do attention to detail, and going over code multiple times, the mistake was spotted and corrected.
The third and likely biggest challenge we faced was getting the speech to text streaming input to co-operate. In the beginning, it did not stop recording at the correct times and would capture a lot of noise from the background. This problem was eventually solved by redoing it by following a tutorial online.
Accomplishments that I'm proud of
WE FINISHED! We honestly did not expect to finish if you asked us at 10 pm on Saturday night. However, things came through well which we were really proud of. We are also really proud of our UI/UX and think it is a very sleek and clean design. Two other things include accurate speech to text processing and dynamically filled values through our database at runtime.
What I learned
Joshua - How to write server-side Javascript using node.js
Leon - Twilio
Joy - Speech to text streaming with react native
Kevin - React-native
What's next for MediSign
If we were to continue to work on this project, we would first start by dynamically filling all values through our database. We would then focus a lot of attention on security as medical records are sensitive info. Thirdly, we would upgrade the UI/UX to be even better than before.
Built With
express.js
google-cloud
heroku
javascript
mongodb
mongoose
node.js
react-native
twilio
Try it out
GitHub Repo


Inspiration
Having never done any javascript, html or css before I wanted to set myself a relatively simple challenge. My main goal was learning and I definitely think I've achieved that!
What it does
It takes inputs from the user and updates a table of tasks with a column for the name of the task, the time at which is was submitted and a button that can be pressed once you have completed the task that deletes the row from the table.
How I built it
I followed online tutorials on html and javascript and slowly bit by bit built more and more complex projects. I started with just a page that said "Henlo." followed by a page with two buttons that would make an element switch between ":)" and ":(". Only once I felt confident enough in the techniques employed in html/javascript development did I move on to my to do list project.
Challenges I ran into
I learned that the action attribute in a form element defaults to the current page, meaning that when a function is executed it effectively refreshes the page. But from my initial perspective it looked as if my function worked for a split second before the output disappeared. I learned that you have to add "return false;" at the end of your function call to prevent the form just immediately reloading the page.
Accomplishments that I'm proud of
I'm proud of the fact that I've built something operational and interactive. I am familiar with typing out a long script in Python that runs, outputs a result and then ends, this project takes inputs and listens for events and feels much more user-friendly
What I learned
I've learned basic javascript, html and css. I learned lots about how websites work and how the different file formats interact with each other. Before this I had looked at the source code of a website with complete confusion, now I can kind of see what's going on (still rather confusing). I have also unexpectedly learned more about code injections when I discovered that I can enter html tags in my "Enter task" field and it can produce some interesting results.
Built With
css
html
javascript
Try it out
GitHub Repo
retsek860.github.io


Home screen
Inspiration
As students who listen to music to help with our productivity, we wanted to not only create a music sharing application but also a website to allow others to discover new music, all through where they are located. We were inspired by Pokemon-Go but wanted to create a similar implementation with music for any user to listen to. Anywhere. Anytime.
What it does
Meet Your Beat implements a live map where users are able to drop "beats" (a.k.a Spotify beacons). These beacons store a song on the map, allowing other users to click on the beacon and listen to the song. Using location data, users will be able to see other beacons posted around them that were created by others and have the ability to "tune into" the beacon by listening to the song stationed there. Multiple users can listen to the same beacon to simulate a "silent disco" as well.
How I built it
We first customized the Google Map API to be hosted on our website, as well as fetch the Spotify data for a beacon when a user places their beat. We then designed the website and began implementing the SQL database to hold the user data.
Challenges I ran into
Having limited experience with Javascript and API usage
Hosting our domain through Google Cloud, which we were unaccustomed to
Accomplishments that I'm proud of
Our team is very proud of our ability to merge various elements for our website, such as the SQL database hosting the Spotify data for other users to access on the website. As well, we are proud of the fact that we learned so many new skills and languages to implement the API's and database
What I learned
We learned a variety of new skills and languages to help us gather the data to implement the website. Despite numerous challenges, all of us took away something new, such as web development, database querying, and API implementation
What's next for Meet Your Beat
static beacons to have permanent stations at more notable landmarks. These static beacons could have songs with the highest ratings.
share beacons with friends
AR implementation
mobile app implementation
Built With
css
google-maps
html
javascript
php
python
spotify
sql
Try it out
meetyourbeat.online


findify-logo
Inspiration
The challenge was to help developers in their daily life, by perhaps making workflow more efficient
What it does
You can define a project location, and what you are searching for and it finds those classes, methods, etc. for you, without you having to even know the name, just things like return types, parameters, etc.
How I built it
We exclusively used java for the code and javafx for the GUI
Challenges I ran into
Parsing the .java files into objects proved to be quite a challenge, since there are so many angles you have to cover (enums, interfaces, etc.) it's not as straight-forward as one might think
Accomplishments that I'm proud of
We applied quite a lot of theory we learned in university (data-structures, algorithms, patterns, etc.)
What I learned
I hate myself and everyone around me
What's next for findify
Perhaps try to incorporate it as a plugin in IntelliJ
Built With
java
sweat
tears
Try it out
GitHub Repo


Inspiration
Often time carers can find themselves isolated or unsure where to seek help from. Unexpected situations can lead to people becoming carers either full time or part-time and at any age. We wanted to offer ways to help alleviate the isolation and difficulty that comes with being a carer by offering them a support network.
What it does
For Charities
To offer their services to the widest audience and be a trusted source of information to carers
For Carers
Smart search people and charities for advice
Smart search for meetups nearby specific to your situation
Offer your help and knowledge to other carers, building a community
Ability to initiate SMS conversations with charities or other carers
How we built it
React frontend with a node backend. We developed special search strategies specific to each kind of search (looking or help/advice/meetups...), each one prioritising a set of criteria developed with people in mind Used twilio for the SMS features
Challenges we ran into
Technically a 5 man team, literally a 2 man team
Accomplishments that we're proud of
Search strategies Look of website
What we learned
Stateless functional components rather quickly become stateful components due to unforeseen circumstances
What's next for Hand.
Add the ability for users to sign up and create meetups. Refine the search strategies further.
Built With
material-ui
node.js
react
twilio
Try it out
GitHub Repo


mingAR icon
Inspiration
Ihr Inspiration is our love for the city in which we live and admiration for modern technologies that change our lives ❤️
For tourists this is a best possibility to see all corners of the city not only in 2D, but also in 3D, which allow him or her to expand horizons.
What it does
mingAR shows in AR points of interest around you, allowing you to quickly understand what do you want to visit next. You can see your location on a map and choose the best destinations there and then find them using AR or just open the AR view and see all POIs you can visit. You are interested what this place or building is about? Just open the mingAR app and you will get a description and all information about it!
Our application also allows the user to collect achievements, accomplish goals and compete with other users. For example, you can collect points for visiting certain places and get beautiful badges for successfully completing the challenges.
How I built it
We‘ve built our app using standard libraries of iOS, such as ARKit and SceneKit
Challenges I ran into
Our main challenge was to show multiple objects around the user on the right positions with a good precision. Starting from scratch we faced many challenges in terms of AR, UI and UX, as well as gamification. However, with our purpose and inspiration in mind, we were able to create a beautiful iOS App.
Accomplishments that I'm proud of
User-friendly interface and useful functions, as well as a real opportunity to help tourists navigate the city and visit as many beautiful places as possible, as well as to learn more about hidden places, which may not even be known to all locals before.
What I learned
How to work with ARKit and maps
What's next for mingAR
Introduction of more data sources, more detailed description of the specific location, more realistic 3D models, as well as introduction of new gamification elements.
Built With
node.js
swift
typescript
Try it out
GitHub Repo


Jetbrains Plugin - Notification that the file has already been edited by other developers and further edits could result in a merge conflict
Inspiration
Beside working alone on a project or copy and paste snippets from different team members, today there exist two forms of collaboration for developers: a VCS like GIT and a live collaboration similar to Google Docs.
None of them are perfect: Live collaboration tools increase the difficulty to work on a stable, testable and executable code basis due to the permanent edits of users. A VCS distincts between the different code bases of developers, however, merging the different versions is a real point of pain. We believe that this can be improved through a combined approach, leveraging both of their advantages.
What it does
Normally changes of the code basis only get distributed through commits and pushes in VCS. However, our system adds a live collaboration layer above GIT. This means that even when files are changed locally without committing, our cloud-based database notes the changes by the users. If other developers with the same commit in the repository want to edit one of those files, they get a notification that this specific file have already been changed by another team member locally. This allows developers an improved coordination of their work, which is helpful for small and large repository or developer teams. It avoids duplicate work efforts and improves communication among the team - and most importantly, reduces the number of merge conflicts in a project.
How we built it
On the server-side, we created a python-based backend with Flask and SQL hostet on Heroku. It is the single source of truth for the so-called live changes (edits that are not yet commited in the VCS). The system is able to track multiple repositories with all the included commits and files for large-scaled projects.
In order to access these information, we created a browser-based frontend in React and moreover, also developed a client-side plugin for the Jetbrains IDE in Java. This plugin integrates into the developer's workflow and gives him real-time notification while he is editing potentially conflicting files. With the activated plugin and connection to the GIT information, developers can completely avoid merge conflicts.
Challenges we ran into
The main challenge was the limited documentation of the Jetbrain plugin development. It took a while to understand the important interfaces and provided APIs in order to listen on file changes and send notification within the Jetbrains environment. A further pitfall was the interaction of the different programs and services (micro-architecture) and the code-split between our team members.
Accomplishments that we're proud of
The project is based on multiple individual components which have to interact with each other. We were particular proud when all those components successfully worked together. It enabled us to use our own product during our development process to avoid merge conflicts and people working on the same files or tasks.
What we learned
The importance of documentation: The case of Jetbrains plugin development documentation reminded us about the importance of well-documented interfaces, libraries and tutorials in the area of IT. A good documentation is a real timesaver when working with libraries and toolkits from other developers.
How to split the workload: Especially during the beginning of the Hackathon it took us a while to get comfortable with the GIT workflow and code-splitting. This was one reason why we decided to approach the challenge of improved developer collaboration - we were affected by it ourselves.
What's next for Merge in Peace
Currently, Merge in Peace works on a file-base, which means that in case of a file change, the complete file is noted as changed in our collaboration database. However, with an improved GIT integration, we can use this information in feature for individual functions. This means developers get only notification when both changed the same functions, but not when they are just changing different parts of the same file. The second point usually does not affect each other and will not trigger a merge conflict. A further step is the improvement of the Jetbrains integration with a better UI, Code-highlighting of affected code snippets and improved configuration settings.
Built With
flask
git
github
gradle
intellij-idea
java
javascript
jetbrains
python
react
Try it out
hackatum2019.herokuapp.com
GitHub Repo
GitHub Repo


Inspiration
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for DDM Classy and Afordable Clothing
Hipeeeeeee


Profile view
Inspiration
According to the WHO, only 50% of patients suffering from chronic diseases in developed nations follow treatments for their illnesses. This occurs mostly due to a general lack of understanding of what the doctor is saying, or uncertainty about whether what the doctor is prescribing is right of the patient's condition. To address these issues and improve transparency in the patient-physician relationship, we built LISA (Loyal Integrated Smart Assistant).
What it does
LISA addresses transparency in the patient-physician relationship on two fronts. It can listen in on the conversation and break down key information from raw audio transcripts about treatments (like medication doses and procedures) for the patient into objective, yet easy-to-understand tidbits for the patient. On the physician's side, it can flag patient information about physical characteristics (like age and sex) and key symptoms in various body systems (ranging from nausea to feeling feverish) for the doctor to note when proposing better treatment plans.
How we built it
LISA was built using Google Cloud's Dialogflow (for conversational capabilities) and Speech-to-Text (for transcription) API's to enable listening for and understanding key medical terms (notably symptoms, treatments, and medications), which are used as trained contexts in the voice-activated assistant algorithm. Speech transcripts are parsed for these terms and matched with some open-source databases (ex. DrugBank, Disease Ontology) describing disease symptoms and medications, both of which are linked as key-value pairs in tables set up in MongoDB Atlas. LISA is hosted on a web application generated using HTML5 and ReactJS, with the UI appearance and workflow prototyped using Figma.
Challenges we ran into
Difficulties with acquiring reputable, open-source datasets and their connection with MongoDB (many are either behind paywalls or require delivery over business days only)
Hard to find elegant ways to hard-code UI wireframes from Figma to the corresponding ReactJS syntax
Encountering differences in audio file types in Google's Text-to-Speech API
Difficulties with training LISA (on Google Dialogflow) to discriminate more than two speakers
Familiarizing with potential legal implications of patient privacy and data protection
Accomplishments that we're proud of
Generating comprehensive lists of terms to train Lisa with (over Google Dialogflow)
Linking relevant and common drug and symptom information from Disease Ontology, DrugBank databases on MongoDB to be matched with incoming parsed audio data
Being able to differentiate two speakers and storing information as two distinct arrays for analysis (one for the patient, one for physician)
Creating a working UI prototype on Figma that is sizable for different screen sizes
What we learned
Many health-related databases from highly-reputable sources can be hard to find, which just highlights the importance of accessibility to objective health information
Not all related APIs are built the same - it is important to read the documentation regarding accepted filetypes and other common setbacks to save time down the line
Learning new features in novel technologies (such as Google Dialogflow, MongoDB)
Taking advantage of sponsors and mentors when dealing with setbacks, clarifying misconceptions
What's next for LISA
Expanding to mobile interfaces (for greater portability by both doctors and patients)
Training LISA to recognize more than two speakers in a conversation, dealing with simultaneous speakers
Testing a greater variety of APIs, partnering with reputable health governing bodies for robust data on medications and illnesses
Further development of the UI and functionality on the doctor's side of the conversation
Making general structure transferable for listening in on other meetings in other industries (like business one-on-one performance meetings)
Built With
dialogflow
figma
google-cloud
google-web-speech-api
javascript
mongodb
mongoose
node.js
react
text-to-speech
the-materials-project
Try it out
GitHub Repo


Inspiration
The rate of post harvest losses in Ghana are very high amounting to 1 million dollars annually
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for ForeverGreen


SENSOR
Inspiration
Real life situations in which strong environmental conditions lead to failure of communication systems.
What it does
Assess the surrounding area utilizing sensors - temperature, water, wind - to detect emergencies - fires, floods, hurricanes, etc. When detected, the information is spread automatically informing not only the emergency, but also the location where it happened.
How we built it
The prototype was developed using as its the Arduino and the TTGO Lora32. Respectively, they are responsible for the sensors administration and the information transmission.
Challenges we ran into
The project is essentially divided into two major sections: the detection and the transmission. The biggest challenge we ran into was making it so that both of these modules worked together in sync. Additionally, it was difficult to set up the connection between two TTGO boards - sender and receiver.
Accomplishments that we're proud of
We are really proud of how we created a prototype that is capable of solving a real life problem. The prototype itself is functional and also visually appealing.
What we learned
The capabilities of the group were very diverse, which means that everyone could learn with what the others could bring to the table. Designers learned electronics, engineers learned business management and so on and so forth. Also, we learned all that we could in these 2 days about the LoraWAN.
What's next for 404!
Improvement, improvement, improvement!! There is a lot of space for optimization and we would love to see how it looks after more time of development.
Built With
3-6v-motor
arduino
dht11
environmentalsensors
fanblade
grove-water
lmic
lora
neo-6m-gps
tinygps
ttgo-lora32


Inspiration value addition
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for BREKLET GH
Built With
api


Inspiration
We were inspired to create Alexa Sage after researching the uses of a voice user interface (VUI) and seeing how it could apply to medical contexts. One social problem relevant for one of our team members was elderly care and loneliness, as their grandparents recently were facing health issues. We identified that there was a need for more scalable forms of health promotion and cognitive decline monitoring among seniors. 15% of Canadians over 65 are in institutional care, and depression rates while in care are 40%, which is much higher than the general population of seniors.
Further, VUIs can be more intuitive for people not used to a smartphone, and have the potential for more organic communication between people and their devices, such as seniors who may be more wary of technology. We also had an interest in wellness and positive psychology, and the medical field, and combined these with our skills in backend programming, data science, and psychology to tackle Alexa Skills.
What it does
Alexa Sage has two primary components: Emotional resilience building (3 gratitudes exercise), and cognitive acuity monitoring (sentence repetition and analysis). Both exercises are empirically backed by research, the first two promoting long-term happiness and resilience against depression, and the second being a standard cognitive test administered as a dementia measure.
Users are prompted on a periodic basis to engage in an informal discussion with Alexa, where they are asked to make voice entries in a gratitude journal, the results of which are given to an R API to analyze sentiment and dictate Alexa's responses, as well as storing happy memories for later replay. During this process, users are also given a brief test of their mental faculties - confirming their name, and checking if they can remember a brief sentence and repeat it back with proper pronunciation.
The results of the gratitude journal analysis and cognitive acuity tests are then stored in a google spreadsheet, where long term trends or abrupt shifts in emotional effect are identified via an R API and used to notify a user's primary caregiver through the Twilio API. Should users have particularly negative responses when asked to recount something they're grateful for, Alexa can also offer to call their loved ones for them.
How we built it
The user interface and the bulk of our program's structure comes from Voiceflow, a visual coding program for building Alexa skills that can integrate with external APIs. We built R scripts to analyze text inputs on one computer and used the Plumber package to set up an R API to send character strings back and forth from a google spreadsheets data storage location. We then used the numerical output (sentiment level based on the R Syuzhet package) from R to store the data and compare to a baseline of user sentiment and an absolute level (if very negative), and make Alexa offer users the option to call loved ones, and should they accept the Twilio API will call or send a text to their loved one's phones.
Challenges we ran into
This was the first hackathon for three of our four members, so understanding the norms of the event was a big hurdle, and only one of us had much coding experience.
Some highlights of the challenges we faced:
Translating psychological concepts, tests, and exercises into a VUI
Coordinating voice flow with a mono database, pivoting to a spreadsheet and R data analysis
Integrating Twilio and R APIs with voiceflow
Getting voice flow to export to the physical Alexa device
The time constraints of the competition
Narrowing our focus to what is feasible
What we're proud of & what we learned
Charvi learned to use voice flow and more about data science and R Anthony is proud we were able to integrate psychological theory with a social impact focus into a cohesive app Yang learned to use the Twilio API Ethan learned how to create an R API
All of us are proud of what we made, and happy that we learned so much in the process.
What's next for Alexa Sage: Promoting cognitive & mental health for seniors
We want to add additional tests and exercises to Alexa, to better build emotional resiliency and monitor cognitive health of seniors. Some possible ones are:
more cognitive games such as drawing and memory recall
suggesting different activities based on the user mood and time of day, such as reading a book, calling a friend, or going for a walk
integrating with a user's medical exercises and medication, to prompt them to do these
As well, the Alexa Prize is currently underway in the US to develop conversational capabilities with Alexa. During these conversations, we could conduct cognitive assessment and promote positive psychology habits as well.
Link: https://docs.google.com/presentation/d/1GrK3_w8w3Fr8feRcucNr2EoXvo0pl_BCWkYn2zdZhGg/edit?usp=sharing
Built With
amazon-alexa
google-spreadsheets
javascript
ngrok
r
twilio
voiceflow
Try it out
creator.voiceflow.com


Inspiration The effect of unmanaged waste on the environment
What it does Exchanges rewards for waste given
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for CashIT
Built With
html
python


Inspiration
We wanted to introduce the world to a new technology. Interactive, real time, immersive, real world, augmented reality mesaruments with mobile technology.
What it does
It gives you the measures of stuff (duh)
How I built it
With Arcore and C#
Challenges I ran into
Debugging mobile applications with augmented reality that require final builds is tricky.
Accomplishments that I'm proud of
It works! (kinda)
What I learned
What Arcore is and how to use it
What's next for The Pink C0re - AR
Re do it, again, properly done this time
Built With
3d
ar
arcore
c#
unity
Try it out
GitHub Repo


Inspiration
Good driving habits such as always scanning an intersection or checking blind spots are important to have both for safety reasons and to pass driving tests. However, as a new driver, it can be hard to remember all these things. Driving instructors can be helpful to remind you of this, but not everyone has one, hard to book and expensive. DriverSyde will remind you of all the same things as a real life instructor as you drive.
Not only is this for drivers who are learning, it provides reminders for all drivers safety and can help prevent common accidents.
What it does
Using the phone's front facing camera, DriverSyde can detect if you are performing the correct actions such as checking the blindspot, scanning intersections and even detecting sleepiness. It evaluates your performance at traffic lights, stop signs and lane changes.
It can prompt you reminders before or give you feedback if you have done something incorrectly afterwards as well.
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for DriverSyde
Built With
android-studio
city-of-london-open-data
firebase
firebase-ml-kit
google-maps
java
particle
Try it out
GitHub Repo


Inspiration
It’s of national interest to grow our economy by reducing importation and growing our local industries, hence, ALJANI.
What it does
ALJANI is an online retail shop purported to sell quality consumer-ready processed products to the average Ghanaian.
How I built it
By forming a team of like-minded people interested in the marketing aspect of the food value chain.
Challenges I ran into
Start-up capital Mentorship Signing up food producers Building a big clientele
Accomplishments that I'm proud of
Formed a team Built strategic partnerships Basic idea of platform details
What I learned
What's next for ALJANI
Launching the service
Built With
html


Inspiration
Daily obstacles during development along with other colleagues
What it does
Gives a developer the opportunity to ask other colleagues for their expert advice
How we built it
Set up git, split up work, communicate and design along
Challenges we ran into
Plugin development, create a link between computers and how to synchronized data between them
Accomplishments that we're proud of
We build in a very short amount of time something that works
What we learned
How to develop IntelliJ Plugins, develop online code editor
What's next for Codellaboration
gives opportunity to request coding challenges, video recording, use it at work
Built With
figma
firebase
git
intelij
java
monacoeditor
node.js
nosql
webcomponents
webrtc
websockets
Try it out
telco-e04dd.firebaseapp.com
bitbucket.org
bitbucket.org


TechConnect Front Page
Inspiration
Throughout our high school years, my team and I were heavily interested in volunteering and humanitarian aid. We joined several youth organizations to contribute our efforts, but we were never able to apply our strongest skill: computer science. We decided to do something about this issue to help computer scientists and engineers to be able to apply their skills and make a profound impact on our society. At the same time, non-profit organizations have trouble recruiting computer scientists to build their software mainly due to their low budgets, which makes it difficult for these charities to function and contribute to society. Thus, we decided to create TechConnect, a platform where computer science enthusiasts of any level can take on software development projects listed by the community organizations. While these freelancers can build their portfolio, the charities benefit by receiving tech support with little to no cost.
What it does
Our website helps match computer programming enthusiasts with non-profit organizations. More specifically, the webform accepts requests for technological aid from non-profits and posts them onto the platform. When programmers are interested in undertaking the project, they can directly apply towards the cause and our website helps match the pair together.
How we built it
We built this project using Javascript, HTML/CSS, Bootstrap, and Firebase. We designed our website with HTML/CSS and Boostrap and implemented the databases using Javascript and Firebase. There were two databases in our program where we stored the non-profit organizations' and job applicants' information.
Challenges we ran into
When making this project, one of our struggles was designing a visually appealing and functional website. By using bootstrap and carefully designing the details, we were able to overcome this problem. The other issue we came across was implementing FireBase to store our inputted data. Since we were new to using FireBase, there were many methods and commands that we were not familiar with. However, through experimentation and self-study, as well as some general aid from the mentors, we were able to quickly gain grasp of the tool and implement it in our platform.
Accomplishments that we're proud of
Dennis and I are really proud of learning and implementing Firebase for the first time. It was difficult at first, but there were very helpful mentors who guided us through the way.
What we learned
We learned how to call, store, retrieve values from Firebase, and developed a stronger understanding of the programming languages that we used to make this project. Overall, it was a great learning experience, especially as it was our first hackathon, and we are very proud that we were able to complete the program.
What's next for TechConnect
TechConnect Next time, we hope to use Firebase to collect all kinds of values. The information that we retrieved from our program were all strings, but we hope to be able to gather files, lists, and more. We also want to implement a cryptocurrency API to make the financial transaction process between the freelancers and organizations easier.
Built With
css
firebase
html
javascript
Try it out
GitHub Repo


Mark is interested in launching Libra. I tried Blockchain, Luno, Hotbit, Binance in a DIY learning process. I got scammed by Hashnow.cloud and Cryptofxspace. *Its not as silly as it sounds being scammed by Hashnow. as a hash refers to the electric usage during the computer breaking down the algorithm to make Bitcoins.**
I had quite a long dialogue with the authors of Cryptofxspace before it was quietly shut down.
This is a key part of Facebook's long term business plan.
What's next for Cryptocurrency Detective Agency
Using my knowledge in a helpful way. Learning more about how to build a Blockchain. I'm trying to help moderate discussion groups on Quora about how to stay safe in the crypto world.
Try it out
t.co
www.facebook.com


What inspired us is the fact that the farmers goo through Soo much difficulty to grow their crops but at the end of the day their produce go waste on the farm without they by not getting it to the desired buyers.
Built With
iot


I like writing and story telling. I created a blog using WordPress for Business. I wanted to see how much traffic I could build to the site and WordPress themselves told me it had a very good audience for an early user website.
I created lots of exciting content to try to get users to click on and interact with the website. My bounce rate is only 16% and my average user make 9 clicks on the site....
What's next for Sophie's World Wide Web
Once I can understand more the techniques to get an audience I can use the analytics on the site back end to tell me what features or stories were most appealing to users and adjust the site accordingly.
I am starting to sell advertising space on a small scale e.g. https://sophiecoopers.com/2019/11/16/alldaydr-guest-post/
Built With
bing-traffic
business-profiles
google
google-analytics
wordpress
Try it out
www.sophiecoopers.com


Web form
Inspiration
Expanding knowledge on Twilio API in order to create a useful SMS application
What it does
We've created an SMS Twilio-based application that allows home owners to text a permanently coded number with specifications in terms of what kind of contract work they would like. This information is forwarded through our service and sent out to the appropriate companies that have signed up through our web form. From there, we receive their quotes and forward this information back to the home owners so they may decide which company to hire for their home renovation.
How I built it
It was built using Python, Flask and the Twilio API in addition to a web form created using React.
Challenges I ran into
Many challenges were faced trying to get HTTP Post requests to work properly with respect to the Twilio API. Also, setting up the Stdlib database for company names/skills and creating the Python function to handle the SMS service.
Accomplishments that I'm proud of
Being able to have a functional Python application working with Twilio API. Also, incorporating Stdlibs platform.
What I learned
Twilio API, Flask, expanded my knowledge on React.
What's next for renoSMS
Fully incorporating Twilio's API with an upgraded account. Having more parameters and specifications with the type of work home owners want.
Built With
css
flask
html
javascript
python
react
twilio
Try it out
GitHub Repo


Alexa APIs for Node.js
The Alexa APIs for NodeJS consists of JS and Typescript definitions that represent the request and response JSON of Alexa services. These models act as core dependency for the Alexa Skills Kit Node.js SDK.
These model classes are auto-generated using the JSON schemas in the developer documentation.
Package Versions
PACKAGE NPM
ask-sdk-model
SDK Documentation
LANGUAGE DOCUMENTATION
English
日本語
Getting Help
The model packages in this repository are auto-generated. The issues and pull request on the repository are not monitored and may get closed without investigation. Please use these community resources for getting help:
File issues and pull requests on the main SDK repository.
Request and vote for Alexa features here!
License
This library is licensed under the Apache 2.0 License.
Built With
javascript
typescript
Try it out
GitHub Repo


bubel-ui
Built With
dart
golang
kotlin
swift
Try it out
GitHub Repo


Friends Tab
Inspiration
Mehul and I have been friends for over a decade. After college, we both moved to different cities (he came to SF, I moved to Chicago). We found ourselves constantly having trouble planning events and were annoyed by the lack of solutions. Furthermore, repetitively texting people was both time-consuming and irritating. After expressing our mutual frustration, we realized there was potentially an opportunity to change how people planned and did social activities.
What it does and how we built it
Wayd is an on-demand platform for social activities. We wanted to create a personalized, convenient experience for people to do the regular activities they enjoyed doing. We built it using a combination of react, express and firebase. A web app made sense because people could easily use it/share with friends without having it downloaded on their phone. This is why integrating with Twilio's API made a lot of logical sense. Instead of having to text friends individually or on a chat, your friends would just get a notification with the title of the activity you were doing with a link to easily signup. Firebase allowed the count to be dynamically updated in real time to give it an almost video-game lobby like experience.
Challenges and Accomplishments
We ran into a couple of major challenges. One was that most API's of companies relevant to this space were unavailable or expensive. Additionally, it was impossible to execute the ML features with no real data. Despite this, we were able to create a minimalist discover section that we think would appeal to our target demographic.
What we learned and what's next
The biggest thing we learned was the value of being able to concisely explain your problem/idea. Next, we hope to grow wayd and start iterating and improving features with a small, sticky user base that sees real value in what we're trying to do.
Built With
express.js
facebook-login-api
figma
firebase
javascript
react
twilio
Try it out
tinyurl.com


The ingame rendering
Inspiration
exporting xodr format into a better usable format for 3D Rendering (Meshes/.obj-Files)
Unity as a good Live-Renderengine for a direct usable product
What it does
it has a custom parser for the xodr Files (written in Java)
it generates .obj files for the street, the pavement and the street markings (according to the xodr file)
these files are then taken into Unity (manually)
then we can beautify the overall model for a more realistic model
How we built it
we build a xodr-parser written in Java which generates .obj files from the xodr format
we created multiple 3D-Models and designed a test-environment in Unity
Challenges we ran into
it is really hard to export euler's spirals from the xodr format into a useful format
the xodr format is really ..., like having all kind of lane entries with type None(?!)
Accomplishments that we're proud of
we made our own parser for .xodr files and read the big documentation, so that's kind of an accomplishment
we made it work to export into .obj models (including pavement and line markings)
What we learned
it has advantages and disadvantages to create an own parser instead of using an existing one ;)
we learned a lot of unity and made some cool stuff there
also some 3D-Modeling in blender which was nice
What's next for OpenDrive 3D Visualizer - OD3V
maybe add in an advanced dynamic environment generation
add automatic traffic-light positioning
Built With
java
opendrive
unity
Try it out
gitlab.com
gitlab.com
1drv.ms


How I to build it:app creation on website servers injected ,install on packages like tcp
Built With
javascript
Try it out
jim3557.xyz


Our team logo
Inspiration
We love to go skiing. Having knowledge of the ski-area brings advantages like better route finding, knowledge of points with a great view and many more. For tourists this knowledge is rather hard to retrieve and thus one primary objective is to enhance winter sports experiences. With extensive use of data we strive to deliver real time information (e.g. snow quality, lift queues) for skiing and other activities in winter sports regions like southern Bavaria and combine this functionality with gamification features to motivate the users to explore the region, visit and support local businesses and enrich their stay. All of this functionality is integrated in user applications, smart speakers (e.g. Alexa) and the environment making use of the cloud and IoT for managing the data.
Features and Goals
Our great goal is to enrich tourists’ experiences in winter sport regions in as many ways as possible. For this reason many different design goals and functionalities have been elicited. In our vision all of them can be integrated into a single, user-friendly system (like a mobile app) and allow for diverse possible applications.
Smart Visitor Guidance: Measure the flow and possible congestion of skiers and snowboarders on the different slopes and lifts and thus minimising wait times.
Gamification: Motivating the users to complete interesting challenges (e.g. visit special places, take a selfie at a point of interest, try to ski 5 km on a single day, and many more) while collecting points. Those points are called SkiBucks and can be accumulated and exchanged for rewards. The real time behaviour of those challenges (each only for a limited time or a specific occasions) makes completing them even more thrilling. This approach has two major advantages: On one hand, we can use our data for smart visitor guidance to steer streams of skiers and snowboarders to lesser busy areas. On the other hand, the rewards can be used to promote local businesses (e.g. by offering coupons for a given amount of SkiBucks) and thus generating customers. Also, knowledge from locals can be used to generate cool challenges.
Context Based Recommendations: Recommender Systems (RS) are commonly used in many applications, especially in tourism domains. Thus, integrating a smart recommender system for different application areas is an important feature to make our system to a powerful tool for tourists. One application area could be recommending appropriate slopes by analysing the previous behaviour of the user (e.g. with GPS traces). Another one could focus on promoting local establishments like Skihütten, Bars, Restaurants etc. As a side effect statistical data may be generated and published for business owners to develop better marketing strategies in the future. Other important points:
Statistics: Showing statistics to the users of the system, for example their total amount of kilometers travelled, max. Speed, total time, …
Accessibility Features: We want to enable all kinds of users to experience the tourism regions. Thus, settings for showing and recommending suitable establishments for impaired people is an important feature. Also the application itself has to be usable for as many users as possible. Concrete ideas for this kind of feature are high contrast modes, text to speech in the mobile app, filters for users in wheelchairs.
Aprés Ski mode: Not every user goes to the slope for skiing only. For this reason creating plans for Aprés Ski activities should be included. They may include functionalities like showing the last ride downhill or using our IoT data to show if there are still free seats in a given establishment.Additionally, party music of the type Malle-Hits should be played while using the app in Aprés Ski mode.
Social Features: Activities alone may not be as fun as together with other people. Thus helping the formation of group and supporting groups with decision making can also be relevant features to consider. This rather big amount of features is complemented by nonfunctional requirements including:
Offline use of the system: Cellular coverage may not be optimal during activities and thus caching data is important.
Extensibility: We don’t know what the future holds. But Augmented Reality features and story based games (“Explore aside from normal challenges”) would be together with other innovations great additions to our service. These are our ambitious ideas for enhancing the tourism experience. There are many challenges for sure, but we think this is a concept to make many stays from just a nice holiday to a great experience.
What we actually built
Complexity and the feature-rich concept of ours in combination with the limited time during this hackathon made it impossible to implement all of the proposed features. In addition, there were things we couldn’t possibly accomplish during a hackathon (e.g. getting field data, generating real data). Thus, we had to elicit the most important ones, which were realistically implementable, and integrated them in a web+mobile app. Our main focus area was implementing the gamification feature complete with an backend storing different challenges and rewards, as well as a frontend application which enables the user to interact with the system. While we didn’t have enough time to implement an IoT device for reporting environmental data, we were able to make some considerations like useful wireless technologies (e.g. LoRa) for future implementations. This leaves us with an overview of the realised concepts and goals:
User-friendly interface: The UI is designed in a way that the user is able to navigate intuitively. Natural Mapping techniques have been applied (for example the use of markers in maps) and well-known layouts (e.g. navigation bars in the bottom of the screen) make the UI feel great.The solution consists of using and adapting different components in the React-framework, which forms the basis for our front-end.
Map View: The Home page allows to user to view all of the available challenges and resources in his/ her near environment and provides and overview of the slopes. This enables him/ her to plan routes manually and to quickly find interesting activities in the area. The map also shows ski routes (which can be custom created for new and interesting slopes or if there isn’t data available) with additional information like difficulty ratings, snow quality, etc.. Also dynamic markers have been included to show geo-locations. A toggle switch for showing the usage of slopes is also in this view. The framework we used is called Leaflet. Implementing the maps has been one of our greatest challenges, since we encountered many incompatibilities to other used modules, but we were able to sort them out.
ListViews: In addition to the map views ListViews allow for viewing the challenges individually in a simple representation. This view also allows for redeeming rewards.
Reward-Redemption with QR codes: In order to get your reward we provide a QR-Code which may be used at participating local businesses. Since there are no local businesses participating right now, we provide a link to another important resource.
Backend: Data management is handled by our backend. The database containing the different challenges, rewards, later more user and environment data is handled there. Cloud native implementation has been achieved by using DynamoDB on AWS and queries can be formed using GraphQL. This allows for easy fetching of data and helps us to deliver our services.The advantage of our cloud native approach is the great amount of flexibility and the possibility to switch to other providers as needed.
Alexa-Integration: Voice assistants are an useful interface option and may provide a comfortable way to interact with the systems. The use cases are plentiful and we started by adding a feature to ask for a plan for a nice winter day. Initially we had problems registering our Alexa skill with our provided device, but we managed to take care of that. In the current version the skill can be called by voice and provided useful daily plans. In addition a tips system has been integrated allowing the user to ask for tips regarding the region. The display of the provided Echo Spot is also put to use and shows the tips in text form.
SkiBucks: We added our own virtual currency and assigned values for rewards and challenges. This is the foundation of the gamification-rewards system. Settings Menu: Just a simple menu providing an overview of possible settings, mostly integrated for the sake of completeness.
How we built it
Primarily as a team. Using GitLab and Git in general we accomplished suitable project organisation. JavaScript in frontend and backend enabled us to rapidly build a functioning prototype of some of the proposed features. The use of the cloud (AWS in our case) made managing the backend simple. This holds also true for the Alexa Skill, which is deployed also on AWS.
Challenges we ran into
Complexity and the fact that we had way too many ideas for a way too short amount of time. Some JavaScript frameworks are, let's call it .. bad and thus we had to change it during coding. Building applications in a very limited amount of time is exhausting.
Accomplishments that we're proud of
Having a running app and a great concept.
What we learned
Lots of stuff, from debugging javascript to the layout of ski-areas. Collaborative work in a short amount of time and practical implementations were fun, too.
What's next for Skibucks Application
First we have to wait for some snow. ;)
If you want access to our repo, just message us. :)
Built With
adobe
alexa
amazon-web-services
computer
graphql
javascript
node.js
photoshop
react
xd
Try it out
gitlab.lrz.de


Inspiration
Paper exams suck. They really do. Save the planet and money by using ExamBee!
There are many drawbacks to paper exams. The obvious one is printing costs. Printing thousands of exams every semester is costly for education institutions.
Paper exams can also be an organizational nightmare. Trying to keep track of hundreds of exams at a time while also checking student ID cards can be stressful, time consuming and distracting to others in the room.
Exam results often take weeks to process and can be error prone.
What it does
ExamBee aims to make all your multiple choice exams electronic. A university purchases iPad's running the ExamBee iOS app, and mounts the iPads to desks in the exam room.
Each student walks in and sits at a desk with an iPad. To authenticate the student enters their student number and uses the iPad to take a 'selfie' of themselves. The app uses an on-device facial compare model to compare the students selfie to their student ID photo stored on our server.
Once authenticated you choose an available exam and submit your answers.
The exam is graded instantly on-device, and the student receives a text message with their exam results.
How I built it
iOS app is built natively using Swift 5 and iOS 13SDKs. No interface builder or storyboard was used, everything done programmatically.
The Backend is built using Sailsjs, a MVC web framework in javascript. I hosted a MySQL database on a digital ocean ubuntu box.
Challenges I ran into
The hardest challenge was trying to figure out the best way to store and retrieve the student ID photos from my backend.
Accomplishments that I'm proud of
Building the entire stack myself and being able to do on-device machine learning without using an external platform like AWS or Google Cloud
What I learned
Lots about SailsJS and how fast it can be used to create fulling featured web applications and CRUD apis. The ORM was easy to work with and very powerful.
What's next for ExamBee
I would like to secure my backend environments and improve the UI of the iPad app. Also a web app for professors to create and manage exams.
Built With
digitalocean
ios
mysql
node.js
sails.js
stdlib
swift
ubuntu
xcode


Inspiration
Clara, one of our team members, commuted two hours on a daily basis to downtown Toronto last summer, where she worked. These long drives during rush hour in combination with her lack of sleep led to extreme fatigue and limited attentiveness while she drove, which concerned both her safety and drivers/people around her. Drowsy driving causes 100,000 crashes, 70,000 injuries, and 1,500 deaths annually in the US. Our team found that Clara, along with millions of others in similar situations, could benefit from having a connected, in-car AI assistant that detects driver drowsiness and provides solutions to keep drivers alert, ensure safety, and prevent accidents.
What it does
The voice-activated Iris AI assistant for connected vehicles constantly monitors the driver’s eye-aspect-ratio and facial expressions using dashboard cameras or smartphone frontal cameras, in order to detect a driver’s drowsiness levels and facial emotions. Iris offers drivers a variety of features, such as suggesting drivers to take a break from driving by recommending cafes, restaurants, or hotels nearby. Iris also allows voice calling or texting for the driver to stay alert, and can suggest and play Spotify songs based on the driver’s facial emotions and mood. Finally, to ensure the safety of pedestrians and drivers around the drowsy driver, the driver will be notified of pedestrian and school crossings nearby and encouraged to take caution.
How we built it
The Iris AI assistant was built in multiple steps. Firstly, in order to monitor the driver’s eye-aspect-ratio, a ResNet custom facial keypoint estimation model was trained on the Google Cloud Platform using the open-source VGG Face dataset. Then, the model was used with OpenCV to constantly monitor and calculate the eye-aspect-ratio of the driver. The facial keypoint data points are also streamed to Google’s Cloud Vision API to constantly monitor the driver’s facial expressions and emotions.
Subsequently, whenever the driver is determined to be drowsy (as the eye-aspect-ratio approaches 0), the Iris AI assistant is invoked to warn the driver. The Iris AI assistant runs on a custom NLP engine that is able to identify user intent, with the aid of Google’s speech-to-text and text-to-speech APIs. Iris is thus able to parse the user’s voice input, understand the intent of the user and act upon it, and respond to the user through voice output.
Finally, multiple features for Iris were built using a variety of APIs with the goal of aiding a drowsy driver. Using the city of London’s Open Source Dataset and the Google Maps API, Iris is able to detect pedestrian and school crossing zones nearby, and warn the driver to be cautious when approaching these zones. Furthermore, the driver can ask Iris to search for nearby cafes, restaurants, hotels, or parking lots, in order to guide the user towards a safe resting spot. The Twilio API was also integrated with Iris so that the latter can access the driver’s contacts to call or text a friend, family, or emergency services. Finally, using the Spotify API’s recommendation engine, Iris can suggest and play songs on Spotify according to the driver’s current emotions and mood.
Challenges we ran into
We ran into a number of challenges when building Iris. Firstly, training the facial keypoint estimation model was challenging due to the limited compute power we had on GCP. It was also challenging to accurately calculate driver drowsiness using our custom model, and build our custom voice-command-based NLP engine to accurately parse and identify user intent. Finally, we had some challenges integrating the Google Maps API with the London Open Source Dataset in order to provide various warnings and location-based features to the driver.
Accomplishments that we're proud of
We’re proud of being able to fully build a functioning voice-activated AI assistant to help detect drowsy drivers. Specifically, we’re proud of being able to build a model that successfully detects drowsiness in drivers, as well as building our own custom NLP engine, and finally integrating our AI with external APIs such as Twilio and the City of London’s Open Dataset.
We’re also proud of our teamwork abilities, as we leveraged each team member’s strengths in front-end, back-end, data science, and business case construction to build a complete and comprehensive solution.
What we learned
We learned a lot while developing Iris, including learning how to utilize machine vision for facial keypoint estimation, as well as learning about how the eye-aspect-ratio and driver’s facial expressions can be used to detect driver drowsiness. We also learned a lot about how to build an entire voice-command AI agent from scratch, specifically concerning intent parsing and recognition. Finally, we learned a lot about how to integrate Google Maps’ geolocation capabilities and the City of London’s open-source dataset to provide more accurate location insights and warnings for the user.
What's next for Iris
We see Iris as an opportunity to ensure the safety of millions of drivers worldwide, both in countries with high traffic density regions and in multiple transportation industries such as trucking, which is one of the most dangerous professions. We want to further explore the possibilities of integrating Iris with vehicle data (such as fuel and engine status), as well as Apple watches/Fitbits to detect heart rates and other measures of drowsiness and wellbeing. With Iris, we believe we can further work with governments and car manufacturers to achieve higher levels of road safety, improve the in-car driver experience, and ultimately save lives.
Built With
city-of-london-open-source-dataset
firebase
google-cloud
google-cloud-ai-platform-notebooks
google-geocoding
google-machine-vision
google-maps
google-text-to-speech
google-web-speech-api
javascript
keras
numpy
opencv
python
spotify
twilio


Best with what's Left
Inspiration :
We wanted to solve a practical problem we'd both faced in our day-to-day lives. Food wastage is a big issue in Canada, with over 2.2 million tonnes of edible food being wasted each year. We wanted to make something that not only makes our lives easier, but make a difference to the environment as well.
What it does
Our project accepts a URL link of a picture of the contents of your fridge. Using the Clarifai API, which utilizes machine learning to recognize specific ingredients in pictures, we take the ingredients identified and return recipes on the site AllRecipes.com that use those same ingredients.
How we built it
Our front end was build using HTML/CSS. We used Node.js to do our server-side architecture, and Express.js as a link between the front-end and back-end. In order to recognize the ingredients in the picture, we utilized the Clarifai API.
Challenges we ran into
One of our challenges was parsing the out Json file correctly to retrieve specific data points we needed for our program. Another challenge we had was linking the Node.js variable values with the corresponding HTML (EJS) file to be displayed on screen, or taken from the screen.
Accomplishments that we're proud of
HackWestern6 marks as the first hackathon for the both of us, and we are very proud of what we've managed to build. It included a big learning curve on our parts given we'd never worked with any other technologies except HTML, CSS and Vanilla Javascript before, and we're especially proud of managing to parse our JSON as required as well managing to redirect our front-end to the require AllRecipes page when the user hits submit, rather than making them manually click on a link appearing on the screen.
What we learned
This entire project was entirely about learning for us. We learned how to implement API's, server-side programming using Node.js and Express.js, and how to work as a team through frustrations and bugs.
What's next for Best with what's Left
We definitely want to advance this project further because we really believe in the practicality and simplicity of this concept and it could become very useful to the everyday family if developed into an app. We want to include the capability to take photos and submitting them instead of submitting URL links, which we understand is a hassle. We also want to implement our own, trained, ML model instead of drawing from an API to get better and more customized results. In the future, we also want to add health benefits to this product, like calorie counting and macronutrient information.
Built With
clarifai
css3
ejs
express.js
html5
javascript
node.js
Try it out
GitHub Repo


Book a regular Sixt Share based on your calendar events
Inspiration
People are often busy doing their tasks and can only look up the way to attend to the next event. An unexpected traffic condition would make it even more stressful for people who try not to be late. It would be great if there is some sort of assistance to plan for their commutes in advance.
Car sharing cars are almost always empty. We would like to use the resource more efficiently and safe to reduce the ecological footprint when traveling from A to B.
What it does
Match riders with drivers.
Plan trips ahead based on everyone's calendar schedule
Safe money, stress, and the environment
How I built it
Python backend using flask, providing the calendars and computing the routes. React for the frontend.
Challenges I ran into
Make it working in time. UI Design and decisions on which functionalities to implement.
Accomplishments that I'm proud of
Made it working in time
What I learned
Azure flask app integration is no fun at 4:30 in the morning
What's next for Sixt Mixed
Go to production and use this awesome feature in real life
Built With
flask
javascript
python
react
Try it out
GitHub Repo


Love is the basis of life. Life is love without love. Therefore, love has been given a high place in the ancient Vedas and Puranas. Life has been conceived as the basis of love for human life. Due to the changing environment and life, there are problems in love life which are causing love problem. Due to which there is sorrow and despair in the life of the people. To solve this love problem, we are going to tell you about such an astrologer who is trained as a love problem solution astrologer among people. The love solution astrologer is able to solve all the problems of life. Because they have been given the mantras & tantra of astrology by the ancestors which is sufficient to solve the biggest problem. Some solutions have been given by love solution expert astrologer to solve love problems which is based on planets and constellations. These mantras can give solution to any problem only when the mantras and tantras are used properly. If these mantras and tantras are used in the wrong work, then these mantras lose their influence. Therefore, before using any mantra and tantra, by contacting a good astrologer or pundit ji or love problem solution astrloger, one should get the complete information about the depth and mantra of that problem. Love Problem Solution By Vashikaran Mantra Vashikaran mantra is most economical for love problem solution. With the help of Vashikaran mantra, any problem can be solved in a very short time and expenses. Vashikaran is made up of two words which means to subdue someone. Anyone can be tamed using this mantra and get the work done as desired. But before taking control of any one, one must consult a pandit or vashikaran expert or love problem solution expert. Love Problem Solution By Black Magic Black magic can be used to love problem solution. For this, you will have to contact a love problem solution specialist or black magic specialist. Because to solve any problem with black magic, full knowledge of black magic is necessary. If a person uses black magic without knowledge and experience, then it is harmful for him. Black magic is performed by black powers. Therefore, full knowledge and experience is required. Therefore, it is clear that astrology has a love problem solution. Therefore, if you also want to find a solution to any of your problems, then you should contact our love solution expert astrologer VK Shastri. They will give you a solution to every kind of problem. +91-9929415910 http://www.exlovebackmantra.com/
Built With
express.js
html5
Try it out
www.exlovebackmantra.com


Inspiration
I was inspired by the lots of reflection we do in school for different classes.
What it does
It allows students to track their reflections and record them.
How I built it
Used InteliJ to edit HTML, CSS, and Javascript files. Used gihub pages for webhosting. Used html5up.net for design base.
Challenges I ran into
I struggled with formating the text and CSS styling.
Accomplishments that I'm proud of
I am a beginner, and I expanded on the WebDev and used a template to help me create a website, which I am pretty proud website.
What I learned
I learned more of how to use HTML, and how to deploy a website to the internet.
What's next for InnerReflect
Add more functionality (saving data, retrieving user data, authentication and login, sentiment analysis, give different advice based on sentiment)
Built With
css
css3
html
html5
html5up.net
intellij-idea
javascript
love
Try it out
22kyang.github.io
GitHub Repo


Inspiration
Athletes and gamers review footage of their performance to accelerate their progress.
Remote teams often interrupt each other, and waste a lot of time on Slack. They lack context on what their teammates are doing.
Freelancers and solopreneurs often feel isolated; they crave community, accountability, and feedback.
Related apps: RescueTime, Momentum (Chrome extension), Slack, Tandem, Focusmate, and Twitch.
What it does
Sesh is a desktop app that runs as an overlay on top of all your other windows (like a heads-up display in a video game). You input what task you're working on, how long you're going to work on it, and press start.
Sesh then captures your work, recording a time-lapse of your screen and which apps you're using. You can also see what your teammates are actively working on.
At the end of your "sesh", you can share the video and metadata to Slack.
How we built it
Sesh is built as a combination React and Electron/Node app that runs locally on your desktop.
Challenges we ran into
Some of the most technically challenging parts of the project involved recording and streaming video from the desktop and integrating React animations into an Electron desktop app.
Accomplishments that we're proud of
We built a well-functioning desktop app in under 24 hours, with no prior Electron experience.
What we learned
On the technical side, we learned a lot about building desktop apps with Electron and the way Electron interops with React and other node modules.
On the product side, we've refined our product and pitch based on a lot of user feedback.
What's next for Sesh
Release it as a downloadable desktop app!
Built With
electron
ffmpeg
html5
node.js
react
slack
webpack
Try it out
sesh.now.sh


Inspiration
Many interesting machine learning models need high quality ground truth data. Data labelling is often painful with clunky UIs and very basic inputs.
What it does
We wanted to build a personalized cosmetics company using machine learning, but finding ground truth for things like lip segmentation is hard. Doing it manually one by one is also painful. Instead we built UIs to quickly label that data, training the ML model in real-time and using it's output for aiding the rater (ex: model guesses a segmentation mask, rater simply corrects it instead of starting from scratch).
How we built it
To keep it simple, we are labelling deep fakes. We got some data from the internet and we ourselves generated some synthetic data.
We have a backend built in node.js, it has the logic for returning images to label and also recording rater results. It includes an ML model which uses tfjs and is updated in realtime as rater input comes in. We have a frontend which lets the rater quickly go through data using keyboard shortcuts, either labelling 1 by 1 or with grids.
Challenges we ran into
Our initial models were simple 4-5 layer deep convolutional networks, the performance was very bad. We ended up switching to using pretrained base models and built classifiers on top.
Accomplishments that we're proud of
We have a real-time updating ML model, we have a slick/fast UI.
What we learned
tfjs, concept of active learning in ml, challenges of data labelling.
What's next for false:positive
Make it a one-stop shot for accelerated dataset labelling.
Built With
javascript
node.js
react
tensorflow


Inspiration
As members of FRC team 670, the idea of making this platform was inspired in part by our experiences in robotics, both with learning and teaching. A source of inspiration was Boston Dynamics' humanoid robots, while we also considered designs and challenges that we faced when we built our 2019 competition robot.
What it does
It has 2 arms and 2 legs with servo motors on the joints. Motion of these subsystems is controlled through Python code, and the robot can be easily programmed to do actions like walking, lifting and moving its arms, and dancing; this platform can be adapted by the user to be as simple or complex as they'd like.
How we built it
Parts for the arm were designed using Fusion360 and 3d printed on a Monoprice printer. All the servos are controlled with a raspberry pi through a 16 channel board from Adafruit. A lot of time was spent tuning values for how much the parts of the robot should move in a balanced way. Coding was done in Python; control from a server and the pi can be accessed from a webpage.
Challenges we ran into
Tuning values for balance to move everything how we want
Mechanical challenges: making sure no parts are loose, everything fits well
Being able to hold weight with the servos
Original plan of coding in Java failed because it relied on a confusing library
Accomplishments that we're proud of
Our robot can dance!
All subsystems work together and move
What we learned
Two of our team members were new to programming, but through working on this project learned to code in Python
Integrating a mechanical and software system
Designing and prototyping
Built With
python
raspberry-pi
Try it out
GitHub Repo


Inspiration
We have came up with this idea, as we wanted to work on a project, which could improve the lives of many.
What it does
It offers many different features for people, who are suffering from memory loss. Such as. detecting the voice of a person and identifying who it is, this would avoid them from getting tricked by people, wo claim to be a friend of them etc. This would also allow them to be more comfortable in life, as even if they forget names, the system would remind it. Another approach is working as a smart personal information collection, which can consist of images, text etc. We then create tags (and word embeddings), which allow user to search these based on a question or tag. As this app is designed for disabilities, they would get to choose the most important information to store in our system, and quickly search for them.
How I built it
We have first started with 4 apis we used from azure: text recognition, face api, speaker recognition, computer vision. As we got them working with python calls, we moved on to more general tasks. In combination with django, we have created a backend and a frontend, which allows us to visualize an app usecase.
Challenges I ran into
Decide, how to create a backend and a frontend, as none of us has any frontend experience.
Accomplishments that I'm proud of
Combining a lot of different functionalities and ideas, such as tags from azure with word embeddings from spacy. We are also very happy that these different functionalities are working correctly.
What I learned
Having a good and motivated team makes this process much more fun.
What's next for SecondBrain
Built With
azure
django
python
scapy
Try it out
GitHub Repo


Inspiration
The vicarious experiences of friends, and some of our own, immediately made clear the potential benefit to public safety the City of London’s dataset provides. We felt inspired to use our skills to make more accessible, this data, to improve confidence for those travelling alone at night.
What it does
By factoring in the location of street lights, and greater presence of traffic, safeWalk intuitively presents the safest options for reaching your destination within the City of London. Guiding people along routes where they will avoid unlit areas, and are likely to walk beside other well-meaning citizens, the application can instill confidence for travellers and positively impact public safety.
How we built it
There were three main tasks in our build.
1) Frontend: Chosen for its flexibility and API availability, we used ReactJS to create a mobile-to-desktop scaling UI. Making heavy use of the available customization and data presentation in the Google Maps API, we were able to achieve a cohesive colour theme, and clearly present ideal routes and streetlight density.
2) Backend: We used Flask with Python to create a backend that we used as a proxy for connecting to the Google Maps Direction API and ranking the safety of each route. This was done because we had more experience as a team with Python and we believed the Data Processing would be easier with Python.
3) Data Processing: After querying the appropriate dataset from London Open Data, we had to create an algorithm to determine the “safest” route based on streetlight density. This was done by partitioning each route into subsections, determining a suitable geofence for each subsection, and then storing each lights in the geofence. Then, we determine the total number of lights per km to calculate an approximate safety rating.
Challenges we ran into:
1) Frontend/Backend Connection: Connecting the frontend and backend of our project together via RESTful API was a challenge. It took some time because we had no experience with using CORS with a Flask API.
2) React Framework None of the team members had experience in React, and only limited experience in JavaScript. Every feature implementation took a great deal of trial and error as we learned the framework, and developed the tools to tackle front-end development. Once concepts were learned however, it was very simple to refine.
3) Data Processing Algorithms It took some time to develop an algorithm that could handle our edge cases appropriately. At first, we thought we could develop a graph with weighted edges to determine the safest path. Edge cases such as handling intersections properly and considering lights on either side of the road led us to dismissing the graph approach.
Accomplishments that we are proud of
Throughout our experience at Hack Western, although we encountered challenges, through dedication and perseverance we made multiple accomplishments. As a whole, the team was proud of the technical skills developed when learning to deal with the React Framework, data analysis, and web development. In addition, the levels of teamwork, organization, and enjoyment/team spirit reached in order to complete the project in a timely manner were great achievements
From the perspective of the hack developed, and the limited knowledge of the React Framework, we were proud of the sleek UI design that we created. In addition, the overall system design lent itself well towards algorithm protection and process off-loading when utilizing a separate back-end and front-end.
Overall, although a challenging experience, the hackathon allowed the team to reach accomplishments of new heights.
What we learned
For this project, we learned a lot more about React as a framework and how to leverage it to make a functional UI. Furthermore, we refined our web-based design skills by building both a frontend and backend while also use external APIs.
What's next for safewalk.io
In the future, we would like to be able to add more safety factors to safewalk.io. We foresee factors such as: Crime rate Pedestrian Accident rate Traffic density Road type
Built With
google-directions
google-maps
python
react
Try it out
GitHub Repo


Inspiration
We wanted to make a website with a basic function in bubble.io with buttons. In those pages that were from clicking the buttons, we made informational pages about a researched subject of awareness, which we decided to pinpoint mental awareness. We decided to pinpoint mental awareness since many people have not only depression and anxiety, but other mental illnesses, and this site can raise awareness based on the information provided.
What it does
It is a simple website with multiple tabs with the main goal to inform others about mental issues.
How I built it
We used the program bubble.io to make the website.
Challenges I ran into
Some challenges we ran into were the last minute decisions that we decided to make about what to do on the project. If we had more thought into the project through hard code, it would have more creative and more diverse in different functions.
Accomplishments that I'm proud of
We are proud of finishing a whole website through logic and not through a simple template.
What I learned
We learned about how to use buttons in bubble.io and how fields were a factor in making the buttons work in every page.
What's next for MentorInMind
To improve MentorInMind, more of the aesthetics could have been better if we were to use another program that would have added effects that were more controlled through hard coding. More features, like a survey to add more input on the information provided on the site would be creative to make.
Built With
bubble.io


God mode
What it does
It's a game. Basically you fly around a spaceship and shoot down other spaceships without getting hit.
How we built it
It was programmed in Java, and most of the images were made in Blender.
Challenges we ran into
Getting waves to work properly, getting lasers to not instant-kill, finding bugs, and loud music.
Accomplishments that we're proud of
Getting a program that compiles.
What we learned
Initializing fields is important.
What's next for Fancy Game 2
More enemy types, more power-ups, functional tutorial level, weapon specialization.
Built With
blender
java
Try it out
drive.google.com


Logo
Inspiration
We were inspired by our own struggles in school. We found it hard for students to be able to seek help from each other and were inspired to create this application.
What it does
It connects students studying the same subject and allows them to chat with each other regarding their specific subject.
How we built it
We build this using HTML, CSS, Javascript
Challenges we ran into
We were unable to find good APIs to use for this application but found an embed workaround
Accomplishments that we're proud of
We were able to put our site together.
What we learned
We learned to persevere even when things went wrong.
What's next for Edmunity
We plan on adding a facetime feature.
Built With
css
html
javascript


Microscopical fractures
Inspiration
Noticing a microscopical fracture on a wing of a plane before it's too late, could mean the difference between someone's honeymoon and funeral. Whether today, or in the future years of technology - the stability of our enormous metal constructions, will remain as relevant as never before. We're a team of three students, who are interested in shaping a safer future for everyone, and plan on doing so in the most efficient way possible.
What does it do
The core of the project is data analysis. Multiple classification and object detection algorithms are mixed together to analyze visual data and provide insigts with minimal computing power. A picture of a solid, fed through our scanning software will be analyzed whether it contains any surface anomalies, and if any of them are present, the software will determine the approximate position and the count of all damage points.
Due to the sheer volume of data, generated by in-depth scans, we knew that the software had to be as efficient as possible - crunching through gigabytes of data in a matter of minutes, it would be able to deal with heavier datasets in a reasonable amount of time already. We have been able to achieve our own-set speed goal and proof test it by performaing crack detection with a live camera footage - the speed of image analysis can easily keep up with lower framerate video streams.
Speed however, while impressive on it's own, is not all that matters. Since the data that has to be analyzed could vary heavily, the software has to be able to adapt to different types of datasets. We believe that we have managed to achieve precisely that - going from micro to macro, analysing camera footage of roads, our software was easily able to identify road cracks and damaged pieces of asphalt without any problems, even though the dataset was vastly different.
The most important part, surpassing both speed and pertinence between datasets, is accuracy. We have expanded the provided data to multiple thousand pictures. We have also taken over 40 thousand pictures of cracked roads from the internet, and left the algorithm to improve for more than 30 hours throughout the whole hackathon. We're really happy with the quality that the software has achieved over the weekend, but we're even happier knowing the full potential of our algorithm, and the accuracy that it could achieve if trained without time constraints.
How we built it
Building such a software was a multi-step process. Just like all the data-driven projects, it started with the first and only possible stage - the data gathering and labeling. We felt that the data we recieved was insufficient and we were lacking pictures of objects without cracks. The work began by artificially increasing our sample size, creating pictures without any cracks for testing purposes, properly labeling and grouping similar data, then once again splitting everything up into multiple training and testing sets. This early time investment allowed us to begin as soon as possible with the second stage of development - actual training of our classifier. Using Keras, the first milestone would be identifying whether a crack is visible in an image. Parallel to our 1st classifier doing training, the 2nd approach was starting to manifest - actively looking for, and pin-pointing the position of any visible cracks using Tensorflow. To save time and increase quality as early as possible, we started training our model on top of a pre-trained Single Shot MultiBox Detector: MobileNet COCO - well known model in the machine learning industry, for its speed and object location times under 30ms. Just as the MobileNet COCO model was starting to show results, our 1st approach finished its planned training and beat all of our expectations with insanely accurate predictions and high overall confidence levels - while happy with the success, we worried about overfitting to this specific sample and started our hunt for more and varied data, thus arriving at the third stage of our development - data generalization. Satellite pictures of rivers, camera pictures of roads, telescope pictures of moon surface - everything even remotely similar to cracked solids was of interest to us - we knew that achieving high accuracy on such a variety of datasets would allow massive freedom when deciding what initial data should look like - precisely what we wanted to achieve.
One dataset after another, our model was starting to get astonishing results on multiple different "crack-classification" problems, while maintaining high accuracy on the initial data. By this time, our crack locating software became really good at pin-pointing cracks not only in images, but in real life as well. We knew we had the time to take the final step of our development - the merge. Both classification and location models were working flawlessly and instead of dropping one of them, we decided to join them into what later became the final version of ExteriScan - the communication between classifier and locator model allowed to wipe out the majority of our remaining problems. In images where no crack can be found to begin with, the locator won't even attempt to find something, not only saving some precious time, but also avoiding potential false-positives. In images where the classifier is extremely confident that a crack exists, the locator will try extra hard to find something even remotely representing a crack, allowing for some insane precision when multiple cracks can be seen at once in one picture. This, combined with a quick live camera feed, is more than enough to display the potential of ExteriScan.
Challenges we ran into
Set high standards and high expectations from our own software definitely created some extra challenges for us. Building on top of an older existing model, while interacting with our own brand newly written classifier, meant nothing else, but compatibility chaos. Different versions of Python, different versions of Tensorflow and different versions of Keras all working together meant rewriting thousands of lines of Tensorflow source code just to get the code to run. Even then, every new line of code, was a risk of hitting a new dependency that wouldn't be compatible with the rest of the codebase - nonetheless, with clever workarounds and combined experience, we were able to make all parts of the code work together for the greater good.
Accomplishments that we're proud of
The biggest challenges are also the most rewarding ones, once you manage to tackle the problem. As mentioned previously, getting all the small pieces to work together was something, that we can all be proud of as a team. But just as we're strong as a team, each of us had his own victories through the hackathon: Valentin, who was working on the classifier, was able to crunch mind boggling amounts of data and see the fruits of his labour immediately after. Mantas, while spending most of his time on object locating, was able to fix hundreds if not thousands of errors by completely rewriting a Tensorflow module for a Python version on which the module isn't even supported anymore. As to Fabian, him being as efficient as ever, goes all the flowers and credit for training our model to the point where it is now. Every single member of the team has had his small victories throughout the hackathon, but it's safe to say, that the final result of the project is something we're all jointly proud of together.
What we learned
The whole challenge was definitely a learning experience - a machine learning experience to be exact. Most of the time was spent on working with ML libraries, classifiers and models, and no matter the background or previous expertise in this field, every one of us learned something new. From training models, to sorting data, from optimal ways of labelling cracks to forcing AI to label the data itself. Everyone picked up a new skill or two, and we're sure these skills will come in handy soon enough.
What's next for ExteriScan
As proud as we are of our software, we can safely say it's far from perfect - the accuracy can always be increased, the code can always be better documented and most importantly, ExteriScan has so much to prove by being applied to specific tasks in the industry. We don't plan on leaving this project alone any time soon, and we hope to find people who would be interested on taking the software on for a test drive and throwing a task or two at it, to see how it performs.
This is not the end; for ExteriScan, it's only the beginning.
Built With
azure
classification
coco
docker
jupyter
keras
labelimg
machine-learning
opencv
python
rtc
tensorflow
Try it out
GitHub Repo


Apple
Inspiration
Many of my friends are going on fruitarian diets.
What it Does
Vanquishes boredom whilst simultaneously educating the product's users of the wacky world of fruits.
How to Use it
On the home screen you can scroll down and click on story to find story behind this project, or one of 6 panels to enter a theme of fruits. Once you enter the theme, you can hover around a fruit until the words for the fruit appears, then when you hold down on your mouse, the full expansion of facts is free to read.
How We built it
We hard-coded all of the information with HTML and CSS. We were going to use an API, but our team didn't know how to code past a beginner level, so we had to keep it relatively simple so we could build a site.
Challenges we ran into
Organizing the team. We all came in as individuals do it took awhile for us to assemble.
Accomplishments that we are proud of
We were able to delegate tasks effectively, and managed to learn a "slam" effect for the home page.
What we learned
I learned how to use APIs effectively (outside of this project), as well as how to make artistic CSS effects.
Bugs we still need to fix
There are design features on the story page that can be stylistically improved. Also, at some pictures the wrong fruit names were used(the right facts). At times he words for certain fruits may not appear but more the most part eventually every fruit once the word appears and you hold down on the mouse does let the facts appear.
What's next for FRUITS2
We are going to expand to vegetables, then use APIs to get data that we can overlay onto our HTML web layouts. Once we master APIs, we'll expand to all types food, and then all kinds of drinks, and finally, to all things purchasable in the global economy, edible or otherwise.
Built With
css
html
javascript
Try it out
GitHub Repo


App home screen
Inspiration
As programming beginners and first time hackathon participants, we wanted to challenge ourselves by building an app and creating a software that recognizes text from an image. Our secondary goal was to create a practical product that solves a common problem. Hence, grocer.io was created.
What it does
Grocer.io is a virtual fridge. It tracks the shelf life of the user’s ingredients: allowing them to eat it while it’s fresh. With the existing ingredients in the fridge, it also suggest recipes most appropriate for the age of the ingredients.
How I built it
Using Android Studio, we created an app that reads text from an image and uploads the detected text to firebase’s real time database. We designed and organized the UI and UX with adobe photoshop, Adobe XD, and Photoshop
Challenges I ran into
Knowing where to start: This was everyone’s first time creating an app! We struggled a lot with knowing what platform to use as well as what we needed in order to put together each component of the app.
Firebase and Gradle: We knew we wanted to use a database in our app, so we attempted to set up firebase (which we found out required some changes to our build.gradle files) At this point we didn’t actually know what gradle did, nor did we know that Android Studio automatically set up these files for us.
Phone-laptop compatibility: When testing our app, we tried to use a variety of phones, source PCs and USB connection cables to get the connection recognized. One persistent issue was that the computer would not recognize our phone as an android device, preventing us from running tests.
Collaboration/file sharing: It wasn’t until near the end of the Hackathon that we started using GitHub to track our project changes and file share. (one of our neighbouring teams had to teach us how to use it). Prior to using GitHub, we had a lot of issues keeping track of the most updated versions merging changes from different team members.
Accomplishments that I'm proud of
We built our first app, learned how to use databases and upload real time data to it, and ideated a solution to a real life problem we identified.
What I learned
We learned how to use android studio, implement databases using firebase, and github. We are very proud of how far we’ve come and now know what areas/ecosystems we need more practice with.
What's next for grocer.io
Improving our Text Vision AI, Tracking item lifespan, Recipe recommendations, and Integrating front-end code.
Built With
android-studio
figma
firebase
github
java
photoshop
Try it out
GitHub Repo


Set It Up
Inspiration :
I've been wanting to dabble in machine learning for a long time but it intimidated me. The app I haven't isn't high level, but it's my first foot into the ML world and I couldn't be happier! I also added in web parsing, which is something I'd been wanting to explore — really, this idea exists because of the things I really wanted to learn but kept putting off due to intimidation.
What it does :
It takes a programming language from the user from the front end, runs it against Indeed.com to find potential employers through parsing, and save the information in a json file. This json file is used by brain.js to train itself to identify data. We then pass the user's language choice as input and ask out program to tell the user which company likely really needs someone talented in that language based on machine learning.
How I built it :
I used Node.js as the backend server. For parsing, I made use of the cheerio library, and brain.js for the actual machine learning portion of the program. The front end was done in pure HTML and CSS, and then connected to the backend using Express and ejs.
Challenges I ran into :
Taking input from html form, and displaying final output on an HTML page was definitely something I spent the longest on, given that this was the first time I was working with Node, Express and ejs. Parsing the input and putting it into the appropriate required json was also one of the challenges I faced. As Node.js is asynchronous, I also had to find work-arounds so it wouldn't use previous data to analyze and train itself, but rather newly generated data after the parser.
Accomplishments that I'm proud of :
Definitely the whole thing. As someone coming into her first hackathon, never having worked with any type of javascript except vanilla, I really wanted to push myself to learn and do things I felt uncomfortable and intimidated by doing. I couldn't have been happier of the result I have, and I can't wait to explore machine learning a lot more from here on. For a moment, imposter syndrome did hit me seeing my own peers do things far more complicated than this program, but for where I started, I've very happy for how far I've made in the past 24 hours.
What I learned :
Not speaking academically, I learned a lot of patience and that I shouldn't give up. I got frustrated, my program crashed and broke several times, and at one point I accidentally wiped my whole program and had to start from scratch. But I came out of it smarter. I learned a crazy amount in just one day, especially in terms of how machine learning works and how to do server side programming, and it really makes me excited to learn more.
What's next for Set It Up :
I'm definitely going to try to set it up (pun intended) with more parameters than just the language and make the interface a lot more cleaner. I would also try to make the training process quicker while making it more efficient. I'm far from done with this project.
Built With
brain.js
cheerio.js
css3
express.js
html5
javascript
node.js
Try it out
GitHub Repo


Inspiration
As the bay area is well-known for its extremely competitive schools, many times it may seem as if high school classes are nothing but a grade. Students are very prone to ignoring the possible relationships to be built between themselves and their teachers and peers. This negates an essential portion of the educational experience: if this connection isn't built, a class is no different from a youtube tutorial or an instructional website. In order to get the most out of their education, students should build these relationships with their peers and educators. Encouragement of the building of this bond is what we hope to achieve with our app.
What it does
There are two types of users that can be created with an email, password, and name: students and teachers. Teachers can create classrooms and delete them, and when they create a classroom, they give their students a code to join the classroom. Our app offers several features per classroom: a conflict calendar, where students can mark the day of the week that they're busiest, and the busier the class on a day, the darker shade the UI for the day will be. This way, the teacher can adjust his/her schedule to the schedule of the students, demonstrating that the teacher genuinely cares about the students' well being and giving the students a say in the class schedule. Another feature is a virtual classroom, where students can send texts to a classroom anonymously if they're in need of help. Both teachers and students can see these texts. Because of the anonymity, students can openly ask questions without fear of getting shamed by the rest of the class.
How I built it
We built this in the Xcode engine with the language swift. A large part of our project was created with the Firebase API, which acts as a remote server where we stored our data. The authentication, the virtual classroom, and the conflict calendar all used the realtime database in Firebase as a method of storing, retrieving, and writing data.
Challenges I ran into
As this was our second 24-hour hackathon, we were unprepared for the physical and mental toll it would take. Two of our members had headaches throughout the hackathon, and we didn't get much sleep. As a result, it was extremely difficult to stay on task and work efficiently even when we had very little energy. Moreover, we were conflicted about whether we would use a project we'd already started on or to create a new one. Several hours in, we decided to create a new project, meaning we'd have to start from scratch and putting us at a disadvantage compared to some competitors of ours.
Accomplishments that I'm proud of
We are all very proud of how diligently we worked today. We didn't let ourselves get distracted very often and we helped each other keep going. There were many periods of time where we ran into stupid errors and while it was tempting for us to give up, we powered. Moreover, we are very satisfied with our end result, considering we only had 24 hours to create it.
What I learned
We grew a lot this hackathon, as individuals and as a team. As individuals, we massively improved our proficiency with Swift and Firebase. As a team, we learned how to efficiently collaborate with each other and be open to each other's ideas. Moreover, we took a lot of time this hackathon to plan out our idea before we executed on it, making the coding process a lot smoother.
What's next for ClassroomConnections
We hope to expand on this by adding several new features and publishing it on the app store. After we polish our app, we plan to implement it into our own school, talking to the staff and offering our own teachers to incorporate the app into their own teaching.
Built With
cocoapods
firebase
swift
xcode
Try it out
GitHub Repo


interface
Inspiration
campis
What it does
fd
How we built it
df
Challenges we ran into
df
Accomplishments that we're proud of
df
What we learned
df
What's next for FasTask
df
Built With
figma
html5


this is a sheet where you write characters.
Inspiration
A common struggle in Mandarin class. We want to store our Chinese notes while also eliminating the laborious process of typing Chinese.
What it does
Given a picture of a Chinese character, our neural net model, built with TensorFlow, identifies the handwritten Chinese characters and creates a Unicode output representing the digital text version of the character.
How we built it
Our IDEs were Jupyter Notebook and VSCode. We built our neural net with Tensorflow and Keras, popular machine learning libraries, and Flask to connect our Python code to our website.
Challenges we ran into
The dataset was too huge and ended up using a lot of time to download, split, train, and test. This caused the project to be incomplete, as we only used a small fraction of available characters.
We also had trouble incorporating a clean front end API and ended up using the basics.
Accomplishments that we're proud of
We were able to create a robust neural net model in less than 4-5 hours.
What we learned
We learned to cut out unnecessary data from the set (who really memorizes 57k Chinese characters?). We also need to make sure our idea hasn't been done already (we used 5+ hours on something already done and had to scrap it).
What's next for Siknow
We entend to conduct more accuracy tests and build a cleaner front end.
Built With
bootstrap
css
flask
html
keras
os
pil
python
tensorflow
Try it out
GitHub Repo


Inspiration- Customer easiness
What it does Enriched- User experience
How I built it -Implementation support
Challenges I ran into placing controls to interface
Accomplishments that I'm proud of -easiness to customers
What I learned how to place -customer first!!
What's next for EzyAdmin Place holder for whole controls!! FFDC contribution
Built With
dotnetcore


Inspiration
I take a lot of video and voice journals, but never look back. Because I feel I can't change anything about them.
What it does
How I built it
tensorflow, react, node, keras, flask
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Voice Productivity Interface


Inspiration
The inspiration comes from dealing with anxiety personally. Some days can be hard and can be difficult to deal with but you have to search for ways to balance yourself and cope. It is important that you have someone to talk to in order to get you through those tough times.
What it does
Sereneti is your wellness assistant. Give her a text, a message on Facebook or talk to her on your smart speaker when you're feeling anxious or unwell.
How I built it
I built on Twilio Autopilot with custom Node.JS functions.
Challenges I ran into
Training the models to improve the NLU & CONNECTING THE BLOODY DNS SERVER FROM DOMAIN.com (like wut - why is this a problem)
Accomplishments that I'm proud of
I'm proud of building a product that gives the user a seamless experience that can help get you through tough times.
What I learned
Don't use custom javascript injections on squarespace if you don't want to spend hours on the support chat
What's next for Sereneti
Making it OMNI-CHANNEL (we will be active on sms, fb messenger, whataspp, google home, alexa, etc.) Building machine learning suggestion engines that can remember how you were feeling, what methods worked for you, and how we can make a smarter decision in the future in the most optimized way.
Built With
ai
javascript
natural-language-processing
node.js
Try it out
sereneti.space


CHECK OUT THE GIT REPO
Inspiration
As many other millennials, we want to work out and be fit, even when life gets really busy with classes, work, projects, and occasional hackathons. There are many options, such as running, working gym equipment machines, or group fitness classes. Yet, few are as effective as free weight exercises that engage multiple muscle groups, grow power, and are very efficient with regards to time spent working out. Sounds like a dream, doesn't it? Well, free weights also need to be performed in proper form. Otherwise, there are risks of not getting the effects of the exercise and getting injured. So do our knees bend properly? Would we snap our backs in the process? How can one monitor all the body parts that need to be kept in specific position all the time?
For that reason, free weights usually require a fitness trainer checking on your form and position. Constant trainer supervision is expensive and unrealistic, because we are all human and look away sometimes. An experienced fitness professional told us that even they seek a coach to overview their form during heavy lifting workouts. Furthermore, once one gets basics down, there is room for self-guided workouts and a reassured monitoring of proper performance. On the market, one can already buy a wearable device that tracks steps and running distance. So why not a free weights digital helper?
This weekend, we decided to face our confusion on the way to fitness. The world, meet Hans.
What it does
LiftHans is a digital trainer that relentlessly supports you during your free weights workouts. The first exercise we have rolled out to support in our app is the mighty yet dangerous unicorn of powerlifting: the deadlift. Hans helps a person perform deadlifts with a correct posture. It can be easily put on the back before the beginning of the exercise. A web app will guide you through the steps and offer a real-time monitor and guide to better posture during deadlifting. In your profile, you can review your overall performance and exercise statistics - in a gaming way!
Hans will benefit any person looking to be fit with the use of free weights. For beginners, it will be an easy and friendly partner as they work to get to the proper lifting form. Gym regulars will enjoy the supportive tracking options and an extra layer of performance statistics and monitoring on their way to more challenging weights or new exercises. So far on the market there are very few wearable devices that focus on such level of performance, learning, and health.
This device will be mostly bought by gyms and health centers that will rent it to their clients upon visit.
How I built it
The first step was to integrate the Arduino Uno with the provided sensors and bluetooth module and make everything run together smoothly. Then, we built a cool webapp with Javascript, NodeJS and React which is used to display everything nicely in one place. The bluetooth is connected to one of our laptops which records the measurements and provides and API for the web app. This way, the data can be accessed from other places as well, such as your mobile or tablet.
Challenges I ran into
To understand, how we can measure and correct the back posture, we had to consult a fitness coach to see what professionals usually look for and how we could translate it into sensor readings. Furthermore, it was quite nasty to figure out the proper calibrations for the bluetooth model and the accelerometer.
Accomplishments that I'm proud of
We have had comfortable and efficient task distribution among members thanks to our well-balanced team.
What I learned
We all did what we were better at and pushed ourselves to learn and practice what we did not that well.
What's next for LiftHans
LiftHans is a promising idea.
Built With
arduino
javascript
node.js
python
react
Try it out
prezi.com
GitHub Repo


Webscraper logo
Inspiration
Our inspiration comes from the summer internship at a bank. Wherein we observed the challenges faced by employees at banks to manually check for the news and track down the activities of their clients.
What it does
Our webscrapper, has a wide range of implementations. One of which is, it can helps financial institutions, government, investors help track of the people involved in money laundering, terror financing and other illegal activities. Further, companies and instituitions could use this algorithm for marketing effectively especially by tracking and understanding consumer behavioral change over time and according to the places and culture. Through this algorithm, the investors could stay on top of the news for the companies in which they are interested in, to help them stay updated with the company and improve their research effectiveness.Our webscraper scrapes data of news websites , uses an NLTK filter to filter out key words and compares the names occurring in the articles with the user database of the bank (made using MongoDB)
How I built it
We used a NewsAPI which helps us to fetch the news articles from a wide range of sources. Once we get the articles in our platform, we then filter the article to remove the noise and extract the relevant information through the use of NLTK library in python. In order to track down Money laundering and other related relevant fields, we compare the relevant information extracted from the article (such as Name of the person involved, in this case) and verify and update it in our MongoDB database to help banks and institutions keep track of it.
Challenges I ran into
-setting up a newsAPI -using NLTK to filter out Names -Building up a MongoDB database -establishing a connection between the MongoDB and python scraper
Accomplishments that I'm proud of

We are proud of accomplishing a web scraper which simplifies the process of tracking clients and increases efficiency while reducing the time taken as compared to the manual employee. Our biggest accomplishment is figuring out the APIs and using them effectively in order to create our service. We are very proud of having set up the MongoDB and synced it with our code.
What I learned
We learnt how to pull API's and get request with the API We also got a chance to use The NLTK library in python and filter out the important keywords getting rid of the noise and other junk We learnt how to work in a team with the maximum efficiency dividing the work load and coming up with real life simple solutions to practical problems
Interested in learning more about our project: Visit our GitHub page https://github.com/Mujtaba521/WebScraper
Built With
api
mongodb
python


expand your mind
Inspiration
What it does
How I built it
I used node and google cloud
Challenges I ran into
Implementing continuous audio recording and transmission from server
Accomplishments that I'm proud of
What I learned
What's next for Memory.io
Built With
javascript
mongodb
node.js


Inspiration
We took quite some time brainstorming about different platforms that up and coming. All of us shared a similar experience of how annoying it is to go through the trouble of reaching out to the dj at a party to play a particular song. We realized that the majority of music streaming users use Spotify which has a great API to use.
What it does
Our app auths into spotify using their SDK for iOS and enables a user to create a hosting session where other users can join. They can then add songs to a queue which in turn automatically creates a playlist for the hosting user. This way the host/dj can accept/deny song requests from users connected to his/her hosting session, making listening to music much more seamless and fun for everyone.
How we built it
We used Swift and Xcode to create an iOS app while using Google Cloud and Firestore for the backend. We used Spotify's API to create tokens and authentications for users as well as third party API's to automatically create playlists within a user's Spotify account. We used logo design maker and Xcode's storyboard to create the front-end
Challenges we ran into
It was difficult to create a peer to peer networking eco-system within the app as none of us had ever done it before. Furthermore, understanding and setting up Spotify's API was also a challenge when getting token's for user sessions.
Accomplishments that we're proud of
We're proud to have a working build where most of the functionalities we envisioned came to life. We were able to create elegant UI with decent functionality.
What we learned
We learned that since Spotify has a such a big advantage being a tech giant in the music industry there arent many API's functionalities that can help other user's make music related products that can level up to the scale that Spotify has accomplished.
What's next for WhatzNext
Built With
alamofire
avfoundation
firebase
google-cloud
ios
spotifyapi
swift
Try it out
GitHub Repo


Introduction
EliOS is a system for understanding, predicting, and collaborating to treat mood disorders.
Through brain scanning, mood tracking, and artificial intelligence, EliOS has the power to change what it means to have a mood disorders.
The system was built for (and named after) our wonderful friend Eli Scott. Eli is a student of Cognitive Science and has Bipolar disorder.
The idea of EliOS was born in a conversation about the role of technology in mental health. We realized that the systems that, at times, make social media like Facebook and Instagram invasive and manipulative could be turned around and used to understand and help people with their mood disorders.
There is also a compelling business case here: None of the mood tracker apps on the market actually helped Eli manage her condition. They didn't visualize the trends in her mood very effectively, let alone make predictions or recommendations. Furthermore, none of the apps had any way to make the process of building and reaching out to a support network any easier.
It also just so happens that the team had an interest in Neurotech, so we brought along a Muse EEG scanner. Why not incorporate brain scanning into the system to further optimize our predictions?
Goals:
To make sure we met the needs of our stakeholders, we conducted a psychological & neurological literature review and a user consultation meeting. Our overall design goals were as follows:
Make a better data entry system.
Visualization data in insightful, interesting ways.
Make useful predictions.
Enable technology-assisted peer support system.
How It Works
User Experience
We spent a lot of time planning exactly how we would implement the idea because we knew user experience is central to the success of the product.
Important: Cross-platform:
Highly efficient UI you can tap through with ease
Automate as much as possible:
Minimalist design with clear, concise visualizations.
Make the process of getting help from support network as easy as possible
Tools
To accomplish the goal of creating an artificially intelligent system for mood tracking, brain scan analysis, and support system management, we used a lot of tools.
We decided to try Vue for the first time for our multi-platform web-app.
Vuex for state management
Vue-Charts for data visualization
We used Google's FireBase for our database, authentication, storage, and hosting, and NumPy, Pandas, and Pytorch for our signal analysis and ML.
Plenty of Jupyter Notebooks for testing out ML and signal analysis ideas, too.
We were also inspired to use Standard Library's text API to create the support system.
It can be very difficult to reach out for help when you have a mood disorder, so removing friction is fundamental.
Standard LIbrary's API helped us make it easier to reach out for those who use EliOS, and they made it easier for us to use awesome API's efficiently and effectively.
What We've Learned
Over the course of this project we picked up many new skills. Coming in, we had no experience with the Vue platform on which our application would be based, nor did we have experience interfacing brain scan data with the web at all. This posed many of its own challenging, from structural constraints to changing in the way that we develop.
We also encountered many challenges in the back-end working on the Machine Learning. Starting with the Digital Signal Processing of the EEG, we developed the new skills required to analyze brain wave data. We could then apply these skills to the Google Cloud, posting our machine learning server to be accessible by our application at a moment's notice.
Next Steps
Next steps for our project include: 1) A live data capture for EEG data within the application, 2) Deepening the learning models we use to predict mood swings as we gather more data 3) Integrating common smart technology data to get more info about the people we want to support. 4) Integrate Google Calendar so that the system can react to life events in real-time.
Built With
batchfile
css
eeg
html
javascript
jupyter-notebook
machine-learning
python
vue
Try it out
GitHub Repo


Inspiration
We we inspired to build Exstrahlen because of the long wait times in hospitals. From the personal experience of one of our teammates, who recently underwent a surgery, long hospital waiting times have become standard, and we're trying to change that.
What it does
Our whole idea was to have an idea that indirectly improves wait time. We found that scans take a lot of time to analyze and must be done thousands of times per day. Thus, we wanted to answer the following questions. How can we make the work of radiologists faster, and how do we improve the wait times for patients?
Utilizing our algorithm lets radiologists immediately jump to key patterns in a scan, saving them 30 seconds to a minute. That kind of efficiency gain is massive when multiplied over the 5000 scans that a radiologist may see each day. Improving this turnaround time means that patients can receive the care they need more quickly and can improve the quality of treatment
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Exstrahlen
Built With
gcp
javascript
machine-learning
node.js
vue
Try it out
GitHub Repo


Inspiration
When being active as a musician, I had deaf people coming to my concerts. They told me afterwards that the enjoyed the music, despite not being able to hear it. They sensed it by feeling the vibration of the room, and by seeing the emotions of the musicians. Knowing, that deaf people can and want to enjoy music, we started developing a rythm game to help them enjoy rythm, a critical element of music. train feeling for rhythm with ease, fun and on the go
What it does
The game demands to feel the rythm, while concentrating on evading wolves at the same time. Haptic feedback in form of vibration helps the user to better understand and feel the rythm. The resulting game is training the rythm sense while being fun, it's portable and easy to use.
How we built it
Using Unity and C# for the game we build the game from scratch, using only self made pixel art with Piskel.
What we learned
We learned to concentrate on the core of a project, keeping it as simple as possible and polishing afterwards with the time won, achieving a greater goal than when aiming for too much.
What's next for Little Red Riding Hoods 6th Sense
Maybe use concept for a bachelorthesis.
Built With
c#
unity
Try it out
GitHub Repo


Our logo
In researching this project, we became aware of the massive food waste problem. 58% of food produced goes to waste, valued at $49 billion. Meanwhile, over 4 million Canadians are food insecure, struggling to put food on the table.
We decided to address this problem by creating a mobile platform similar to Kijiji for food. Users can post offers or requests, which include multiple food items and their respective quantities. They can browse on the home screen by most recently posted as well as on the explore map to find the nearest available offers or requests.
In the future, we want to establish a way for larger organizations to use the service where big quantities of offered food can be distributed easily to a homeless shelter or food bank. Long-term, Faste is easy to scale since the main component of the app that would grow is the MongoDB Atlas database, which can be expanded by buying more cloud storage.
The app was built using React Native for the front-end making it easily available on iOS and Android. Google's material UI was used for styling components to provide a familiar user experience to the common user. The backend was built on Node.js using the Adonis.js framework. This backend server was hosted on Linux Centos ensuring robust security for the app. The app's database was hosted on MongoDB atlas using Google Cloud underneath.
Built With
adonis
axios
centos
expo.io
express.js
mongodb
node.js
react
react-native
redux
Try it out
GitHub Repo


Inspiration

We were very inspired by Trump
What it does
How I built it

General AI with a bit of 1C programming
Challenges I ran into

PowerPoint
Accomplishments that I'm proud of

Install PowerPoint
What I learned

Platypus doesn't have nipples, but it's a mammal
What's next for Comment-to-Go

Odnoklassniki release
Built With
love
Try it out
GitHub Repo
GitHub Repo
docs.google.com


Inspiration
What it does
Our machine learning model is built into a simple website. Anyone can go to the website to record or upload an audio file. The audio file is transcribed to text and it is run through a model trained on thousands of Wikipedia articles to the topic of conversation. The text is evaluated to determine the topics and label areas of interest. We will soon expand to use a more complete dataset with more topics that have been robustly trained.
How we built it
The core of our model is built in Python using Flask. We used the Google Speech to Text API to transcribe the data and the NLTK library for the natural language processing functionality to analyze the text. We trained a Latent Dirichlet Allocation model on the English Wikipedia Articles 2017-08-20 Models dataset for classification. The model was trained using gensim. Our website is built in React and have integrated the machine learning model into an API to connect it to the website.
Challenges we ran into
We ran into some difficulties in training our model initially, as our dataset was over 17GB and therefore would take days to process. By using a smaller dataset and the accuracy was lower than we expected and with the time constraints we weren't able to take as many passes to train the model as we had hoped.
Accomplishments that we're proud of
We are proud to have figured out how to successfully train a model despite no team members having prior experience in machine learning.
What we learned
We greatly expanded our knowledge of machine learning, natural language processing, and web development.
What's next for discussion
Our number one goal is to provide more accuracy in determining topics. We want to develop a more robust model with the larger dataset to improve our accuracy.
More about our team:
Meghan Lo: https://www.linkedin.com/in/meghan-lo-ab39b214b
Matthew Chiang http://matthew-chiang.com/
Built With
flask
gensim
google-web-speech-api
nltk
python
react
Try it out
GitHub Repo


Inspiration
Having smart home makes you lazy - very lazy. Zzzzzzz helps you solve that (by being even more lazy)
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Zzzzzzzzzzzzzzzzzzzzzzz
Built With
amazon-alexa


An example conversation using Twilio API of someone who is interested in the service.
Inspiration
Waste management is an often overlooked and underappreciated yet vital part of a city’s operations. There is relatively little innovation in the waste management industry, so we aim to change that by suggesting ways to improve efficiency and cost-effectiveness of existing programs.
What it does
Our goal is to make disposal of non-standard waste (e.g. oversize trash such as old couches or refrigerators) more efficient. We integrated London’s open source data into our maps to categorize sections of the city into zones. This categorization will optimize waste collected per distance travelled by trash collection agencies, increasing fuel efficiency and reducing operating costs. We are using Twilio to facilitate communication between our clients’ mobile devices and trash collection agencies to make it convenient for people to request waste pickup as needed. Clients can contact our service and the automatic response system will determine what kind of waste is being collected and notify residents of the time of the next scheduled pickup. When the number of residents in each zone that need waste pickup reaches a threshold level, the city can send collectors to retrieve the waste.
How I built it
We used the Twilio API to program an infrastructure that allows clients to use SMS messaging to contact a waste collection service. The system automatically keeps track of the number of residents in each zone that need non-standard waste pickup. These zones were taken from the City of London Open Data website. When the number of waste pickup requests reaches a threshold level, the waste collectors can go pick up several neighborhoods’ worth of waste.
Challenges I ran into
We ran into challenges integrating a counter into our program to keep track of the number of residents that need non-standard waste pickup. Meeting a specified threshold of residents should lead to the automatic text message sent to the residents in the zone to notify them that a truck will be sent out to their neighborhood on a specified date. Integrating the Twilio with the map algorithm was hard.
Accomplishments that I'm proud of
Learning to use all the tools was very rewarding when it came together. It was also really rewarding to work as a team and troubleshooting all the code was a good challenge.
What I learned
We learned how to use Python to program Twilio for SMS messaging, how to use the Open Portal Data of London, GeoSpatial libraries, and algorithms to find the shortest most efficient path.
What's next for EnviroPickup
This could potentially expand to include garbage route optimization to determine the most fuel efficient path for pickup. We could also integrate a chatbot that can respond to all different sorts of inquiries so that the program is not limited to yes/no questions and preprogrammed waste categories.
Built With
python
twilio
Try it out
GitHub Repo


Inspiration
Recent breakthroughs in Artificial Intelligence, particularly object detection and image classification, and the proliferation of mobile technology at cheaper and cheaper prices open lots of exciting possibilities to improve the daily lives of disabled people. Inspired by the rapid advancements in computer vision and the omnipresence of mobile phones in our daily lives, we were wondering how the small yet incredibly powerful device we use every day could improve the lives of disabled people. In our brainstorming process, the range of possible applications we could think of turned out to be extremely vast, but because of the extremely tight time constraints of a 36-hour hackathon we chose to limit our efforts to developing an application that could help blind people navigate around the world.
What it does
AEyes uses the mobile camera to continuously take images, compress them and send them to a neural network for object detection that runs in the cloud. The neural network returns the objects detected in the given image, and sends them back to the phone. The phone then uses a text-to-speech system to read out the objects detected. Another feature is fEyend: hold the touchscreen of your phone and say what you are looking for. Your phone will then tell you to keep moving around the room until it finds the object you’re looking for.
How we built it
In order to be able to run our application on both iOS and Android without having to write code in both Swift and Kotlin, we wrote our application in React Native. While we originally planned to use Azure, we ended up going with AWS Rekognition to detect the objects because its performance on our test data was significantly better. After we finished our idea, every member of our team worked on a different part of the app: using the AWS APIs to upload the images and extract information from them, continuously taking pictures and compressing them in real time and building the user interface.
Challenges we ran into
The time we had to develop our app was very limited. Some of the technologies we tried did not have sufficient accuracy or speed to be used for our application. For example, the latency on the Azure neural text-to-speech APIs was too high, so we ended up using the native alternative that runs instantly but doesn’t sound as natural. Another problem was that the Azure SDKs are not optimized for React Native, so we ran into lots of problems and eventually decided to go with simple POST requests using a standard library for REST API calls.
Accomplishments that we're proud of
We were able to develop our first functioning prototype within 8 hours. This was a big relief because many parts of the development process were plagued by errors and we often had to adapt our plans to limitations we were not aware of before and did not have enough time to address.
What we learned
It is best to initially limit your idea to a narrow domain after the brainstorming session and ship an MVP. Additional features can be added later.
What's next for AEyes
AEyes does not have to be the only feature of the app: It would be very well possible for it to be part of a more generalized application that leverages the power of mobile and cloud computing to help people with all kinds of disabilities. After starting the application, the user could select the disability they cope with with, which would make available a specific set of tools tailored exactly to their needs. Some of these tools could include: location tracking and detection of unusual patterns in daily routines of people with Alzheimer’s disease, verification of faces or voices (e.g. whether a person is a relative or someone trying to scam you out of your savings) for people with dementia and a voice recognition service running in the background that calls/texts a list of relatives if it recognizes sentences asking for help. The societal impact of such an application would be unparalleled and the scope of future improvements is nearly limitless taking into account the continuously evolving capabilities of AI, increasing data transfer rates provided by 5G and thus further the shift in computational limits away from the small handheld device we all possess to gargantuan data centers. This is why we would be incredibly grateful if you support our idea. Thank you for your attention.
Built With
aws-rekognition
azure-cognitive-services
javascript
react-native


Inspiration
There are multiple challenges that come along with immigrating to a new country. Along with being in an entirely different culture, the top problems that immigrants face include the language barrier, access to services, isolation, as the confusing bureaucracy.
What it does
Step One's mission is to make the experience of immigration easier and a more smooth transition for new coming immigrants in providing an easy to use interface for users. With the use of the Amazon Echo, Step One aids immigrants to keep track of all the tasks that they need to complete on their immigration journey, while providing important tips and nice-to-knows along the way. Step One is offered in multiple languages
How we built it
Firebase back end,
Amazon Echo integration,
React front end
Whats next for Step One
Expanding our application to include the functionality to connect people going through the same process to form community
Built With
alexa
amazon-web-services
css
firebase
html
javascript
react
Try it out
GitHub Repo


Helping amateur athletes learn from their Heroes
Whether your an amateur looking to become like your Idol or a professional athlete, we at anymotion will help you become better at your chosen discipline.
What we learned?
How to work on the full stack from Azure over Application to Hardware.
How did we make it?
With determination and not enough sleep.
Components
Posenet estimator for expert motion provided in flask api
Arduino acceleration sensor code
Flutter mobile app
Posenet
Posenet is implemented with detecron2 from facebook. Given a reference motion from a video, a target trajectory is generated.
Flask API
Hosted on Azure VM.
GET
/ Provides generated angle timeline of expert motion
/video Provides video of pose estimation
/angles Precomputed angles for demonstration
Arduino
Basic data pipeline using a kalman filter for state estimation.
Sensors
Sen-MPU6050 Gyroscope & Accelerometer Module
HC-05 Bluetooth Module
Flutter
State based prototype app for android and iOS. The app provides multiple exercise, animated in real time @60fps to compare.
Available exercises:
Weightlifting
Bizep curl
Entry point for all connections regarding bluetooth and webservices. © 2019 - anymotion team - All Rights Reserved
Built With
arduino
python


Node.js is a JavaScript runtime built on Chrome's V8 JavaScript engine. For more information on using Node.js, see the Node.js Website.
The Node.js project uses an open governance model. The OpenJS Foundation provides support for the project.
This project is bound by a Code of Conduct.
Table of Contents
Support
Release Types
Download
Current and LTS Releases
Nightly Releases
API Documentation
Verifying Binaries
Building Node.js
Security
Contributing to Node.js
Current Project Team Members
TSC (Technical Steering Committee)
Collaborators
Release Keys
Support
Looking for help? Check out the instructions for getting support.
Release Types
Current: Under active development. Code for the Current release is in the branch for its major version number (for example, v10.x). Node.js releases a new major version every 6 months, allowing for breaking changes. This happens in April and October every year. Releases appearing each October have a support life of 8 months. Releases appearing each April convert to LTS (see below) each October.
LTS: Releases that receive Long-term Support, with a focus on stability and security. Every even-numbered major version will become an LTS release. LTS releases receive 18 months of Active LTS support and a further 12 months of Maintenance. LTS release lines have alphabetically-ordered codenames, beginning with v4 Argon. There are no breaking changes or feature additions, except in some special circumstances.
Nightly: Code from the Current branch built every 24-hours when there are changes. Use with caution.
Current and LTS releases follow Semantic Versioning. A member of the Release Team signs each Current and LTS release. For more information, see the Release README.
Download
Binaries, installers, and source tarballs are available at https://nodejs.org/en/download/.
CURRENT AND LTS RELEASES
https://nodejs.org/download/release/
The latest directory is an alias for the latest Current release. The latest-codename directory is an alias for the latest release from an LTS line. For example, the latest-carbon directory contains the latest Carbon (Node.js 8) release.
NIGHTLY RELEASES
https://nodejs.org/download/nightly/
Each directory name and filename contains a date (in UTC time) and the commit SHA at the HEAD of the release.
API DOCUMENTATION
Documentation for the latest Current release is at https://nodejs.org/api/. Version-specific documentation is available in each release directory in the docs subdirectory. Version-specific documentation is also at https://nodejs.org/download/docs/.
Verifying Binaries
Download directories contain a SHASUMS256.txt file with SHA checksums for the files.
To download SHASUMS256.txt using curl:
$ curl -O https://nodejs.org/dist/vx.y.z/SHASUMS256.txt
To check that a downloaded file matches the checksum, run it through sha256sum with a command such as:
$ grep node-vx.y.z.tar.gz SHASUMS256.txt | sha256sum -c -
For Current and LTS, the GPG detached signature of SHASUMS256.txt is in SHASUMS256.txt.sig. You can use it with gpg to verify the integrity of SHASUM256.txt. You will first need to import the GPG keys of individuals authorized to create releases. To import the keys:
$ gpg --keyserver pool.sks-keyservers.net --recv-keys DD8F2338BAE7501E3DD5AC78C273792F7D83545D
See the bottom of this README for a full script to import active release keys.
Next, download the SHASUMS256.txt.sig for the release:
$ curl -O https://nodejs.org/dist/vx.y.z/SHASUMS256.txt.sig
Then use gpg --verify SHASUMS256.txt.sig SHASUMS256.txt to verify the file's signature.
Building Node.js
See BUILDING.md for instructions on how to build Node.js from source and a list of supported platforms.
Security
For information on reporting security vulnerabilities in Node.js, see SECURITY.md.
Contributing to Node.js
Contributing to the project
Working Groups
Strategic Initiatives
Current Project Team Members
For information about the governance of the Node.js project, see GOVERNANCE.md.
TSC (Technical Steering Committee)
addaleax - Anna Henningsen <anna@addaleax.net> (she/her)
apapirovski - Anatoli Papirovski <apapirovski@mac.com> (he/him)
ChALkeR - Сковорода Никита Андреевич <chalkerx@gmail.com> (he/him)
cjihrig - Colin Ihrig <cjihrig@gmail.com> (he/him)
danbev - Daniel Bevenius <daniel.bevenius@gmail.com> (he/him)
fhinkel - Franziska Hinkelmann <franziska.hinkelmann@gmail.com> (she/her)
Fishrock123 - Jeremiah Senkpiel <fishrock123@rocketmail.com>
gabrielschulhof - Gabriel Schulhof <gabriel.schulhof@intel.com>
gireeshpunathil - Gireesh Punathil <gpunathi@in.ibm.com> (he/him)
jasnell - James M Snell <jasnell@gmail.com> (he/him)
joyeecheung - Joyee Cheung <joyeec9h3@gmail.com> (she/her)
mcollina - Matteo Collina <matteo.collina@gmail.com> (he/him)
mhdawson - Michael Dawson <michael_dawson@ca.ibm.com> (he/him)
MylesBorins - Myles Borins <myles.borins@gmail.com> (he/him)
sam-github - Sam Roberts <vieuxtech@gmail.com>
targos - Michaël Zasso <targos@protonmail.com> (he/him)
thefourtheye - Sakthipriyan Vairamani <thechargingvolcano@gmail.com> (he/him)
Trott - Rich Trott <rtrott@gmail.com> (he/him)
TSC Emeriti
bnoordhuis - Ben Noordhuis <info@bnoordhuis.nl>
chrisdickinson - Chris Dickinson <christopher.s.dickinson@gmail.com>
evanlucas - Evan Lucas <evanlucas@me.com> (he/him)
gibfahn - Gibson Fahnestock <gibfahn@gmail.com> (he/him)
indutny - Fedor Indutny <fedor.indutny@gmail.com>
isaacs - Isaac Z. Schlueter <i@izs.me>
joshgav - Josh Gavant <josh.gavant@outlook.com>
mscdex - Brian White <mscdex@mscdex.net>
nebrius - Bryan Hughes <bryan@nebri.us>
ofrobots - Ali Ijaz Sheikh <ofrobots@google.com> (he/him)
orangemocha - Alexis Campailla <orangemocha@nodejs.org>
piscisaureus - Bert Belder <bertbelder@gmail.com>
rvagg - Rod Vagg <r@va.gg>
shigeki - Shigeki Ohtsu <ohtsu@ohtsu.org> (he/him)
TimothyGu - Tiancheng "Timothy" Gu <timothygu99@gmail.com> (he/him)
trevnorris - Trevor Norris <trev.norris@gmail.com>
Collaborators
addaleax - Anna Henningsen <anna@addaleax.net> (she/her)
ak239 - Aleksei Koziatinskii <ak239spb@gmail.com>
AndreasMadsen - Andreas Madsen <amwebdk@gmail.com> (he/him)
antsmartian - Anto Aravinth <anto.aravinth.cse@gmail.com> (he/him)
apapirovski - Anatoli Papirovski <apapirovski@mac.com> (he/him)
aqrln - Alexey Orlenko <eaglexrlnk@gmail.com> (he/him)
bcoe - Ben Coe <bencoe@gmail.com> (he/him)
bengl - Bryan English <bryan@bryanenglish.com> (he/him)
benjamingr - Benjamin Gruenbaum <benjamingr@gmail.com>
BethGriggs - Beth Griggs <Bethany.Griggs@uk.ibm.com> (she/her)
bmeck - Bradley Farias <bradley.meck@gmail.com>
bmeurer - Benedikt Meurer <benedikt.meurer@gmail.com>
bnoordhuis - Ben Noordhuis <info@bnoordhuis.nl>
boneskull - Christopher Hiller <boneskull@boneskull.com> (he/him)
brendanashworth - Brendan Ashworth <brendan.ashworth@me.com>
BridgeAR - Ruben Bridgewater <ruben@bridgewater.de> (he/him)
bzoz - Bartosz Sosnowski <bartosz@janeasystems.com>
calvinmetcalf - Calvin Metcalf <calvin.metcalf@gmail.com>
cclauss - Christian Clauss <cclauss@me.com> (he/him)
ChALkeR - Сковорода Никита Андреевич <chalkerx@gmail.com> (he/him)
cjihrig - Colin Ihrig <cjihrig@gmail.com> (he/him)
claudiorodriguez - Claudio Rodriguez <cjrodr@yahoo.com>
codebytere - Shelley Vohr <codebytere@gmail.com> (she/her)
danbev - Daniel Bevenius <daniel.bevenius@gmail.com> (he/him)
DavidCai1993 - David Cai <davidcai1993@yahoo.com> (he/him)
davisjam - Jamie Davis <davisjam@vt.edu> (he/him)
devsnek - Gus Caplan <me@gus.host> (he/him)
digitalinfinity - Hitesh Kanwathirtha <digitalinfinity@gmail.com> (he/him)
edsadr - Adrian Estrada <edsadr@gmail.com> (he/him)
eljefedelrodeodeljefe - Robert Jefe Lindstaedt <robert.lindstaedt@gmail.com>
eugeneo - Eugene Ostroukhov <eostroukhov@google.com>
evanlucas - Evan Lucas <evanlucas@me.com> (he/him)
fhinkel - Franziska Hinkelmann <franziska.hinkelmann@gmail.com> (she/her)
Fishrock123 - Jeremiah Senkpiel <fishrock123@rocketmail.com>
gabrielschulhof - Gabriel Schulhof <gabriel.schulhof@intel.com>
gdams - George Adams <george.adams@uk.ibm.com> (he/him)
geek - Wyatt Preul <wpreul@gmail.com>
gengjiawen - Jiawen Geng <technicalcute@gmail.com>
gibfahn - Gibson Fahnestock <gibfahn@gmail.com> (he/him)
gireeshpunathil - Gireesh Punathil <gpunathi@in.ibm.com> (he/him)
guybedford - Guy Bedford <guybedford@gmail.com> (he/him)
hashseed - Yang Guo <yangguo@chromium.org> (he/him)
hiroppy - Yuta Hiroto <hello@hiroppy.me> (he/him)
iarna - Rebecca Turner <me@re-becca.org>
imyller - Ilkka Myller <ilkka.myller@nodefield.com>
indutny - Fedor Indutny <fedor.indutny@gmail.com>
italoacasas - Italo A. Casas <me@italoacasas.com> (he/him)
JacksonTian - Jackson Tian <shyvo1987@gmail.com>
jasnell - James M Snell <jasnell@gmail.com> (he/him)
jasongin - Jason Ginchereau <jasongin@microsoft.com>
jbergstroem - Johan Bergström <bugs@bergstroem.nu>
jdalton - John-David Dalton <john.david.dalton@gmail.com>
jkrems - Jan Krems <jan.krems@gmail.com> (he/him)
joaocgreis - João Reis <reis@janeasystems.com>
joshgav - Josh Gavant <josh.gavant@outlook.com>
joyeecheung - Joyee Cheung <joyeec9h3@gmail.com> (she/her)
julianduque - Julian Duque <julianduquej@gmail.com> (he/him)
JungMinu - Minwoo Jung <minwoo@nodesource.com> (he/him)
kfarnung - Kyle Farnung <kfarnung@microsoft.com> (he/him)
kunalspathak - Kunal Pathak <kunal.pathak@microsoft.com>
lance - Lance Ball <lball@redhat.com> (he/him)
Leko - Shingo Inoue <leko.noor@gmail.com> (he/him)
lpinca - Luigi Pinca <luigipinca@gmail.com> (he/him)
lucamaraschi - Luca Maraschi <luca.maraschi@gmail.com> (he/him)
lundibundi - Denys Otrishko <shishugi@gmail.com> (he/him)
maclover7 - Jon Moss <me@jonathanmoss.me> (he/him)
mafintosh Mathias Buus <mathiasbuus@gmail.com> (he/him)
mcollina - Matteo Collina <matteo.collina@gmail.com> (he/him)
mhdawson - Michael Dawson <michael_dawson@ca.ibm.com> (he/him)
misterdjules - Julien Gilli <jgilli@nodejs.org>
mmarchini - Matheus Marchini <mat@mmarchini.me>
MoonBall - Chen Gang <gangc.cxy@foxmail.com>
mscdex - Brian White <mscdex@mscdex.net>
MylesBorins - Myles Borins <myles.borins@gmail.com> (he/him)
not-an-aardvark - Teddy Katz <teddy.katz@gmail.com> (he/him)
ofrobots - Ali Ijaz Sheikh <ofrobots@google.com> (he/him)
oyyd - Ouyang Yadong <oyydoibh@gmail.com> (he/him)
princejwesley - Prince John Wesley <princejohnwesley@gmail.com>
psmarshall - Peter Marshall <petermarshall@chromium.org> (he/him)
Qard - Stephen Belanger <admin@stephenbelanger.com> (he/him)
refack - Refael Ackermann (רפאל פלחי) <refack@gmail.com> (he/him/הוא/אתה)
richardlau - Richard Lau <riclau@uk.ibm.com>
ronkorving - Ron Korving <ron@ronkorving.nl>
RReverser - Ingvar Stepanyan <me@rreverser.com>
rubys - Sam Ruby <rubys@intertwingly.net>
rvagg - Rod Vagg <rod@vagg.org>
ryzokuken - Ujjwal Sharma <usharma1998@gmail.com> (he/him)
saghul - Saúl Ibarra Corretgé <saghul@gmail.com>
sam-github - Sam Roberts <vieuxtech@gmail.com>
santigimeno - Santiago Gimeno <santiago.gimeno@gmail.com>
sebdeckers - Sebastiaan Deckers <sebdeckers83@gmail.com>
seishun - Nikolai Vavilov <vvnicholas@gmail.com>
shigeki - Shigeki Ohtsu <ohtsu@ohtsu.org> (he/him)
shisama - Masashi Hirano <shisama07@gmail.com> (he/him)
silverwind - Roman Reiss <me@silverwind.io>
srl295 - Steven R Loomis <srloomis@us.ibm.com>
starkwang - Weijia Wang <starkwang@126.com>
targos - Michaël Zasso <targos@protonmail.com> (he/him)
thefourtheye - Sakthipriyan Vairamani <thechargingvolcano@gmail.com> (he/him)
thekemkid - Glen Keane <glenkeane.94@gmail.com> (he/him)
thlorenz - Thorsten Lorenz <thlorenz@gmx.de>
TimothyGu - Tiancheng "Timothy" Gu <timothygu99@gmail.com> (he/him)
tniessen - Tobias Nießen <tniessen@tnie.de>
trevnorris - Trevor Norris <trev.norris@gmail.com>
trivikr - Trivikram Kamat <trivikr.dev@gmail.com>
Trott - Rich Trott <rtrott@gmail.com> (he/him)
vdeturckheim - Vladimir de Turckheim <vlad2t@hotmail.com> (he/him)
vkurchatkin - Vladimir Kurchatkin <vladimir.kurchatkin@gmail.com>
watilde - Daijiro Wachi <daijiro.wachi@gmail.com> (he/him)
watson - Thomas Watson <w@tson.dk>
XadillaX - Khaidi Chu <i@2333.moe> (he/him)
yhwang - Yihong Wang <yh.wang@ibm.com>
yorkie - Yorkie Liu <yorkiefixer@gmail.com>
yosuke-furukawa - Yosuke Furukawa <yosuke.furukawa@gmail.com>
ZYSzys - Yongsheng Zhang <zyszys98@gmail.com> (he/him)
Collaborator Emeriti
andrasq - Andras <andras@kinvey.com>
AnnaMag - Anna M. Kedzierska <anna.m.kedzierska@gmail.com>
estliberitas - Alexander Makarenko <estliberitas@gmail.com>
chrisdickinson - Chris Dickinson <christopher.s.dickinson@gmail.com>
firedfox - Daniel Wang <wangyang0123@gmail.com>
imran-iq - Imran Iqbal <imran@imraniqbal.org>
isaacs - Isaac Z. Schlueter <i@izs.me>
jhamhader - Yuval Brik <yuval@brik.org.il>
lxe - Aleksey Smolenchuk <lxe@lxe.co>
matthewloring - Matthew Loring <mattloring@google.com>
micnic - Nicu Micleușanu <micnic90@gmail.com> (he/him)
mikeal - Mikeal Rogers <mikeal.rogers@gmail.com>
monsanto - Christopher Monsanto <chris@monsan.to>
Olegas - Oleg Elifantiev <oleg@elifantiev.ru>
orangemocha - Alexis Campailla <orangemocha@nodejs.org>
othiym23 - Forrest L Norvell <ogd@aoaioxxysz.net> (he/him)
petkaantonov - Petka Antonov <petka_antonov@hotmail.com>
phillipj - Phillip Johnsen <johphi@gmail.com>
piscisaureus - Bert Belder <bertbelder@gmail.com>
pmq20 - Minqi Pan <pmq2001@gmail.com>
rlidwka - Alex Kocharin <alex@kocharin.ru>
rmg - Ryan Graham <r.m.graham@gmail.com>
robertkowalski - Robert Kowalski <rok@kowalski.gd>
romankl - Roman Klauke <romaaan.git@gmail.com>
stefanmb - Stefan Budeanu <stefan@budeanu.com>
tellnes - Christian Tellnes <christian@tellnes.no>
tunniclm - Mike Tunnicliffe <m.j.tunnicliffe@gmail.com>
vsemozhetbyt - Vse Mozhet Byt <vsemozhetbyt@gmail.com> (he/him)
whitlockjc - Jeremy Whitlock <jwhitlock@apache.org>
Collaborators follow the COLLABORATOR_GUIDE.md in maintaining the Node.js project.
Release Keys
GPG keys used to sign Node.js releases:
Beth Griggs <bethany.griggs@uk.ibm.com> 4ED778F539E3634C779C87C6D7062848A1AB005C
Colin Ihrig <cjihrig@gmail.com> 94AE36675C464D64BAFA68DD7434390BDBE9B9C5
Evan Lucas <evanlucas@me.com> B9AE9905FFD7803F25714661B63B535A4C206CA9
Gibson Fahnestock <gibfahn@gmail.com> 77984A986EBC2AA786BC0F66B01FBB92821C587A
James M Snell <jasnell@keybase.io> 71DCFD284A79C3B38668286BC97EC7A07EDE3FC1
Jeremiah Senkpiel <fishrock@keybase.io> FD3A5288F042B6850C66B31F09FE44734EB7990E
Michaël Zasso <targos@protonmail.com> 8FCCA13FEF1D0C2E91008E09770F7A9A5AE15600
Myles Borins <myles.borins@gmail.com> C4F0DFFF4E8C1A8236409D08E73BC641CC11F4C8
Rod Vagg <rod@vagg.org> DD8F2338BAE7501E3DD5AC78C273792F7D83545D
Ruben Bridgewater <ruben@bridgewater.de> A48C2BEE680E841632CD4E44F07496B3EB3C1762
Shelley Vohr <shelley.vohr@gmail.com> B9E2F5981AA6E0CD28160D9FF13993A75599653C
To import the full set of trusted release keys:
gpg --keyserver pool.sks-keyservers.net --recv-keys 4ED778F539E3634C779C87C6D7062848A1AB005C
gpg --keyserver pool.sks-keyservers.net --recv-keys B9E2F5981AA6E0CD28160D9FF13993A75599653C
gpg --keyserver pool.sks-keyservers.net --recv-keys 94AE36675C464D64BAFA68DD7434390BDBE9B9C5
gpg --keyserver pool.sks-keyservers.net --recv-keys B9AE9905FFD7803F25714661B63B535A4C206CA9
gpg --keyserver pool.sks-keyservers.net --recv-keys 77984A986EBC2AA786BC0F66B01FBB92821C587A
gpg --keyserver pool.sks-keyservers.net --recv-keys 71DCFD284A79C3B38668286BC97EC7A07EDE3FC1
gpg --keyserver pool.sks-keyservers.net --recv-keys FD3A5288F042B6850C66B31F09FE44734EB7990E
gpg --keyserver pool.sks-keyservers.net --recv-keys 8FCCA13FEF1D0C2E91008E09770F7A9A5AE15600
gpg --keyserver pool.sks-keyservers.net --recv-keys C4F0DFFF4E8C1A8236409D08E73BC641CC11F4C8
gpg --keyserver pool.sks-keyservers.net --recv-keys DD8F2338BAE7501E3DD5AC78C273792F7D83545D
gpg --keyserver pool.sks-keyservers.net --recv-keys A48C2BEE680E841632CD4E44F07496B3EB3C1762
See the section above on Verifying Binaries for how to use these keys to verify a downloaded file.
Other keys used to sign some previous releases:
Chris Dickinson <christopher.s.dickinson@gmail.com> 9554F04D7259F04124DE6B476D5A82AC7E37093B
Isaac Z. Schlueter <i@izs.me> 93C7E9E91B49E432C2F75674B0A78B0A6C481CF6
Italo A. Casas <me@italoacasas.com> 56730D5401028683275BD23C23EFEFE93C4CFFFE
Julien Gilli <jgilli@fastmail.fm> 114F43EE0176B71C7BC219DD50A3051F888C628D
Timothy J Fontaine <tjfontaine@gmail.com> 7937DFD2AB06298B2293C3187D33FF9D0246406D
Built With
batchfile
c
c++
dtrace
emacs
html
javascript
makefile
perl
python
r
roff
shell
Try it out
nodejs.org
GitHub Repo


Inspiration
We wanted to use one of the most important purposes of a block chain system: decentralization. After a short brainstorming session we came up with the idea of CARSTEN.
What it does
The project is a peer-to-peer car sharing app, that uses the block chain technology Ethereum to ensure a secure service for both of the contract partners without a trusted middle man.
How we built it
We wrote the Ethereum Smart-Contract using the remix IDE from ethereum.org, compiled it on a linux machine and deployed it in the test block-chain rinkeby (infura.io). To access the smart contract and provide a user interface we built a iOS app with Swift.
Challenges we ran into
The first challenge was to familiarize ourselves with the smart contract environment. After some time we figured out how to write the contract and deploy it. The second biggest problem was of conceptual nature: how to make the process secure for both of the contracting partners.
Accomplishments that I'm proud of
We are proud of understanding more of the concept of cryptocurrencies like Ethereum and Smart Contracts. It is a huge success for us to write our own smart contract that is in the public test block chain.
Built With
blockchain
bmw
car
carsharing
ios
peertopeer
solidity
swift


company slogan and logo
Inspiration
A lot of new or intermediate motivated developers want to produce meaningful personal projects to add to their software repertoire, but either lack the manpower needed to realize their ideas or haven't yet discovered a project that peaks their interest. In comes our application! Portfol.io is a central hub for developers to gather and enhance their skills while building up a software portfolio. Users can browse through suggested projects based on their current skills, join teams of other like-minded individuals and create meaningful projects to add to their resumes.
What it does
Portfol.io is a web application that prompts users to link to their GitHub accounts (or create a profile), from which the AI will browse through their repositories (or current skills tags on their account) to match the user to software projects currently offered from other users on the platform. Projects can be uploaded by any user with an account and can house teams of up to 4. Each project has a main page and chat room for teammates to communicate ideas and share code snippets. The main purpose of Portfol.io is to help match developers to projects that will apply their current skills, as well as building up a portfolio that will put our users in the fast-lane for career-searching.
How we built it
Portfol.io was created using Reactjs, Nodejs and Express.
Challenges we ran into
Our main challenge was avoiding rabbit holes/chasing bugs that could cost us a lot of time. We had to juggle between setting up core functionality and fixing bugs.
Accomplishments that We're proud of
We are proud of the healthy amount of time we spent planning our application as it sped up the development process as well as our scoping exercises.
What we learned
Our team was unfamiliar with Reactjs so learning the syntax and logic behind the library was a great learning experience.
What's next for Portfol.io
Our next steps for the application would be: implementing the artificial intelligence that will match users to projects and populate a suggested list. creating the chat room for team members to collaborate effectively.
Built With
express.js
node.js
react
Try it out
GitHub Repo


Inspiration
What it does
We are optimizing the time that hardware testing takes. Through analysis how long each part of the testing takes, we developed the following approaches (with decreasing impact):
check if tests are unnecessary (never fails or only fails IF another test fails) --> that was not the case in the fiven dataset
optmize order in which the tests are conducted (_test duration_, _likelihood that test fails_) -> _order of test_ We reached a time saving of 7.8 hrs!
optimize calibration. only calibrate when necessary by detecting calibration error in data We have a PoC that calbration errors increase differently after each calibration and thus it makes sense to adapt the calibration to the real error
How we built it
Data processing was done using python with the provided scripts as a starting point
Challenges we ran into
Many plots were uninteresting because most values were normal-distributed, so we had to tweak the machine simulator a bit
Accomplishments that we're proud of
We already have a real proof of concept that optimizing the order the tests are conducted on-the-fly can reduce testing time. And we visualized it in a nice video
What we learned
Creating animated graphs :)
What's next for Rot-Weiß
Testing the approaches with real world data in order to give an estimation of the time saving potential!
Built With
matlibplot
numpy
python
scikit-learn
Try it out
bitbucket.org
docs.google.com


Home page
One of our team member brought up the idea of using available APIs to read tweets, and calculating the sentiment behind it, to compile a one of a kind playlist for any person on Spotify.
We wanted the web application to provide the Twitter login page so that a person can login and discover a playlist made for them
We used oauth.io 's Twitter API to create the login form. After the login sequence, the web application would read their recent tweets and shares (25) and write it into a csv file. After that, the app would calculate the sentiment score of each tweet, and using that information, use the Spotify API to create a playlist, which they could save.
For all of us in the team, it was the first time we used APIs and developed a web app. We spent most of our time in researching the most efficient way to implement our idea. Lacking time, we were unable to finish our project.
We are proud of ourselves, even though we weren't able to finish our project, as we worked together, learned from one another and were able to finish one crucial part of the application, which was the Twitter login pop-up.
We were able to learn how to implement APIs to create a web application and how to code using Flask.
Our team is planning to complete the project very soon, and we are planning on including more features in the UI, to make the application have a wider range of users.
Built With
css
google-cloud
html
javascript
python
tweetfeel-twitter-sentiment
twitter
Try it out
tweetunes.space


Maths equations which we not really implemented
Inspiration
Simulation is important in industrial development. We plan to do the optimization of a simulated test-system to reduce measuring time and increase product output.
What it does
The optimization code maximizes the output per 24h
How we built it
We wrote a Python testing script based on the DUT simulator source code.
Challenges we ran into
We spent the first night to understand the source code of the simulator.
The generated samples from the DUT simulator is random. So it's hard to find the pattern/correlation between measurements.
Lack of theoretical knowledge in data science and machine learning
Nobody really knows Git
Accomplishments that we're proud of
Group work in a team of all Hackathon beginners.
The measurement time is reduced by (a few) percents!!!
No black-box ML/DL model used!
What we learned
Git SCM via GitHub
Python framework: pandas, numpy, scipy
Pycharm IDE
What's next for DUT Me
clean the messy coding style of Python test script
make an accurate DUT simulator based on the real device
Create a database of simulated DUT with different number of measurements (N) and number of measurement ports (P)
Built With
numpy
pandas
python
scipy
Try it out
GitHub Repo


Main page
Inspiration
Our interest in pursuing higher mathematics courses led us to enroll in advanced calculus classes at our local community college. While working on assignments and furthering our knowledge of the subject area, we realized that graphing software used by a substantial portion of enrolled students is exorbitantly priced or largely inaccessible. Consequently, we decided to build a software that could be used by students who wanted to graph 2-dimensional functions on the xy plane and 3-dimensional functions on the x, y, and z axes. Additionally, we aimed to implement calculator software to derive key values, such as extrema, limits, values at specific inputted points, and intercepts.
What it does
Compass intakes handwritten images through either a manual upload of an image that has a function written on it, either handwritten or printed, or allows the user to write the function on a JavaScript canvas included on the website by using a cursor. The image is then processed through Google's Cloud API which converts text within image to separate functions. This function is then analyzed using Wolfram's API to isolate key values, including extrema, limits, and other indicative values through processes like integration. This information is displayed on a results page along with the 3-D graph of the function on an xyz plane as well as with a solid model.
How we built it
We approached the majority of data analysis using Python and used this language to transfer data from our code to varying APIs, including Google's Cloud and Wolfram API. We also used PHP to transfer user data and used JavaScript to enable the handwritten canvas portion. The bulk of the website that we built was made of HTML and CSS. To understand the varying relationships between functions and editable graphs, we also studied the Desmos API, but decided against implementing it in our final models. Prior to building out the final version of our website, we also analyzed the MNIST dataset, a dataset consisting of tens of thousands of handwritten characters, and constructed a model that could differentiate between the varying digits. This was completed using Python and Jupyter Notebooks and served as a seamless introduction into the relationship between machine learning and image processing as they related to user input.
Challenges we ran into
We initially experienced trouble installing tools and transferring data among the various APIs and programs that we implemented in our software. We resolved these challenges by shifting our attention to APIs that were more conducive to our product and could be used among a host of plotting and calculation programs. Additionally, while converting user input to data that could be processed by the remainder of our program, we experienced difficulties integrating various languages at the same time, such as with JavaScript and PHP. By scouring online documentation and consulting previous forums, we were able to identify the functions necessary for our software and implemented them accordingly.
Accomplishments that we're proud of
While searching for website backgrounds, we stumbled upon a minimalist image of two compasses. From this simple source sprouted our product name, Compass, representing the math instrument and the tool of journeymen on their quest to succeed, accompanied by a simple black and white theme.
Instead of hosting our application locally, we used a cloud computing service in order to run our code 24/7. Using buckets, event functions, and the cloud engine, requests are processed and sent between each other. Through the Google Cloud services APIs, we used the Google Cloud Vision API to process incoming images as text so that they can be sent to other APIs for display, such as with the Wolfram Alpha API.
What we learned
Through transferring data across multiple platforms and implementing the varying functionalities of cloud-based APIs, we learned to harness our backgrounds in computer science while also building upon our existing knowledge by using online documentation. For instance, we applied our backgrounds in Python when working with other programming languages, especially as we transferred data across sources while using niche APIs.
What's next for Compass
Compass's use cases can be expanded into more advanced math scenarios, such as triple integrals, polar functions, and differential equations. A mobile app would allow for problems to be inputted more seamlessly and just as quick through cloud computing. As our website allows the user to draw their problem on the website, we could also implement this functionality on the mobile app and expand input sources to taking live images. One of our early ideas was to use augmented reality (AR) to visualize multiple graphs simultaneously so that the user can have a comprehensive understanding of 3-dimensional plots.
Built With
css
google-cloud
html
javascript
php
python
wolfram-technologies
Try it out
GitHub Repo


Charging
Inspiration
Charge Electrocar during driving
What it does
It will gives ability of charging with out stopping
How we built it
by Inductive Charger
Challenges we ran into
organizing network to exchange data between vehicles
Accomplishments that we're proud of
we used two robotic cars and integrated wireless charging
What we learned
Raspberry Pi3 computer, Arduino UNO hardware and software how tho run robot car
What's next for IN DRIVE charging solution
Implement on real life solution


embarking on a trip planning adventure!
Inspiration
As citizens of the world, we all like to travel. However, the planning process can be a real pain, from coordinating with friends, to finding accommodations and flights, to splitting costs afterwards. Travel.io is an innovative web app that allows users to collaborate with their travel mates to make the planning process as smooth-sailing as possible.
What it does
travel.io empowers users to focus on their travel ambitions and enjoying the company of their friends without having to worry about the monotonous aspects of trip planning. The web app aggregates flight and accommodation details for the user's destination of choice. The users are able to plan out events that fit every individual's schedule, and track their spending on the trip. Additionally, users are able to see a breakdown of who owes whom how much.
How we built it
With great difficulty!
Challenges we ran into
Real-time communications presented a challenge in their limited compatibility with their Google Cloud Platform.
Accomplishments that we're proud of
We created a fully featured application in a limited amount of time. Although none of us are experienced at front-end, we still managed to create a web-app that is full of user interactivity.
What we learned
We learnt about web sockets and the struggles that come with secured networking. We also learnt about sending HTTP requests, and became more familiar with source version control.
What's next for travel.io
Creating a user authentication system that would allow for individuals to engage in multiple trip workspaces with different friend groups.
Built With
css
flask
html
javascript
jquery
python
Try it out
GitHub Repo


Inspiration
In Germany, delays of buses or traffic jams are very common especially during rush hour.
What it does
By controlling the traffic signals, a bus will have priority to pass the intersection. The more passengers on board, the easier to avoid traffic jams.
How I built it
Use a camera box (Raspberry pi + camera + Arduino shield) to catch traffic info at the intersection Use a paxcounter to estimate current passengers on the car Connect the hardware to TTN Get GPS info and traffic light info from the third party By using all the info above, use SUMO networks to optimize the traffic light
Challenges I ran into
Connect hardware to TTN. Make a neural network run on raspberry pi, make Sumo model run
Accomplishments that I'm proud of
Teamwork, build a car counter neural network, build Sumo simulation, build paxcounter and car counter camera box which connects to TTN
What I learned
TTN, Rabsberry, Neural Network lite, ...
What's next for IngoX
Research purpose: make data available for research
Demand Responsive Transport: passengers can request for shuttle buses from A to B. And a shuttle bus will be assigned to pick up the passenger. Different fares depend on the urgency and corresponding maximal arriving time is calculated. If a new passenger is assigned to a shuttle bus, the new route of the shuttle bus should not harm the maximal arriving time of other passengers on board.
P+R last mile service
Built With
lorawan
neural-network
paxcounter
python
raspberry-pi
sumo
tensorflow


Inspiration
i wanted to make a a calculator as its useful and good online calculators are hard to find
What it does
i multiplies, divides, subtracts, and adds
How we built it
we used java in android studio
Challenges we ran into
we miked up two parts of the program, so we had to re-write it
Accomplishments that we're proud of
we made our first app
What we learned
how to make apps
What's next for calculator
we are gonna add powers, roots, e, pi, trig, etc, repeated addition,
Built With
java
Try it out
GitHub Repo


Inspiration
Goldman Sachs Challenge
What it does
Very little
How we built it
In a very panicked fashion
Challenges we ran into
Where do we start...
Accomplishments that we're proud of
It works
What we learned
Version control on a single page app is hard
What's next for Kwiddy - Your personal finance manager
The software dumping ground
Built With
css
html
javascript
Try it out
GitHub Repo


Three Nodes
Inspiration
After recent environmental events, PG&E cut our power resulting in internet service outages across California. In the few days without power, we caught a glimpse of what it meant to live without the internet. Today, caught up with the latest iPhone, we often forget that almost half of all people have no internet access and many others have limited internet access. We sought to create a cheap easily deployable internet solution that could function independently of a grid. This internet solution could be deployed in communities where internet access is limited or non-existent and after natural disasters where communications and infrastructure are compromised.
What it does
AtomicNet is a low-cost mesh network of raspberry-pi nodes that work together to provide communication and information in a low bandwidth network. Each node is equipped with a wifi module so that it may connect to nearby wifi devices or other nodes and optionally a radio module so that it can connect to nodes further away (up to 2km).
On top of this network, we built four main applications which we call the Atomic Suit: Electron Chat, a messaging app; Protron Forums, online forums; Neutron Library, a collection of all Wikipedia articles; and Lepton Link, a connection to the full internet (available when an exit node is connected).
These four apps are able to provide communications in a disaster situation. Relief personnel can use Electron chat to communicate with victims, good samaritans can use Proton forums to post about new materials they have for donation, victims can use Neutron Library to learn about ways to improve their situation, and families can use Lepton Link to communicate with loved ones.
These four apps also provide core internet services to those in developing countries who lack consistent internet access. Friends can chat over Electron chat, communities can organize through Proton forums, and students can learn on Neutron Library.
The network nodes themselves are made of the Raspberry Pis 0s, lithium-ion batteries, charge circuits, a wifi router, and an optional solar panel. The lithium batteries are able to keep the Pis running for two days. This ensures if there is a prolonged power outage or no sunlight (for solar-powered Pis), the network will remain running.
Unfortunately, we did not get the chance to add LoRa radio transceivers to our Pis (we didn't bring any with us) but we designed our system to be compatible with them. We purposely designed our system to use a low bandwidth that the lower frequency transceivers would be able to transmit in a timely fashion.
How we built it
The backend is is a mesh network made using BATMAN-adv, and a server written in Golang that uses a PostgreSQL server as the database.
The frontend was created with JavaScript, React, and the ANT Design library. A focus was placed on ensuring that all webpages on the frontend worked seamlessly on mobile devices since phones are often the only way people access the internet.
Challenges we ran into
One of the biggest challenges we had was how to network multiple Raspberry Pis together, because the MakeSchool network had network segmentation, and prevented us from connected the Pis to each other easily.
Another challenge we had was to build an entire software suite in 24 hours. Each of the four applications that individually could have taken months to design, develop, and debug had to be written in a matter of hours. While we were unable to code perfected versions of each app, we were able to create a first version for each.
Accomplishments that we're proud of
We are proud of being able to network raspberry Pis together and coding the Atomic Suite in so little time. Also, we are proud of being able to adapt to learning new languages that we may not have used before. In addition, Wikipedia which due to its scale, proved difficult to parse especially when writing code that would run on a $10 computer. We hashmaps to achieve an o(1) when processing Wikipedia data.
What we learned
We learned how to use React and ANTD. This was something we had wanted to learn for a while and it was great to finally learn React and use it in a project. We also learned the ins and outs of batman-adv, the software we used to help network the Pis. But more importantly, we learned the value of teamwork and collaboration, and how to work better and more effectively as a team.
What's next for AtomicNet
In the future, we hope to further refine the Atomic Suite while also allowing other developers to create applications for Atomic Net.
In addition, we would like to program drones to airdrop Atomic Net Nodes. In the event of a disaster, drones can drop AtomicNet nodes at predetermined locations. A drone-enabled system would allow for a rapid deployment of AtomicNet during emergencies. Since it will be a nonprofit and sold at cost, with sufficient donations, we can quickly spread the scope of AtomicNet and increase the access of Internet to more places than ever.
Built With
antd
batman-adv
go
javascript
python
react
Try it out
GitHub Repo
docs.google.com


Inspiration
The agric value chain has so many different players and at every point, lots of support and other services are needed to increase efficiency and competitiveness.
What it does
AgriVax will give players along the value chain gain access to information, input, advisory, tech support, extension services, post-harvest management consultancy,markets... etc that they need to be efficient. Eg. A commercial seed grower who signs up will see what point of the value chain they fit in. They will be able to understand the needs and expectations of their client and get the right assistance that will help them meet those needs almost exactly.
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for AgriVax
Built With
figma


Inspiration
The inspiration behind this app was that we had previously put a deposit down on our second-year house, we had realised the pain of splitting bills with people within our group and we thought to solve that! We wanted to build an app that would allow us to view our outstanding bills, the bills that we have made and then a method of paying the bills that we owe using PayPal or Stripe.
What it does
It is an Android App that has multiple screens, it has; a login screen, sign up screen, forgot password screen. After these details are sent to the API (made from scratch) it populates the relevant table in the Mongo atlas database, it also responds with signed JWT authentication tokens and refresh tokens to ensure the security of communications and to keep track of users access levels.
After moving through different screens, different post and get requests are sent with either population values or expecting a value in return.
How we built it
We delegated tasks where one of us would create the front end of the app and one of us would make the back end. We ended up working together somewhat on the backend to ensure that they meshed together properly.
We used android studio and created a RESTAPI to handles requests, as well as using MongoDB repeatedly to make and store test data and then real data.
Challenges we ran into
The main issues that we ran into were handling the asynchronous functions that were unavoidable to use, we managed to get around this problem, but not without a lot of effort and different approaches. We then used our new found method to create the rest of the program. However, it was very difficult to follow what was happening at points, it took many step backs and re thinking to get it done!
Accomplishments that we're proud of
That we created our very first android app, it was very new to both of us and we managed to get it working to a decent standard.
What we learned
We learned how to use android studio and the process of creating an app with many different features. As well as using this app to connect to a self-made API to handle the javascript, mongoose and mongo interfaces.
What's next for HouseMo
We plan to develop it further and implement all the features that we envisioned. As well as clean up our code!
Built With
android-studio
express.js
google
java
javascript
mongodb
mongoose
restapi
volley


Inspiration
The pain points of finding quality leads for mortgage origination and closing gaps in a homeowner's mortgage origination journey
What it does
generate quality leads from core banking system, baring together different stakeholders in a mortgage journey for a better and fulfilling experience
How I built it
Utilized available FFDC open APIs, and leveraged angular to build a robust front end
Accomplishments that I'm proud of
Designing the workflow, being involved in technical decision making and solving technical challenges
Built With
angular.js
api
ffdc


Shooting Gallery
Inspiration
A deep passion for Jenga and being provided Leap Motion controllers to try out.
What it does
A small suite of AR games based around practicing simple motor control. It includes Jenga, Shooting Gallery and Juggling.
How We built it
Built it using the Leap Motion SDK for Unity which made it simple to integrate Leap Motion into our Unity Projects.
Challenges We ran into
Leap Motion is designed to be paired with a VR headset, which we did not have access too, so we had to overcome orientation and depth perception issues. We were also not familiar with C# and Unity so we first had to learn this.
Accomplishments that We're proud of
We are proud of Jenga.
What We learned
Developing simply games with Unity and the basics of C#.
What's next for HHH AR GAMES
Probably not a lot.
Built With
ar
c#
leap-motion
unity
Try it out
GitHub Repo


Notification for checkup
Chronicle
Inspiration
With an increasingly ageing population, social care faces continuous challenges in providing services of health, housing, welfare and leisure.
For the scope of this project, we aimed at improving the process whereby patients receive mental health support. This is currently a manual process which may results in delays in therapy which may be detrimental to the health of the patient.
What it does
Chronicles simplifies the process of collecting information from the patients and helps open up a communication channel between social care workers and patients.
The patient may be prompted to fill a questionnaire on their phone, after a regular period of time set up by the social care worker (eg. weekly, bi-weekly...). The results from this questionnaire are sent to a web version of Chronicle which allows doctors to visualize the progress of the patient over time.
The doctor can also access vital signs data from the phone Health App such as step count and heart beat. This data can be used to track the effects of specific medications and are analysed by an Echo State Neural Network (ESN) to predict whether the patient may be depressed.
How I built it
Mobile App
To make the service universal and as available to as many people as possible we used the flexibility of the web to build the mobile app, which was developed as a Progressive Web App with the Vue.js framerork and depolyed to Google Firebase.
Web App
Similar to the mobile app, the web app was built with Vue.js framerork and depolyed to Google Firebase. Its aim is to visualize the data received by the patient, helping doctors making informed decisions.
ESN (Neural Network) and CNN
In this experiment an ESN is used to detect depression in patients via activity from a smart watch (DepresJson dataset). This was used a a benchmark to demonstrate how quantitative data can be used to indicate symptoms of mental illness. This will improve doctors/social workers understanding of their client without relying on the client to accurately depict their mental health.
What's next for Chronicle
In the future we believe that data from chronicle could be used to help better understand side effects of medication by linking patients data to descriptions. This would help medical companies see how their drugs negatively or positively effect their clients and provide a better quality service. Having a large user base of patients and their health data would provide an ideal framework for research in big pharma.
Appendix - Echo State Network Theory
Feed-forward neural networks (FNN) are a key part of machine learning. They are well defined and exhibit linear, non-dynamic behaviour which is very well suited to some tasks. However, they often struggle to solve problems with temporal data. This is due to difficulties in preparation on the input vector and their lack of long term memory.
FFNs traditionally require a fixed-sized input vector. This means that some pre-processing of the input signal is almost always required. Basic methods include re-sampling or feature extraction. Both involve information loss of the original signal. Temporal significance of the input is lost in both cases.
To improve upon the problems FNNs have with temporal data various other models have been introduced. In 1982 Hopfield introduced a network architecture to model associative memory that some believe have similarities to human memory. In Hopfield networks, the input signal is sequentially inputted into the system. The input is mapped via a non-linear function to individual attractors of the networks state which contains 'memories'. The non-linearity of Hopfield networks come from the cyclic nature of the network, where neurons feed data back into previous neurons each step. This feedback gives Hopfield networks the echo state property, which allows the previous inputs to retain temporal significance. A generalisation of Hopfield networks is now studied as recurrent neural networks (RNN).
Although RNN's have a lot of theory supporting them they are very hard to implement in practice. This is due to various training problems, especially the vanishing gradient problem.
ESNs are a lesser known class networks that retain some of the benefits of RNNs but are significanty quicker to train as they only have a single trainable readout layer. Internally an ESN is a sparsely connected RNN where each node can be describe by a random non-linear function. The theory is that a linear mapping of these functions can act as a universal approximator. This linear mapping is trained whilst the internal weights of the ESN are kept fixed.
Built With
firebase
firebase-cloud-functions
google-cloud
javascript
keras
numpy
pwa
python
sketch
vue.js
Try it out
GitHub Repo
GitHub Repo
GitHub Repo


Fourier Transform
Inspiration
Companies have succesfully created app only consumer banks to help users manage their money, and offer innovative features like budget monitoring. With being app only these companies have high operational efficiency and as a result can offer lower fees to their customers. We aim to bring this disruption to consumer investing allowing regular people to manage their investments and grow their money.
What it does
Molecule is an app only hedgefund, powered by deep learning. Molecule is designed to change the way people invest. The app is designed to make financial services accessible to the many, and not hidden behind large fees, or large minimum investments. We have 3 funds the adventurous, which carries more risk, safe which has less rsk but lower returns and the ethical fund which doesnt invest in fossil fules or wepons manufacturers and favours companies that work to improve the environment. Each day users can place money from their wallet into a fund, and watch it (hopefully) grow.
The money in each fund is invested in various financial markets using the neural network we trained to predict the price of certain assets at the end of the day users can withdraw money from the fund into their wallet or leave it in the fund for it to continue being invested. Molecule has a price prediction model which allows the money in funds to be invested in various financial markets.
The model uses various technical indicators and prices of correlated assets to predict whay the price of an asset will be tomorrow.
E.g. For Goldman Sachs, molecule uses data such as: *Similar companies such as JPMorgan Chase *Composite indices (NYSE, FTSE100, Nikkei225 …) *Fourier transforms of the price of GS with varying somponents to analyse small and large-scale trends.
How we built it
Trained an LTSM on various technical indicators about a stock price and the prices of correlated asset, to try to predict the price tomorrow.
Built a react-native app with a nodeJS reat API and mongoDB to allow users to deposit money ad invest it in funds.
Created a react-native ap with a nodeJS rest api to allow users to deposit money and invest in funds.
Challenges we ran into
Getting a recurrant neural network to train properly.
Accomplishments that we're proud of
We are proud we managed to deliver a price prediction model and a UI.
Our Expo mobile application had difficulties connecting to our node.js API
What we learned
We learned how LSTMs work.
What's next for Molecule
Bigger dataset
Try to include an adversarial architecture (we looked at Metropolis-Hastings GAN)
Include fundamental analysis into our predictive model (sentiment analysis of news articles relating to the asset as a given time as well as yearly shareholder reports)
Built With
arima
javascript
keras
mongodb
node.js
pandas
python
react-native
xgb
Try it out
GitHub Repo


Our welcome page
Inspiration
California has the highest amount of homeless people. There are 130000 people currently homeless in California. That is a lot! Seeing the homeless problem for ourselves and hearing about the recent wildfires inspired us to help those affected and California.
What it does
Our app is a user- friendly way for a person in need of shelter, food, a place to take refuge after a disaster and much more unfortunate events. It connects an organization with resources with those without resources. More importantly, if you don't have a device to access it, the website can be run from any public place with computers.
How we built it
We used virtual studio code to communicate and code on. We used many languages including python, javascript, HTML, and CSS
Challenges we ran into
Sometimes we ran into many problems like bugs and our .json file wasn't working so we had to use a SQL file instead. Running into unexpected problems was one huge factor in how we had to modify our code in a lot of ways
Accomplishments that we're proud of
We are proud of having:
A nice, userfriendly, login page
A cooperative team
We all split up the work evenly between ourselves very smoothly and managed to get it all done before the competition ended.
We learned a new language
What we learned
We learned:
A new framework (flask)
A new language (Markdown)
Beginning of Android studio
How to cooperate and communicate with each other under pressure
A new site for creating professional presentations
What's next for Find My Shelter
In the future we will:
We will open it up to more than San Fransico
We will add an option for Companies to become a partner with us that will always be open to help the people in need
We will tighten up security and make our web app into a phone app
Built With
css
flask
html
http
javascript
jinja
jquery
json
markdown
python
rest
sql
typescript
visual-studio
web-components
Try it out
GitHub Repo


Inspiration
So many times after playing pickup basketball we've wished we could see replays of the moves we did
What it does
Allstar understands what is happening in videos of pickup basketball games. This means it can watch recorded or streamed footage of a game and know who is scoring, rebounding, etc. and everything that goes on in the game (some human in the loop as the AI is not perfectly accurate). This allows for creation of stats and highlight videos for each play for each player.
What we used
Neural networks in tensorflow, basic landing page with square space, azure container instance for deploying tensorflow model on gpu in cloud. Ffmpeg for editing/clipping videos. Python for managing tensorflow and ffmpeg.
Challenges
Biggest challenge was finding the best way to succinctly articulate what allstar does to a wide range of people.
Accomplishments that we're proud of
Signing up several paying users in such a short time and delivering for them.
What we learned
-People are willing to pay to acquire highlights from pickup games -How to approach customers -Better to spend more time finding a viable idea than just build something for the sake of building it
What's next for Allstar
Find more users, understand the best way to monetize, obtain more data to improve algorithms and lower necessity of human in the loop, build out the rest of the infrastructure, eventually add mobile app, eventually add wall mounted cameras rather than our mvp of phone cameras.
Built With
azure
ffmpeg
react
tensorflow


Inspiration
I was in a life-threatening situation, I almost did a deadly accident in Ingolstadt just because the street light was not bright hence the street was so dark, not only that but the city is consuming so much energy that could be saved since many streets are not in use but still the street lights are working most of the time with their highest load.
What it does
Our platform is a service/solution for the cities to take control of the history and be updated by everything such as dim lights notification and save so much energy just by using our technology
How I built it
We used for the prototypes Arduino UNO, LoRaWAN & angular CLI to build a web interface
Challenges I ran into
Lack of support about the new thing for us which is LoRaWAN
Accomplishments that I'm proud of
We built a complex system with everything connected together using even the knowledge from last year and we learned new things
What I learned
We learned to program on Arduino, establishing a connection between it and LoRaWAN and our system
What's next for Paladia
We are planning to test our prototype in real-life situations and make it go through all the requirements and start implementing it in our city Ingolstadt as a first Client.
Built With
adobexd
angular8
arduino
css3
dialogflow
html5
iot
lorawan
typescript


What is it?
This project NodeJs wrapper for a ESP32 to send signals to the blutetooth car. This allows anyone to control the car by hitting a http endpoint. Also built a hand gesture controller using Leap Motion as a proof of concept of the types of controllers that could be used. Finally built a Web client that allows of a user to control the car using a web app and display car statistics back to the user.
Possible Applications
Home
Gaming/Racing
Warehouses
Wheelchairs
MiIitary
Rescue Missions
Why We Hacked This
ANYWHERE, ANYTIME
Extend the range of remote control from a couple meters to around the world
OPEN SOURCE
Provide an interface where others can create their own controllers
STATISTICS
Provide car owners with real-time car statistics
If There Was More Time
Added more functionality to the REST API, adding more different kinds/series of signals to be sent to the bluetooth car
Added Sensors to the car and send that data back to a web client
Added an Authentication process to use each vehicle so only registered owners/users may send signals
Built With
ble
bluetooth
css3
esp32
html5
javascript
leap-motion
node.js
rest
Try it out
web-car-controller.firebaseapp.com
GitHub Repo


Inspiration
One of us lives in SF, and another lives in Fremont -- as a result we don't meet up enough as good friends. This inspired us to look into the area of organizing friend gatherings, and the underlying user problems it uncovers.
What it does
Checkpoints enable users to select their meetup preferences, and follows up by providing recommendations for places to go. Users then check in at the location together with their friends interactively to complete challenges, and for whistles and laughs.
How we built it
We built it with Swift on the frontend, and TypeScript NodeJS on the backend.
Challenges we ran into
While Azure mostly worked great with Github and VSCode for standing up quick backends, we ran into MongoDB database configuration issues (╯°□°)╯︵ ┻━┻
Accomplishments that we're proud of
We were proud of the activity picker we built out. It was inspired by letting users express their preferences.
What we learned
We did some UX research with family and friends, and received signal that the user problem is valid, and that scheduling was a big problem to solve.
What's next for Checkpoints
We would want to jam further on the user problem given our learnings, sharpen our understanding of it further, and evolve the product towards solving for that.
Built With
ios
javascript


Inspiration
realistic rendering
What it does
visualizes roads, pavements, road markings, nature (grass) to enable AI models to learn self-driving cars in a virtual environment. The data is given in 2D street data (Open Drive format) and converts it to a nice looking 3D map (See photos).
How we built it
converted 2D to 3D coordinates
applying height to vertices by using Perlin noise to generate terrain
added 3D models and road markings to scene to make it realistic
Also added sidewalks and street lights for a better ambient
Challenges we ran into
xodr visualizer does only work with English locales
rendering textures on 3D objects (we hated Unity for a while)
limited power on our laptops
Accomplishments that we're proud of
Having street lamps
To accomplish more then we expected to especially in the last 10 hours
What we learned
learned a lot about 3D modeling, rendering and texturing
learned how to use Unity
What's next for roads.sexy
Put in more auto generated stuff like houses along the sidewalk
Better Shaders and Textures
Improve performance
But first of all, have a very very good Sleep!
Built With
blender
c#
c++
opendrive
unity
xodr
Try it out
GitHub Repo


Inspiration
In a fast-paced Agile work environment, scrum meetings are organized to maximize efficiency. However, meetings that are supposed to last less than 15 minutes can often drag on for much longer, consequently draining valuable time.
What it does
Kong is a voice-enabled project management assistant. It acts as the voice-automated scrum master by leading the daily meeting in a concise, efficient and logical manner. Furthermore, it dynamically modifies tasks by connecting to an Agile project management software maintained through the cloud.
How we built it
Using Google Cloud Natural Languages API, our team built a program that transcribes the users' speech to text, converts text to JSON commands, and finally transforms JSON commands into information that you see on the screen. Ultimately, Kong can filter through the noise to collect the most relevant data to be transformed into instantaneous updates for users enrolled in the project to view on their personal devices.
Challenges we ran into
Our team had to pivot many times when we realized that certain frameworks we wanted to work with were not compatible for the ideas that we had planned with the time frame we were working with. For example, SOX, the Google Cloud Speech-to-Text API and the Google Cloud Natural Language Syntax API were used instead of DialogFlow.
In addition, every single person purposely decided to tackle new challenges. Individuals who had little experience with coding attempted to learn front-end design through React. Meanwhile, those who have built projects using React in the past looked towards back-end development using Firebase. Moreover, all of our members ventured into voice-enabled technology for the first time.
Accomplishments that we're proud of
We are most proud of our willingness to take risks and try new challenges. When obstacles were encountered, we relied on each other for expertise outside of our own familiar domain. Challenges and teamwork inspired us to not only improve the product but ourselves as well.
What we learned
Within these 36 hours, we obtained the fundamental knowledge of new technologies even if they were not all applied n the final product (e.g. CSS, HTML, JavaScript, Express, Python, Google Cloud API, DialogFlow, Twilio, etc.). In addition, we learned how to quickly find reliable and comprehensive resources. More over, we learned to use our network and reach out for help from the right people.
What's next for Kong
Some possible next steps for Kong is to find a way to export the information through APIs. Additionally, our team could reduce the response time and expand the length of the recording. We may also expand our software to support voice recognition for individual users and delve into integration with personal notification systems (e.g. google calendars). Finally, it should be a long term goal to improve the security and storage of Kong.
Built With
axios
express.js
firebase
google-cloud-natural-language-syntax-api
google-cloud-speech-to-text
google-cloud-text-to-speech
json
node.js
nosql
python
react
sox
Try it out
GitHub Repo


Inspiration
In a fast-paced Agile work environment, scrum meetings are organized to maximize efficiency. However, meetings that are supposed to last less than 15 minutes can often drag on for much longer, consequently draining valuable time.
What it does
Kong is a voice-enabled project management assistant. It acts as the voice-automated scrum master by leading the daily meeting in a concise, efficient and logical manner. Furthermore, it dynamically modifies tasks by connecting to an Agile project management software maintained through the cloud.
How we built it
Using Google Cloud Natural Languages API, our team built a program that transcribes the users' speech to text, converts text to JSON commands, and finally transforms JSON commands into information that you see on the screen. Ultimately, Kong can filter through the noise to collect the most relevant data to be transformed into instantaneous updates for users enrolled in the project to view on their personal devices.
Challenges we ran into
Our team had to pivot many times when we realized that certain frameworks we wanted to work with were not compatible for the ideas that we had planned with the time frame we were working with. For example, SOX, the Google Cloud Speech-to-Text API and the Google Cloud Natural Language Syntax API were used instead of DialogFlow.
In addition, every single person purposely decided to tackle new challenges. Individuals who had little experience with coding attempted to learn front-end design through React. Meanwhile, those who have built projects using React in the past looked towards back-end development using Firebase. Moreover, all of our members ventured into voice-enabled technology for the first time.
Accomplishments that we're proud of
We are most proud of our willingness to take risks and try new challenges. When obstacles were encountered, we relied on each other for expertise outside of our own familiar domain. Challenges and teamwork inspired us to not only improve the product but ourselves as well.
What we learned
Within these 36 hours, we obtained the fundamental knowledge of new technologies even if they were not all applied n the final product (e.g. CSS, HTML, JavaScript, Express, Python, Google Cloud API, DialogFlow, Twilio, etc.). In addition, we learned how to quickly find reliable and comprehensive resources. More over, we learned to use our network and reach out for help from the right people.
What's next for Kong
Some possible next steps for Kong is to find a way to export the information through APIs. Additionally, our team could reduce the response time and expand the length of the recording. We may also expand our software to support voice recognition for individual users and delve into integration with personal notification systems (e.g. google calendars). Finally, it should be a long term goal to improve the security and storage of Kong.
Built With
axios
express.js
firebase
google-cloud-natural-language-syntax-api
google-cloud-speech-to-text
google-cloud-text-to-speech
json
node.js
nosql
python
react
sox
Try it out
GitHub Repo


Login page
Inspiration
We wanted to create a web application that had significant social impact, and we decided that enabling a particular group of people (i.e. deaf people/people hard of hearing) to be more self-reliant was a good starting point.
What it does
Sign2Voice is a web application that is able to recognize American sign language gestures and translate them into text, and eventually into speech, bridging the communication gap between deaf and non-deaf individuals.
How we built it
We mainly used JavaScript in our web app to receive input from a client's webcam, make API requests to classify the gestures, and convert the resulting text into audio. We trained a custom model on Google's AutoML Vision for classification, and we used Watson's text-to-speech API to eventually translate it into speech.
Challenges we ran into
We faced a few technical challenges: Most notably, it was difficult to train a sufficiently-accurate classifier for the gestures, given the limited time and compute power that we had available. Additionally, it was a challenge to get the user interface exactly the way we wanted it to look and perform.
Accomplishments that we're proud of
We're proud of the usability and overall aesthetic of the user interface of our web application. Additionally, we're proud that we achieved a minimal viable product in a short span of time.
What we learned
We learned how to create a good user interface for a web application, about how to create efficient computer-to-computer interfaces, and picked up a few new technologies (e.g. Google Cloud SDK). We also learned how to work more effectively with other developers.
What's next for Sign2Voice
In the future, we hope to improve the accuracy and minmize the latency of our gesture classifier. We also plan to do more usability testing to improve the visual and interaction design of our user interface.
Built With
automl
ibm-watson
javascript
standard-library
Try it out
GitHub Repo


Inspiration
We wanted to make a project that was both useful (no one developed a fall detection app for fitbit yet) and fun to do, while still making use of the hardware of durhack and twilio interface.
What it does
It's an app for the fitbit wristbands that works indipendently from any smartphone app. Once you select a phone number of a relative you'd like to alert in case of a fall, the app works in the background using the accelerometer to detect falls.
How I built it
Using the fitbit developing language which is basically javascript with an user interface built with some kind of html and css. We also used the twilio API for sending sms.
Challenges I ran into
Reliably detect falls was the biggest difficulty. Also the fitbit developing utility is somewhat peculiar which led to some roadblocks in the developing of the app.
Accomplishments that I'm proud of
The app could actually help someone in real life while beign simple, accessible and good looking.
What I learned
How to better use javascript and the fitbit user interface. How to use twilio.
What's next for FallDet app
Ideally it would be nice to use some machine learning to refine the fall detection algorithm and maybe adding the option to have a "contact list" and send a sms to each contact in there.
Built With
css
fitbit
html
javascript
twilio


Inspiración
Después de analizar los retos, nos hemos interesado por las tecnologías relacionadas con el IoT por lo que hemos apostado por la creación de un sistema de monitorización a baja escala con la intención de empezar con un proyecto accesible, pero con mucha capacidad de crecimiento.
Que hace
Nuestro sistema mide parámetros ambientales a nivel de hogar (temperatura y humedad) a través de sensores conectados a un sistema operativo Raspbian, conectado a su vez con un API alojada en un servidor Web propio. Los datos obtenidos se transmiten a diversos dispositivos. En este momento tenemos implementada una integración con sistemas de asistencia por voz (Amazon Alexa) y con smartphones, con la intención de otorgar una mayor versatilidad y accesibilidad a los usuarios objetivo. El usuario puede, en función de la información aportada, tomar decisiones para activar sistemas relacionados con los parámetros tomados. En nuestro caso, tenemos implementado un sistema LED que simula una instalación de climatización a pequeña escala.
Como lo hemos desarrollado
La Raspberry funciona con su propio sistema Raspbian. El servidor aloja una API programada con Flask (python). El sistema de reconocimiento de voz está programado con Lambdas de Alexa para obtener los parámetros.
Retos afrontados
En un principio, no hemos dispuesto de la tecnología necesaria para el reto, de modo que hemos buscado alternativas para solucionar los deficits y afrontar el reto de la forma mas viable posible. Hemos intentado ampliar nuestro sistema con un asistente de voz, por lo que hemos tenido que entender la programación de Amazon Alexa y hemos implementado un sistema de Machine Learning que, aunque no hemos podido introducir en nuestro Backend, nos ha permitido crear una Red Neuronal para la predicción temporal de Temperaturas.
Logros
"Think out the box" Conexiones hardware con un sistema Raspberry Pi3 (sensor de temperatura/humedad DHT11 y puertos GPIO). Creación de skills de Alexa. Creación de una pequeña red neuronal para predecir Temperaturas en función de los parámetros obtenidos. Conseguir mediante el flujo Alexa/App que los sistemas funcione (en nuestro caso, simulación con sistema LED). Construcción de web app multiplataforma para adaptarlo a la mayoría de dispositivos del mercado.
Que hemos aprendido
Conocimientos adquiridos sobre el sistema de programación de Alexa y Machine Learning. Construcción de una arquitectura completa End-to-End con algunas tecnologías con las que no habíamos trabajado.
Posibilidades de futuro
Todavía queda mucho trabajo por delante. La principal idea es introducir el sistema de machine learning para poder predecir, con una buena accuracy, y automatizar los sistemas. Lo ideal sería introducir una mayor diversidad de sensores para una monitorización completa.
Built With
amazon-alexa
flask
ionic
python
raspbian
tensorflow
Try it out
GitHub Repo


Distress function
Inspiration
We have attended Western for the past 4 years, and have seen the growing effects of the opioid crisis on the citizens of this city. It is a major concern and very little services exist to mitigate or reduce the problem. We hope to bring forward a technical approach to tackling the issue, and as a community we can look out for each other and create a safer environment.
What it does
We created an emergency response mobile application where individuals who are heavily dependent on drugs, such as fentanyl, can receive the help they need in the event of experiencing a drug overdose. Our app immediately contacts 911, as well as any nearby registered responders who are carrying naloxone kits. Nearby responders will be able to attend to the victim quickly as they will arrive before the ambulances, which could give more time to transfer the victim to a hospital before reaching critical condition.
How we built it
We created the app using Ionic and Angular for the frontend, and Node for the backend. We integrated Google Maps to help the responders quickly locate and intercept victims of overdose. When an anonymous user sends the distress signal, all registered responders within a close proximity are contacted VIA Twilio services with an alert and are provided with a location. Responders are also given valuable information provided from the London Data Portal to assist with anything they may need.
Challenges we ran into
We were unfamiliar with Angular and Ionic coming into the Hackathon, which definitely ate up a lot of the development time. We encountered many bugs and difficulties when trying to integrate Google Maps and set up the connection with our backend.
Accomplishments that we are proud of
We had doubts about our scope for this weekend, and are super happy that we were able to put together a working project. We are also proud of creating a viable prototype that could have the potential of protecting many people from harms of drug abuse.
What we learned
We learned to take breaks when feeling exhausted, and looked out for each other. We found that by doing so, it creates a more positive team attitude and leads to greater success.
What's next for Lifeline
We were initially thinking about using the phone's sensor capabilities and ML libraries to autonomously detect if someone is entering a state of overdose, or adding a group chat functionality to allow close responders to communicate with one another from within the app; however, given the time frame, we did not think it was feasible. It would be awesome to implement in the future, though!
Built With
angular.js
google-app-engine
ionic
javascript
london-open-data
node.js
socket.io
twilio
typescript
Try it out
GitHub Repo


Normal User confirming a task sequence
Inspiration and idea
After attending Durham County Council's workshop and learning about adult social care, we sought to tackle the issue of the elderly and impaired not being able to do certain tasks we take for granted. These tasks can vary from fixing a chair leg to helping with personal budgeting. Oftentimes, these people rely on a friend or family member to do the task, but this may take days due to availability. What if instead they could rely on a local community of volunteers able to step up at the chime of a phone notification? We hope these small exchanges will strengthen cohesion in communities, bridge the divide between generations in the UK, and lessen the stigma towards disabilities.
System description
We chose to design an app as the platform to connect our two user bases: those in need of a task being done (Normal Users), and those willing to help carry out that task (Carers). The app allows Normal Users to create tasks and for Carers to search, view and accept these tasks. Normal Users will be able to see how many Carers have accepted the task they created, and can view each Carer's profile before confirming who they want for the task. There is a Comments section to each posted task as well as a messaging service on the platform to allow communication between a Normal User and Carer. Upon each task being completed, each party will be able to leave a review for the other. Reviews are public and contribute to a user's rating, which serve as a benchmark for Normal Users to assess Carers and vice versa.
Concerns we ran into
We acknowledged early on that the security of both parties is of highest priority. A solution may be for a DBS form to be required in setting up a Carer profile, or proof that a Carer is registered with a trusted organisation such as Social Care Direct or Age UK. There is potential for Durham University students to register with the university's charity committees such as Durham University Charities Kommittee (DUCK) or Durham University Student Volunteering & Outreach once these organisations have been trained and approved by the council. As for verifying Normal Users, it may be the case that they need to supply proof of disability or disability support.
What's next for hAccess
We acknowledge that this idea and proposal requires further inspection by the council to continue. If the council sees potential for this idea, we would be very happy to be contacted.
Try it out
GitHub Repo


The site uses google cloud integration to verify the user
Inspiration
The idea came from the ubiquity of similar apps for planes and trains. We thought that, just like how you book seats on those, you could book spaces in a car park. An ideal case for this would be a university open day. With so many people coming, parking would normally be hectic. Now, the people to book in advance, which would save the person the stress of finding a space and would reduce the traffic caused drivers looking for spaces of not there.
What it does
The site asks the user for their mobile and, once verified by text, they can pick a location and time (given there are enough spaces). 10 minutes before the time, they will be texted a reminder about their space. Currently, this is only available for some car parks in the university. By using firebase, it is easy to add car parks and spaces. Parking spaces can have any location, such as a floor in a car park, a street name or an address. This means it can be applied to any parking situation.
How we built it
The website was written with HTML and javascript. Firebase was used for the database and Twilio was used to send messages.
Challenges we ran into
It was hard to test and debug using firebase as it took a while to upload the functions to the server. Most of the team was unfamiliar with html and css so it took a while to learn the skills needed, but it worked out in the end.
Accomplishments that we're proud of
Learning HTML and CSS in a short space of time.
What we learned
Most of the team had little to no experience with javascript and HTML before starting. Going from that to a complete project meant learning a lot.
What's next for Parking Space Booking
We want to expand the capability of the time booking, allowing the user to book in advance and on repeat. This would mean that people that need to park there every day could be ready in advance. There is also a government database that lists all the parking spaces. An obvious next step would see this be usable across the UK.
Built With
firebase
google-maps
html5
javascript
twilio
Try it out
parkbook.tech


Overview
Inspiration
A lot of drivers are frustrated about finding a good parking spot, especially in downtown areas, so our team decided to create an application that would help them find the closest parking spot given their destination. This way, they spend less time wandering around for a parking spot.
What it does
This application acts as a navigator that will direct the user to the nearest parking spot to their destination and display a walking route from that parking area to the destination. Keep in mind this application only takes into account London parking data.
How we built it
We used Flask as the framework to build our web application, Google Maps API to display routes for the user, SKLearn to classify groups of parking spaces, FireStore to host our database, and Google Cloud to host our Flask web application.
Challenges we ran into
None of us have any experience with Flask and Firebase products so as a result, we struggled to deploy the web application to firebase for hosting purposes. In addition, it required a significant amount of effort to set up the database because the parking space data needed to be cleaned, processed with machine learning, and then stored for future use by the Flask application.
Accomplishments that we proud of
Finished this project in a day and a half
What I learned
How to choose the right machine learning method to solve real-life problems even with simple data like coordinates. We learned how to use APIs in conjunction with each other to extract and display the data we want. We also learned more about the end-to-end process of web development from setting up the database, developing the application, and designing the front-end.
What's next for NavPark
A viable feature for the future would be to provide multiple parking spaces for users so if one parking space is full when they arrive, the user can request for NavPark to redirect them to the next closest parking spot. Another robust feature would be for NavPark to determine if certain areas for parking, especially parking meters, will be all taken at a certain time and whether to ignore these areas from NavPark's considered parking spaces.
Built With
firebase
firestore
flask
google-maps
javascript
london-datastore
london-opendata
python
sklearn
transport-for-london
Try it out
GitHub Repo


Inspiration
There are many reasons why people eat alone. Maybe they prefer the solitude. Maybe they have a lecture at odd times that no friend of theirs is taking. Maybe they are new to TUM and don't have many people to eat lunch with yet.
For the latter reasons, wouldn't it be nice to bring people together at the lunch table? The casual and relaxed setting is great for building relationships of whatever kind without any obligations.
What it does
With our app, it is easy to find someone to eat with (a MensaBuddy!). Simply select a Mensa, enter a time interval in which you'd like to have lunch in (eg. 1-2 pm), and a minimum duration for the meal (e.g. 30 minutes).
Then, our app matches you with another user of the app, with whom you have an overlapping time interval with. To improve the quality of matches, we developed a set of psychological questions everyone answers, and a intelligent matching algorithm that takes a bunch of factors into account.
Very importantly, the matching is totally anonymous. You don't need to sign up, you just download the app and jump right in. Nobody will know anything about their MensaBuddy until they actually meet. We see this as an analogy to sitting next to someone randomly and getting into a conversation them.
After lunch, users can decide in the app if they would like to exchange contact information. Only if both agree, they can send a message to each other.
How we built it
As we had some prior experience with Android, we build a native Android stack with Kotlin. For the backend, we chose Firebase, which is very flexible, easy to scale and can be set up very quickly.
The matching algorithm is implemented in Node.js/TypeScript and runs as a Firebase Cloud Function. Conceptually, we used a stochastic Monte-Carlo like approach, sampling a number of different matching configurations among all users currently matching and choosing the "best" matching. This approach ensures that the algorithm yields good results, even with scale.
Challenges we ran into
As we both did not work much with backend systems before, it was quite a challenge to build a backend system this quickly. Fortunately, Firebase is quite intuitive to use and provides a lot of documentation.
In addition, developing a satisfactory matching algorithm was not easy. Particularly for large numbers of users, it is computationally infeasible to always find the optimal matching configuration. This is why we backed to a stochastic approach as described above.
Accomplishments that we're proud of
First of all, a working prototype! ;)
In addition, we gave a great deal of attention to our user interface and we're proud that is has become quite intuitive and aesthetically pleasing.
We also believe that we have developed a good matching algorithm that is well-suited to the problem, giving fairly satisfactory results considering its compactness. Also, it is easily scalable and can still process large amounts of users relatively efficiently.
What we learned
A learned a lot about how to build a project from scratch efficiently, and in particular how to set up backend systems. And one thing most of all - teamwork.
What's next for MensaBuddy?
The matching algorithm can be improved in various ways. One idea is to develop a neural network that improves the matching quality by looking at which people stay in touch based on their answers. This could substantially improve the matching accuracy.
Also, we would to extend the app to serve more Mensas (there are 33 Mensas in Munich alone!)
Finally, while we would like to retain the anonymity in our app, we recognize the potential for abuse. We plan to introduce a one-time email verification scheme, so every user must verify that they are a student by signing up with their university email.
Built With
android
firebase
kotlin
node.js
typescript
Try it out
GitHub Repo


Login Screen
TravelNut
We are nuts for travel.
Idea
Write out your travel bucket list and get trip suggestions. Check off all your destinations. Complete fun scavenger hunts and travel challenges. Compete with your friends. Let the app to guide you through visiting all of them.
Inspiration
We want to upgrade travel. We want to create a new way of experiencing vacations.
Implementation
We have used Adobe XD to create the application interface. In the future we will use Flutter to implement the UI. As for the information inside the app, we plan on using available data sets which include travel tendencies of different control groups. Web scraping can be a powerful tool for us to find the best possible trips available, or even a partnership with an existing service that provides trip consulting.
Challenges
The biggest challenge was combining our separate skill-sets and narrowing our ideas down to something that maximizes our potential and showcases our talents.
Built With
experiencedesign
flutter
live-travel-data
world-travel-and-tours
Try it out
GitHub Repo


Inspiration
Our idea araised from seeing how some unfortunate individuals have sparkling ideas but struggle financially. We would like to act as the medium between them and certain commercial banks that might be interested.
What it does
It helps young entrepreneurs to fulfil their business dreams through applying our app, once their proposals are approved by the Commerical banks. We are dedicated to showing a high success rate of helping the entrepreneurs to get approvals than them directly applying themselves or through other agents. What we offer is guidances and what they need to know when they are applying for angel funds. Since time is money and they can definitely save some money through us!
How I built it
Creating accounts to Capitalone and saving the information to the database
Challenges I ran into
Getting all the technology stuff working and everything, which includes Twilio. Also, it took a long time setting everything up initially. We have a long working system.
Accomplishments that I'm proud of
The database is working!
What I learned
Twilio is not very useful in terms of the texts. we had to change it from the US to UK credit base. We tried to figure out what Twilio returning to.
What's next for Yunus Finance
Built With
angular.js
express.js
ionic
mongodb
node.js
trilio
Try it out
yunus-finance.herokuapp.com


Inspiration
Almost 1.5 million students enter Indian engineering colleges per year & almost 80 percent of them graduate to not be fit for any job in the knowledge economy. The top most contributing factor to this is lack of quality teachers & curriculum (https://www2.deloitte.com/content/dam/insights/us/articles/6322_future-of-indian-higher-education/figures/6322_Fig1.jpg). While online courses from top universities like MIT, Stanford do offer very high quality content. But, their conversion rate is at 3%.
What it does
Index spawns very low cost peer-to-peer driven physical learning communities. It brings high quality education content from universities like MIT, Stanford and mentors from top companies & startups to the students with a hope that carefully built communities will have way higher conversion than 3%. Index's mission is to improve the quality & diversity of higher education in developing nations.
How I built it
I built the website using Material-UI Theme (from Creative Tim), ExpressJS & React. I used Google Sheets for storing data, Mixpanel for analytics, FB ads for running A/B tests & Render for deployment.
Challenges I ran into
Building brand of Index to drive it's adoption.
Built With
express.js
javascript
material-ui
node.js
react
render
Try it out
index-1z9v.onrender.com


Inspiration
We were listening to the pitches at the opening ceremony, trying to jot down keywords that would maybe spark an idea. One of the phrases that I wrote was "Uber but for a more focused group".
Later when I pitched the idea to the team, everyone seemed to like it, so we ran with it.
It is another story that we have no inspiration left to actually implement the idea. We just cannot be bothered.
What it does
It's an app that lets OAP create one-off tasks that they want to be done for them. The two actors for our user story are a tasker and a taskee. The tasker sets the tasks, accepts requests and reviews the task. The taskee views and picks the tasks, does the task and gets redeemable points.
How I built it
We did not. We spent way too long struggling with MongoDB. Then set up Google Cloud Platform and Google Actions. Did something with Raspberry Pi, and created a really ugly looking single page pretotype of our idea (it is sort of better than a ppt presentation but not really)
Challenges I ran into
Lack of dedication. MongoDB. Trying to learn react. Trying to learn google actions.
Accomplishments that I'm proud of
Oooooo we finished a couple of levels of overcooked, that was a pretty amazing accomplishment. Won a few matches in super smash bros (Kirby is the best), which was a first. Super proud about my gaming adventures, might mess around and became a gamer twitch streamer. Like. Share. Subscribe.
What I learned
The full form of OAP. Not to misspell OAP Taskr as OAP Trackr.
What's next for OAP Taskr
Maybe actually implement the idea at some point, but not really?
Built With
css
html5
javascript
json
mongodb
pencil
react
Try it out
GitHub Repo


Inspiration
John Hammond's Smart Choices lays out a scientifically proven method for effective decision making which can be used alone or in a team to make the right choice. This method can be time consuming, involve some math, and hard to remember, so we built a tool that enables a group of people to put this scientifically researched method into action together.
What it does
Our app allows multiple users to simultaneously participate in a decision making problem, with real time updates presented to each individual. The system guides its users through the process of identifying the alternatives they wish to select between, the criteria on which they wish to make their decision, the relative weighting of those criteria, and how each alternate stacks up on each of the criteria. In the end, the user is presented with a table representing the information we collected from them.
How we built it
We built this app using Socket.io and React. Our server ensures that collaborators can see changes in real time, with each addition by a colleague showing up, and progress through the process synchronized between browsers.
Challenges we ran into
Concurrency issues due to simultaneous processing
Working with new tools to us like Socket.io React
Accomplishments that we're proud of
Building an end to end product that we're excited to use ourselves, and share with friends
At most companies, poor operational decision making compromises upward of 3% of profits, according to research by Gartner, we're proud to offer a tool firms can use to combat this.
What we learned
How to dig deep when challenges threaten to block you.
What's next for Decidely (decidely.co)
We're keen to build in a deeper account system to allow users to keep track of their past decisions, and add features that identify dissenting or polarizing elements of a group decision based on the distribution of submitted values.
Built With
apache
bulma
css3
html5
javascript
node.js
react
socket.io
Try it out
decidely.co


Inspiration
As a pet lover, it is really hard to to a right pet service. Wanted a tailored platform for pet owners.
What it does
Find the best matching pet service on our platform and book through us.
How we built it
Leverage web technologies such as React, Node,AWS. Conducted surveys on Facebook
Challenges we ran into
Optimizing our search functionality.
Accomplishments that we're proud of
We finished a MVP
What we learned
Building a cohesive web app is really difficult and build a web app that meet the convergence of developers' objectives and end users' needs.
What's next for PawAdvisor
Get funded
Built With
amazon-web-services
css
golang
google-directions
html5
node.js
react
redux
stripe
Try it out
pawadvisor.co


Landing Page
Inspiration
In today's society, it is very difficult for insurance companies to connect with customers directly. Since everything is online now, so there is less direct communication between the clients and companies.
What it does
We created an algorithm that matches insurance brokers with people who are seeking specialized insurance packages within their price ranges.
How we built it
We created a REST API with NodeJS and ExpressJS connecting it with a MongoDB Cloud Database. We used ReactJS for the frontend.
Challenges we ran into
Coming up with the idea to solve this problem and trying to implement other 3rd party APIs.
Built With
express.js
javascript
mongodb
node.js
react
Try it out
GitHub Repo


Inspiration
Thomas always felt like there was so much to do in his hometown Sonthofen but most tourists only get to see the ski slopes. Therefore we created an application that helps travelers to get the full Allgäu-experience.
What it does
Spätzle-Jagd is not just another boring coupon app that promotes businesses to you. It connects you with locals and other travelers while providing you with awesome challenges that make exploring your surroundings even more exciting. You'll get a whole bunch of local experiences other people enjoyed. In order to get exclusive discounts from our partners you have to share proof (in form of creative pictures and funny quizzes) that you completed the challenge with other tourists.
How we built it
We used the latest and greatest tools for creating android apps: Android studio was used for our apps front-end while plan on creating an node.js back-end server in order to actually connect the users.
Challenges we ran into
Neither of us has ever build an android app before. Learning such an amount of new concepts within just a few hours sure was a challenge but it was also a super fun an interesting opportunity.
Accomplishments that we're proud of
We're really proud of the idea of building an tourism app that stands out of the mass by combining fun concepts from excising traveling services, social networking and mixed reality gaming!.
What we learned
We gained a surprisingly broad knowledge base on app development.
What's next for Spätzle-Jagd
Next we need to add more things to do in the Allgäu until users are willing to use and contribute to the app. Additionally the concept only works if there are interesting local partners. Finding these should not be very hard though, since they benefit from the application as well. There is of course still room for improvement from a technical point of view. For instance users can't create accounts yet.
Conclusion
Not only did we make a objectively great app, we also had a lot of fun while we were at it!
Built With
android
java
node.js
sql
sweat
tears


Inspiration
While reading about disruptive finance initiatives, micro finance isn't the usual thought for most people, however, we thought it also has some of the most untapped potential within the financial sector with plenty of room for innovation.
In a lot of places worldwide, people do not have local access to a bank so cannot get funding for any sort of ventures. This is where microfinancing fits in, an NGO takes the role of banks/governments to provide small, short term loans to encourage ventures and cover cashflow issues.
However, even within this industry, access to microfinancing and NGO’s is still limited or non existent in many areas, especially rural. This is where our platform fits in; it provides a platform for both people looking for finance and NGO’s providing them to access each other through the use of an app for the client looking for finance meaning they do not have to leave their home to travel to an NGO. This is beneficial for both sides here as it widens the potential pool significantly of who can access finance as well as streamlining and automating a lot of the service provided by the NGO’s by giving them a web platform to look at and accept/reject applications from. This combination of both platforms working in tandem gives a solution which would bring microfinance to significantly wider pool of people and digitising an NGO/government for very little cost and investment from their side.
What it does
Our platform has a client-sided app in which a potential applicant would sign up and fill out a preliminary application form. From here, on the website side, an NGO would look at the basic application details and decide whether or not to progress the application to the next stage where the candidate would be informed they have progressed to the next stage. This can all be monitored from the NGO's web page while the candidate would be able to monitor the application from the app.
In the end, if they're successful then various payment methods would be given depending on the particular NGO and location of the applicant.
How we built it
As of right now, the app has been built in Kotlin with our backend database being built with MongoDB and hosted on Google Cloud. This gives us a dynamic database that is stored independently of the application meaning it can be accessed elsewhere such as our webpage with no issues. We used Django to build the webpage backend for the NGO's to use for monitoring and modifying applications, it has good integration with MongoDB meaning an online database can easily be accessed for information.
Challenges we ran into
The challenges we faced included learning Django from scratch and building a functional, proof of concept website within the time given and integration with our API.
Accomplishments that we're proud of
We're particularly proud of the application as it is well built and developed, along with an API made for our database the backend is also pretty complete.
What we learned
We learned how to use MongoDB Atlas as well as Django to build a database and web application to implement and access it, this has been a good learning experience.
What's next for μFinance.Me
In the future, we would like to potentially add in the integration of smart contracts on the ethereum blockchain network to store contracts between NGO's and clients, this improves accountability and transparency as well as assisting in decentralising and making the system trustless to reduce inefficiency and corruption within the industry.
Also deeper integration into our django website to potentially include machine learning insights from Google Cloud on the DB. Deeper Twillio integration to allow texts to be used for notifications and potentially applications themselves for people without smartphones.
Built With
css
django
html
kotlin
mongodb
python
Try it out
GitHub Repo
GitHub Repo


Inspiration
Many elders and those with disabilities are unable to partake in the world as most young able bodied people are able to; whether that's from lack of knowledge on social medias, anxiety from interacting with people who may not be experienced in socialising with disabled people, or simply being wanting support from people who have gone through the same challenges / know the conditions they suffer from. Having seen first hand the impact of severe physical disability on social interaction and mental health, we believe it necessary for the well being of the isolated to find community and friendship when they most need it.
What it should have done
Our social media like website is a forum for the elderly, disabled, and their carers to find one another, users will be shown the profiles of people that share similar situations, location, and interests in order to connect, offer support, or potentially find a hobby group / people with shared interests. User's will also be able to post events happening in the area or invites to activities (for example, going to the cinema, a board game night, etc). User's will be able to message with other users they have been connected with if they so choose.
How we built it
The back end was built MongoDB and python, with the front end being html and JavaScript. The website was going to be hosted on Google Cloud. The problem however was bringing it all together.
Challenges we ran into
We were too ambitious, so it is clear that the end result will not be as we hoped; however it is still a project worth attempting, and we gave it our best, with better planning I believe we could have succeeded. The bulk of html / profile editting that was needed was more than we expected, and was probably the most nerve wrecking aspect, had we started with this and built up it would have been more manageable.
Accomplishments that I'm proud of
Our database on Mongo was particularly intriguing to put together, and the team member tasked with setting it up did an amazing job with no prior experience which we were particularly happy with.
What we learned
We have learnt the basics to some tools that we hadn't even heard of before, such as Mongo and Flask; similarly, for those more experienced in computer science, there was certainly growth in tying all the aspects of the code together and getting it all to communicate in the desired manner. Although we did not complete the project in the allotted time, we gave it a good shot and tried new things.
Built With
flask
geopy
google-cloud
html
javascript
mondodb
numpy
pillow
pymondo
python


Inspiration
If we can fix education, we can eventually do everything else on this list. - Y Combinator
To provide top-quality education, we need top-quality teachers. While teaching is a rewarding career, it is also extremely demanding due to its long hours and heavy workloads. Without proper support, teachers are in danger of being overworked and not taking care of their own mental and physical health needs.
Teachers practicing self-care is a potential solution to providing all children with a quality education (UNICEF - whole child development), decreasing teacher churn and improving teaching experience. It is predicted that by 2030, we would need 69M new teachers globally.
What it does
Coach Lisa is a next-generation mobile health improvement tool partnering the science of behavior change with the power of social connectivity for the roughly 80 million teachers working within PK-12 globally.
We have evidence-based research to show that self-care works. We know self-care is within the grasp of every person. We know our science has improved teacher retention and more. So what are we doing now?
Well, we believe LISA is about to utilize mobile technology to support and unlock the power of our world’s most organized and powerful agents of change — teachers who are healthy, well and connected.
How we built it
Angular, Node.JS, PubNub
Accomplishments that we're proud of
Prototype V1.0 developed at the hackathon in under 20 hours.
Team
Coach Lisa is the brainchild of Lisa Marquart - founder of Baton Health and a Stanford-trained behavior change coach with 25+ year of experience in the domain. Bringing her vision to life is Vidur S. Bhatnagar - founder of Keriton - technologist and product expert who was the youngest product owner (globally) at SAP. Keriton was founded at UPenn on an award-winning hackathon idea, judged by YC Partner - Kevin Hale.
What's next for Coach Lisa
We plan on launching LISA in WA and CA as the co-founder/CEO - Lisa Marquart - already services these regions and their teachers via her behavior health company - Baton Health.
Built With
angular.js
graphql
node.js
pubnub


Dolly
Inspiration
Cloning people is not unethical
What it does
Clones people
How I built it
With python and lots of love
Challenges I ran into
Everything
Accomplishments that I'm proud of
The prject
What I learned
My teammate is really competitive
What's next for Dolly workers
Start cloning real people
Built With
keras
python
tensorflow
Try it out
GitHub Repo
drive.google.com
www.flaticon.com


std-terraform
Inspiration
As a big data developer on my co-op term I use Terraform to create infrastructure as code (IaC) on Google Cloud Platform. While creating infrastructure, I wanted to have a simple way to see what infra I deployed and to what project.
What it does
std-terraform is a Slack Bot & Github Infrastructure as code integration. When a developer pushed new code to Github to create new infra a Slack message is sent to a channel describing the infrastructure bing created.
How I built it
I used the std library to create the slack integration and used Google Cloud Functions to do the backend data processing to find out the created infrastructure.
Challenges I ran into
The std lib does not have an easy way to process data from Github so I had to work on Google Cloud Platform to do data processing and pass data back and forth.
Accomplishments that I'm proud of
I was able to create modular and scalable code based on a serverless microservice structure. It successfully tracks Terraform infrastructure and passes back the modules in a user friendly manner. The code I created is all open source and free for anyone to use under the MIT license.
What I learned
I learned how to use the std library and learned how to create an open source tool.
What's next for std-terraform
I plan on integrating std-terraform at my co-op position to easily display all the infrastructure on our large infra.
Built With
cloud-functions
google-cloud
python
stdlib
terraform
Try it out
GitHub Repo


Inspiration
The lack of availability of clean water poses an acute problem, particularly for First Nations communities across Canada. Inspired by RBC's challenge of tackling a problem for a community we care about, our team created Glass Half Empty, a poignant game with a serious message.
What it is
A narrative game with custom illustrations and voice enabled interactions to immerse the player in the story of an ordinary Western University student visiting his friend's home on a reserve in Garden Hill, Manitoba.
The character encounters several interactions throughout "Level 1", which is the "becoming aware" stage of the game. By realizing the impacts of unpotable water in these communities, the character has the ability to "take action" (progressing to level 2) or ending the game and thus losing. Although we've only developed Level 1 during Hack Western, the idea is that the character would go through levels 2 and 3; taking action (level 2) and then impacting others through various methods such as advocation and presenting in classrooms (level 3).
How we built it
The game was built with the d3.js framework, using Google's Dialog Flow to create and implement the voice interactions. The graphics and user interface were created in Adobe Illustrator.
Challenges we ran into
This project, and game design in general, was new territory for all of us, so it was both a lot of learning and a lot of challenges. Communication between design and development had to be navigated, and several reiterations of design were re-done but in the end we were able to come up with a completed game.
Accomplishments that we're proud of
Conveying an important message through a unique medium, and of course, seeing a project through from start to finish!
What we learned
For some of us, this project meant learning entire libraries in just a couple hours and exploring voice implementation; for others, designing for the nuances of game design and voice interactions. For all of us, this project proved to be a really great learning experience in not only technical skills, but also in collaboration and storytelling.
Built With
adobe-illustrator
d3.js
dialogflow
javascript
photoshop
Try it out
GitHub Repo


Schedulr
Inspiration
We started out brainstorming wondering about how hard normal routines must be for people struggling with mental health issues and how few resources there were for helping improve their daily lives. So our original idea was meant for those demographics and it was created to ensure they didn't become overloaded with work, and we wanted to help them decrease their stress levels.
What it does
Schedulr is an accessible platform on slack that can manipulate your google calendars schedule of your daily tasks by getting rid of events, moving events, or scheduling breaks in between events depending on the answers which are given through various questions asked by a bot set up on slack. The bot can also set reminders, and display the overall calendar to see how the day looks.
How we built it
We split the tasks up and then integrated it into a bigger complex task. The 3 separate tasks were; getting the google calenders set up and fully functioning for teams and individual members on slack, activating and setting up the functionality of the bot, and creating the API's which would bridge the gap from the calendar and the slack bot to allow the bot to perform the functions it was intended to perform.
Challenges we ran into
The biggest struggle we faced was when it came time to incorporate the API into the slack bot functionality. We had very few resources to go off of and had to essentially trial and error our way through it, which took a pretty long time. Luckily, we each had different strengths in different departments and were pretty adaptable to overcome the challenges we faced under the given timeline we races against.
Built With
googles-api's
javascript
slack-api
slack-bots
uipath
Try it out
GitHub Repo


Inspiration
ML products will have a larger impact than ever before as more and more companies incorporate business-critical machine learning products and models into their businesses and production systems to assist in essential workflows. This makes the need to find bugs and fix issues paramount challenges. Additionally, for many of these models, especially deep networks, it's not clear how to formally define or solve these problems. This is why we built a platform that uses the power of crowdsourcing to find and address bugs in machine learning systems.
What it does
Bug bounty platform for finding issues in machine learning systems.
How we built it
We split work between a frontend, backend, and several machine learning APIs that we ran on remote EC2 servers. The frontend was built using react.js and next.js, running as a single page application in the browser that is server-side rendered. The backend was built using bottle.py with sqlite3. It consists of an API that handles user account management, managing the testing suite, and handling remote requests to servers hosting ML models. Additionally, we had a built-in fuzzing module that added random gaussian noise to images to try and break the ML models. This would then email the user when their model was broken, and with the specific input.
Challenges we ran into
There were a lots of moving parts with this architecture, as we not only had the traditional fullstack application, but also had to outsource computation to external services. Additionally, because none of us were designers or UX experts, figuring out how to implement a clean and consistent frontend and user experience was a challenge.
Accomplishments that we're proud of
We're proud that we build a real and functioning product within the span of 24 hours that works for image classification tasks. We resolved many backend issues including authentication, server coordination, fuzzing and image transformation, as well as efficient storage and ranking algorithms for search and leaderboards.
What we learned
Initially, we started out with a project that could automate software patches using AI. We learned that automated software patch generation is a lot more challenging than initially suspected (as in, 5 years and a team of PHD's). We learned to iterate quickly, and decided to pivot to a marketplace for machine learning security. This is a far more tractable problem, and with no less impact.
What's next for Patchwork
We are looking to expand our testing suite to validate ML models designed for different product classes such as image recognition, text processing, and audio. We want to find startups with ML products that would be willing to pay out for bugs found and hackers who want to play with ML products.
Built With
amazon-web-services
bottle.py
keras
next.js
python
react
tensorflow
Try it out
GitHub Repo


Home page
Inspiration
The idea for Memolytic originated from one thing that everyone on our team had individually aligned with, which was that we enjoyed tracking our day-to-day activity via journalling but found it challenging to find the time and motivation to create entries every day.
What it does
Memolytic turns the act of journalling into a habitual conversation with your virtual assistant of choice right before your go to bed each night. Your responses are recorded, converted to text, and analyzed using a text-blob NLP algorithm to measure the state of your overall wellness across 7 dimensions (environmental, emotional, financial, social, spiritual, physical, and intellectual). Armed with this information, you can identify areas of your wellness that merit more attention, allowing you to become a more mindful, happy person.
How we built it
Memolytic was built using three main components. First, a Voice User Interface (VUI) was used to interpret the spoken responses and save to the MongoDB database. Second, two servers were established to store journal data and transfer and interface with the data. Lastly, an open-source NLP library was used to evaluate the _ polarity _ (i.e. degree of positivity or negativity) of each response.
Challenges we ran into
The biggest challenge we faced was while attempting to successfully interface among a wide variety of tech stacks (Python, Node.js, Google Cloud, MongoDB, Voiceflow, and JavaScript frontend), since they all had different requirements and operated on their own terms. Another ongoing challenge we had was in debugging JavaScript... it was like prime-factoring, there's simply no efficient way to do it :(
Accomplishments that we're proud of
The thing we accomplished this weekend that we are most proud of was being able to reimagine journalling by integrating the act of daily individual reflection into a normal nighttime routine.
What we learned
The two most valuable things we learned through this project were 1) the concept of the "7 dimensions of wellness" and how each dimension plays a critical role in ensuring good overall health, and 2) using voice as a data stream and a user interface.
What's next for Memolytic
There are many potential avenues for Memolytic. Down the road, the platform will be able to provide personalized recommendations in order to improve overall wellness by prompting more insightful user responses and integrating their daily calendar to optimize productivity and mindfulness efforts.
Built With
css
dialogflow
express.js
google-cloud
google-home-mini
html
javascript
jquery
mongodb
mongoose
node.js
pymongo
python
textblob
voiceflow
Try it out
GitHub Repo


Measure.me personal A/B Platform
Measure.me is a voice-enabled personal experimentation platform.
What does it do?
Measure.me guides users through any personal experiment, from health to social interactions.
Use Case of Mesure.me platform
From experience in Health Innovation in subsaharien Africa (English Speaking Kenya) healthcare access is limited, people often diagnose and treat themselves. When they see a physician, they don't communicate their self-treatments (exercise or antibiotics). Also, there is a lack of overall medical history(records) and EHR systems are limited and fragmented due too low funding and infrastructure.
Issues
Patient often don't have access to quality healthcare. They create their own treatments and preventive care routines which they don't document. Their effectiveness is unknown and treatment history is not recorded.
Health records are not document properly, not owned by the patient, are paper based and not easily transferred between clinics.
Often doctors from Europe and North America come for short periods of time see patient and then leave. Or, patient see many different doctors.Therefore the original diagnosis is not tracked and treatment is not monitored and followed-up. which results in inconsistent patchy healthcare.
What it does
Documents wellness and personal treatments (valuable for medical history and useful for insurance compliance)
Dictates patients conversation with physician (For subsequent physicians understanding)
Dictates Physician notes (paper based and often lost)
Outlines physician treatments
Allows users to input data
Shows results of treatments.
How we built it
Created a statistical model in python
Developed UI
Explored market use cases
Conduct Market Research and competitive analysis
Challenges we ran into
Recruiting teammates Verify product market fit Determining how to create a fitting statistical model
Accomplishments that we're proud of
We Made Something We built a tool/platform that patients, physicians, and insurers in subsaharien Africa really need. Also built the ability for the platform to be used in many different use cases Ability to use NPL for dictation and use of a medical vocabulary
What we learned
Finding a team of good people is difficult People in the bay area are obsessed with self optimization A generic platform can be use in many ways, but specif uses cases allow for better product market fit
What's next for Measure.me
Partner with insurance providers in subsaharien Africa , AMRAF and an influential hospital networks.
Further test and iterate MVP
Create a Pilot
Start bettering peoples lives!


Crake
Unsupervised crack detection and more for microscpopic metal surfaces. Uses no deep/machine learning but just image processing from opencv.
Components
Cracke has the following components:
Image Processing Pipeline (bounding_box.py)
Median Blur Filtering
Canny Edge Detection
Morphological Segmentation
Bounding Box Generation
Crack Estimation Pipeline (report_output.py)
Approximate Crack Length 2 Use Paris Equation for crack propagation
Compare with standard loading for a given material
Report Generation Pipeline (generate_report.py)
Status of the material
Analysis of the image
Estimate crack start and cause
Generate report
Flask App (run.py):
Contains the flask app code for the HackaTUM 2019 demo presentation.
Cross Platform App (/my_app/)
Coontains code for the ionic app.
Requirements
python dependencies - see 'requirements.txt' other dependencies: ionic.
Running the App
go to /app ionic cordova run browser
for server go to /server python run.py
HackaTUM Presentation: Click Here.
Devpost Link: Click Here
PS: The entire pipeline was coded in a day for the hackathon and therefore is crude and raw and at times even unintelligeble. We'll try to fix bugs and clean up the code as much as possible. In the meanwhile please also feel free to fork and contribute to our codebase.
Contributors
Aadhithya Sankar
Abinav Ravi Venkatakrishnan
Jyotirmay Senapati
Abhijeet Parida
HackaTUM 2019
Built With
batchfile
c
c#
css
html
java
javascript
jupyter-notebook
objective-c
python
typescript
Try it out
GitHub Repo


Inspiration
When Flappy Bird was released onto the App Store about 6 years ago, it fundamentally changed the mobile gaming landscape and impacted all of our lives drastically. So when MicroFuzzy gave us their hardware list, we knew what had to be done.
What it does
An Arduino checks for accelerometer input that is then being fed to an Android device via bluetooth.
How I built it
Using an Arduino Nano, a HC05 bluetooth module and an mpu6050 accelerometer on the hardware side. We used Android Studio for constructing our port of Flappy Bird.
Challenges I ran into
Figuring out how to connect the bluetooth module, the accelerometer and the Arduino with one another
Accomplishments that I'm proud of
The fact that we did not have any real setbacks that took some 20 hours to fix.
What I learned
We learned how I2C works, what can be achieved with Android Studio and how versatile an Arduino Nano truly is.
What's next for Flappy Bird with motion controls
Maybe we'll seize work on the project, maybe we'll tape the controller to a pidgeon and teach it how to flap it's wings. We don't really know what's next.
Built With
android
arduino
c
java
Try it out
GitHub Repo


Manna
Knowledge workers spend a majority of their time on repetitive menial tasks which prevent them from focusing on thoughtful work which they thrive to do. After talking to several knowledge workers in consulting, banking, marketing, etc we realized that a majority of these undesirable tasks involve locating sources of information and pulling data from them. And thus we built manna to solve this problem.
Manna is a browser extension that let’s users quickly retrieve information from their documents. When working on a document or email users can press cmd+e to call manna which analyses the current context and recommends them the most relevant pieces of information from their online and offline files. They can also query manna to find more information.
How we built it
As a proof of concept, we scraped and indexed public SEC filings. Then we developed search algorithms that would direct the user the correct part of the document when queried.
Coming up with a good search algorithm was hard, we tried Word2vec, Whoosh and bi-direction transformers (BERT) and in the end we did multiple levels of search granularity, starting with a high level search to find related chunks of documents and then a finer grain search for finding desired phrases.
Based on the page the user is at we create a context vector and combine it with possible search queries that a user might have. Then we feed this request to an initial coarse search that uses Whoosh to narrow down which section of which document to look into. Then we used Word2Vec and bi-directional transformer models (BERT) to find the sentences that are related to what the user wants to see.
On the front-end side we developed a chrome extension that has a search UI that queries a flask server and display the most relevant search results.
In the end, we successfully developed a ready to use chrome extension that let’s us search our documents much faster than
What’s next
Despite the universality of our problem space, we think private equity firms are the perfect beach head to start with. A typical private equity analyst receives 1000 documents every few weeks on Intralinks or box and has to make sense of the data and analyze it in the next two weeks. The current products have a frustrating user experience mainly because of an incentive misalignment in the market. The customers of cloud drive services are banks that are trying to sell their companies not not the buyer private equity firms that need to analyze the documents. Because of this the current solutions serve the needs of the seller and not the buyer and thus don't have any notion of fast context-based search. Therefore, we think there is a market gap and an easy to adopt local chrome extension can help them reduce their current 8-10h time of understanding the structure of documents in a data-room to less than 4 hours.
We believe this can be a first step towards a self-driving browser that automates thoughtless parts of work and lets us focus on what we are best at.
Check out our work!
GitHub - behzadhaghgoo/manna-yc
Built With
bert
flask
javascript
python
pytorch
Try it out
manna.plus


Viable pioneers take care of all these to make a beneficial gathering. Recuperation Specific Losses Loss is an unadulterated part of the act of recuperation. Call your doctor for restorative counsel with respect to symptoms.
What You Need to Do About Togel Contrast Starting in the Next Two Minutes No store remunerates moreover have wagering necessities you should complete before it is conceivable to pull back your prizes in the occasion you've been lucky. Indeed, even surely understood and reliable organizations have taken alternate routes that have prompted dangerous weapons and harmed notorieties. Aside from putting away at a web betting club by methods for your credit or charge card, there are a few electronic decisions most by far of which give minute help trades without the related issue and high costs.
The technologist will do the test when working at a Togel Singapore PC past the room. The degree of oliguria can be variable relying upon the time viewed as zero'. You, in light of the fact that the organization client, have really an approach to look at over the composition to have the option to discover most of the unacceptable parts or a few mix-ups. In the event that there's an image of you on our site and you don't give it a chance to be shown on our site, if you don't mind educate us by means of the contact page. So kids require an outstanding way to deal with client examine for various reasons. Float over the hover to verify progressively advanced subtleties.
As the hydrogen particles come back to their standard arrangement, they emanate different measures of vitality dependent on the sort of body tissue they're in. In any case, every immunosuppressive medication increment the threat of disease and need to get utilized with alert. Greater solutes will approach an increasingly reduced volume and the other way around.
It is astounding how a couple of foundation hues can impact the arrangement of a site. As we choose how to execute these foundations, we should remember that every single foundation adds to the complete look of our site. Watchword esteems may likewise be joined. The program will in this way manage the progress between the two hues. Append another needle preceding each utilization.
It was made to help expelled follicles since they form into develop eggs. Endeavor to anticipate utilizing clear glass cups and dishes as they are normally all the more testing to see. Going for brilliant shades is suggested. Regardless, most of the stages give some kind of an arrangement wizard that will oversee you get past the development of your absolute first shop.
Essential Pieces of Togel Contrast Recorded as a hard copy a differentiation article, you must give close consideration to the structure or configuration you're following to watch out for the stream. On the off chance that result doesn't again fulfill you, pause for a moment to copy the methodology. A MRA test may or probably won't use differentiate material.
Brief appropriation of high phenomenal models is significant at our paper administration that is composing. One must pass on in a language that is not one's very own the soul that is one's own. Interesting points before playing.
Living day to day After Togel Contrast It's startling on the grounds that its lone applications have been associated with the absolute most significant wrongdoings against mankind ever. I only here and there utilize both of the previously mentioned. You will be provided with earplugs or earphones to reduce the sounds made by the scanner. What's more, it is easier to clean moreover.


Inspiration and What it does
We've got a modular system that adapts dynamically based on real world data and sensors. We've built that solution based on long tested software frameworks and technologies while using a flexible approach. This allows the user to set a lot of logic based on complex rules.
How we built it
We get the data from the Arduino with SigFox, process it with a backend made with Flask and IFTTT and then send the data to a Laravel based frontend with advanced chart javascript frameworks. On top of the frontend we've built an Android app that has the same functionality.
Challenges we ran into
As our requirements evolved we had to improve the performance of our application to manage Heroku requirements. We also had some very extreme limitation coming from SigFox.
Accomplishments that we're proud of
A modular, complex, and highly customizable system based on which one can create and customize advanced rules based on sensors and real time data while being extremely efficient in the process.
What we learned
To use SigFox in very contraints enviroments of computation and data transmission
What's next for The Pink Core
Rebuild the components with more mature technologies like Django
Built With
arduino
c
flask
ifttt
iot
laravel
php
python
Try it out
GitHub Repo
GitHub Repo
GitHub Repo


Inspiration
As developers, we know that writing documentation is a chore, but high quality docs are invaluable. We make it easy to write docs, simple to keep them up to date, and help you view them when you need them most.
What it does
It is an editor plugin that lets you write documentation side by side while you write code. Describe what your code does while it's fresh in your mind, not next week.
How we built it
VSCode editor plugin as the client
Flask server to communicate with the client, generate html, process data
Mongodb database as our document store
Challenges we ran into
Dealing with multiple users working on the same comments was tricky. Keeping track of comment locations in a source file was hard (until we found a better way!)
Accomplishments that we're proud of
We quickly put together a bare-bones version of our product, and used it while building out the rest of the features. By using our own software from the first step, we learned a lot about how users will interact with our product, what makes it valuable, and what features are a priority.
What we learned
Even for a 2 person team, written documentation makes communication easier, and bugs less frequent.
What's next for Hyperdoc
Launch :)
Built With
flask
gunicorn
markdown
memcached
mongodb
nginx
vscode


Logo
Inspiration
Meeting new people while traveling does not have to be hard. That is why we created Outdoorly.
What it does
It lets you book activities/ hotels/ rent a car either with your friends or you can connect with complete strangers from all around the world who share the same mentality. It also helps you split the costs more easily.
How we built it
We use SwiftUI Framework to implement the most used features for our next-gen app.
Challenges we ran into
Finding the best way to connect people while not giving away privacy.
Accomplishments that I'm proud of
That we found an impactful idea and implemented it in a day.
What we learned
Time management, working under time constraints. Coordinate tasks efficiently within the team.
What's next for Outdoorly
Spreading the word and making it worldwide
Built With
switft
Try it out
GitHub Repo


Logo
Inspiration
We wanted to create a project that could help improve multiple aspects of society at once, while still being a simple and practical implementation, where the results can be understood by people who are not experts in technology. We believe we can help the City of London by showing, from period to period, what alterations need to be made in the traffic lights to help increase the flow of traffic, decrease commute times, improve the economy and decrease emissions.
What it does
Our algorithm runs in a simulation and learns, through AI, how to optimize the intervals of the traffic lights to decrease the average number of cars stopped at any given point in the simulation.
We picked an intersection next to where we live (Oxford St W & Wharncliffe Rd N) and used data from the City of London Open Data website to populate and try to simulate the intersection. The Traffic Volume data was especially helpful. Also, we believe the similarity is fairly high, considering we had limited hours.
Average number of cars stopped at any given time before optimizing: 3.22088 Average number of cars stopped at any given time after optimizing: 1.653533 Improvement: about 96.9%.
How We built it
We used and modified an open-source implementation of the simulator, called CityFlow, using a docker container. There, we create our own model for an intersection similar to the one we live nearby. The optimizer and gradients were created in python using machine learning (scikit-learn) using auxiliary libraries from calculating gradients.
Challenges We ran into
Creating the reinforcement learning model was definitely the hardest challenge. We didn't have that much experience so we struggled. But in the end, we manage to create a solution that worked, so we are proud of that.
Accomplishments that We're proud of
We are proud of having finished a hack that can be used in real life by cities.
What We learned
We learned how to use docker, improve our c++ and python knowledge, and had fun working as a team.
What's next for SmartCommute
We plan on making our simulations bigger, more realistic, and improving our reinforcement learning algorithm so it learns better. Our vision was to be able to provide automated monthly traffic advice to the City of London on how to improve the traffic lights, at a low cost, without having to add additional hardware to the traffic lights.
Sincerely, Caio and Matthew
Check our Github Link for GIFs of before & after
BEFORE
AFTER
Built With
c++
docker
git
json
machine-learning
python
scikit-learn
Try it out
GitHub Repo


Inspiration
Smile
What it does
Transforms speech to funny sounds
How I built it
Swift
Challenges I ran into
Integrating with iPhone
Accomplishments that I'm proud of
What I learned
What's next for Pitch Perfect
Team members: Zulia Shavaeva Jonathan Digweed Maksud Rahman Viv Mehta Edward Hayes
Built With
swift


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for noSuicideSquad
Vibrant Safety Plan
Try it out
GitHub Repo


Website
Inspiration
The challanges and the theme of the hackathon inspired the idea
What it does
Shows you local projects in the community that need funding. You can contribute donations or micro-loans to local businesses, projects or individuals. This would allow you to contribute and help improve your local community.
How I built it
Python, Flask, SQLite to build the backend and the set up the database that we are using. We are using Javascript, React JS, HTML to build the front end of the website.
Challenges I ran into
None of us has used Flask or SQLite before, so the challenge of learning it quickly and getting a database up and running. We did struggle with the relationship between the databases for a while. We split up our website project badly, so even though we set up Google Cloud and have a domain linked to the bucket, we can't use it. Ran out of time to do stuff as usual in these types of events.
Accomplishments that I'm proud of
That we managed to build a functioning website with a full back end.
What we learned about
Flask, SQLite, Git, Python, Javascript, React JS. Learned about Domain.com and Google Cloud.
What's next for DMoney
To add more functionality. We have only build the skeleton/prototype for the idea.
Built With
flask
html
javascript
python
react
sqlite
Try it out
GitHub Repo


Inspiration - Hackathon
What it does - Not much
How I built it -
Challenges I ran into - Conflicts
Accomplishments that I'm proud of - Great Team
What I learned
What's next for hackmisfits
Built With
api
cloudwatch
dynamodb
gateway
lamdba
s3


Inspiration
Human children passively learn language by hearing 1000s of words spoken around them before eventually speaking their own first one. Blind-deaf children cannot as easily perceive their environment and instead need to be actively taught Braille or sign language to communicate. As a consequence, they often develop their cognitive and social skills much more slowly, and in the long run suffer from isolation or struggles with integration into adult work life.
What it does
Sertio is a language learning assistance system, which enables blind-deaf children to more passively learn words as they explore their environment- without supervision of a parent or teaching specialist. Sertio is a learning kit consisting of a small discrete wearable camera, a braille-SmartWatch and an App that allows parents to track their child's learning. The deaf-blind child wears the smartwatch and the camera (mounted on a pair of glasses), and as it explores its surroundings and feels different objects. Sertio uses Object Detection to identify the object and display the braille word on the smart watch. This way, the child can feel the word on the watch over and over as he plays with the same objects again, and over time and can learn the new words. The app gathers a list of the words that a child got displayed on his phone, so that the parents know what the child has learned.
This way, children that are normally highly dependant on a teacher can gain language skills through their own exploration. This can give them an essential head-start and confidence in pursuing their further education and reaching their full academic capacity.
How we built it
We used Microsoft's Cognitive Services for Object Detection. We also used a public project for Hand detection in order to robustly detect the relevant object in the child's hand. We used Swift for the UI and App development. For the communication between our AI system on the cloud on the App, we used a Flask Web App.
Challenges we ran into
Accomplishments that we're proud of
After a long night of brain storming and researching we're proud to have come up with a unique idea, that has not been tried ever before. In addition, we're very thrilled to contribute towards the well-being and empowerment of an underserved group of people, who we think can really benefit a lot from this system.
What we learned
What's next for sertio
Language learning is a complex process and many linguists have come up with smart theories how to best approach it. In order for our system to actually work, this has to be incorporated. Examples of this could include: Using video data instead image data for verb learning (using LSTMs or similar). Learning hierarchy of words by displaying multiple words after each other: tool, hammer, wooden hammer.
Built With
azure
azurecognitiveservices
azurefunctions
azurerestapi
braillewatch
python
swiftui
tragbarekamerabrille


Inspiration
It's already hard without disability to traverse all the construction sites plaging the public transit network
What it does
Shows defects in elevators/escalators for people with disabilities before they use public transportation makes Disability Access more transparent.
How we built it
java in Android Studio. We used Azure maps as well as google Firebase as a backend
Challenges we ran into
Azure map api syncronisation , unity bing maps
Accomplishments that we're proud of
it just works, is easy to use and extendable
What we learned
android studio was never a tool we used much so its nice to learn more about it as well as the services we used
What's next for BananaFree
cogitive services to confirm validity of the reports as well as method of input to reach more people
gamification to insentivate users to report
commenting and rating system
3d map
Built With
android-studio
azure-maps
firebase
java
Try it out
GitHub Repo


Help animals
Built With
amazon-web-services
api
cloud-formation
cognito
dynamodb
ecr
fargate
gateway
lambda
rekognition
s3
Try it out
devpost.com


Cricktech proto
Inspiration
The need to understand and connect science behind bio mechanics with technology for analysis as per problem statement of #micro fuzzy
What it does
It formulates the scenario by crating a 2DOF contour , through a mathematical model of arm .The data is gathered for scenarios for condition with the bowling action .
How we built it
Using Arduino with gyro sensors and Bluetooth module for data logging,and MATLAB for building and possessing it into final plots through algorithm in MATLAB.
Challenges we ran into
Understand the sensor callibration,low memory of micro controller for making a real-time systems, visualising bio-mechanics of human arm
Accomplishments that we're proud of
Full functional implementation, visualising results into plots, validation will real data, embedded coding (Arduino)
What we learned
Teamwork Roler coaster ride through high and low moments
What's next for Crictech
Integrating complexity with high fidelity sensors, visualising bio-mechanics in details. Developing into a product later
Built With
arduino
cricket
data
gyro
matlab
plots
Try it out
drive.google.com


Helping Patients with their Physical Therapy
Whether you have chronic back pain or are in recovery from an injury, physical therapy will help you get healthy again. Physical therapists are in hot demand and we at anymotion aim to help them and their patients with their recovery.
© 2019 - anymotion team - All Rights Reserved
Components
Posenet estimator for expert motion provided in flask api
Arduino acceleration sensor code
Flutter mobile app
Posenet
Posenet is implemented with detecron2 from facebook. Given a reference motion from a video, a target trajectory is generated.
Flask API
Hosted on Azure VM.
GET
/ Provides generated angle timeline of expert motion
/video Provides video of pose estimation
/angles Precomputed angles for demonstration
Arduino
Basic data pipeline using a kalman filter for state estimation.
Sensors
Sen-MPU6050 Gyroscope & Accelerometer Module
HC-05 Bluetooth Module
Flutter
State based prototype app for android and iOS. The app provides multiple exercise, animated in real time @60fps to compare.
Available exercises:
Weightlifting
Bizep curl
Entry point for all connections regarding bluetooth and webservices.


We were inspired to make an app that records movements of the professional dancers, football players, boxers, etc.
The app offers you to choose a movement of different spheres like dance, sport or medicine, sampled from professional dancers, sportsmen, etc.
We have spent a lot of time try to get the sensors right. The soldering challenge was actually not the challenge we expected, as we wanted to focus on the software, not the hardware.
We have gained a lot of experience managing problems that we do not expect.
Pro Motions can grow to a popular or original app.
Built With
arduino
firebase
python
swift


our logo design
Inspiration
Our main goal with OpenBook was to address some of the flaws we found when trying to get and give homework help online. We’ve tried a fair amount of other softwares that have had their advantages and shortcomings, so we wanted to try our hand at making one. Some of the places we were coming from when designing OpenBook were using class-based group chats, Google Classroom, and annotation software. The most successful solution we saw was nb.mit.edu, which allowed teachers to upload readings and homework and let students annotate the documents directly for all their peers to see. However, some of us found their implementation of this lacking and a bit outdated. We decided to take this idea of having “open source” insights on shared resources and create a web app that could make this easy for students to use.
What it does
When creating OpenBook, we focused the functionality around letting students share, be it questions or insights. Sharing is the main point in collaboration, and so all main features center around it. We took inspiration from nb’s annotating system and built upon it to allow users to highlight a part of a document and either share a comment or ask a question. Either of those would be visible to anyone viewing the document, so someone could get a helpful explanation of a confusing textbook passage or give a hint on a problem someone was stuck on in the homework. We also implemented a feed system that allows users to see recent activity and active questions.
How we built it
We first went to Figma for some quick prototyping and making sure we all had the same final product in mind. After that prototyping, we used glitch.com, a free collaborative online web development platform to enable us to work together. We could all edit the code at the same time and test it quickly, though some of us at times would do other tasks besides coding. We also used firebase for a quick and easy database backend.
Challenges we ran into
A problem we faced early on was the choice of database/backend. Due to some miscommunication, we started off with a backend that no-one was particularly experienced in and so we had lots of trouble in the beginning. Once we figured that problem out, our main hurdle was keeping the ever increasing codebase readable between all four members. This problem was compounded once one of the more experienced coders in our team had to leave early due to a headache. A final problem we had when adding the last pieces of functionality was that the way we set up the database required lots of asynchronous calls, which were tedious to get correct. None of our solutions were entirely perfect, but we were able to get it good enough to carry on.
Accomplishments that we're proud of
I’d say that everyone in the team is proud of how much we’ve accomplished in just a single day. Since half of us have never done a hackathon before, we’re mainly proud at how effectively we were able to work together. We identified a problem that we all were familiar with and that could help our community, we designed a potential solution, and we made lots of progress on the prototype of it. We worked pretty hard all day, and we’re happy with what’s come out.
What we learned
Our team has all sorts of backgrounds with coding and design, and as this is our first hackathon together (and just first hackathon for some of us), we’ve been able to learn from each others’ experience. For instance, I specifically got to learn some more Javascript and how Firebase is used. Some other things we taught each other were design thinking principles, good coding practices, graphic design, productivity tips, and of course, teamwork.
What's next for Open Book
Our prototype does not have full functionality, so a good next step would be reaching MVP status. From there, we would touch up the UI a bit to make navigation simple, and then just get it into the classroom and in the hands of students! These would be our peers and teachers, who would be more than happy to give feedback on it.
Built With
bulma
css
firebase
html
javascript
Try it out
proof-frontier2.glitch.me
glitch.com


This project was bootstrapped with Create React App.
Available Scripts
In the project directory, you can run:
npm start
Runs the app in the development mode.
Open http://localhost:3000 to view it in the browser.
The page will reload if you make edits.
You will also see any lint errors in the console.
npm test
Launches the test runner in the interactive watch mode.
See the section about running tests for more information.
npm run build
Builds the app for production to the build folder.
It correctly bundles React in production mode and optimizes the build for the best performance.
The build is minified and the filenames include the hashes.
Your app is ready to be deployed!
See the section about deployment for more information.
npm run eject
Note: this is a one-way operation. Once you eject, you can’t go back!
If you aren’t satisfied with the build tool and configuration choices, you can eject at any time. This command will remove the single build dependency from your project.
Instead, it will copy all the configuration files and the transitive dependencies (Webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except eject will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.
You don’t have to ever use eject. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.
Learn More
You can learn more in the Create React App documentation.
To learn React, check out the React documentation.
Code Splitting
This section has moved here: https://facebook.github.io/create-react-app/docs/code-splitting
Analyzing the Bundle Size
This section has moved here: https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size
Making a Progressive Web App
This section has moved here: https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app
Advanced Configuration
This section has moved here: https://facebook.github.io/create-react-app/docs/advanced-configuration
Deployment
This section has moved here: https://facebook.github.io/create-react-app/docs/deployment
npm run build fails to minify
This section has moved here: https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify
Built With
css
html
javascript
python
Try it out
git-codecommit.us-east-1.amazonaws.com


Inspiration
The problem statement was inspiring and challenging. It was great to see that with the available technology what we could do to detect oil spills which would otherwise be not possible at all.
What it does
With machine learning we can detect oil spill from the images provided and generate awareness and possibly detect the responsible party.
How I built it
We use AWS services (Serverless architecture - lambda, S3, Dynamodb, API Gateway) for developing our solution.
Challenges I ran into
We could not use pre-trained model for inference.
Accomplishments that I'm proud of
Our team was glad to work on this project because this can generate insights which can help in making a big impact to the environment.
What I learned
What I dont know.
What's next for EagleForce
Viva Las Vegas!
Built With
amazon-web-services
node.js
react
scala
Try it out
GitHub Repo


What inspired you
The emotional distress which is created by separation of pets from its family due to disaster or any situation and tedious current process causes more delay and stress.
What it does
Simplifies and accelerate the reunification process of pets with its family.
How I built it
Serverless micro services application using HTML5, Python & AWS Web Services.
Challenges I ran into
The lack of availability of data for pet and their owners.
What I learned
The efforts and challenges faced by Best Friends to reunify the pets to its owners.
Built With
amazon-web-services
html5
lambda
python


See Powerpoint File
Built With
amazon-web-services
api-gateway
cognito
dynamodb
lambda
s3


Inspiration
Distracted driving has been, and continues to harm society everyday. NotCrash is our first step into making the world a safer place.
Distraction was a factor in nearly 6 out of 10 moderate-to-severe teen crashes.
80% of collisions and 65% of near crashes have some form of driver inattention as contributing factors
Economic losses caused by traffic collision-related health care costs and lost productivity are at least $10 billion annually
What it does
A connected vehicle application that brings a new safety system which acts from the inside. Leveraging machine learning classifiers and speech recognition software from OpenCV, dlib, and Google Cloud APIs to check and restore driver alertness while providing aditional hands-free functionalities. When a driver is determined to be inalert, an auditory cue is initiated and can only be disengaged by verbal confrimation by the driver. Each incident is recorded in a MongoDB collection, past a certain threshold an SMS message is sent to the user that includes the timestamped incidents.
How we built it
The image recognition component of the project was completed using OpenCV and dlib. The voice recognition was completed through the use of Google Cloud Speech Recognition which provided the data to be stored in a MongoDB (Atlas) database. When documents accumulated in the database, an SMS message is sent through the MessageBird Stdlib API to the user as a report. This API service was also used for the voice command text message feature.
Challenges we ran into
Due to the processing power required to run OpenCV, in combination with the Google Cloud Speech Recognition API, there was severe lagging occurring between the processes which resulted in frequent crashing. There was also the issue of actually integrating our separate Python modules together which caused flow conflicts which needed to be solved.
Built With
computer-vision
connected-vehicle
dlib
google-cloud
google-web-speech-api
mongodb
opencv
python
safety
stdlib
voice-recognition
Try it out
GitHub Repo
drive.google.com


Inspiration
You never crack alone
What it does
Allianz thinks its helps them save money, they think wrong.
How we built it
trade secret!
Challenges we ran into
Our existence, and the fact that image_dataset has a focal point badge on every image which is a whole different dimension of pain!
Accomplishments that we're proud of
Our existence
What we learned
Nicholas needs to work harder!
What's next for CrackaThon
Hardik for president!
Built With
love
python
pytoch


Inspiration
Everyone wants to draw something at sometime, but what do you do if you can't see the canvas? It's not about being da Vinci, but about showing the emotion and sharing it with people you love (especially in Christmas).
What it does
DrawMeA takes the speech commands as input, and draws objects accordingly on a canvas. The full process is voice-guided.
How I built it
We build on top of Azure Cognitive Service's Speech (LUIS) AI service, and use Python tuned to take specific commands (objects to draw, location to put objects). A pre-defined database contains 10 categories as optional objects to be drawn on the canvas.
Challenges I ran into
The Azure service is not so easy to get in it as a beginner of cloud user. And testing with speech recognition is not Intuitive as classical program debugging.
Accomplishments that I'm proud of
The test run is quiet successful. And all the team members can get familiar with Azure AI services, which we have no clue about how to use. Most importantly, the team works so smoothly and efficiently.
What I learned
Azure AI service framework; great team work needs efforts from everyone.
What's next for DrawMeA
Bring the desktop version to a web platform, which can be easily share to visit by anyone and anywhere; add more categories of objects; add more sophisticated strokes to draw fine details.
Built With
ai
azure
python
Try it out
GitHub Repo
docs.google.com


Default Screen
Instago
Instago! Your goto travel planner app! We're taking the most annoying parts about planning for a trip and leaving only the funnest parts to you! Just give us your destination and we'll quickly generate you a trip to the 5 most attractive tourist destinations starting at the most ideally located hotel at your destination.
We were inspired by our experiences with planning trips with our friends. Often times, it would take us a few days to find the best places we were interested to see, in a city. Unfortunately, we also had to spend time filtering away the destinations that we were uninterested in or did not fulfil our constraints. We hoped that by building Instago, we can help reduce the time it takes for people to plan their trips and get straight to the exciting preparation for the big day!
In this project, we chose to run our front-end with React and build our back-end with Stdlib, a technology we have never used before. On the front-end side, we used Google Maps API for the first time in conjunction with React. This proved to be more challenging than expected as Google does not provide any in-house APIs that primarily support React. We also lost a significant amount of time trying many npm wrapper packages for google maps. They either did not support Google Directions, a key feature we needed for our project or were poorly documented. We ended up discovering the possibility of introducing script tag elements in React which allowed us to import the vanilla Google Maps JS API which supported all map features. The largest challenge was in the back-end. While Stdlib was phenomenally flexible and easy to set up, test, debug and deploy, we needed to write our own algorithm to determine how to rank tourist attractions. We considered factors such as tourist attraction location, type of tourist attraction, number of ratings and average rating to calculate a score for each attraction. Since our API required making multiple requests to Google Places to get tourist attraction information, we had to make compromises to ensure the speed of our algorithm was reasonable for users.
The number of next steps for our project is boundless! We have plans to integrate Facebook/Google login so that we can take in user likes and preferences to make even more tailored travel plans (Users can also store and share their trips on their associated accounts)! We want to apply a semantic similarity calculation using Word2vec models and compare a city's tourist attraction names and types with the interests of users to gather a list of places a user would most likely visit. Concerts or sport games that are happening around the time of the user's trip could also be added to an iteniary. We also have plans to add budget constraints and modes of travel to the calculation. It was too much to add all these cool features into our project before demoing, but we are excited to add them in later!
Overall, this was an awesome project and we are so proud of what we made! :)
Built With
css
google-directions
google-maps
google-places
html
javascript
react
stdlib
Try it out
GitHub Repo


Game Logo
Inspiration
To never give up.
What it does
Entertains People
How I built it
Using python and web templates
Challenges I ran into
lack of water and object organization
Accomplishments that I'm proud of
the game that we made
What I learned
to program for long periods of time
What's next for Galactic Defenderz
It's on our website
Built With
python
Try it out
www.wix.com
GitHub Repo


Inspiration
This years challenge hosted by the city of Munich
What it does
The App combines interactive game with clever guide and useful informations. Imagine, you are walking the streets of Munich and passing an interesting building, statue etc.. With "Pretzel Hunt" installed on your mobile phone, it only takes a few moments to get the important facts and some bonus points - the pretzel points! Pretzel points are given, each time you pass a sight and scan its QR code. You also can take a walk and follow a given route including more stops. For taking the public transport, riding a bike or just walking, you can earn even more pretzel points. In the future you can redeem your pretzel points for cool rewards from the partners of City of Munich.
How we built it
With ReactJs as front-end and java as our back-end with APIs
Challenges we ran into
QR-scanning. There were no react-plugins working correctly.
Accomplishments that we're proud of
We learnt how to work in a team and maintain the good spirit.
What we learned
We learnt more about a new framework and api's.
What's next for Pretzel_Hunt
Built With
balsamiq
java
javascript
mongodb
react
Try it out
GitHub Repo


Neuroclass
A integrated and intuitive brain deformation and system healthiness classifier
The model(based off of the famous Resnet) is in this repo. The model used the publicly available NIH malaria dataset on rescaled malaria cell pictures. Using this model, we get arounda 96% accuracy rate in detecting whether or not a cell is infected or not.
The file 'classifier.h5' contains the full h5 file of the resnet model including all weights biases, and values. To run the model, simple load the model and apply the predict function onto an image for a probabalistic distribution of whether or not a cell is infected.
The web app is a cleverly integrated system that uses flask to allow a user to upload an image and have it be classified by the model. Flask.py is the general use backend for the flask application, the html is packaged into the app as well.
Built With
html
python
Try it out
GitHub Repo


Inspiration
Technology helped change the way we live our daily lives. From finding out information lightning fast to learning a new skill from the commodity of your home. Technology has made our lives easier and it's potential is yet to be unlocked. In times where everything is possible, we can help people with disabilities overcome their deficiencies.
What it does
ComKey Sign Language intends to help deaf people communicate with people with no auditive deficiencies. Moreover, our application aims to give a smoother transition, from natural language to sign language, to people that recently lost their hearing or speaking abilities. The core functionalities of the application are Speech to Text transformation and Sign Language recognition. With the help of his smartphone, the person can photograph/film the gestures of the sign language user and receive its textual translation.
How We built it
One of the core mechanisms of this application is the sign language recognition. The recognition is achieved through a image classifier written in Python. The dataset used for the training is provided by link. The mobile application was developed with the Android Studio IDE. The two applications exchange data through a firebase database.
Challenges We ran into
Tensor Size compatibility in convolutional neural networks (fancy words).
Changing the challenge after the first day.
Sleep deprivation. (A double-edged sword)
Exchange of data between applications.
Using Mac.
Accomplishments that We're proud of
Learning more about machine learning and trying to develop and adjust an image classifier.
Participating in yet another edition of HackaTUM.
Learning the sign alphabet.
Assembling Arduino hardware. (not related to this Challenge)
What We learned
We improved our teamwork skills and organisational skills.
We expanded our Computer Science knowledge (Machine Learning, Microsoft Azure, Android Studio).
What's next for Comkey
Hopefully we get to participate to a lot more Hackathon's in the future.
Maybe develop some more in the field of medical informatics.
Built With
android-studio
firebase
java
keynote
python
Try it out
GitHub Repo


login screen
Inspiration
We find ourselves wanting to walk to school, but we can't, because we don't know who to walk with, or we don't schedule a time in the morning.
What it does
It allows students to collaborate to fix a time to walk or bike to school together
How I built it
We built it using SwiftUI
Challenges I ran into
We often ran into errors that easily fixable.
Accomplishments that I'm proud of
Being able to pinpoint a location using Xcode's MapKit.
What I learned
I learn how to use MapKit, and Authentication Services to find a location.
What's next for Walk Buddy
push notification
encryption for school ids
Built With
xcode
Try it out
GitHub Repo


Inspiration
We want to help visually impaired people in countries lacking modern and necessary infrastructure to accommodate their needs. We found out that it's not only 3rd world countries that might benefit from additional aid, but also large cities like New York with a large population of visually impaired that could certainly use a safety and quality of life upgrade.
What it does
Uses machine vision to analyze the environment and gives the user the needed feedback to safely cross intersections. Notifies the user when they get close to an intersection. If there are no traffic lights, checks for cars.
How we built it
Frontend: Webapp using HTML, CSS, JavaScript and Jquery Backend: Python (flask and geocoder), Azure Computer Vision
Challenges we ran into
Browser push notifications, accurate geo location
Accomplishments that we're proud of
Learning and implementing a new framework, linking of front- and backend
What we learned
New framework (flask), improve our knowledge of REST-APIs
What's next for TrafficSight
Develop native apps for iOS and Android, improve functionality, expand use of computer vision beyond traffic lights, migrate to a server
Built With
azure
css
flask
geocoder
html5
javascript
jquery
python
Try it out
GitHub Repo


Inspiration
We wanted to check whether this challenge is really as difficult as promoted. We also wanted to make something new, something that we don't normally do, and learn from it.
What it does
It renders a OpenDRIVE track into the STL format. The resulting file can then be imported into a rendering program such as Blender.
How we built it
We started with the OpenDRIVE documentation and the provided library. We extracted the geometry data from the original OpenDRIVE files and then triangulate the surface of the roads. We imported one model into Blender and included it in an animation.
Challenges we ran into
Using CMake is always a problem until you make it work. Even more if you try to use it on Windows. After these obstacles were overcome, we faced problems with the rounding of floating point numbers that caused gaps in our models.
Accomplishments that we're proud of
We successfully triangulate a road's surface and create a mesh that can be rendered on a screen.
What we've learnt
We got familiar with the OpenDRIVE file format which provides an impressive amount of options. The triangulation algorithm provided an interesting and fun challenge to devise, implement and debug. We also got familiar with the process of rendering roads and making animations in Blender. Only one of us knew how to use Blender before the hackaTUM 2019.
What's next for The Road to 3D
The OpenDRIVE file format can encapsulate additional information about the roads, such as surface properties, material or the intended purpose of the road to name just a few. This information is currently ignored. Further versions may translate this appropriately. The export to file formats that support such information (e.g. Wavefront obj) has to be added.
Another great improvement would be wrapping our program into a Blender plugin. Finally, our animation could be made significantly more realistic by adding lane markings, road signs, textures ...
Built With
blender
c++
cmake
Try it out
GitHub Repo


Motion and Moisture Prototypes Tweeting to the concerned Person
LIVE ConeCTED
Inspiration
With rapid technological advancements every moment and budding ecosystems, the smart systems that exist now still hold some constraints on their operating conditions with respect to coverage, inter dependency etc. Having a framework and a communication method that could handle numerous details from different locations in an ecosystem e.g., like a colony in a city, would enhance the possibilities to interlink, interpret its data and harvest beneficial results which improves Safety, Health, Productivity.
What it does
The framework is designed to collect useful information such as humidity, human presence, air quality, smoke etc from numerous sensors placed at various houses, supermarkets, gardens, farms, schools etc under one zone. The zone is confined to strong coverage area of a LoRaWAN gateway. Collected data is used to establish a visualization such as air quality map of a zone and humidity information for controlling water sprinkler at farms/gardens on a single platform. Metadata can be intelligently used to react faster in the emergency situations can be thought of, such as Fire accidents, Gas leakage, motionless person detection at a house etc., can trigger an emergency alert to the houses in the zone and also to emergency services. All these can work independent of internet availability.
How I built it
Different sensors were integrated with Arduino WAN1300 boards to communicate surrounding information they sense, to TTN console through LoRaWAN. The data received is then processed through math scripts at ThingSpeak API, thereby logging and visualizing the consolidated data from time to time and if necessary, trigger an alert or notification.
Challenges I ran into
Analyzing different data from different kind of sensors. Finding a proper procedure to establish a closed loop through various APIs to link sensing with actuation. Establishing a downlink request independent of uplink request. Possibility to check the working of a class C sensor with TTN due to incompatibility of the console.
Accomplishments that I'm proud of
Structuring out a concrete plan of application with LoRaWAN within few hours. Creating common interface for different sensors thereby having a visualization. Quick know how with numerous APIs, frameworks, methods. Finally Bringing out an excellent feasible and reliable product that could really make lives stand out in extreme situations of network coverage, emergency etc.
What I learned
So many hidden or unnoticed flaws like network coverage, lack of a standalone single application for controlling etc, with various existing smart solutions can be solved with LoRaWAN. Networking across devices is seldom required and when needed can be realised. Networking can be made easy by fusing the data from several homes using just a single gateway. There is a tremendous scope of improvement for data integration along with further controls which can turn the systems more powerful.
What's next for LIVE ConeCTED
Integrating class C devices to TTN and LoRa zone making standalone downlink feasible, thereby bringing out more options to control actuations. Expanding the application to several LoRa zones established close by, thereby creating “connected cities”.
Built With
arduino
c
matlab
thingspeak
ttn


Simulated fire
Inspiration
California wild fires
What it does
Simulates wild fires
How I built it
Unity and C#
Challenges I ran into
Rigid-bodies
Accomplishments that I'm proud of
Helps people
What I learned
Unity Physics
What's next for FireGuard
Machine learning
Built With
c#
unity
Try it out
drive.google.com


Inspiration
Music is the essential part of our lives. Everybody has a melody in mind sometimes. We want to make your movements audible, so you can hear your body’s sound. Our inspiration originally came from playing drums. We imagined, with motion detection technology, one can use motion to make music.
What it does
It is a life experience application that takes movements and turns them into sounds. Using motion detector as input provider, we use directional movements to create music notes, and by using the notes your own songs.
How I built it
We used Arduino Nano and a motion sensor(MPU6050) to create the data. We used machine learning and statistical analysis to estimate the direction of the motion using the accelerator. We used Python for data analysis and musical display. For the music notes, we used .wav files of piano key recordings, guitar key recordings and some drum beat recordings.
Challenges I ran into
We had a problem doing the setup for Bluetooth. It took a lot of time to sustain the communication between the Bluetooth device and the computer. We had a problem finding appropriate music notes. The hardware that we had is not suitable for the body, so we think about using mobile phones to collect movement data.
Accomplishments that I'm proud of
Setting up the hardware part and collecting data from it. Analyzing this data and assigning it to the voices. Getting a song from the movement of a person.
What I learned
We knew how to use Arduino, but Arduino Nano was new for us. We learned getting signals from sensors and board by physical connection. Also, communication with Bluetooth is new for everyone in group.
What's next for SenseBeat
Option to create other instrument sounds such as bass, violin, etc. Make the notes have other duration options. Learn more gestures, make the interaction continuous.
Built With
arduino
bluetooth
machine-learning
python
Try it out
GitHub Repo
docs.google.com


Inspiration
Reto de BonArea
What it does
A partir de machine learning, analiza una imagen e indica si es correcta o no
How we built it
.NET Core con ML.NET
Challenges we ran into
Solament el de BonArea
Accomplishments that we're proud of
Modelo me machine learning funciona
What we learned
.NET Core y funcionamiento de machine learning
What's next for Hackeps2019 - Spahetti team
Lo veremos el año que viene
Built With
.net
.netcore
c#
css3
html5
Try it out
GitHub Repo


What did you do?
We used three random English words to consent and share access to safety plans
Why did you do it?
Words are easy to remember and spell out over the phone
Three words that expire gives reasonable security for the use-case
What worked?
The problem at hand doesn’t seem to require any complicated technical solution, i.e. technology is not the limitation in this case
How does this make things better?
Both caller and crisis counselor have access to the same channel, information is optionally anonymous, and caller is in control of what is being shared – this builds trust while remaining emotionally safe for the caller
How can this be deployed?
Built with AWS CDK, just point to AWS account and shoot
What’s next?
Continuous emotion tracking (and analytics?)
event based notifications, e.g. when average mood drops below certain point counselor can be notified and reach out
Granular consents: caller has control over what information is shared with counselor
Try it out
reinvent-stack-staticsc14ef19b-1gb3f3xxg6z4w.s3.amazonaws.com


Inspiration
I have visited a Job Fair in Chicago with my friend who is a worker. She tried to apply for some of the companies, but actually couldn't find and apply for any job. Because of a lack of skills. It's very difficult nowadays for workers to build a career. More than 20 million blue collar workers in the US want to apply for a better job but don’t have appropriate skills. They dream about a career uplift but it’s not transparent how to approach it.
What it does
Promozip empowers blue-collar workers with a clear path to build up their professional career. We build a platform that allows blue-collar workers to master new skills and get a job they are dreaming about.
How I built it
Worker put a job description which he likes and skills which he has. We match his skills to the job description and show a learning plan which will help him to get his job.
Challenges I ran into
In the process of building a platform I found out that is very difficult to find some really good courses for workers
Accomplishments that I'm proud of
My business partner got sick. So I did idea polishing, coding and pitching by my self.
What I learned
I have learned that I have to spend more time on thinking about the idea, impact and use cases than on coding. it's very important to give workers a helpful tool that will help to build a career.
What's next for Promozip
I'm also a Co-Founder & CTO of Workly which is an on-demand workforce platform for workers. And we will integrate Promozip with Workly to help people get new skills and after apply for more qualified jobs.
Built With
elasticsearch
node.js
react-native
Try it out
GitHub Repo


Inspiration
We were inspired by the need to help clients access their personal safety plans in an easy, dynamic and engaging manner.
What it does
It provides a chatbot for the counsellor to create a personal safety plan in a secure manner, and to share that with the caller. The caller can later access it in a secure manner and share it if they choose to.
How we built it
We used Lex to built a chat bot that uses Lambda as the back end to store the details of the personal safety plans. We use S3 with an added layer of encryption and with lifecycle policies to ensure private data is destroyed within a specific time window of not being accessed.
Challenges we ran into
Privacy and security concerns. It forced us to innovate on how to tackle the handling of personally identifiable information (PII) and we ended up with using S3's built-in lifecycle management for that.
Also working Lex we needed to ensure we define custom slot types and test for the open-ended questions the plan asks.
Accomplishments that we're proud of
We got a working demo with a secure architecture and got the chance to talk to AWS experts in the areas we needed most (compliance!) We talked to multiple stakeholders from Vibrant and we felt like we understood their issue and were able to plan a reasonable minimum viable product (MVP) for today.
What we learned
You need to focus on keeping our MVP small - there is risk of overthinking and adding features that we do not have time to do. We learned about many new technologies including Lex, S3 presigned URLs, S3 lifetime policies and more!
What's next for VibrantChat
Rework on the Lex integration for a more refined questions and slot filling. Look at integration with Facebook Messenger
Built With
ksm
lambda
lex
s3
Try it out
vibrant-chat-public-demo.s3.amazonaws.com


Inspiration
Non-technical staff should not have to learn SQL anymore. Not all insights can/should be gathered from standard visualizations and reports. You should easily be able to get the answers you need, in a userfriendly way.
What it does
Natural language based query, with suggestions and pattern recognition to show you relevant metrics
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for AnswersDB
It's in a prototype phase currently. Make it work across all databases.
Built With
node.js
react


Inspiration
I want to commoditise "developers" by allowing them to sell their time to the highest bidder whenever they want. People with programming skills should be able to work whenever they want at the real market rate.
A key issue to achieve this is to be able to "price" dev skills. Pricing of dev skills can be done algorithmically via data-driven approaches.
What it does
Estimates market demand for each Python library. It also estimates how strong is the supply for each of these libraries.
At this point, I implemented a very simple model that assumes that dev's value is solely determined by the number of libraries s/he uses.
It continuously clones open-source repos and retrieves contributor's number of adds/deletes to each
How I built it
Model assumptions:
There's only one programming language in the economy: Python.
Developer skills are solely determined by the libraries they know how to use.
A developer knows how to use a library if he/she has edited a file that imports it.
Market demand for libraries is perfectly correlated with the frequency library appears in the dataset I scraped.
Looked for a dataset of open source repository links.
Explored, the dataset and selected repos that had at least ten lines of Python.
For each GIT link: 3.1 I cloned the repo. 3.2. For each repo: + I filtered out Python files. + Computed how many additions/deletions each of the repository contributors had in each Python file. + Extracted all "import" statements to quantify which libraries are present in each file + Inserted data into a database.
Built dashboard to visualise results
Challenges I ran into
Dealing with very large datasets. ~15TB in total. I had to write code to do all the parsing.
Accomplishments that I'm proud of
Way to model the problem. Getting to build dataset, clean it, design database, and deploy a dashboard without other teammates :):
What I learned
There is a LOT of data hidden in GIT repositories.
What's next for Quine
Defining an MVP and build it. Put it up on Reddit.
Built With
dash
python
react
sql
Try it out
docs.google.com


Inspiration
YouTubers are struggling to monetize their audiences and continue to rely on big brands (YouTube, Instagram, Patreon) in order to build and strengthen relationships with their audiences. David Dobrik, a YouTuber with 15 million+ subscribers, makes $2,000/month from YouTube. We're working towards a better way for influencers like David to make money from his audience by reducing dependence on today's incumbents.
What it does
Step 1 (this prototype) plays embedded YouTube links and a simple CTA to "Join" via a $1.99 monthly payment. This is only meant to gauge interest in exclusive content for a small monthly price.
What's next for durtedom.tv
Focus on community building within a creator's audience, host exclusive videos on the site, build for more creators and get their feedback.
Built With
react
Try it out
durtedom.tv


Learn
Who's it for?
Software devs who want to learn codebases, languages, and frameworks faster.
What is it?
Learn is a Visual Studio Code extension which takes advantage of a few newer technologies to provide developer learning opportunities where they matter most: directly inline with the codebases and languages you are working on. It helps you stay in the flow of editing and building, while providing you several new ways to traverse the codebase at hand expressly for learning purposes. Since we had 24 hours, we focused on one particular language: Rust, which gives programmers several new mental models and tools for solving problems with code, but which has a (fair) reputation for having a significant learning curve.
Features
CODE INTELLIGENCE BASED ON DEEP SYNTAX PARSING
We use a duo of newer code parsing technologies, language server protocol and tree-sitter, in order to have live reference not only to the normal call-site -> definition and docstring parsing most tools come with, but to the actual abstract syntax tree underlying which represents Rust's semantics and best captures what's unique and valuable about this language.
This allows us to do things like differentiate reserved keywords from each other (which most code editing tools fail in an epic way at), linking to the higher-level docs which get at the "why" of the language, not just the what. We can also parse, differentiate, and document symbols and operators, of which Rust has notoriously many, and which are often the hardest parts of a language to "just Google."
CONCEPT SEQUENCING FOR ACQUISITION
The higher level of curated conceptual linking that this rich code metadata gives us also enables to capture and order the language concepts which particular codebases and files make use of. With this data, we can provide purpose-built learning tracks which will help you learn just what you need to to understand the code you are looking at, fast.
FUTURE: TEAM CODE CURATION
All of the above data we have captured in comments, documentary links, and examples which don't just show up at particular lines in the code: they are linked to the underlying concepts and language primitives of Rust, as expressed first in ./src/data/nodeTypeToConcept.json. This is a declarative format, which we intend in future work to attach to tools that let teams capture important codebase- and language-specific knowledge. Instead of sending a teammate to a README or even worse a wiki, this will allow documentation to show up wherever concepts are, even as they move around or pop back up in code that doesn't even exist today
(AND ALL THE OTHER STUFF TOO)
We have implemented this all in the context of Visual Studio Code, an increasingly popular tool which provides compatibility with many teams' workflow and preferred toolchains. This is the perfect place to develop Learn into a learning tool for any language or framework, but also for any developer or team's personal learning and development workflow.
Requirements
VSCode. It'll tell you if it's too old. Clone this repo, cd into it, and run code . That will open up an editor, and if you then run F5, you'll launch the extension in a second test instance of Visual Code Studio. Simply navigate that instance to a Rust source file to start trying and developing Learn.
Anything else?
It will crash if RLS (Rust Language Server) (server, but not the VS Code extension) is not installed YOLO
Here's what we learned: built our first VS Code extension, learned a ton about the amazing tree-sitter and language server protocol, and most importantly, were so grateful to hear all of your stories about what was frustrating and exciting as you learned new technologies and languages in your own careers.
Thanks, and hit us up at hello@platter.dev if you're interested in collaborating, sharing your stories and wishlist for dev tooling and learning, or just hanging out together in person or online. Cheers!
Built With
code
javascript
rust
typescript
visual-studio-code
Try it out
GitHub Repo


Inspiration
On the plane ride over to the hackathon, we were brainstorming ideas, and Zach came up with the concept to try and create diagrams to explain privacy policies.
What it does
MOP'd can transform a website's privacy policy page into a visualization, showing the different parties and what actions they take on your data.
How we built it
We used NLTK to analyze the text of Facebook's Privacy Policy. We built a prototyping tool for ourselves to mark up and annotate the data, to look for patterns. Once we had settled on a pattern, we built a parsing grammer within NLTK that pulled elements of that pattern out of the document and rendered it in a PlantUML diagram.
Challenges we ran into
Getting the privacy policy into a machine readable format took some thinking. We couldn't simply use plain text, since we lost some contextual information like the page headings, but using HTML would have been too complicated. We eventually settled on transforming the document into YAML following a few simple rules from the page hierarchy.
Accomplishments that we're proud of
When we first rendered the document where we could see all of the elements, we saw our vision come to life, and were both surprised by how close it ended up being to our original idea!
What we learned
We learned about using NLTK to do pattern matching through a grammar structure, which will help us build better NLP models in the future.
What's next for MOP'd (Mapping Out Privacy, Dynamically)
We believe this technology can be used to analyze all sorts of legal documents. Legal documents are interesting since they typically use a subset of restricted language, and often follow strict formal rules when they are written, making them more syntactical. We believe this is a largely unexplored area with a lot of potential.
On the software side, we're excited to explore potential improvements in our privacy policy scraping process, grammar design, and training the NLTK classifier to have better part-of-speech tagging.
Built With
fathom
natural-language-processing
nltk
plantuml
python
yaml
Try it out
GitHub Repo


Inspiration
My passion for quantum computing started back in my PhD in Theoretical Physics in Stony Brook. I even wrote an introductory e-book at that time http://www.astro.sunysb.edu/steinkirch/books/qi.pdf
After that, while working as a software engineer in companies such as Apple, Yelp, and Etsy, I continued following the developments in the field. I presented a talk on "Hacking Quantum Cryptography" at DEF CON 23 (cryptovillage).
Recently, I have been active in the quantum computing open source community, submitting contributions for projects such as Google's Cirq and AWS s2n (post-crypto) library.
Try it out
qcsandbox.com


Inspiration
Finding quality podcasts is hard. Right now, the process is based on tactile and visual feedback. However, that’s not how you consume podcasts in the real world. 48% of podcasts are consumed at home, when people do something else. Podcasting is a passive experience, so you can't afford to be tied to your device.
Similarly, we realized that finding good information is also hard. Googling has become a game of avoiding SEO trolls and while content is plentiful, it's getting increasingly time intensive to distinguish between high quality sources and ad traps. We built Ava hoping to solve this problem by allowing you to get information and satisfy your curiosity by learning from the smartest people in the world.
Special thanks to all our friends and family who listened to us asking them about their podcasting habits during the past week or so. Our ideas are directly inspired by their needs and goals.
Why we think this could turn into a business?
First of all, the podcasting market is huge and growing at an unprecedented rate. 65% of active podcast listeners have started listening in the past year and 1/4 of Americans listen to a podcast weekly. Furthermore, on average, Americans listen to 7 podcasts weekly (~ 6 hours and 37 minutes time spent on average).
Furthermore, according to A16z, "the ad revenue is estimated to hit $500M in 2019" and has been doubling yearly.
Given this market, we believe we can monetize through referrals to podcast creators, advertising, and premium subscriptions. We would talk to users to better understand how to tackle product-market fit.
Figures from the A16z Podcast Report: https://a16z.com/2019/05/23/podcast-ecosystem-investing-2019/
What it does
Ava answers your questions using a deep learning model that queries podcast transcripts. Using this personalized source of information, it's able to provide great answers and also suggest great content.
Why this team?
We're all from vastly different backgrounds, hailing from Canada, Romania, and the U.S. But what united us to come together for Ask Ava was our passion for empowering content creators using creative technical solutions. Between the three of us, we've seen the unique challenges of the audio medium while working at a radio station, worked hard to sell photo prints despite the steep costs of e-commerce platforms, and struggled with the question of how to promote indie content on YouTube. We hope that Ask Ava is the tool that will both be a boon for content creators and for budding podcast listeners.
How we built it
We built Ava using Alexa Skills and a server system that queries a BERT NLP deep learning model. The model is trained on the SQuAD data set from Stanford. We transcribed tens of hours of podcasts in order to feed the model so that we could then create a Q&A system based on podcasts.
The Alexa skill pings the server with a question and the server returns a response and a link to a podcast to play.
Challenges we ran into
Transcribing data was more difficult than we expected. Even transcribing a short podcast takes a lot of time, which meant that we had to be very efficient about what podcasts we chose.
Getting the model to run was also difficult, since we relied on IoT, ML, a web app client, multiple databases, a web scraper.
Accomplishments that I'm proud of
We made it work without having prior experience with AWS, EC2, S3, Alexa Skills, and web scraping. We've learned a lot in the past 24 hours alone.
Code
We have four repos (client/server, web scraper, Alexa skill, and ML) which can be found here: yc-hacks
What's next for Ask Ava
We only had a limited amount of time to train our model on podcast transcripts so look forward to further training on new podcasts and refining our training methodology.
Built With
alexa
amazon-web-services
beautiful-soup
ec2
express.js
node.js
pandas
python
react
redux
s3
semanticui
Try it out
ava-hub.herokuapp.com


Inspiration
One-way meetings suck. They take up a bunch of time and waste valuable resources as well as employee attention. We propose substituting one-way informational meetings for emails with quizzes, which we think will be better for both prospective meeting holders and potential meeting attendees. With quizzes and writing, employees can injest the information they need to know faster, with an incentive to actually learn the material. Managers and other meeting holders can now have quantitative verification that their people know what they need to know. People can retake quizzes as many times as they like until they get all correct answers.
We have a very rough MVP right now, but hope to expand to AMP for email, provide aggregate/history sections for employees and users, mailing list support,
Built With
flask
python
twilio


The video is meant as a cheesy TV ad - not everything has to be 100% serious, right? :)
Inspiration
For decades there have been no big innovations in the art of the discuss throw. Due to the nature of the sport, practicing the throwing technique requires a large area and a trainer.
We seek to change that by introducing TheThrow - combination of a special glove and an app! With TheThrow, all you need is a relatively small area, in which you can spin around and imitate the throw of the discus.
Additionally, the grandfather of one of the team members is an award winning and still active track and field trainer, who has trained the Latvian national track and field youth team in the 1970s. By innovating the training of the discus throw, we are paying tribute to our elders and contributing to their legacy.
What it does
The App is always ready when you are. Just throw a discus (no actual discus needed) and within seconds, it will score your throw, provide feedback and give exact tips.
It says which part of your movement you should improve, on which aspects you should focus while throwing, and where you lose your energy.
The exact things a trainer would tell you, but faster, more precisely, and of course: Wherever you are!
How I built it
We wanted a system that is fast, accurate, and user friendly. To achieve all of these goals, we used the "divide and conquer" technique. Splitting up the whole process into different parts allowed us to ensure that everything worked perfectly.
First, we have different sensors (accelerometer, gyroscope, 3D-Hall sensor) that measure the needed data and (using I2C and Serial communication) share it with a microcontroller. A bluetooth module then is used to share this data instantly with a computer (which leads to our system being compatible with both android and iOS). Additionally, a computer can analyze data way faster than any mobile device, even with more precise calculations and is thus more reliable.
The raw data of the sensors is translated into forces, velocities, angles and relative distances of your arm, hand and fingers. Putting those together creates a digital representation of the whole throw. The main problem was to teach the system how to recognize mistakes that can happen during a throw. We decided to go trough a 3-step process: 1) Collecting common and uncommon mistakes that can happen during a discus throw, and finding out every body part and movement that is involved 2) Reproduce the mistake over and over again, to find patterns in the data that represent it. 3) Create an algorithm for each mistake, train it, test it, improve it.
The feedback and information about the throw are uploaded onto a database, to which the app connects and about one second after the throw, the final results are presented to the user in a clear and easy-to-use app.
Challenges I ran into
Sharing the data with a bluetooth module is not as big as a deal as we initially thought, but sharing it fast enough to produce enough data during one throw (~1sec) was not that easy. We had to improve the sketch for our microcontroller, and the receiving computer, as well as the way of receiving the data several times, until we were satisfied with the results.
The next challenge was the beginning of the data analysis. Not having any experience with the sensors, we had to find out (willingly and unwillingly) that the precision, the data ranges and physical side effects often are challenging. But with enough data, there is always a way, so, fortunately, "challenging" didn't mean "impossible".
Because our app should be as user friendly as possible, one of the main aspects was that the user decides when to throw, to ensure the best possible throwing technique. That meant that the app has to be able to decide what a throw is and what isn't. This proved to be not an easy task, as the athlete can make a few "warm up" swings, which aren't quite as easy to differentiate from the swings while actually performing the technique. We managed to accomplish that, as we had enough knowledge about our data to create the evaluation system. We trained the system to structure and score different mistakes, and improved the feedback provised during many many tests.
What's next for TheThrow
While the prototype, and the training part of the app works already seamlessly, there are many more possibilities to TheThrow. In the future we want to integrate challenges, that allows specific analysis of special aspects of the movement and an achievement system to keep the user motivated. A "Versus Mode", where you can play against your friends and people all over the world is planned as well, so that you can compete on the Leaderboards and compare yourself to others, creating an international discus throwing community.
Furthermore, a new discus could also be developed with the sensors inside of it. With such a device an athlete could gain significant information about the quality of his actual throw.
Built With
arduino
java
motionsensors


RAN OUT OF TIME TO FINISH RENDERING THE VIDEO. Help me acquire some better GPUs here :) http://patreon.com/yosun
What if these virtual beings become influencers? Who would own the rights to them if they were generated based off a real image of someone's face - and yet stylized enough to look not exactly like that?


This image is currently processing. Please be patient...
Inspiration
Bring the experience of an expert tour guide to everyone with a phone whilst allowing content creators to make money selling GPS triggered audio guides.
What it does
Whilst the user is driving around, their phone delivers narrations that explain the natural, historical and cultural features in the landmarks that they see.
How I built it
Web scrape for initial sample content Googles text to speech to synthesize realistic audio snippets Android Studio to show map and playback audio snippets Splash page with AWS S3 bucket
Challenges I ran into
Initially attempted an alexa skill or google assistant but lack of automatic notifications was a blocker
Accomplishments that I'm proud of
The android app
What I learned
Dialogflow, Jovu and Googles text to speech
What's next for TripNarrator
The platform!
Built With
android
auto-summarization
gps
natural-language-processing
text-to-speech


Vision
To enable neurodiverse individuals to search for jobs they can thrive in based on Strengths, Culture Fit, and Environment
What it does
A simple search tool that allows individuals to search for cultures and environments they feel they can be comfortable and effective workers in.
How we built it
We used Vue for the frontend, Google Firebase for the database & logic, Algorithmia for the AI Model, and Algolia for the search API.
What's next for Diversely
Becoming the leading job search platform for going beyond titles and responsibilities.
Built With
algolia
algorithmia
express.js
firebase
node.js
vue
Try it out
docs.google.com


Inspiration
We are techies in our 30s and have demanding and stressful jobs. We have been dabbling with meditation to relax and purchased subscription for the popular apps. However, most current apps in the market aren't personalized to our needs and journey. They play the same similar music and tend to get repetitive over time. We wanted to build something that is personalized to us and makes meditation easy.
What it does
Beads is a personalized meditation coach that enhances your meditation experience by tracking your breathing in real time using your phone's camera. It follows your progress through your session and your journey and customizes the guidance accordingly. It also allows you to build a wellness quotient based on breathing rhythms just like Fitbit does for steps & fitness.
How we built it
TensorFlow, Python and Red Bull
Challenges we ran into
Detecting breathing is more challenging than we thought especially given the different noise sources that disrupt the measurements.
Accomplishments that we're proud of
We were able to build a real-time breathing tracking which creates a visually enhanced meditation experience that responds to you and makes it easy to focus.
What we learned
That we only need 3 hours of sleep.
What's next for Beads
YC. What else? ;)
Built With
node.js
python
tf


Tempy the chameleon
Inspiration
Spent a lot of time writing the same sort of content (eg. introductions, sales emails, booking guests for podcast, etc)
What it does
Template platform that lets people create templates with variables, conditionals and the ability to import other templates. After creating a template, user can "fill in the values" and publish anywhere (eg. clipboard, gmail, pdf, social media, etc).
How I built it
Using expressjs, asciidoc parser, react and AWS backend.
Challenges I ran into
Frontend code, making different parts of templates highlight correctly with live preview.
Accomplishments that I'm proud of
Amount of non-core features that were cut out for the demo (eg. originally had a whole knowledge base component were we would store all your published templates as well as build workflows on top - ended up being out of scope for our two person team due to time and was glad to have caught that early before we sunk more time into it).
What I learned
Sleep is important
What's next for Tempy
Build it out into a real product and start finding customers
Built With
amazon-web-services
asciidoc
express.js
node.js
react
typescript
Try it out
tempy.thence.io


Landing Header
Inspiration
I decided to build Greenwood for my hack because I've experienced how complicated using decentralized finance is and I've noticed how confusing it is for beginners.
What it does
Greenwood is a hosted Ethereum smart wallet that makes decentralized finance easy for people with a Coinbase account by handling all of the complexity of interacting with the decentralized finance ecosystem behind the scenes.
How I built it
I built Greenwood by integrating with the Coinbase API using Oauth, piping Coinbase user data into a React frontend, and connecting the React frontend to a node.js backend running web3 that for creating, signing, and sending raw Ethereum transactions via Infura. The Greenwood hack allows users to buy DAI with USD directly, skipping the intermediate step of having to purchase ETH or USDC and then deposit DAI into the Compound Protocol and earn interest.
Challenges I ran into
I ran into some hiccups trying to integrate with Coinbase as their documentation is rather sparse and their error codes are vague. I also ran into issues with broadcasting transactions to the Ethereum network because there are a bunch of rules and if a transaction violates any of them the EVM will revert the transaction. I also broke my Coinbase account when trying to build out the withdrawal feature by sending a transaction to Coinbase with a price per coin of NaN.
Accomplishments that I'm proud of
I'm super proud that I was able to build out an interface that was similar to the designs I made because I'm not a great frontend dev. I'm also proud of the fact that I was able to overcome my challenges with Coinbase and get deposits to Compound working!
What I learned
I learned that I need to build out tooling for Ethereum testnet development because developing on mainnet is time-comsuming and risky. Also, I learned that it's probably not smart to continue to add functionality as hackathon deadlines approach.
What's next for Greenwood
I'm going to finish the withdraw from Compound functionality and then build out integrations with Maker, dy/dx, Uniswap, and Set Protocol. Ultimately, I'm going to build the easiest way for people with a Coinbase account to create and manage a decentralized finance portfolio!
Built With
coinbase
heroku
infura
node.js
postgresql
react
web3


Landing Page (1)
Inspiration
As juniors at college, we've realized that it can be difficult to form new friendships beyond established cliques after freshman year. As a way to break out of our social circles this year, we've arranged and attended dinners with mutual friends, who hadn't yet known each other. It was always a fun time, and everyone walked away with new friendships!
What it does
Our app allows any Vanderbilt student to sign up for dinner with 7 other Vanderbilt students they don't know. Then, we handpick a group that we know will get along really well, book the venue, and facilitate the dinner.
How I built it
We used Squarespace to build the MVP.
Challenges I ran into
We are both just learning how to code, so we spent a lot of time attempting to create an app. In the morning, we decided to use Squarespace instead as a more efficient tool for our purposes.
We also struggled to figure out how we were going to make this profitable without a product to sell. We decided to establish partnerships with restaurants close to campus to solve this problem.
Accomplishments that I'm proud of
We came in with a vague idea yesterday and we have been able to sign up 33 users already! This means we have 3 dinners planned for the week commencing Monday, December 2nd and that we will have to do more the following week! We are organizing dinner at restaurants near campus that allow students to purchase dinner with campus meal plan money. This eliminates any financial barriers when forming new friendships!
Today, we established partnerships with two Nashville restaurants. We will receive 20% of the revenue from Urban Cookhouse and Hopdoddy by customers who dine there through our app. Chipotle has also offered us free drinks and sides for dining with them!
What's next for friendible
Our current bottleneck in scaling up is that we need to attend and facilitate these dinners so that we create a memorable experience for our users. This stops us from having more dinners, more often. To solve this problem we will have a way in the app to assign someone that we trust to be the facilitator.
As we hold dinners, we think that the news of these dinners will spread like wildfire across Vanderbilt's campus both through social media and word of mouth. We expect these referrals to be the best way that we get more users.


Refurby
REFER YOUR FRIENDS TO THE JOB THEY WANT VIA BLIND IN-NETWORK REFERRALS.
The problem
Finding the perfect people in your network to refer for opportunities requires a lot of overhead. Opportunities come up to refer people in our network all the time, but it's rare that we'll blast a listserv or search LinkedIn for every request. We need an efficient but high-touch way to bridge these missed referral connections.
Our solution
Find the high-potential referrals in your network with Refurby's model
Broadcast opportunities over text to people who will actually be interested
Optionally anonymize your recommendations to people you don't want to spam
Refurby allows you to send opportunities over text to high-potential referrals in your network. Our ML model surfaces the first- and second-degree connections who would be the best fit for the role. Choose the people who you want to broadcast the opportunity to from Refuby's curated list. Then, kick off a conversation about the opportunity with the potential referral with an optionally-anonymous text message.
When we're connecting the right people to opportunities they are actually interested in, the likelihood of a successful referral is high. Our friends find the jobs they want, companies find team members who fit, and we get rewarded for making the connection.
How we built it
Text integration via Twilio
High-potential referral ML model built with Python / Pandas
Typescript / React for a delightful frontend
Python / Flask for a reliable REST API
Our team
Tadas: Full-stack doctor building websites that keep us healthy
Morgan: Software anthropolgist studying stubborn users in the wild west of js
Adrian: Building ML models for lazy, busy humans
Dennis: ML-augmented bounty hunter for bugs in our democracy
Andrew: Standing up infrastructure for the future of transportation
Special thanks to Furby for inspriation.
Built With
css
flask
jupyter-notebook
python
twilio
typescript
Try it out
refurby.netlify.com


logo
Inspiration
Phoebe spent a year studying task delegation, behavior change, and developing tech for emerging markets with Stanford HCI Lab and Microsoft Research in India, China, and Oxford. Now that she's back at Stanford, her team is building a better gig work platform to upskill stay-at-home moms in the Philippines while providing high-quality work.
What it does
Our human-centered BPO platform provides companies with affordable, low-overhead lead gen, market research, image labeling work while upskilling people in developing countries through teamwork, behavioral assessment, and expert feedback.
How I built it
React
Built With
react
Try it out
GitHub Repo


Inspiration
Most family stories and memories are passed down generation by generation in piecemeal and lost entirely to time.
Few of us will ever have a biographer to sit down with us for hours on end, ask us about our lives, and transcribe our answers. This is a problem that strikes close to home for our team as we have aging grandparents and relatives and are acutely aware of how much knowledge, tradition, and history we stand to lose if we don't act to preserve these memories soon.
What it does
Quilt is your personalized, automated family historian.
Quilt helps families
facilitate meaningful conversations through thoughtful prompts
automatically transcribe conversations and record highlights
automatically compose beautiful biographies and memoirs for your entire family
create and your family tree and securely explore your genealogy
What's next for Quilt
We started this entire project from scratch at 6pm on Friday. This was an idea we had been chewing around on for a while, and YC Hackathon was a great catalyst to take our first stab at fleshing it out. We plan to continue work on Quilt since it's a product we are building for our own families. We hope to use Quilt to make it easier to capture, organize, and share our family memories for posterity before it's too late.
In time, we plan to integrate deeper AI components into Quilt to make the conversations less structured (automatically infer topics, chronology, etc.) and explore deeper AI narrative technologies to craft personalized, high quality prose.
How we built this
Using state-of-the-art speech to text through Azure, we have built a platform that dynamically stores and understands your family history on a deep level. Using a graph datastructure, we are mapping family members to events, major life questions, and highlights of their lives. All data is collected through a live messaging interface using WebRTC, where participants simply lean back while their conversation is saved, transcribed, and mapped back to the individual person's timeline.
Built With
azure
javascript
natural-language-processing
php7
scss
webrtc
websockets


Inspiration
Manual process on various price checking, licensing policy checking and submitting evaluation requests and order estimate request to CS
What it does
In Progress, when we are having more products and services as well as getting more partners to help us selling. Because there are different rules involved in each product pricing and licensing (i.e. product code, version, platform, license model, subscription or perpetual, maintenance rate, etc). Manual process is involved in information verification and preparing the emails to CS before an estimate request or evaluation request can be sent.
The chatbot can provide features such as:
Pricing information (e.g. Unit price of different product, maintenance rate, Professional Services consultant rate)
Licensing questions (e.g. OpenEdge product trade-in, license definition)
Creating email automatically to CS for applying product evaluation for customer/partner who wants to test upgrade (this is mainly for OE customers who are not going to upgrade to latest version and want longer trail period)
Creating Order estimate on various products (not real quotation)
For POC, a chatbot could be created to answer price and licensing questions as well as providing estimate price of an order if time permits.
How I built it
Use OpenEdge database to store product price and policy information (since we are not sure the system and data sources used by CS)
Create OpenEdge REST API
Create chatbot using NativeChat
Use Kinvey as chatbot backend to prepare JSON and invoke Corticon decision services for retrieving policy information and calculating order estimate
Implement the rules in Corticon for retrieving policy information and calculating order estimate
Challenges I ran into
It may not be possible to deploy the services as we are using developer edition of Kinvey and Nativechat.
Different skillsets are required to build this project such as preparing JSON and invoking Corticon decision services in Kinvey, creating OpenEdge REST API, creating rules in Corticon, etc.
Accomplishments that I'm proud of
What I learned
What's next for Sales associate bot
Built With
corticon
kinvey
nativechat
openedge


People counting
Inspiration
Urban transit planners make decisions that impact huge populations, and the data they need to make those decisions is hard to find. Municipal transit agencies currently measure utilization by counting ridership manually, as well as surveying riders on the street.
These two traditional methods are labor-intensive and error prone. They don't accurately represent the 24/7 nature of urban transportation. They only measure when people are on the vehicle, but not the important journey they took to get there.
What it does
We built a computer vision solution that can be combined with an IoT camera to count the amount of people waiting at a bus stop, and how long each of them have been waiting. This data will be published to a dashboard that we created for consumption by transit planners.
How we built it
We used a MERN stack (Mongo, Express, React, Node) to build the dashboard.
For the computer vision tracking of riders we initially used YOLOv3 but this doesn't have the capability to ID and track a particular user which is necessary for computing overall wait times. To solve this we used a Multiple Object Tracking repository which generated features for person reidentification using the cosine similarity of CNN features. To generate these features we needed to provide proposal regions for humans - which we generated and converted to be compatible with the other repository. The full solution allows us to ID a person and track them even in the event of prolonged occlusion.
Accomplishments that I'm proud of
We're proud of how much we finished! This was our first hackathon together.
What I learned
We both learned a lot about CNNs and computer vision.
What's next for RouteIQ
We didn't get to start hardware component of this, but we're looking forward to it! That will tie together our dashboard and our data.
Built With
javascript
mongodb
node.js
react


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Vibrant - Table 40
Built With
node.js
react


Inspiration
TBD
What it does
TBD
How we built it
TBD
Challenges we ran into
TBD
Accomplishments that we're proud of
TBD
What we learned
TBD
What's next for anythingyouwant
TBD


Inspiration
Our decision to create an e-commerce application for men's fashion came from banter about wanting a way to easily browse outfits. We noticed that as guys, there were not that many ways we could learn how to dress. Sure, we could take inspiration from small subthreads and youtube videos here and there, but these were all based off perspectives of one or two people who often, we had a hard time relating to because of their age, wealth, or just the fact that they were models with six-packs. We wanted to create a free, convenient, and highly accessible mobile platform that would allow normal, regular people from all over the world to post outfits of themselves to other regular people who could actually relate to the affordability and comfortability of what other regular people wear. We often revel at how well someone dresses, but wanting to get out of our way to ask them has been something no one wants to do. This application was built with the intention to tackle these widespread issues and give people a platform to learn and grow with others.
What it does
*Our mobile application Seamless web-scrapes subreddit threads whose users post outfits of themselves. We took this idea further by giving users the names of individual pieces that are being worn in the picture. One of many instances of such a subreddit is r/malefashionadvice, which has 2.2 million users and growing. This subreddit is simply outfits that other men take inspiration from. However, we noticed that the pieces being worn were not always advertised. We wanted to tackle this issue ourselves. Aside from the main goal being outfit tagging, we also wanted to allow users to buy pieces they like through a fluid in-app purchasing flow. Additionally, we wanted to provide a social media aspect to our application by giving users the ability to comment on others fits, and connect with other users who use the application.
How we built it
Seamless was built using the mobile application framework React Native. We decided to use expo CLI in order to streamline our development process, and for the backend used Django and dbSQLite. We also web-scraped reddit in order to create our feed, and used Nginx to setup our webserver.
Challenges we ran into
The biggest challenges were in the engineering side of the process, and trying to learn and utilize new libraries such as Redux, for example, which was necessary for persistent storage and making sure items added to the cart would stay there upon exiting the application. We also spent a significant amount of time figuring out the user-authentication process, particularly for Google sign-in into Seamless, and configuring applications such as Nginx and Django in order to set-up our webpage.
Accomplishments that we're proud of
As a group, we are extremely proud of what we were able to accomplish in these 24 hours. We knew that coming into this competition, as undergraduates, we were against formidable teams that were much more experienced and skilled at the technologies they used during this Hackathon. Sleeping around 2-3 hours each for this 24-hour hackathon, we were able to create an entire landing page using Django, deploy a functional application that webscraped reddit and create a user-auth.
What we learned
We learned that we were capable of so much more than we thought, and when we applied ourselves and kept going because our teammates were working hard as well, we pushed boundaries we would've never pushed individually. It was an inspiring experience that taught us the value of sticking together through the challenges we faced, to never give up on each other, and help each other up when we faced adversities in our coding development. This was not just an extremely rewarding experience, but one where our struggles and accomplishments will push us to conquer new obstacles and have the confidence to say it's possible and I will overcome it.
What's next for Seamless
We are extremely satisfied with Seamless, and are all very interested to continue our development of the application. We are optimistic that we'll be able to launch next month, and by the end of next year have a formidable market share in the e-commerce space.
Built With
django
python
react-native
stripe
Try it out
www.seamlessfits.com


Inspiration
Fitness is something that we are very passionate about- we go to the gym every day and we know that the most important thing about going to the gym is your form. Proper form is what lets you generate maximum Power (hence watts) and also lets you remain safest when lifting. When at the gym one time doing squats and deadlifts and really focusing on keeping our weight balanced on the center of our feet we had the idea- what if there was a shoe that could correct your balance in real-time and tell you if you are too far on your toe or heel? What if you could look back and see the weight distribution graph for your last rep?
What it does
What Wattz does is it takes in the values received from the pressure sensors in the shoe, and calculates a toe-to-heel weight distribution ratio which gets inputted into a heatmap of the users foot in real time on their phone. They can use the heatmap imaging to easily fix their form during their rep. The data also gets sent and stored in the app's database, which is then used to draw post-analysis graphs of the users set to see where their form was the best/worst, and what they can improve on.
How we built it
The hardware for this project consisted of 2 ESP8266 Wifi Development boards each wired to their own FSR 400 pressure sensor via a breadboard. Each of these boards collects live data from the pressure sensors and stores it in a online database for future reference by the graphs and app. The graphs were created using the canvasjs library. This allowed us to process real time data and display it in multiple different graph formats. We were also able to process our data into live foot heatmaps using the heatmapjs library. The database was built using Firebase and the graphs were displayed in the app using webview. The phone application was built using React Native, making the application usable on both android and iOS.
Challenges we ran into
By far the biggest challenge our team ran into was the time constraint! We had so many ideas and plans that we wanted to implement and started out planning, but as the days went by and problems arose, we quickly realized that many of our ideas would have to be saved for future implementation, and that we would have to focus our current efforts on a select few things.
What's next for Wattz
In the future, Wattz won't just be a single user feedback app, but a platform in which users can share and compare data. Each user's profile will have a "Wattz" score number generated, using the amount of times they worked out, the length of their workouts, and their balance/form. Users can grow this number and share/compare it with their friends. The analysis pages will also go from being just raw graphs, to full on analysis, with customized tips for the users on how to correct their form and which portions of the rep range they need to work on fixing the most. The shoe will also hopefully be upgraded from having just a toe and heel pressure sensor, to having a multitude of sensors along the sole to more accurately measure weight distribution across the foot.
Built With
arduino
canvas.js
esp8266devboard
firebase
heatmap.js
html5
javascript
react-native
webview


Inspiration
We love our grandparents but feel guilty that we don't talk to them often enough. Like them, there are millions around the world that are lonely and are longer for more meaningful family interaction. We are bridging the communication gap, so that grandchildren can communicate more easily and intuitively with their grandparents.
What it does
Allows the grandchildren to communicate like they do on their social media (Snapchat, Instagram, Facetime) and creates a seamless intuitive interface for their grandparents.
How I built it
We employed a variety of micro-services to allow for the different features. These include: machine learning to detect face and motion, web-application for grandparents, swift iOS application for grandchildren, etc.
Challenges I ran into
The computational constraints of the raspberry pi and associated web cams.
Accomplishments that I'm proud of
Made a hardware device, an iOS app, and a web app that communicate.
What I learned
We learned how to use a raspberry pi and iOS development. Learn about a completely underserved and neglected market.
What's next for Bridge
Bridging the gap between the billion grandparents and their families.
Built With
flask
node.js
swift
twilio
vue


Letssplit
Inspiration
I operate many shared subscriptions. It's a pain to form and manage groups. As a result, not a lot of people do it. We've made that process simple.
What it does
For $1 / month, you can join unlimited discounted subscriptions. But it’s free if you already have a group to share with. Just hop on the app, join as many subscriptions, and within minutes get connected with coworkers looking for the same plan.
How we built it
Adalo
Challenges we ran into
Fleshing out idea, business model, etc.
Accomplishments that we're proud of
Got working app
What we learned
how to use adalo
What's next for Letssplit
Finish building it (maybe start MVP with just helping manage groups use case, then forming). If things work great, we may expand to other ways to help people save money (e.g. ebay buy/sell auction, meet other people)
Built With
adalo
Try it out
lets-split.unicornplatform.com


Inspiration and What it Does
Have you ever felt trapped with two hands on the wheel and a million ideas that come up while we are driving? Unleash your brain and keep your hands and eyes on the road! ThirdArm can run in the background while you dictate ideas, content, commands and actions that trigger third party apps, without ever requiring your attention on the screen. All activity is saved for you to trigger actions when ready and nothing is ever lost, because your audio and transcription are both saved.
We are not just Hands Free, we let you offload your brain screen free and trust it will all be saved and ready for you when your hands become available. Audio is both transcribed real time and recorded in an easy to reference way, so you can correct transcription if it ever errors, and train the transcription to be the best ever possible for your voice.
Third party apps can receive actions. You can also save notes for future mailing. The opportunities are endless. Focus on what you need to do, and leave the screen.
ThirdArm can count on affordable monthly subscription and spread virally with discounts for inviting friends to use the app.
How is it different?
Unlike Siri or Alexa, or any other voice assistant that asks you to check entries for immediate action, ThirdArm is not just Hands Free, but also Screen Free! Other transcription software on the market offers back only transcription which may or may not be accurate. For long form content, that leads to major problems and makes entry unfeasible. ThirdArm allows you to trust the system will never lose your notes, because we preserve your audio for immediate reference back to the text that was transcribed. We can train transcription and voice recognition algorithms faster than any competitor because our users correct the transcription for us easily.
How I built it
Built using Unity, ThirdArm runs on iOS and Android, and Windows Phone. The transcription process can be trained our users to be the best on the market with instant feedback and audio to text correlation. We can easily add spacial computing.
What's next for Third Arm
Running it on the drive back home :) The app can become an indispensable partner for millions who spend hours driving, operating machinery, cooking, working out. It allows your brain to be productive when your hands are busy. Would be fun to see how many truckers publish books thanks to ThirdArm :)
Bigger mission
Beyond enabling you to be creative, ThirdArm enables us to get back to a life away from screens. You can have your phone jot down your ideas, but not have to stare at it.
Built With
android
dreamlist
ios
natural-language-processing
platform
unity
voice-control
Try it out
www.thirdarm.app


Kind-Feedback
Nina had the idea to improve the process of giving feedback in large teams. Usually the employees in charge of teams have to provide feedback to code submission of their teammembers while also keeping their motivation up. Through motivation theory we want to improve the motivation and feedback process by provide personalized suggestions on how to give feedback.
Built With
azure
github
javascript
node.js
python
Try it out
GitHub Repo


Inspiration
I love anonymous funny stories or and enjoy anonymous rant.
What it does
Allow you to post anonymous stories (or tea), comment and react on other people's confession anonymously
How I built it
ReactJS and Radiks for front end NodeJS and Radik-server (Gaia) for back end
Built With
radiks
react
Try it out
confessin.com


We have built this transaction and expenditure analyser as people often do not often realise and lose track of how their money is spent. Spending aggregates and this eats into their monthly income. We aim to make the users more aware about their financial decision making quality.
Our project has been built entirely using Python. We have created our data sets with consumer expenditures and transactions. Using numpy we have calculated an ideal amount they should spend based on their past transactions. Further we have created graphs displaying users total expenditure as well as their savings in a given year.
Once we have read a list of transactions from a CSV file we analyse each individual transaction and give it a smart score which measures how sensible that transaction was. This score is calculated using a function which takes the necessity and how much they spent on this transaction relative to others.
Initially we were not very familiar with Git but over time we improved our collaboration skills. We did spend a lot of time generating our data sets and figuring out how to analyse transactions.
We are happy with what we achieved in our small diverse team of 3 especially in the short time frame. Given more time we would like to provide users more information so that they can increase their savings rate as well as make better financial decisions.
Built With
matplot
matplotlib
pdfpages
python
tkinter
Try it out
GitHub Repo


Inspiration
We are a team of college students who love to shop. However, we have found that discovering when items go on sale is tedious. Although there are products like Honey, they only support specific merchants that they have explicitly partnered with. We decided to take on this problem, wanting to build a general-purpose solution to track any item on the Internet.
What it Does
COP allows you to paste a link to any product and track the price of the item. A user tells us the price point that they wish to be notified at, and we send a text message to the user as soon as the price is below that threshold.
How We Built It
We created a simple backend with Flask, using a database backed by sqlite3 to prototype and deploy changes as quickly as possible. We used ngrok until we were finished, then deployed our code onto an EC2 instance. The entirety of the iOS client was designed in Figma and coded in Swift.
Challenges We Ran Into
The main challenge we ran into was correctly determining the price of an item, given the website. Although this seems like a trivial problem to solve, there exists a significant amount of noise, and each website shows the cost of a product in different ways. We realized that existing platforms only worked on certain websites because they added manual handling for every website they supported. We aimed to solve this in a different way by asking the client to submit the current price of the item they want to track. Given this additional information, we found that we had enough signal to be able to correctly track price changes consistently across different sites.
Accomplishments That We're Proud Of
We originally planned to work on an existing idea, but were inspired by the others' pitches to work on a new idea from scratch. We brainstormed different approaches, designed, and developed a fully functional product in 24 hours.
What We Learned
We learned that getting enough sleep before hackathons is crucial, and drinking Red Bulls only works to a certain extent.
What's next for COP
We plan on increasing our consistency with new websites as much as possible, and using our data to eventually create a ML model for this problem.
Built With
figma
python
swift


Inspiration
Voice input is becoming increasingly important in the era of smaller and smaller devices. However, those without voice are left behind. Even for those with vision, keyboards on smartwatches are notoriously tricky to use due to small screen real estate - meaning voice is often the only usable input method.
Many IoT devices have no speakers, meaning blind people cannot use acoustic screen readers.
We propose a general purpose input/output method using morse code for input via a single button and output via vibration - being usable even on small devices and by people who have neither vision nor hearing.
Trained morse operators can routinely reach speeds of 50 words per minute - faster than the average person using a smart phone keyboard (40 wpm).
What it does
Our smartwatch app translates single button touch morse code into text. After entry, each character is repeated back to the user through watch vibrations in morse. This way, even blind deaf can check what they've entered is correct and proceed.
How we built it
With Kotlin and Android studio on a Fossil smartwatch running Wear OS.
Challenges we ran into
Couldn't get Android Studio to emulate virtual devices on a Windows Computer - getting nonsense error messages (enable setting X in BIOS, despite it being already enabled). It worked straightaway on MacOS.
Android doesn't provide a standard library for identifying swipes, only short and long presses are easy to detect without rewriting gesture recognizers.
Accomplishments that we're proud of
Proof of concept of a working morse keyboard with vibration feedback on a smartwatch
What we learned
Morse code! Android development, in particular for WearOS.
What's next for Morsify: General Purpose I/O for blind-deaf people
Built With
android
custom-keyboard
java
kotlin
smartwatch
wear-os
Try it out
GitHub Repo


Inspiració
El repte proposat per Origen ens ha motivat a fer aquest projecte perquè, ens permet integrar diverses tecnologies que no havíem utilitzat fins ara.
Què fa
El nostres sistema està compost per tres blocs principals, un d'ells que fa servir sensors per llegir la llum que hi ha en una determinada habitació, l'altre és l'encarregat de controlar la llum de l'habitació en qüestió, finalment l'últim bloc és l'encarregat de gestionar la informació del primer bloc per controlar el segon. Aquest últim bloc, a més a més, et permet veure l'historial de llum ambiental que hi ha hagut en una habitació al llarg del temps.
Com l'hem construït
El primer bloc utilitza una placa NodeMCU ja que, té un adaptador de Wi-Fi integrat a la placa que fem servir per comunicar al servidor la informació que llegeix del sensor de lluminositat que hi hem connectat. El segon bloc consisteix és un "smart plug" de la marca ZOOZEE, i utilitzem el servei conegut com a IFTTT (IF This Then That) per tal d'activar i desactivar la llum que hi connectem.
Finalment el tercer bloc és un sistema de temps real que serveix tant una RestAPI, que es fa servir des del primer bloc per transmetre la informació dels sensors, com un servei web, pel que l'usuari pot visualitzar l'historial que s'actualitza en temps real amb web-sockets, tots aquests serveis estan programats en GoLang, i JavaScript.
Dificultats que ens hem trobat
Inicialment teníem la intenció d'utilitzar el sensor de temperatura i humitat, al veure que no funcionava i no n'hi havia més de disponibles, vam decidir que utilitzaríem el seu lloc un sensor de lluminositat.
Aconseguir que la placa NodeMCU tingués memòria no volàtil per tal de no perdre la informació mentre es trobava en mode repòs.
Hem hagut d'implementar el protocol HTTP/1.1 per a la NodeMCU, concretament la codificació correcte dels JSON i els headers del protocol.
Integrar l'actualització a temps real dels plots que es mostren a la pagina web. Integrar la base de dades SQLite3 amb el servidor programat en GoLang.
Assoliments dels que estem orgullosos
De resoldre les dificultats que hem mencionat anteriorment.
Poder acabar un projecte que inclou tantes tecnologies diferents i aconseguir que funcionin totes juntes.
El que hem après
Utilitzar les bases de dades SQLite3.
Creació de gràfiques amb D3.js
Entendre el protocol HTTP/1.1
Utilitzar IFTTT
Quin és el futur de Smart lights
Integrar més sensors i endolls per a controlar-los en funció dels altres sensors, com per exemple, que quan obris la porta engegui la Nintendo Switch.
Built With
arduino
css3
d3.js
go
html5
http1.1
ifttt
javascript
smart-live
Try it out
GitHub Repo


Hackatum 2019: fortiss - Gondelfunk
Built With
canvas
css
dockerfile
html
javascript
node.js
react
websockets
Try it out
GitHub Repo


Inspiration
Recently, there has been an explosion in the awareness and study of student mental health. Multiple studies have shown that compromised mental health often leads to decreased motivation, heightened stress, and decreased motor function, all of which serve to further deteriorate one’s mental health (Accordino & Slaney, 2000; Weissinger & Iso-Ahola, 2013; Rouse, 2011).
Students often experience the perfect storm of these internal factors, combined with external pressures of increased responsibilities, academic rigor, social expectations, and other common characteristics of young adulthood. This has led many to characterize student mental health, especially on university campuses, as a “crisis” (CBC News, 2019; The Guardian, 2019; Forbes, 2019).
Psychological studies have also shown the power of positive reinforcement and habit formation in effecting positive change in mental health (Sigler & Aamidor, 2005; Gardner, Lally, & Wardle, 2012). Just as negative behaviours and negative thoughts mutually reinforce each other, positive behaviours and thoughts do the same.
In this project, we channel all of this information and combine it with our passion for technology into a mobile application: XtraLyfe. XtraLyfe provides a simple, entertaining context to a student’s otherwise mundane daily tasks. We aim to break the overwhelming, repetitive stress of continuous task management by placing it in the context of a game, giving users a sense of progress that positively reinforces their behaviour, rewards positive habit formation, and ultimately, improves their mental health to empower them to develop these skills on their own.
What it does
Picture this: You get out of bed and walk into the kitchen. You see some bread and fruit that you know you should eat for breakfast, but you’re not sure you’re in the mood. You have to go to 6 lectures today, and 3 exams coming up in the next week. You’re also trying to learn a song for your upcoming piano recital. You think back to this past week, and how this same stress has start to become all too familiar.
Now picture this: You’re a futuristic space explorer, charting your conquest of the galaxy. Your spaceship has an odometer, and you’ve become addicted to the thrill of increasing those miles. As you fly, you fight asteroids and other obstacles, earning gold for every step of your mission. Your handy-dandy camera captures proof of your journey. Each day, you conquer new obstacles, becoming stronger as each leg of your journey passes by.
Our application aims to bridge the former, mundane situation with the excitement of the latter. It places the user in the driver's seat of a futuristic space exploration scenario, where tasks are represented by miles travelled, gold accumulated, collectibles collected, and asteroids destroyed. The user sets their identity with something they’re all too familiar with: their school login. Their class schedules and other daily routines (ex. meals) are automatically imported into the app every day, and users are incentivized to attend/complete them as, using GPS and timers, their attendance/completion is rewarded with in-game accomplishments (miles travelled, gold earned).
Users can also input their comparably long-term goals (ex. exams, learning a new skill), represented as asteroids for them to destroy over the course of time. Their gold can be exchanged for collectibles, allowing them to personalize their journey and take ownership of their progress.
Finally, none of this would be effective if users were not held accountable for completion of tasks — our application also encourages users to take pictures of their meals, classrooms, outdoor excursions, etc. This enables users to not only charter their journey, but also enables the app to confirm completion of tasks.
All of this is meant to foster positive habits through positive reinforcement. As the user interacts with the application, our hope is that they become less reliant on the application’s entertainment focus, and can instead incentivize themselves to see their responsibilities as positive steps along their life journey, over which they feel ownership and control.
How We built it
We use React-native to build this application, writing our frontend and backend from scratch. We used a MongoDB database to store all persistent data, and used GCP to deal with the photo feature mentioned.
What's next for XtraLyfe
There are many improvements we hope to make to facilitate our application’s integration into the lives of our users. Firstly, implementing any sort of speech/audio input/output would provide an alternate means of interacting with our application, encouraging its expansion. Furthermore, we hope to integrate texts/notifications/reminders into the application, in case the user does not remember to log their progress themselves. Finally, since the focus of this entire application traces back to mental health, having professionals (possibly as NPCs in the application) could also be beneficial to helping users take ownership of their progress, and ultimately, become strong, positive actors in their own lives.
Built With
express.js
gcp
javascript
mongodb
node.js
react-native
Try it out
GitHub Repo
GitHub Repo


Inspiration
In the cities around the world there is a huge amount of cars, that are used rarely by their owners. That's why so many cars only stay in their parking lot. This circumstance obviously is a waste of technology. On the other side there is a raising need for efficient and new mobility solutions, which are more flexible and cheaper as cities won't stop growing. In Germany (the birth country of cars) for 73% of the people their car is an important part of mobility. For young people (< 25 years) this fraction is only 36%. (https://www.zeit.de/mobilitaet/2018-04/autofahren-bedeutung-junge-menschen-stadt-land-studie).
Our aim was to enrich the future of mobility by creating a green, open and connected solution.
What it does
We empower car owners to rent out their cars to other people through an extremely simple process. Through a mobile app car owners can earn money by just setting a time frame, in which the car is available to renters. Renters on the other hand have access to a huge amount of cars, which they can rent for short use and a cheap fee.
Now a question may arise: "Why should I as a car owner trust a stranger to take care of my car?". The answer is simple: Renters are rewarded for proper driving behaviour, since the car tracks it through its sensors. Therefore, when he doesn't drive bad (uses brakes a lot, won't keep distance to car in front, ...) he will have to pay less to the car owner at the end of the use.
How We built it
We developed a smart contract, which handles the financial transactions between renter and car owner. Through a mobile app both of them communicate with it.
What We learned
We learnt a lot about the development of smart contracts and blockchain in general and how it can be used for a greater good.
Built With
ethereum
ios
mapkit
smartcontract
solidity
swift
webfrontend


Inspiration
We found combining art and technology is pretty sexy.
What it does
It analyzes the body movements and matches a sound to it.
How we built it
We assembled an Arduino Kit, collected body movement data, analyzed the data using Python, and found some specific patterns in some movement and put notes on them.
Challenges we ran into
Making it a real time system.
Accomplishments that we're proud of
Pushing our boundaries between art and technology.
What we learned
Arduino and hardware stuff.
What's next for X-Tunes
Use more complicated sounds.
Built With
arduino
bluetooth
python
Try it out
GitHub Repo
docs.google.com


Inspiration
We thought about different ways to complete the Microsoft challenge and that idea seemed like the best to us
What it does
Automatically detects epilepsy inducing content on your screen and tries to mask it so that you don't get a seizure
How We built it
We used a 3D neural network to detect problematic areas of the screen using 15-frame buffers
Challenges We ran into
Making the Matlab AI compatible with Python screen capture
Accomplishments that We're proud of
Trained a complex neural network with the help of the amazing guys at MathWorks
What We learned
A lot about how AI works, many things about some python tools that we didn't end up needing
What's next for antileptic
Optimizing, lowering latency, making it usable
Built With
ai
matlab
opencv
python


Inspiration
We were inspired by the social fitness network Strava that is primarily used to track cycling and running exercises, using GPS data. We wanted to extend the concept behind Strava to an efficient driving system where people are encouraged to optimise average monthly fuel consumption on certain stretches of a route.
What it does
Encouraging people to have an efficient drive via a leaderboard.
Companies sponsor the challenge for a particular route.
Cars/drivers undertake it.
Every month all users on a particular route is evaluated in the form of a leaderboard based on the average fuel consumption on that route.
The user with least fuel consumption (present at the top of the chart) receives a token.
How we built it
Frontend:
Python Flask (WIP)
Backend:
Solidity:
deploy the smart contract
add User: adding a new user to the app
add route: new challenge route is added to the system
subscribe to the route: user subscribing to the challenge
add drive to route: user drives along the subscribed challenge
get the average fuel consumption score for the subscribed route
transfer rewards (tokens) at the end of the month
Integration:
Web3js
Challenges we ran into
New topic -- new concept & technologies (Solidity, Blockchains etc.)
Integrating backend and frontend
Sleep deprivation, not enough pizza ;)
Accomplishments that we're proud of
Our awesome team! B-)
Successfully deploying a smart contract using ethereum
Surviving the Hackathon ;)
What we learned
Concepts of Blockchain, Ethereum, Smart contracts
Flask, webapps
What's next for IncentiDRIVE
This can be extended as tokens for sustainable charging of electric cars
Built With
css
html
javascript
python
solidity
web3js
Try it out
GitHub Repo


Inspiration
Make your dev life great again!
What it does
We have made an INTELLIJ-ent stress level tracker that provides live feedback based on a person's facial expressions
How we built it
Our solution comprises of two pieces
Developing a model for predicting the stress levels
Creating an Intellij plugin that invokes the model and triggers a response
Challenges we ran into
Creating the exclusive dataset for the model.
IntelliJ plug-in SDK.
Synchronizing the response of ML model with IDE's plugin in real time.
Accomplishments that we're proud of
Teamwork
Skills development
What we learned
Knowing more about yourself, how far can you push!
Sharing diverse perspectives
What's next for Chill Me Out
We are planning for making Chill Me Out as a cross-platform service across all Intellij products
Built With
intellij-idea
java
python
pytorch
Try it out
GitHub Repo


Inspiration
There have been reports of people having an emergencies in a public places, who did not receive help, even though they are obviously in danger. This is because of the "bystander effect", the phenomenon where people don't feel responsible when someone is in need of assistance, because "somebody else will take care of it".
What it does
The device will connect to an app and is worn on the upper body. Using machine learning, it can be detected if the user falls down. If that happens, the Phone will play a prerecorded message, commanding explicitly everything that needs to be done to help the person. For a person with a known heart condition, the instructions would be to call an ambulance immideatly. If the person has epillepsy, the instructions might be to remove anything from the vicinity of that person, that he might hit during a seizure.
How we built it
An Arduino will constantly transmit data from a gyroscope and an accelerometer via bluetooth. The app then determines whether a fall has occurred, using a model made with machine learning. This will trigger the app to make a loud noise, followed by instructions.
Challenges we ran into
Finetuning the machine learning algorithm was very hard as nobody in the team has used machine learning techniques before. (Thanks Eric!) Also, programming the arduino bluetooth module was new territory to us all.
Accomplishments that we're proud of
We each learned something completely new to us. Machine learning, programming hardware controllers and managing bluetooth connections
What's next for Soft n' Fuzzy
We want to achieve a more friendly UI and add different profiles for different disabilities
Built With
android-studio
arduino
c
java


Screenshot of the web app
Inspiration
Tourist numbers are unpredictable, which leads to a poor experience for tourists in popular areas. In the peak periods, main attractions are packed and uncomfortable while in the lean period, they are empty. This leads to underutilization of tourist spaces. This also make its hard for local companies to build and manage facilities. We unlock insights from historial and current tourist data to improve the tourist experience.
What it does
Predicts tourist footfall, outdooractive page views and page clicks based on facilities present there, difficulty of activities and so on. This is used as feedback for tourism agencies and local governments to improve the tourist experience, and also by tourists to avoid crowded spots.
How I built it
Scrape tourist popularity measures from the outdooractive.com website, and tourist facility information using their Data API. Train machine learning models on this data to then predict the popularity of a tourist spot given its features.
Challenges I ran into
Fast web scraping, machine learning model tuning
Accomplishments that I'm proud of
Built a minimum viable product (MVP) with about 8 hours of effort. Used the Outdooractive API and learnt about web scraping
What I learned
New technologies and the kind of data that is present in the tourism industry, how to scrape websites. Implemented linear regression from scratch in Numpy
What's next for HappyTrip
Use more kinds of data from the outdooractive API and other sources such as Google Maps, Google review to improve the accuracy of prediction
Built With
beautiful-soup
numpy
python
scikit-learn
selenium
Try it out
GitHub Repo


Inspiration
We followed the guidelines shown in the website of that chapter
What it does
It tries to calculate the salami slicing with a simple algorithm
How we built it
We came up with a generic formula to calculate the sum of all the bills and then with the discount try to calculate the salami slicing
Challenges we ran into
Actium Digital Challenge
Accomplishments that we're proud of
This was our first hackathon and we have reached the final stage, more than we had expected.
What we learned
How does a CTF work and its procedure to solve it. We also learn how to find text hidden on images and audio tracks.
Built With
c++
Try it out
GitHub Repo


Inspiration
Wasted time, effort and money in production
What it does
Optimizes the production in a smart way by learning about the DUTs
How I built it
Python, Machine Learning and a lot of fun
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Smart IoT AI
https://github.com/tobiolalusi/rus-dut https://drive.google.com/open?id=1Y_JpHK9ZE1RQKnZDBGxsM1aMVQs4qeSI
Built With
flask
python
react
scikit-learn
xgboost


Inspiration
Solving a real-world problem
What it does
Detects cracks in industrial material via images
How we built it
Using deep learning and computer vision techniques
Challenges we ran into
Manually doing annotations, getting deep learning models (U-Net, Yolov3) to run
Accomplishments that we're proud of
The application works extremely well
What we learned
Hackathon is not easy
What's next for AutoCracker
Not much
Built With
python


Logo of igit
Finding the right commit message is hard. Maybe it's even tempting to ignore them and add a placeholder instead. Every git user did the git commit -m '.' at some point in their career.
What it does
igit commit takes information from your issue tracker, the git repository and the staged code. Those are used to render a smart commit message template, helping the developer to fill them with meaningful and explaining content.
How we built it
We built igit as a python package with focus on extensibility of information sources, e.g. the issue tracker or language support. To interface with git, we used pygit2. Template rendering is done via jinja2.
Information are gathered in dedicated modules and rendered with a template that can be configured for different git repositories similar to a .gitignorefile.
Challenges we ran into
missing or incomplete documentation for a package
working on a subset of files with multiple people (happy merging!)
Accomplishments that we're proud of
working command line interface
structured repository
What we learned
We learned that collaborative work, given only a short amount of time, is challenging. But working in a small (local) team makes prioritizing issues and solving problems as they arise a lot easier. Someone with an idea is around to help.
What's next for igit commit
The next steps involve building a igit command line interface, supporting:
other programming languages
different issue trackers (e.g. GitHub, Atlassian Bitbucket)
more subcommands, helping the developers with changelog creation or merge request processing
Built With
git
love
python
Try it out
GitHub Repo


Inspiration - Make life easy for the banks business team, products implementation teams
What it does - Standard way for eliciting business requirements, ready made solution from Finastra payment product
How we built it - PHP,JAVA,SPRINGBOOT,AZURE AI
Challenges we ran into - making the UI jazzy
Accomplishments that we're proud of - It will really solve a practical problem that all the teams face
What we learned - Learned integrating Chat bot
What's next for BLEND- creating a platform, add ML
Built With
angular2
azure
chatbot
java
mongodb
php
springboot
Try it out
labtrendz.com


Inspiration
After decades of dictatorship and past-revolution corruption, the people of Tunisia elected a candidate who was entirely new to politics as their president. To them, this proved that they are finally living in a truly democratic system and that the power is in their hands. This excitement resulted in different movements like Consume Tunisian and We always want our Tunisia to stay clean. The latter inspired thousands of people of different ages and backgrounds to come together and clean beaches, roads, and other places in their neighborhoods. However, this movement is organized in a decentralized way on various different Facebook groups. With up to 50,000 active members in one group, finding events that are nearby can be really time consuming and chaotic. We believe that such a movement could develop an even greater impact if events and actions are all being organized and communicated on the same platform. As waste pollution is not a Tunisian but a worldwide problem, we decided to build an app that enables communities to motivate and to organize themselves all over the world.
What it does
After people have signed up or have signed in, they see a map with the cleanup-challenges that are announced, being worked on or completed in their neighborhood. You can click on an announced challenge to see the details like time, location, and volunteer for it. By clicking on a completed challenge, you can scroll through pictures and text posted by the people who cleaned up during the event. A click on an ongoing event brings you to live-pictures that can be swiped through. In addition, people can create new challenges by entering location, date, time and some more details. Signing up for challenges or creating new challenges gives the user points; the users with the most points are listed in a leaderboard.
How we built it & challenges we ran into
We built the webapp in javascript, node, featherUI, framerXUI, cantomap, and html/css.The map we first wanted to use was buggy, so it took us some time to find a good one.
Accomplishments that we're proud of & what we learned
One team member bailed on the way to our project, so we are proud that we were able to finish the challenge with such a pretty result. During the process, we learned how to do front-end development. Additionally, we know now that it might be better to look for reliable and motivated teammates ahead of the hackaTUM.
What's next for Clean it up
As there is actually a need for such an app, we are going to see if we find a few more people who are willing to work on developing an actual app out of our webapp.
Built With
carto
coffeescript
css
feather
framerx
node.js
react
tinyfaces
Try it out
GitHub Repo


Inspiration
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Kotumba
gvgvg


RepUp - Logo
RepUp - Gamified issue tracking
A lot of large software projects suffer from known issues that simply aren't being worked on - by anyone. at all. ever. There are a few reasons for this (high effort, low reward; low visibility; unattrative tasks; ...), which realistically won't be solved by assigning random indiviuals to these issues alone. That's where RepUp comes into play: By rewarding users for every fix they make, we encourage high amounts of participation and effort.
Older issue? More points! High priority? More points! Continued participation? More points!
We hook directly into YouTrack, one of the most popular issue tracking solutions available today. By aggregating the supplied data we can make solving issues more fun and rewarding than ever.
You will RepUp your issues in no time!
Built With
css
html
javascript
python
react
Try it out
GitHub Repo


Logo
Inspiration
When working with multiple windows and countless tabs, finding the right one is a hassle and pulls you out of your focus.
What it does
Kaneda gives you a fuzzy search that allows you to type e.g. "stacflow add child" and immediately switch to your browser window and there to the tab "StackOverflow: How to Add a Child in JavaScript".
Challenges we ran into
Switching to an open tab from within an extension is easy. But how do you do it from outside of the browser? Also tricky: A system-independent way of accessing open windows.
About the name
Kaneda is the protagonist of the wonderful anime "Akira" from 1988.
Built With
css
html
javascript
python
x11


Inspiration
Since we are quite far in our bachelors degree of computer science we all have some ideas how to improve the life of a software engineer. And often it's one of the biggest issues to orient oneself in a new software project. So we want to tackle that problem. We are trying to rethink the ways in which software projects are navigated and viewed.
What it does
Our Project ⊤.ology visualizes a Java software project with all the dependencies in a git repository. It shows who writes a lot of the important code of a class and other contributors, so a new developer can find the perfect contact person for a problem.
How We built it
The service is built on top of Spring Boot in a very extendable manner. The frontend code runs separately from the backend as visualizes interesting data about software projects in different manners.


Our logo!
Inspiration
Probably billions of people around the globe are facing the same nuisance: long periods of sitting and and little physical motion. Due to this fact, back pain and other related complaints are common troubles in our society. In a large part of the cases, bad posture contributes to the complaints or even makes them arise in the first place. We indend to develop a new digital solution to this problem using motion sensors. This should be a helping reminder and an incentive at the same time - for a health benefit of large numbers of people.
What it does
Our system analyzes the neck position and motion with a microcontroller based motion sensor directly attached to the neck. With the associated smartphone app, users can compare their own sitting posture with the ideal one in a precise three-dimensional figure. In particular situations, users are reminded to keep a healthy position or warned to return to one.
How we built it
We assembled a small circut board with an Arduino microcontroller, a combined acceleration/gyroscope sensor and a bluetooth sensor. After retrieving data from this, we apply some filters to make it smoother and more usable. Using some person-dependent coordinate mappings, we can translate the recorded movements to a live app with a 3D model displaying the neck posture captured by the sensor board.
Challenges we ran into
The sensor data typically contains noise which requires the application of a smoothing filter to make it more applicable. Also, gravity and effective accelerations are only observed together by the accelerometer. Proper usage of gyroscope measurements are required to separate them. Mapping the sensor measurements into a 3D model for motion analysis and display required some coordinate transforms which need to be adjusted to individual users.
Accomplishments that we're proud of
We managed to implement a detailed three-dimensional display of the actual neck position and movement which can then easily compared to the ideal position. This is complemented with a simple scoring system such that users can evaluate their current posture.
What we learned
We made new experieces in methods to adjust sensor data and make it more usable for practical purposes. This project could also give us some insights into retrieving and processing sensor data in all levels including the hardware.
What's next for xPosture
xPosture has a potential for further development and extensions in several different aspects. By adding more sensors, also more parts of the body could be considered in the analysis to produce more detailed results and recommendations. Making this product available to a broader audience, e.g. elderly or physically disabled people, would most likely require some adaptions to anatomic differences as well as individual needs. With the functions to analyze and evaluate postures, this product might also be used in medical studies to further investigate optimal postures and their consequences.
Built With
arduino
c
python
unity
Try it out
GitHub Repo
docs.google.com


Inspiration
70-80% of people with poor reading skills suffer from Dyslexia. Whilst it may not be very physically painful or require you to take a lot of Pills, it hits people on a different level. Often people with Dyslexia are labeled just too stupid to read, or too lazy to learn it, that is why a lot of the affected are embarassed to search for help. Especially adults who suffer from Dyslexia tend to hide it, and thus are unable to fight named disability. That is why we tried to create a virtual helping tool, which enables patients to learn reading at their own pace, and without needing to consult other persons. Although the application is mostly targeted towards Dyslexia patients, it is suitable for everyone who has reading issues.
What it does
We designed a quest-like app on iOS platform providing some challenges for users with Dyslexia, which find difficulties in associating the written words with the meanings. We provide a stress-free platform for the users to practice their reading. Our quests have different levels, from the beginning levels which are familiarizing different syllables, to more advanced levels which deal with vocabulary in daily life, making a gradually progress in imitating daily conversation, famous quotes from movies to pop songs. When users make continuous progress in the quests, it helps them to stimulate their ability to associate the written words with the meanings , strengthen their reading ability, and build up confidence in interpersonal communication.
How I built it
We started our ideas originally by designing the app with an IOS frontend and a backend develop by .Net Core hosted by Azure. First, when entering the app, the app will ask the user to sign up first so that the backend can either retrieve their user profile or create a new profile. After the backend receive their profile ID, it will generate quests for users according to their levels, which include the words/ sentences and the sound associate with them. The user will try to read a word/sentence out loud and press the button to record their speaking.Then, their recorded sound will be posted to the backend to compare the word and the sound user actually recorded (The comparison is done by calling Azure cognitive service speech to text), then they will be scored. Afterwards, the Users can play the sound in the app (The sound is retrieved by calling Azure cognitive service text to speech) and thus hear the correct pronounciation. There will be highlighted parts of the words/ sentences if there is some parts need the users to pay attention to. Then the user can repeat the test to see if they make any improvement.
Challenges I ran into
Right in the beginning we were confronted with the challenge of how to implement and design the communication between the user and the program. Obviously it cannot be done via written text, so the more or less only alternative was to use Text to Speech. As Dyslexic people often have problems with writing as well, we had to find a way for them to put in their solutions differently. We settled on using Speech recognition, which turned out be quite a challenge as well. Normally the user speaks in a very clean way when trying to communicate with a device, which Dislexya patients are capable of, but when reading something out load, they are often very slow and mispronounce a lot of words. That is why the speech recognition had to be able to locate these mistakes, while still recognizing the correct words. Furthermore, we had to find a special method to make the patients remember what they learned, as the conventional way already failed to do so. There is a multitude of approaches to this issue, but the most common one is the use of Phonetics and Symbolism. All in all, it was quite challenging to step into the shoes of a dyslexia patient, as reading is something so natural to the people who do not have problems with it.
Accomplishments that I'm proud of
Creating a working basis for a program that is designed to help people, and including methods which are adapted to methods that proved to be a useful help to people with dyslexia. Also the fact that we created this project as a team and all contributed. The work with Cognitive services also appeared like a big challenge to us at first, but we managed to include it in our program in a very useful and efficient way, which is something that we are really happy about.
I can get familiar with Microsoft Azure within an evening. Previously I was using Windows Servers technology, in this challenges I learn the skills to develop on Azure platform, and successfully develop some API connecting with Azure SQL database.
What I learned
When it comes to the non- technichal aspectsThrough the challenge, we got to know many types of disabilities, though some of them may not be well-known, we really need to pay more attention to them. We have done some research on Dyslexia, to know more about the symptoms, the cause of it, the challenges the patients are facing, and the possible ways to assist them. Time management and stress management within a limited time span, is something that we also had to learn and which was fairly difficult at first but with the time became more easy. For the technichal aspects, we learned about Rapid prototyping, work as a team when it comes to writing code and to separate the tasks between frontend and backend. Development and deployment with the Microsoft Azure platform. Also, we got to know the Azure cognitive service and learned how to make use of their services.
What's next for Reading Coach for dyslexia patients
Possibly enable the Application for different Languages and having a broader dictionary. Longer Sentences and a more diverse number of tasks. A further gamification to make the learning part more fun for the users. Integration with conversation agents. Developing a Web-Application and Android Application. A more diverse backend, possibly with a learning aspect about the users individual strengths and weaknesses.
Built With
speechapi
swift


Dance Monkey
Inspiration
'Those who were seen dancing were thought to be insane by those who could not hear the music' --Friedrich Nietzsche
One of my friend i know who was very popular in school and university, he was intelligent, smart and funny. However when it came to parties he was very boring because he could not dance. And we think that everyone has a right to dance. That is why we wanted to create a tool that tracks your body motion and gives you positive feedback so that you can learn to dance the way you want to in your private space.
What it does
We use sensors ,such as accelerometer, gyroscope and camera to track your body movements. These detected motions / body movements are analyzed using machine learning and referenced against the best dancers in the world to give you active feedback. This provides an oppertunity for the user to analyze how he can improve as a dancer.
How we built it
We used sensors and camera to collect the data. Then the data is analyzed using OpenCv to catogarize the dance moves into Novice, Advanced and Master. The website provide a live demo on how it works, analytics of user's performance, the business model and the pricing model.
Challenges we ran into
Lack of hardware provided
Availability of True Positive Data
Accomplishments that we're proud of
Collecting Data from Sensors, analyzing it and using visualization it is displayed.
Working model that detects the movements
Comprehensive and minimalistic Website of our product.
What we learned
What's next for Dance Monkey
Store the data of true positive
Extension in medical field for physiotherapy
- More sensors for accurate measurements.
Built With
accelerometer
arduino
bluetooth
camera
gyroscope
machine-learning
opencv
sensorfusion
Try it out
dance-monkey.launchaco.com


Using Twilio
Inspiration
Trumpify It! is a humorous take on an engaging conversation with your favourite - or perhaps, not-so-favourite - personality of choice. Instead of canned responses, your deepest thoughts and questions will be met with such character.
What it does
Trumpify It! re-vamps the generic chat bot experience for a more tailored response.
How we built it
Trumpify It! was built using Node.js, React, Redux, Firebase, Google Cloud Compute Engine, Python, and Flask.
Challenges we ran into
Some of the challenges we encountered include trying to find an alternative implementation to Dialogflow as well as deciding on a backend. We also ran into some issues with calling the backend API from within React. Other challenges involve deciding which features to implement.
Accomplishments that we're proud of
We're proud of the fact that we've used various trending technologies (such as Cloud and AI) to create a fun and unique chatting experience. We've also thought quite a bit regarding our user interface.
What we learned
We found the Dialogflow workshop to be rather enlightening, albeit there were some technical issues at the end which stopped us from implementing it. We've also learned other technical skills regarding React and Firebase, as well as social skills.
What's next for Western Hack
The next step for this would be acquire a bigger dataset of potential questions and answers so as to adopt more characters into the chatting experience.
Built With
by-voice
firebase
flask
google-cloud
node.js
python
react
redux
twilio
Try it out
GitHub Repo


We believe that many of the fractures in large assets, such as turbines and power plants, can be discovered before the damage becomes irreversible. For such high-cost systems, it is crucial to detect a seemingly small fracture before it turns into a disaster.
Our objective is to prevent severe damages caused by microscopic fractures in assets such as power plants and turbines.
What it does
By the prevention of such damages, we aim to reduce
Time spent by domain experts on the manual evaluation
Cost of maintaining the assets by predict the critical damages
How we built it
We propose a solution to detect the cracks in materials using computer vision which will lead business insights for the benefit of both the customers and Allianz.
Accomplishments that we're proud of
We are proud of having a working demo! \o/
Built With
flask
javascript
love
magic
python
unet
Try it out
GitHub Repo


Inspiration
Replace people cars with other services for transportation through seamless mobility.
What it does
App for making people share a ride, either getting home from the office or going on an adventure to the Alps.
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for Sixt experiences and Rideshare
Built With
android-studio
happy-thoughs
kotlin


How to use
Inspiration
Our inspiration stems from the new canteen at the tum campus in Garching, which just two months after completion is already reaching its maximum capacity. This means long queues, which can really take away valuable time between lectures. One of the main bottlenecks of the new canteen lies in the cash registers, which are self-service and not the most reliable. Often these registers are the point where everything slows down and one can end up waiting in excess of 10 minutes, just to pay. Our solution aims to adress this issue.
What it does
Our solution to this very common problem is simple, taking self-service to the next level. Nowadays everybody is walking around with the smartphone already with them, so why not use it to handle the payment process. Our system uses computer vision to identify the products and meals and calculate the appropriate price. While taking the photo the student places his payment card, including a barcode on his tray. Our software recognizes and reads the bar code and automatically charges the associated account. Each purchase is associated with a table, enabling efficient auditing for staff. The interface is accessed by the end-consumer scanning QR-Codes on their table and provides an easy admin system for staff. In addition, our program uses know ingredients lists and allergy information associated with the user account in oder to warn the user of consuming any products that may be detrimental to their health.
How we built it
Our software is built around the Azure Custom Vision API, which we use to recognize the products and determine the position of the student card. We use our own training data to train our models. We also built an web interface and backed it with a Azure SQL database.
Challenges we ran into
Getting reliable results identifying objects using our trained machine learning system. As well as recognizing and scanning the bar code, particularly when it is oriented differently or partially in the shadow.
Accomplishments that we're proud of
Pretty reliable (for a proof of concept) recognition of some objects and, limited by time, other objects to a lesser degree. With our method we would be able to expand on this quite easily.
What we learned
We practiced using industry standard technology and expanding on those systems to develop our own product fulfilling a certain use case. We also took the opportunity to grow as a team and use each team members personal strengths.
What's next for GastroPay
Following the successful development of a proof of concept during the hackatum event, we are looking forward to develop the idea further in the future.
Built With
azure
computer-vision
mysql
php
python
Try it out
hackatum19.stei.ml
GitHub Repo
tumde-my.sharepoint.com


Inspiration: The analysis of the expenses which will help us in a better planning
What it does: The expenses will be distributed over a pie chart on a monthly basis or based on a customized dates in terms of percentage
How I built it :I built it with a diverse team of mine, on a mobile platform using Android Studio in which various APIs are consumed to acquire Account and Customer details
Challenges I ran into: Getting access of the APIs, understanding the concept of using Open APIs
Accomplishments that I'm proud of: The creation of the mobile app in a very short span of time
What I learn: APIs, Python, functional, concepts of banks
What's next for 360 degree view of bank statement: Currently only current account in a same bank or different banks is included for expenses break, later we will include multiple Credit Cards and family expense
Built With
apis
mobile


Inspiration
There exists no crack annotation tool for analyzing crack images.
What it does
CRAT is a cross platform preprocessing and annotation tool for cracks in materials. It allows the user to isolate cracks from the materials using machine learning algorithms and annotate them with other useful parameters. It also allows manual overrides by the user in case the annotated data is estimated incorrectly. The image of the crack is saved along with the data annotated for the crack. Since we have the crack shape as well as the material image (since cracks are removed from it) , the preprocessed data could be used as input to more sophisticated learning models to study cracks. The cross platform nature of the application makes it possible to use this tool on any device (mobiles, tablets and PCs) thus making it more convenient to annotate images on the go.
How we built it
The application is developed using Python and Kivy.
Challenges we ran into
Defining the problem to solve. Being Neuroengineering students, crack analysis was something we were unfamiliar with
Accomplishments that we're proud of
We were able to pose a solution after much brainstorming. App under development. Once developed it would be cool.
What we learned
We will be learning app development with Kivy
What's next for CRAT
Can be deployed as a preprocessing tool for more advanced machine learning for crack analysis
Built With
kivy
python


Inspiration
It takes years of practice and tons of money to train a National Level player. In the beginning years, they do not know the correct technique and what they are doing wrong, which results in investing money in individual coaching and in some cases losing interest.
With this in mind, We decided to do some data-driven performance analysis that could make training easier and faster.
Our goal is to develop a technology that helps the players improves training effectiveness from the beginning. We want to give an experience where a novice can train better, perform better and learn quicker.
What it does
The ball contains a motion detection technology. It collects and reports data on the web such as force, trajectory, spin, number of passes and number of touches. Then uses this data to provide coaching cues to help you improve your game. Some of the Features of our TrAIner are -
Keep track of ball passes
Keep track of touches, Force applied, Spin, Play Time
Keep track of player's progress
Build and store player's historical profile
How we built it
First we bought a ball to build the TrAIner. And then worked on hardware setup and soldered all the components to make a compact design. We programmed our hardware to sense the data and send the data to the computer. We created a web-based UI for data visualization. And then created a data set using different motions with the ball. Then we worked on AI based recognition system using Python.
Challenges we ran into
The main challenge was hours and hours of brainstorming to find an out of box idea. And then the next challenge that we came across was deciding on the ways and algorithms to use to convert our vision into reality.
Managing the team and task distribution as well as the data collection part was a bit challenging.
Accomplishments that we're proud of
We are proud of making progress in the implementation of the idea that was just in our minds till yesterday. Additionally, we were very successful in collaboration and each team member contributing equally. None of us have ever been on a team that worked so well together and had each member working to the best of their ability for the full twenty-four hours.
We are very proud of our product we are building and its potential!
What we learned
The whole challenge was a great learning for each and every team member. We learnt how we can use technology to make someone's life easier and help them in their development with the right training. And also how to manage a team with people from diverse technical and cultural backgrounds. With combined efforts a lot can be achieved in 36 hrs.
What's next for TrAIner
TrAIner has a lot of potential for future growth. Our goal is to bring soccer and other ball games to the next level where players will perform targeted training to strength their weak points based on the recommendations of TrAiner. Our next step will be a more sophisticated study of the market and its needs. Based on that study, we will optimize our features and also add the missing ones. At that level we will release our MVP as a Beta App to some professional athletes and trainers to get their feedback about the product and fix detected bugs and issues. After that we will release the product for the public and start a first funding round. We expect many sports companies to be interested in investing in our company since they care a lot about the teams their are sponsoring. TrAIner will not only help developing the individual levels of each player, but also enhance the overall playing tactics and strategies of the team based on the strengths and the weaknesses of each team member.
Built With
arduino
css
html
javascript
python
Try it out
GitHub Repo


Inspiration
The drivers have limited parameters on which they can decide the areas where they can maximize their chance of finding rides. We intend to provide drivers with insights that improve their chance of a pickup, real-time. An efficient demand model based on multiple key points drawn from different clusters of a city helps drivers navigate to get more pickups.
Users suffer when there are insufficient cabs available, both in terms of time and money. We intend to alleviate this problem by distributing cabs based on real-time demand. So our service hits both ways, demand, and supply.
We intend to keep the human touch in a way that achieves a synergy effect. An operator can override any functionality or rating and has tools like Areas of Interest, Holiday Calendar, etc for assistance to do this.
What it does
We are offering two solutions: one for drivers which help them find riders and the second, which helps the operator to supervise and intervene when needed. Even though we don't offer users any direct interaction, both the solutions help the users in better pickups.
How we built it
With mind, body, hand and soul. And of course, Seasonal and non-seasonal ARIMA.
Challenges we ran into
Working out the details of the idea and finding relevant real-life data wasn't trivial. Building out the whole system in limited time has its own challenges.
Accomplishments that we're proud of
We were able to decide on a common idea—out of the many we came up, that targets a common problem in delivery/logistics/mobility.
What we learned
Agreeing on an idea by discussion, deciding what are the important features and distributing the work load among ourselves in the limited time we have.
What's next for Hunter
Building a stronger demand model, if we had real-time pickups. Add features like reassigning drivers based on the nearest pickup, clubbing multiple pickups...
Try it out
GitHub Repo
GitHub Repo
damp-inlet-23657.herokuapp.com


Inspiration
Mental health tools are as important as any other study tool. Students are prone to anxiety and depression due to the challenge of managing studies, friends, family, self-care and finances, all at the same time. Not everyone is good at organizing their lives well around these things. These people need an aMIGO in their life, as their assistant, life coach, and friend.
Most organization apps are those people forget to use after 5 days of installing it. Annoying notifications don't help either. MIGO is designed to be more like a friend who stays in touch with us, through a messaging-like platform. catching up to us
What it does
MIGO is a highly customizable assistant who keeps you on track with your goals even when you're going through stressful times. Students communicate their needs to the app through the bot.
How we built it
Azure chatbot, App prototyping in Proto.io
Challenges we ran into
Azure platform was difficult to get running up. NLP Bots are still not perfect. Making this a usable product would require continued efforts making communication with the bot more natural.
Accomplishments that we're proud of
-Getting a basic chatbot running from azure (hopefully)
-Developing an app oriented to making student life (ultimately, our life) easier
What we learned
NLP Advancements don't necessarily translate to making the development of NLP driven apps easier. It's a lot of manual work. Still, Azure's BOT APIs are a great starting point offering a sensible workflow to start with and learn about.
What's next for StuMIGO
MIGO is smart enough to hear students out on any topic and give them useful advice
Integration with google calendar/time organization apps, so MIGO organizes around your schedule better
Right now, we have only began working on the chatbot but it needs to be deeply integrated with an actual app with all the functionalities like managing eating habits, catching up on where you are with your goals
Use conversation history to predict depression/anxiety levels of students
Making communication with the bot more natural
Built With
azure
Try it out
pr.to


Action from the Files-Menu
Inspiration
GIT-Blame gives us just a subset of all the possible information about a specific snippet of code. Currently, GIT-Blame only works on single Lines. This makes it quite hard to get an overview, to find the best person to Contact about a given Code-Segment. So we wanted to create a software, that can ease that workflow.
What it does
We analyze the git history for a given file. From this Data we give the developer valuable insights, who to talk to, based on the number of Lines/Character edits/Number of Commits.
How we built it
Superstats is written Java using awt and swing for the gui. The UI is either Based arround Java or around the Jetbrains Action and Notification APIs. (we have a developement Prototype and a finished Plugin) For fetching git data we used jgit instead of the proprietary JetBrains API, due to documentation problems we encountered.
Challenges we ran into
Sometimes the official documentation for a specific part of the API only consists of "tbd", or has nunfunctional examples, or is simply lacking in details.
Accomplishments that we're proud of
We got a JetBrains UI working, even though we were told not to do so.
What we learned
Using the Jetbrains Plattform and Integrating it with our Backend Code.
What's next for superstats
More ways to slice the Data. Add the JBTable object, instead of an Text-Object, to allow sorting.
Built With
git
intellij-idea
java
Try it out
GitHub Repo


Inspiration
aa
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for Smart bank account


Inspiration
Have you ever walked or jogged along a heavily trafficked main street and been worried about all the polluted air you are breathing in? With FreeYourLungs we have a solution for that!
What it does
FreeYourLungs is an App, which shows you the best route to get to your destination or just to go for a walk with the least amount of air pollution and avoiding car fumes.
How I built it
Based on network graph theory commonly used in general direction applications and implementing the impact of the air quality into the optimal paths calculations. Web app running on Azure app services.
Challenges I ran into
Make sense of the different environment data sources. Efficient use of the Azure platform.
Accomplishments that I'm proud of
Whole development process, from brainstorming to deployment in one weekend with a small team of 4.
What I learned
Don't give up, things that seem difficult are easier than you think and things that seem easy are harder than you think!
What's next for FreeYourLungs
Taking into account other factors, such as noise pollution path/road quality in different weather. With the expansion of the SmarterTogether project Munich, the accuracy and coverage will only improve.
Built With
azure
flask
java
python
Try it out
gitlab.com


Inspiration
Every coder in a team knows the problem. One reads code someone else wrote, the documentation is bad so you have to waste your time trying to understand what the code actually does or waste time searching for the author. Our plugin aims to solve this problem.
What it does
Our software helps you as a developer to save time, code more efficiently and concentrate on problem solving. It does so by providing you with an easy way to contact your fellow teammates, when trying to understand the code they authored. Without leaving the IDE you are able to select the respective code and request further explanation or better documentation. In the background the responsible author is determined and a message with an absolute reference to the corresponding code chunk is being sent. Beside the time saving it also prevents misunderstandings between you and your colleagues.
How we built it
Since the purpose of the whole idea is to not leave the IDE we started with implementing an Intellij Plugin. For that we used Java. Additionally we implemented the management of versioning related functionality in python for rapid development of a prototype. In the versioning section we heavily rely on Git since its state of the art. Since there is a variety of messaging services used by different organisations/teams we offer a generic interface. You can easily add services like Teams, Slack or Mail (which we implemented for demonstration purposes).
Challenges we ran into
Gradle was driving us nuts
Git did not offer all the functionality we needed so we had to adapt
The Outlook Rest-API is a fucking mess
We first developed in Java and Python but they did not like each other
Accomplishments that we're proud of
Providing a robust but flexible workflow might enrich the lives of thousands of developers :)
Successfully integrating a plugin into Intellij!!1!
What we learned
Getting Gradle up and running (had no experience before)
Nobody really knows git
What's next for co-brain
In the future want to improve the workday of coders further. This means improving/extending the proposed solution. Besides we have one more major idea:
Integration of Stackoverflow
Like in the proposed solution we want to enable coders to be able to retrieve answers from Stackoverflow without leaving the IDE.
And last but not least
2020: Intellij.sexy
Built With
intellij-idea
java
python
Try it out
GitHub Repo


Inspiration
The Micro to Small Enterprises are 99% of the 1 million total enterprises in Philippines.As per data, 86% of the adult population are unbanked and we only have 36% internet coverage across the archipelago with average speed of 3.7 mbps only. The low financial literacy and the lack of access to online services impedes the financial tech initiatives and processes in the country that affects our economic growth and global competitiveness.
What it does
We propose, FincED: a fintech mobile app targetting Micro to Small Enterprises. The front-end will be designed to appeal to the masses and will be user-friendly as much as possible. On top of that, in the back-end, a platform using the Rest API will be developed to enable Smartphones and Dumb Phones to access the system using SMS. This will extendcoverage to areas that has no internet but has mobile network signal. The process is to get them onboard by sending info text blasts, enable them to register, send payments, and more. With this, we take a step back to leapfrog few steps forward to the future by getting everyone onboard.
How we built it
The “FinancED” mobile app will utilize the Rest API and GSM Gateway to bridge the 2G (SMS) technology with the 5G (online) technology. The Rest API is a powerful back-end platform that opens to limitless possibilities. This could connect to other solutions like bills payment, online marketplace, and more. However, for the project, the focus is to get the Micro to Small Enterprises onboard by educating, awareness, inquiries, registration, and transition to online platforms using SMS legacy technology and online platforms combined.
Challenges we ran into
We ran into financial challenges to acquire the tools and access that we need.
Accomplishments that we're proud of
We worked as a team and has past results that will somehow successful creation of the proposed project.
What we learned
There will be a lot of challenges along the way but a creative and innovative thinking as a team helps a lot to get us thru.
What's next for FincED: 2GBanking
We are looking at the integration with the Blockchain Technology for higher level security thru smart contracts and also crypto currencies.
Built With
finastraapi
gsmgateway
kotlin
photoshop
php
postman
protopie


What I learned ;login into web using ,python language improving onon appscreation& accuracy allowing more ,sharing using codes on x.files
Built With
c++
javascript
python


Question
Inspiration
We all know these messages that pop up everytime we open an IDE, the ones we automatically close without reading a word of them. Most of these messages want to inform us about the tool we're using, but developers usually have worked in these surroundings for quite some time. What coders need more is information about the project itself. But because reading documentation is boring we found a way to make the learning process more interactive.
What it does
Opening a window with quiz questions when opening the IDE. The questions are about recently committed code written by developers informing the team members about changes and animating the others to look at the code. Questions can be related to certain files and have various levels of detail. The closer developers work on a certain part of the code, the more specific are the questions they get about it. The idea behind this is that they need to have an overview of the whole project while implementation details are only important if they are working close at this code. Questions can also be more general, e.g. asking about the goals of the project. When answered correctly the user will receive a point. The scoreboard keeps track of the best developers.
How we built it
Java, A MySQL Database, Swing.
Challenges we ran into
Java Swing.
Accomplishments that we're proud of
Works on every platform.
Automatic user identification due to git integration.
That the GUI background is kinda black.
What we learned
Sleep is important. Never use Java Swing.
What's next for quizard
Prioritizing questions depending on the area you are working on.
Earning achievements for answering questions right or writing questions.
Possibility to ask questions and discuss problems directly with the project manager or authors of questions.
Adding weekly or daily leaderboards for motivation.
Possibility to add images to questions if necessary.
Possibility to do code golf challenges.
Built With
java
sql
swing


Inspiration
Over a billion people suffer from their disabilities of which most of them stay invisible (asthma, Parkinson, autism, etc). Not only do these people have to fight with their disabilities, but they also experience exclusion from societal interactions and withdraw from public life. Many had bad customer experience, especially the way how service agents deal with disabilities causes great concern.
What it does
We provide customer service agents with additional information on their customer's disabilities to foster The user selects his/her type of disabilities in the app. Once the customer approaches a shop, the information on disabilities and specific recommendations are displayed at the point-of-sale (POS). This enables the customer service agent to address needs and provide an outstanding customer experience. This not only benefits the customer but also let the offering company gain a competitive advantage.
Example You have epilepsy and are going on a long-haul flight from Munich to San Francisco. Instead of proactively approaching the service agents to communicate about your potential risk, you do not have to think about it again, as everything is handled automatically. You onboard the airplane where a friendly stewardess welcomes you with an additional blanket (which decreases the risk of cold-temperature related seizures) and assures you about anti-seizure medication on board. You feel relaxed and are looking forward to your upcoming internship at Microsoft in Mountain View.
How we built it
We created an iOS app for people where they can select disabilities. When they come close to one of our beacons, an event is triggered which will then enqueue the app user into the beacon queue. The closer the user gets to the beacon which will be e.g. a Point-Of-Sales, he will move up in the queue. If it's his turn at the POS, his disabilities will be shown at the desktop of the system to the customer service agent. As soon as he walks away, he is dequeued again.
Challenges we ran into
Accomplishments that we are proud of
What we learned
Daniel
Building the backend using Django as well as MongoDB
Niclas
Building the iOS app using Swift 5
Leander
how to apply react.js for web app development, specifically how components interact
What's next for Curic
We are convinced that our solution has the potential to create a massive impact and we want
Further use cases include but are not limited to:
Ticket and vending machines which automatically increase the font size for visually impaired people
Diabetes patients getting information on the bread units of their meals in restaurants
People with autism enter football stadium through a separate entrance to avoid sensory overload
Rheuma patients get shopping items carried to car
Built With
django
mongodb
react
sketch
swift
Try it out
GitHub Repo
www.beautiful.ai


Home Screen
Inspiration
Imagine a time where open source contributers are rewarded like normal programmers writing code for companies? Thats what we want to achieve.
Projects like DLive/DTube and Steemit which provide a similar service to Content Creators like video producers or photographer.
Why we built it
To support and reward open source developers!
Making it easier to support open source developers for users.
Companies want to support open source projects they are using but struggle to do so.
What it does
Our Project supports Developer, which are contributing to OpenSource Projects by rewarding them for pull-requests that get merged into participating open source repositories with gitcoins.
How we built it
We developed a rudimentary Cryptocurrency with Google's Dartlang.
We choose Dartlang because it's easy to learn, but yet powerful and supports a wide variety of Operating Systems like Windows, macOS, and Linux.
The frontend is connected via REST api and written in vue.js.
Challenges we ran into
We ran into two major challenges.
First
The first challenge was choosing a secure signing algorithm to create trusted Transactions between multiple users. We used pointycastle's RSA Signature Algorithm because it is commonly used by developers all around the globe. Even though the Elliptic Curve would have been more secure.
Second
The second challenge was to provide a peer to peer connection between two Nodes(Clients). We decided that each Node is a webserver and also an http-client. That worked out well because http communication is quite simple and fast.
Accomplishments that we are proud of
The Blockchain algorithm and the complete project came together in a nice way. We implemented a nice looking frontend in darkmode :). Also our blockchain works on distributed nodes.
What we learned
I think we just scraped the surface of cryptography and decentralized engineering.
What's next for gitcoin
It would be great to have something like this accepted and implementend by the open source community.
Thanks for reading! Gitcoooooonneeeeeeeect
Built With
dart
restapi
vue
vuetify
Try it out
GitHub Repo
GitHub Repo


Inspiration
More than 300 million people worldwide are not able to recognise all colours - they suffer from colour vision deficiency (CVD) and therefore are often called colourblind. We are courageous to help these people to participate better in the world wide web.
What it does
Our AddOn starts with a small test, which spots if the user is colourblind - and which kind of CVD. There are different kinds of colourblindnesses. We differ between Protanomaly, Protanopia, Deuteranomaly, Deuteranopia, Tritanomaly, and Tritanopia, also the different dichromatic and anomalous trichromatic CVDs. With an algorithm we change the colours so, that only colours are used which are visible and distinguishable for the user.
How we built it
We developed an AddOn for Mozilla Firefox using javascript. First, you can choose from which kind of CVD you suffer. Likewise, we wrote a script to convert the colours in javascript. Therefore, we read colours, convert them first to RGB values if they are not in RGB yet, then convert them to HSL, converting by a image processing algorithm within HSL and converting back to RGB before replacing the old page by the new one.
Challenges we ran into
All of us usually don't code much in javascript, so this was a big challenge for all of us. The problem that challenged us the most is executing the code on the users machine, since most html files are really big so that we ran into performance issues.
Accomplishments that we are proud of
We became a great team. Also developing the algorithm that changes the colors to make the users life easier was a difficult task we managed. Due it looks different than real views it is very useful for CVD patients.
What we learned
We learned to increase our social and web developing skills. It's the first hackathon of three of four.
What's next for Colour Deficiency Extension
There are different further possibilities to extent this tool. The smallest additional is a test which kind of CVD you suffer from. We started building an AI, but didn't get time to implement it. It can be extended for other visually impaired people, e.g. by bigger font sizes or by increasing contrasts and saturation. Another extension could be the hatching of different colours for graphs and diagrams, also used for gray-scale prints. Although, there are some people with monochromacy which need other requirements for viewing. Techniques for this could be really difficult.
Built With
css3
firefox
html5
javascript
Try it out
GitHub Repo


Inspiration
Our motivation is to provide support to use smart devices to people who are suffering from Parkinson disease and other conditions that result in hand tremor. A shaking condition complicates many simple situations that we must face everyday. Introducing data to an smartphone or a tablet is one of them, since the user may not tap at where he or she wanted because of the tremor. Our goal is to record real-time shaking data to collect information about the user's shacking characteristics and facilitate the interaction with the screen.
What it does
Fubbles collects shacking data from the user. This data is used to do a correction offset of the user's tap and thus improve the user's life quality. Collected data can also be used for medical purposes, such as monitoring the patient's shacking. Moreover, we can create a unique shacke-ID, which has many potential applications such as safe unlock.
How we built it
Fubbles collects data using a motion sensor, which is mounted next to the finger tip. The user should just where a glove or a ring with the sensor, and it will send data to the Cloud. There we carry real-time data processing.
Challenges we ran into
Our main battle field was the Bluetooth connection. We planned to work on SWIFT but Apple does not support the Bluetooth connection and thus we had to change our initial plans and develop a web app instead.
Accomplishments that we're proud of
We are extremely happy that we manage to get our idea real by combining our different backgrounds and experiences.
What we learned
To make Fubbles real we had to struggle with data acquisition and filtering issues. Several programing languages were used for different tasks and
What's next for Fubbles
Next step is to get an autonomous device instead of a cable connection to PC. We believe that if we improve our treatment of row data, all
Built With
arduino
c
matlab
python
swift


Inspiration
We were thinking of how we can bring together physical retail and social apps to create an immersive shopping experience and came up with the idea of in-store mode that can be implemented in any social app or retailer's app.
2/3 of shoppers check phones in-store for product information skipping store associates
70% of shoppers who try on articles of clothing in the fitting room are more likely to make a purchase
85% of textiles go into landfills each year. People buy a lot of unmatched clothes and don’t wear them
Do you recognize yourself?
What it does
If implemented in your favorite app, it allows you to switch on in-store mode, and when you post pictures from the fitting room, automatically recommends additional items from the particular store assortment that go well with what you are trying on at the moment.
How We built it
Due to limited time, we decided to use Clarifai for visual search, apparel, and demographics recognition.
Challenges We ran into
The time is the biggest challenge.
What's next for Pickio Pro
We are going to reach out to retailers for the pilots. If you are a retailer and like the idea, don't hesitate to contact us.


it was easy
Built With
css
html


Built With
objective-c
ruby
swift
Try it out
GitHub Repo


Inspiration
The disease is a motor disability ,impairing mobility of the patient.There can be a possibility of hazards like tripping on road,slip of hands which can be fatal .Once detected early,the severance of the disease can be minimized with proper rehabilitation from physiotherapists under the guidance of the doctor.Our goal is to provide a reliable,intuitive & unintrusive solution to reduce the severity of the occurrence of the disease.
What it does
The key features of the solution are early detection of the disease occurrence&un-intrusive measurement. Primary symptom of the disease is "Pill Rolling Tremor",distinguished by excessive trembling of the fingers or the entire body.The product is a wearable hardware solution with the facility to feed live data to a web base application.The motion of the patient is assessed on his position and acceleration data obtained from the sensor. Moreover,if already diagnosed ,the solution assists in monitoring the rehabilitation progress .Warnings or alert are provided when the patient surpasses his safe motion limit.
How we built it
A wearable sensor hardware with IoT, is implemented using Arduino nano,Bluetooth module and an IMU(Inertial Measurement Unit) to analyse the live data.Primary objective is to ensure unintrusive data measurement and minimal signal losses.
The live data is then fed to the back-end code developed using Python/Node.js. The raw data is filtered further,analysed with the aid of Data analytics frameworks such as numpy .The filtered data is then compared to the ideal case of a normal person to distinguish the symptoms of the disease.
The relevant data is displayed using an interactive web application that depicts the warnings,alerts and rehabilitation progress monitor.The application is developed using React,Node.js.
Challenges I ran into
The project is an IoT solution with equal importance of hardware and software implementation.Primary challenges faced were : Develop a compact and intuitive wearable hardware with no loose components. Dearth of obtain quality datasets to train the Data analytics module. Ensure connectivity of the wearable hardware to the monitoring system. Creation of an intuitive web application to assess the data Developing a unique patient record for the analyses of the doctors.
Accomplishments that I'm proud of
Developing an integrated wearable IoT sensor solution that provides us with live streaming facility from the motion sensor.The solution provides valuable datasets for the analysis of the occurrence of motor disabilities.
What I learned
Importance of team work,Analyzing problem statements,Hardware interfacing,IoT development and communication,Importance of quality data and analytics engine.
What's next for Parkinson Assistant
Testing phases and a product launch.
Built With
analytics
arduino
iot
node.js
python
react
Try it out
hackatum19-w.herokuapp.com


Inspiration
fun to build
What it does
looks sick
How I built it
love
Challenges I ran into
time
Accomplishments that I'm proud of
it works
What I learned
easy money
What's next for Terrainy
saving for the domain name
Built With
unity


Inspiration - Wanted to experience team work
What it does - checks for the spellings from an image
How I built it - using android studio and azure API
Challenges I ran into - Working under stress
Accomplishments that I'm proud of - Using APIs for the first time
What I learned - Working under stress
What's next for Spell Check - To improve it
Built With
android-studio


One in ten American adults do not hold a high school diploma. A big reason for this is because the education system isn't made for students' individual needs. Our innovation that can fix this. The Educational Tracker is a personalized method to figure out what concepts students need help with. In our tracker, we used standard geometry curriculum. However, this project is proof of concept that can be applied to any academic subject. We used python to design the Educational Tracker, utilizing many lists, functions, and if statements.
Built With
python
Try it out
GitHub Repo


We wanted to make an ease-of-access site that can calculate your expenses and helps you budget your money
We made it using Python, as we listed out all of a person's daily expenses and helped them budget through knowing their salary. We also made it accessible to calculate other costs to make it more realistic and usable. Our website was created in order to reinforce the code and make it easier for consumers to view. We were inspired by our parents' own expenses and how they can budget their money by using an easier and more consumer-friendly method.
Built With
python
Try it out
expense-tracker-application1.kash2415.repl.run


This project was bootstrapped with Create React App.
Inspiration
AllAboutThatPose wants to enable people to master complex movements without the help of a professional trainer. We also want to help people master movements as fast as possible by giving them the best possible advice.
Our special focus is on helping men and women with disabilities, for example blind people.
What it does
AllAboutThatPose records movements (for example Push-Ups) as a sequence of different poses. The observed poses are then analyzed with modern computer vision and deep learning technology to offer the user valuable feedback for improvement.
Blind users can interact with the app through text-to-speech and speech recognition technology and do thus not depend on external help.
How we built it
We used complex, state-of-the-art, deep learning algorithms for computer vision. To make the application more accessible we used modern text-to-speech and speech recognition frameworks. To connect these different technologies into one finished product we used javascript with react.
Challenges we ran into
The challenge was not only in applying the state-of-the-art technology on new problems but also at the intersection of the different technologies we used.
Accomplishments that we are proud of
That we managed to combine many different complex technologies into one product that works well. Posenet is the part that calculates the pose and our own algorithm how good the movement is.
What we learned
Valuable insight in state-of-the-art computer vision techniques.
What's next for AllAboutThatPose
Expand AllAboutThatPose to be able to analyze movements from all areas of life, for example:
Sports: Deadlifts, long-jump, etc.
Dances
In the workplace, to teach employees new manual tasks
Built With
With web technologies, deep learning and computer vision techniques.
Built With
computer-vision
deep-learning
javascript
love
react
speech-recognition
tensorflow
text-to-speech
Try it out
GitHub Repo
all-about-that-pose.herokuapp.com


Inspiration
The keyboard is the standard input for coding. Since it's invention in 1868 it has dominated as the primary input medium. Almost unavoidable for many workplaces, it is also a major cause for Repetitive strain injury (RSI). Society is diverse and we are glad to have those among us who struggle using keyboards. Inspired by pen and touchscreen we propose a faster, fun alternative to keyboard coding.
What it does
Draw your code, AI will digitize it for your computer to understand! Our use-case is the creation of a docker-compose file by drawing.
Example:
You draw: Triangle -> Cat
Leading to: Project push to Github
Done!
How I built it
Our productivity tool is using the Cognitive Services on Azure for OCR. We use a flask server for requests and logic. For the GUI we use javascript.
Challenges I ran into
The complexity to create a complete drawing language is high. (Imagine designing French from scratch!) To meet time constraints, we decided to equip our drawing language only with the tools to showcase a constrained use case. Very excited to hear the feedback!
Accomplishments that I'm proud of
A live demo that gives a clear insight how we enable people with disabilities (or injuries) and how we can ease the workflow of coding.
What I learned
We learned a lot about web development and Azura's cognitive services.
What's next for .YADL
.YADL (yet another drawing language) is a complex challenge that needs language experts to develop it to become a swiss army knife - handling a wide variety of use cases. A start would be to make an architecture that can be easily extended and covers relevant coding workflow processes. This would turn it from a gimmick into a potentially useful product.
Built With
azure
flask
javascript
python
Try it out
GitHub Repo


Inspiration
What it does
extract vertices from a OpenDrive File to a Text File and creates a aproximation of the RoadSystem in Unity using Splines.
How we built it
Challenges we ran into
Detecting witch vertices belong to the same Road
Accomplishments that we are proud of
What I learned
What's next for Roadify
Built With
c#
c++
unity


Inspiration
Often, we find that we have questions in class which we don't wish to hold up everyone else for. By having a class chatroom, we can ask our peers and teachers questions and get answers as people are available.
What it does
Users can input their class and name, and converse in a group chatroom.
How I built it
Our team worked together with GitHub. I (Peter) worked on the server framework and css, Atharv worked on the login system, and Chris worked on the chatroom proper. We all worked predominantly in javascript and html.
Challenges I ran into
We were unable to connect the login and chatroom functionality, but both are fully functional individually.
Accomplishments that I'm proud of
This was our first hackathon, and we came very close to making a functional webapp with no prior experience.
What I learned
How to use git on windows, some javascript, some html, and integrating our code with existing libraries.
What's next for APC Chat
We will work to produce webapps inspired by this, possibly reusing some of the code.
Built With
css3
express.js
github
html
javascript
routing
socket.io
Try it out
GitHub Repo


Inspiration
Since we are just booking a skiing trip and it's super cumbersome, we tried to reinvent this process. That's why we built Bay´n´B.
What it does
It takes over the whole process of booking a trip. It suggests you an accommodation, a form of transportation and possible activities for your given preferences. You can then book those with just a few clicks. Thus, we replace travel agencies and make the whole process of booking a trip a lot easier.
How we built it
We built an IOS App which uses API´s to gather information from different sources and merges them into one booking process.
Challenges we ran into
Sadly you need for nearly all transportation companies API keys, so we were not able to connect to those in this short amount of time. Since we are just 2 team members the project size was kind of overwhelming, which is why some detail views are missing.
Accomplishments that we're proud of
The idea!! And of course we are happy about our MVP, we are going to present. It's incredible what you can built in just a few hours of coding.
What's next for Bay´n´B
Bay´n´B should get a whole network for booking activities. Activity providers should be able to offer their services in our app and make the booking process for those a lot easier. User´s should be able to search for all possible activities and book these with transport and accommodation in just a few clicks. The booking process should be able through Siri, to make it even easier. A model should be trained to react to overbooking and suggest alternative destinations. An "In-Activity-Navigation" should be added to take even more care of capacity problems: e.g. suggest a different slope or hiking path to offer the best experience.
Built With
bayern-cloud
swift
Try it out
GitHub Repo


Inspiration
Still nowadays, humans and machines do not collaborate effectively together. Allianz showed us that even cracks at micro-level can have a huge impact. Sixt is fighting the problem of personell-intensive assessment of damages to their mobility assets. For example, the risk of giving decisions about repairs only to machines would be too high.
So we combine the best of both worlds, our excellent Human-Decision-Making capabilities with the raw and tremendous power of Machine-Learning in the Cloud. We seek to improve the currently slow and exhausting process of data classification, by giving the possibility to interact.
What we provide
„Human-in-the-Loop“ Training for complex classification tasks providing a usable system from the start. We continuously receive images of cracks or other features from various cameras, which will be evaluated. Hard classification entries are forwarded to a human decision maker. The decision maker’s feedback will in turn improve the ML-model and help future classifications. A convenient, easy-to-use and integrateable user interface is provided for user interactions (like Slack or Mattermost).
How we built it
We built a docker-based microservice solution that consists of 5 parts:
The image acquiring system (camera)
The Core (acts as an interconnect for all the other services and handles database)
The ML-Connector (is responsible for training & modeling ML)
The Mattermost-Connector (handles the connection to the user-interface)
Mattermost (provides the user-interface)
Since it is a Microservice application, we were able to develop the different services using different programming languages, for example the Mattermost-connector and the AI-Connector in Golang, the Core in Node.JS and the camera adapter with Python. For the ML-tasks, we use the Azure CustomVision, but it would be possible to connect to any ML framework.
Challenges we ran into
Clearly defining interfaces between services using REST
One huge challenge was the connection to Azure (bugs in the official Golang-SDK lead us to building creative work-arounds)
Microservice orchestration of different independent services
Accomplishments that we’re proud of
Providing a working prototype.
Having a at least moderately capable AI model
Each of us was able to use his favorite programming language but still working together on one project.
What we learned
Communication is key, as with microservices as with humans
A little bit of golang for everybody
Python glues everything together
Docker enables heterogenous developer teams
Sleep is for the weak!
What's next for Autocrack
Support for more types of messengers
Improvement of AI Backend
Improvement of the AI models
Stay hyped for our release!
Built With
docker
express.js
go
node.js
postgresql
python
rest
shell


Inspiration
The Inspiration in back of this idea was Malaria remains a major burden on global health with roughly 200M cases world wide and more than 4 lakh deaths per year.Beside biological research and political efforts modern information technology is playing a key role in many attempts at fighting the disease. I want to Contribute something more for Medicare System in IT.
What it does
The algorithm assists Microscopes in area where there are limited resources but perhaps even increase their detection accuracy. Here basically we are dealing with the image data, image of a cell in terms of Malaria detection.The data set was collected at a hospital in Bangladesh and made public by researchers at NIH.
How we built it
Challenges we ran into
Accomplishments that we're proud of
Accomplishment is really proud moment, yes we did it.
What we learned
What's next for Contour Detection
Built With
pandas
python
Try it out
GitHub Repo


Uma causa nobre


Inspiration
Dan, Dom and I have often brainstormed ideas to extend the Field Service demo mobile application that Dan and Dom built for Innovation Tour events over the past year. One area of potential extension is adding file upload, perhaps for images of damaged devices as part of a warranty claim process that the field service rep could initiate for the customer as part of their repair service... Or images of device serial numbers to match device IDs in backend systems, or personal customer info (like drivers license image) as part of a warranty application process that the field service tech could run through their mobile app... MoveIT is a great solution for that use case. This would add additional physical device functionality tie-ins which reinforce the native mobile vs. responsive web story, justifying the creation of a native mobile app. This could be extended even further by geo-tagging any photos... (Though, of course, PWAs could achieve a similar end, but we'll pretend for now I didn't just say that :-)).
Could potentially add some MoveIT Automation scripts on the backend that process the images, perhaps running them through Google AI image libraries to confirm they are indeed DL images, or to do some OCR from them to confirm names, addresses, or the format of serial numbers...etc.
Or could have the backend lookup device reference material, parts list info and availability and/or repair instructions based on device image recognition or serial number match up...etc. We can pivot on the specific use case, enabling technology remains the same/similar...
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Secure mobile upload of sensitive files and images
Built With
kinvey
moveit
nativescript


Inspiration
When we use the bus to go to school or work, we noticed that some busses are always filled with people and some are always almost empty. We thought that if there were some way the bus company could easily and accurately track the usage of their bus routes, they could make smarter decisions about their network.
What it does
We use sensors to track the MAC addresses of mobile devices of passengers on the bus. This data together with the GPS location of the sensor enables us to track what exact routes in the bus network were taken, how crowded they are at different times of the day, which routes are rarely used etc.
How we built it
The sensor is made with an arduino that sends the GPS location and truncated MAC addresses (the last half of the address) over LoraWAN to a TTN gateway. The packets are then forwarded to an application server running in the Azure cloud that saves the data to a database which is then visualized in Tablo.
What's next for Smart Bus
Creating a smarter algorithm for using and visualizing the recorded data. Adding sensors to bus stops to track waiting times and in general to get a better tracking of passenger flow through the network.
Built With
arduino
azure
lorawan
mssql
spring
tablo
ttn


Inspiration
Funniest Hack
What it does
Generates a list of optimum hideouts from your current location, using a set of initial conditions
How I built it
Using Google maps API integrated into python code for the backend. Javascript to glue it together.
Challenges I ran into
Learning how to use APIs and modelling elevation, food resources and distances in 3D space
Accomplishments that I'm proud of
Coding a function that generates an elevation score. Designing the webpage
What I learned
APIs, the complexity of web platforms
What's next for Zombie Apocalypse
Today Durham, Tomorrow the world...
Built With
css
html
javascript
python
Try it out
GitHub Repo


Inspiration
with drowsy driving responsible for 72000 crashes a year in America, I wanted to develop a tool that could help people detect when they're at risk.
What it does
UpRight monitors facial movement, and detects when the user's eyes begin to close. if your eyes are closed too long, the application issues a warning to the user. This prompts the user to take precautions against drowsy driving, such as taking a break from the wheel or passing driving privileges to another person in ther car.
How I built it
I built the basic application using Python and OpenCV, using a few detection classifiers that were built-in to OpenCV or Haarcascade.
What's next for UpRight
I'd like to first rebuild the detection functionality into a standalone API, before porting the application to mobile devices. I belive that this will allow for better usability among customers and promote better driving. Secondly, I'd like to partner with insurance companies, who could offer lower premiums to clients who use UpRight when driving as a safety precaution.
Built With
dlib
opencv
python
Try it out
GitHub Repo


Visualization of the target implementation with elevation maps
What it does
The framework we had created during the hackathon allows overlaying data detected by a drone on 2D maps. In the extension of this framework we could apply the same methods to work with elevation maps from various sources (open digital elevation models, photogrammetry or LiDAR scanning).
How we built it
We created a simulation showing capturing LiDAR data from a drone and building an elevation model from it. In this step we used ROS (Robot Operating System) with Gazebo running as a simulator and RVIZ for displaying the received data.
For map display we had created a webpage with custom data source and linking to MapBox.
Accomplishments that we're proud of
We are proud of completing a working prototype of the framework throughout the hackathon and the reactions we had when we were presenting our idea to other people.
What's next for AniMaps
We still need to get in touch with experts to validate the viability of the idea. Then we would like to take the framework to next level and showcase data collected in real time appearing on the map and allowing the user to filter it.
Built With
html
javascrip
mapbox
ros
Try it out
GitHub Repo
docs.google.com


Inspiration The fact that kathmandu is such a polluted area and we need foreign support to get some sensing device . We wanted to do something for the community by our own
What it does- It records the level of dust concentration, humidity , temperature of an area
How we built -it using arduino ,dust sensor , rh sensors, cardboard, jumper wires, Power source
Challenges we ran into
Programing the codes, buying the sensors , making the cardboard box,joining the piece together
Accomplishments that we're proud of
We made it and it worked
What we learned
Lots and lots of information about new technologies
What's next for Dust And Weather Indicator
We want to launch it in the market
Built With
arduino
dustsensor
rhsensor


Inspiration
It is a great idea
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for AgriPro


Inspiration
One of our team members grandfathers had Alzheimer's and we wanted to make a system that would remind him about meals and to drink water as well as any social engagements that he may have had that day.
What it does
We used a Google Home Mini for the interface as it is easy for anyone to use. We used Google Cloud and DialogFlow to control the Google Home and allow it to communicate with the user and to give the user reminders. We then stored the user's data in a MongoDB database. To allow the user to communicate easily we used Twilio to allow the user to send and receive text messages through the Google Home.
Built With
dialogflow
firebase
google-actions
google-app-engine
google-assistant
google-cloud
google-home
javascript
mongodb
node.js
twilio


Inspiration
To avoid E-commerce users from scams and phishing.
What it does
Analyzes user history of a specific website and determines if the website is safe or not.
How I built it
Data analysis using python and sqlite which communicates with google chrome extension in javascript.
Challenges I ran into
Making connection between python and javascript was difficult as it required backend server instead of performing in the browser.
Accomplishments that I'm proud of
Learned how to develop a chrome extension.
What's next for Vault-transaction
Add more features (like ML and AI) to make the analysis more accurate and efficient.
Built With
firebase
gcp
html
javascript
python
sqlite
Try it out
GitHub Repo


BlindSight
Web application that identifies objects and their positions (including facial expressions) in your immediate surroundings and their positions. Aimed at the visually impaired to be able to take a quick "look around".
It also provides functionality to recognize emotions in peoples faces, which can be used by both the visually impaired and users that may be unable to recognize emotions themselves.
We are using Google's Vision API for object recognition.
BlindSight
Built With
css
html
javascript
Try it out
GitHub Repo
blindsight-durhack2019.appspot.com


Inspiration
With the API's provided and the challenges set we endeavored to create a project to that tackled the problem of improving adult social care by using financial data for good.
What it does
It analyses the financial transactions of a patient. Using this data it can spot anomalous behavior and alert a social worker to this. This can help social workers better allocate there time to patients that are doing activities that are out of the ordinary. as a change in behavior may indicate a degradation or potential improvement in their condition worth a checkup.
How we built it
Using a Node.js back end we interface with the Capital-One Hackerthon API. Every day at 9am we analyse the expenditure of patients and identify 'unusual' behavior through statistical analysis. Every user of concern should then be mapped to their social worker. Then their social worker is sent a text, alerting them they may want to check in with those patients. If a social worker wants to know more information about one of the patients they've been alerted to, they can reply to the text which runs a twilio webhook and they will get a text back with more information. We have built a express webserver to give a webportal to social worker allocation.
Challenges we ran into
Coordinating the sleep deprived team. Using many new API's there was a lot to learn.
Accomplishments that I'm proud of
All of the API interfacing works. Making the base of a system that could be genuinely useful in the real world.
What I learned
Lots about REST API's
What's next for Plutus
Fleshing out the functionality. Training AI models on real data to out preform our current statistical analysis
Built With
bootstrap
capital-one
node.js
twilio


Inspiration
What it does
Allows elderly people to sign up for community events organised by Durham City Council, encouraging inclusivity in the community.
How I built it
Node.js, Bootstrap, HTML, MongoDB
Challenges I ran into
Limited timeframe Event handler with client-side JavaScript
Accomplishments that I'm proud of
Successfully debugged event handler issue with JavaScript, mostly reviving the log in system.
Built With
bootstrap
html
mongodb
node.js
Try it out
elderly-care.herokuapp.com
GitHub Repo


Inspiration
Resolve the crime and be the best detective on this side of the world
What it does
Resolve the challenge problems.
How we built it
With love and patience
Challenges we ran into
Struggled a lot with sql and rounding
Built With
curiosity
frustration
love
patience
Try it out
GitHub Repo


If you have an online business and hope to make your fortune selling online, then a little green padlock better be next to your web address. Having Secure Sockets Layer, (SSL) certified website means your customers can be sure their personal information is not being captured by hackers and identity thieves. There are several levels of SSL certificates, but even the most basic offers protection for online business success.
Why Your Business Needs SSL Certification?
How Does It Work?
When you sell online, your customers enter personal and sensitive information such as usernames, passwords, credit card numbers, and other information on your website. This information is passed from computer to computer through a network until it reaches the destination server. At any one of the intermediary computers, someone could conceivable see and take your customer’s private information.
If your site has an SSL certificate, your customers will know immediately by looking at your web address and have the confidence to share their personal information to get the product or service you offer.
SSL Certification
SSL is the standard security technology that establishes an encrypted link between a browser and a web server. It ensures that all the data that passes between the two is private and integral. With SSL certification security, from a professional service, your site can have the same encryption protection that is used by the top corporations for a much lower fee. There are several levels of certification starting with the most affordable hosting solution to ensure your site is protected. You will have domain validation, compatibility with most browsers and authentication of your website.
Two SSL Certificate Primary Functions
The two main SSL functions are authentication of your website identity to your customers as well as to visiting browsers and encryption, which is the technical process that supports SSL certification. It means it protects your customer’s private information such as credit card numbers and account numbers and passwords and allows data to be securely transferred between several computer networks. It masks data so any unauthorized source is not able to intercept it or read it. The highest standard of encryption in the industry is 256-bit encryption.
How Do Your Customers Know They Are Protected?
Your website will have HTTPS, which is the secure version of HTTP at the front of the web address for example : https://www.lilo.net.au . It will also have the browser padlock symbol and a secured site seal from your hosting company.
The highest level of SSL certification turns your browser bar green whenever a customer opens your website on Internet Explorer and Firefox and gives a green padlock on Google Chrome.
You can also get protection for subdomains if your website has several domains for different areas of your website.
Who Needs the Highest Protection?
All businesses that include ecommerce require essential SSL certification. There are higher levels of protection, but extended validation is mainly necessary for Limited Liability Companies or corporations, unincorporated businesses and sole proprietorship businesses, government organizations and NGOs and International Treaty Organizations.
If you haven’t uploaded your ecommerce website yet, you should look in to SSL certification before you start. If your website is already up and running, do not wait another minute, but get SSL certification as soon as possible. You never know how many customers you lost because they hurried away from an unsecured site.
Built With
hosting
magento


Stage 1 — 2019: Stage One involves raising awareness among U.S. citizens about the GCP approach to helping the homeless by means of a long-term and aggressive advertising strategy. Our hope is to create an army of private citizens who help the homeless in their own communities throughout the U.S. in two ways:
Want to help the homeless? The Gift Card Project proposes that you carry with you at all times $5 or $10 gift cards to local fast-food restaurants and be on the lookout for the homeless in your neighborhood. People in need are more efficiently and effectively helped by those on the local level.
Have a kind conversation with the person you are helping. Central to the GCP is the reminding of the person that their dignity is not depleted because of their current state. Many models of charity (non-profits that accept donations or church food pantries asking for canned goods) insulate the helper from the helped. The GCP brings one face to face with the person being helped by means of a donation, which is vital because practical assistance without emotional support goes only so far.
Stage 2—2025: The long-term and ultimate goal of the Gift Card Project is to provide the homeless not with gift cards to fast-food restaurants, but rather with gift card vouchers that give the homeless access to our nationwide vending machines filled with basic goods like food, blankets, toiletries, pre-paid cell phones, etc.
Built With
wordpress
Try it out
giftcardproject.com


Inspiration
  Albert did the encrypted QR code project back in summer and it was more of a product varification process: the companies generate the QR code and the users scan the QR code and get the result. This process is implemented with DES,RSA and a bit of Ceasar cryption. Then we decide to extend this program so that the users could upload files like photos, videos, etc... and share the secure QRcode to another user who logged in.
What it does
 The users upload the files in the app and the app would generate a url link which directes to the cloud where the files are stored. After that,the link will be encrypted and a QR code picture is generated.according to the encrypted text. Then user can send the QRcode to another user. The receiver can scan the QR code on App and the decryption will be done and the url link which contains the info will be returned.
All the encrytption and the decryption are done by web server(should be) and the keys will be stored in the database. Since the time issue, we basically just store the keys in text book and run the code on our own laptop.
How I built it
we used flutter for the app and java for QRcode.
For App, we used the flutter framework provided by google. We used a QR scanner API for use in the scanning portion of the app. All designed by Yassine.
For QRcode, we are using google.zxing package for generating the bitmap of QRcode and reading the content of QRcode. This package is open sourced so it was easy to implement and modify.
For encryption, we are using java.security and javax.crypto to implement DES and RSA.
These two packages can encrypt and decrypt the information using different type of encryption methods(DES,RSA,AES,MD5,SHA-1...) that the user input which is pre-coded into BASE64. It will also geneate the corresponding private/public key in a given length which will be stored into text book for later decryption.Besides, Ceasar cryption is eazy to find on the Internet.
Challenges we ran into
The most challenging stuff we faced is that we need to find a way to link the java and flutter. We found 4 ways to solve it (1.method channel 2.run java code on web server and return the result to the flutter 3.put everything into the jar file and run it with flutter 4.use xml file to specify buttons) But they are all FAILED, since we dont have much experience of android developing, we choose the developing platform which we are not familiar with.We were reaching out for help but nobody could help us.
Accomplishments that I'm proud of
The encryption way we are using is not only secure but also effect.The plaintext will first be encrypted by Ceasar encryption (shifting value is random between 100 and 999 )to avoid chosen plaintext attack.Then we chose DES to encrypt the plaintext and use RSA to encrypt the key of DES, since use RSA to encrypt the entire plaintext is pretty slow and use DES only is not safe. We also refactored the code to make it more flexible(more competible with GUI) and you can add icons in QRcode.
What I learned
We learned how to build android app, technology of QRcode and cryptography.
Try it out
GitHub Repo


Startup.io
HackKings 2019 project
Built With
dart
kotlin
objective-c
swift
Try it out
GitHub Repo


Inspiration
make it better
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for likileaks
Built With
html
javascript


Inspiration
We created this project push our limits and showcase our Artificial intelligence skills.
What it does
MeBot reads
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for MeBot
we did it for the lulz
Built With
machine-learning
python
Try it out
GitHub Repo


Inspiration
We thought it would be fun to access tinder from the command line
What it does
this port allows the user to view profiles and swipe on tinder
How I built it
we utilized python, with requests, and queried tinder's endpoint which had sparse documentation by people on github
Challenges I ran into
since it wasn't well documented, we had to find out through trial and error what worked and what didn't when requesting the endpoints. We were going to input similarity scores for bios but were unable to since bios are rarely filled. We were also going to add messaging capabilities but were unable to due to the fact that its hard to find the IDs of people you have matched
Accomplishments that I'm proud of
Learning to use requests (maxim, victor), dealing with state machines in python(nikola), making a complete app by the end of a hackathon (all of us)
What I learned
What's next for Terminalder
We can add more functionality in way of displaying images or messaging if the API is better documented or we find other endpoints
Built With
fabulouspy
filestackasciiapi
python
requests
tinder
Try it out
GitHub Repo


An organization platform for students where they can create meetups to discuss problems with other students and instructors and keep track of coursework and deadlines.
Built With
css
firebase
html
javascript
vue
Try it out
GitHub Repo
eduki.netlify.com


Inspiration
Environmental Data is currently very hard to find, we need to open it up so that consumers can make better purchasing choices.
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Empact
Built With
css
graphql
html
javascript
mongodb
react


This image is currently processing. Please be patient...
Inspiration #teamtrees and Amazon rainforest fire.
What it does plants seeds or saplings
How I built it We scaled it down to a simple prototype where we added a 3D printer drill then ran it with a motor
Challenges I ran into difficulty in programming and difficulty in acquiring materials
Accomplishments that I'm proud of...we built it at last.
What I learned...we have to have a more detailed plan so than we won't face standstills.
What's next for Plant planting machine using control systems to make it automated.


Inspiration
A different, more user friendly approach of retrieving information regarding a topic of interest using multiple reliable sources.
What it does
First, it takes user input, through voice recognition or manually typed text, and optimises the input for search engines (extract key words). Sends off a query through google and looks at the first 'x' amount of credited and reliable pages regarding your query. From the pages, Qoi extracts the most relevant information and summarises it for the user in basic terms.
How we built it
Using python and spaCy as our building blocks to setup NLP for user input and summation of query results. For speech recognition we used pyaudio to capture sound from the default microphone set on the device and pocket-sphinx to recognise speech. To gain query results we used the google search api and for web scrapping we used BeautifulSoup4, lxml and requests. Finally to portray the output we used tkinter to create a simple GUI.
Challenges we ran into
After deciding on the concept, we research the most capable NLP APIs available and found spaCy to be the most reliable. However, 2 out of our 4 members had no prior experience using Python. Furthermore, none of us had experience using NLP or web scrapping. Our main goal going into this project was to explore new technologies and learn how to use them.
Accomplishments that we're proud of
Managing to have a minimum viable product in the 24 hour time frame of the hackathon.
Using NLP for input of phrases and reducing them to keywords for a query.
Using NLP to summarise text.
Web scrapping capable of taking input from websites with different structures.
Voice recognition integrated into our application.
What's next for Questions of Interest - Qoi
Check requests to websites before trying to use in the program to avoid HTTP Error 403
Improve text obtained by the web scrapper, possibly train a model to navigate through HTML tags and retrieving more accurate output, and avoid unwanted data (strips metadata, headers, explicit content, etc.)
Koi Fish Logo
Improve GUI aesthetics, by either using another python library such as FLASK or integrating another language like java and using javafx
Never ending project, always evolving...
Built With
beautiful-soup
google-search-api
lxml
pocketsphinx
pyaudio
python
requests
spacy
tkinter
Try it out
GitHub Repo
drive.google.com


Inspiração
Eu gosto de flores, então gostaria de fazer um jardim virtual.
O projeto
O hospital tem um custo mensal para operar, porém exibir isso para o público em um dashboard com gráficos e números, pode não ser efetivo e não gerar comoção ou empatia necessária, então ao invés de um dashboard, será criado um jardim virtual, onde as doações irão virar flores, e quando atingir o custo mensal ele ficará no máximo de flores, porém conforme o valor for diminuindo durante o mês (pois o hospital irá utilizar o dinheiro) as flores irão sumindo, também para gerar mais empatia, as flores irão "conversar" através de balões de texto, onde terão frases como "Olá! Que tal plantar uma sementinha do bem? :)"
OBS: No "Try it out" coloquei um exemplo de uma florzinha bem simpática criada com CSS que o Hangs Breaker fez. Também coloquei o link do GitHub para um exemplo.
Built With
css
html5
python
Try it out
codepen.io
GitHub Repo


Inspiration
12% of all food is wasted yearly.
What it does
It connects vendors with food waste to those who need it, such as homeless shelters, at a discounted price. We use computer vision to determine the quality of food so that spoiled food does not pose liability issues.
Built With
clarifai
express.js
heroku
node.js
vue
Try it out
GitHub Repo


Inspiration
Back in 2017 I was looking for an engineering role in blockchain industry and opportunities were hard to find.
What it does
Companies post jobs on the site and candidates apply. We don't scrape or aggregate positions.
How I built it
I wanted to test the idea, so i coded first version in just 2 days with Node/Sails.js. Now, that there is quite a bit of traffic and feature complexity, i'm moving things to React.
Challenges I ran into
Accomplishments that I'm proud of
So far we've got over 1.1k job listings from 570 crypto companies and over 20k job applications.
What I learned
What's next for Crypto Jobs List
IPO, ICO and maybe even IEO. lol
Try it out
cryptojobslist.com


Thresher component
When I was in my hometown people were threshing the Maize with great effort and taking really long time to do the work.So, I thought a idea to make something that can thresh the mail ze.
This device thresh the maize grain.
With our team collaboration and help from the organizer,and availability of material we did our work.
From the beginning of the work we had to go through the challenges like less availability of material with frequent breaking of our materials.
Let us see what happen.
At first I learned to me management, team work and there was a huge mistake and the quote "learn from the mistake" was a great motivation for us.
We might use the AC motor for running it.
Built With
bearing
drill
wood


Inspiration
Ever notice that there are some people who you give a lot of attention to, and a lot of people who you are just prone to ignore? Have you ever felt neglected because of someone's inattention, or wished that someone else would hold you more frequently in their mind? In the spirit of inclusivity and diversity, our application, the Quantum Friendship Network, will supercharge your relationships!
What it does
Our application automatically counts the number of messages you have sent and received for every person you messaged on messenger. Then, based on the total number of messages sent, and more importantly, the ratio of messages sent and received, we generate a model of the friendship network. If the messages you sent are disproportionate to the messages received, it indicates an unbalanced relationship. If you sent more, it may mean the other can find you annoying, if you send less, you may be neglecting and hurting others. Then, after adding several constraints and going through the computations, we suggest who to focus more attention on and who to focus a little less.
How we built it
It takes in JSON files you can readily download from facebook. We apply some common sense filters (for example, we remove the people who you only sent a few messages to) and we calculate the strength of the relationship through the sum total and difference of the messages. Then, using the strengths as our parameter, we push our model through the DWAVE 2000Q quantum computer, which spits out who you should become better friends with.
Finally, we take those suggestions and give our users concrete steps (who to message more, who to message less) to improve their friendships!
Challenges we ran into
Finding good filters to put and implementing a strong model. Figuring out how to reframe our problem in a Binary Quadratic Model to utilize the DWAVE computer, which is much more efficient in solving this kind of network problem. Time restraints, we couldn't brush up our output in a nice, easily readable way.
Accomplishments that we're proud of
IT ACTUALLY WORKS!!
What we learned
Quantum Computing, Getting a lotta data from messenger
What's next for quantum friendship network
Clean it up, make it pretty
Built With
dwave
facebook-messenger
python
Try it out
GitHub Repo


This project was bootstrapped with Create React App.
Available Scripts
In the project directory, you can run:
yarn start
Runs the app in the development mode.
Open http://localhost:3000 to view it in the browser.
The page will reload if you make edits.
You will also see any lint errors in the console.
yarn test
Launches the test runner in the interactive watch mode.
See the section about running tests for more information.
yarn build
Builds the app for production to the build folder.
It correctly bundles React in production mode and optimizes the build for the best performance.
The build is minified and the filenames include the hashes.
Your app is ready to be deployed!
See the section about deployment for more information.
yarn eject
Note: this is a one-way operation. Once you eject, you can’t go back!
If you aren’t satisfied with the build tool and configuration choices, you can eject at any time. This command will remove the single build dependency from your project.
Instead, it will copy all the configuration files and the transitive dependencies (Webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except eject will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.
You don’t have to ever use eject. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.
Learn More
You can learn more in the Create React App documentation.
To learn React, check out the React documentation.
Code Splitting
This section has moved here: https://facebook.github.io/create-react-app/docs/code-splitting
Analyzing the Bundle Size
This section has moved here: https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size
Making a Progressive Web App
This section has moved here: https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app
Advanced Configuration
This section has moved here: https://facebook.github.io/create-react-app/docs/advanced-configuration
Deployment
This section has moved here: https://facebook.github.io/create-react-app/docs/deployment
yarn build fails to minify
This section has moved here: https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify
Built With
css
html
javascript
Try it out
GitHub Repo


nwHacksBuildDay
This is our project for nwHacks Build Day 2019!
Built With
css
html
javascript
Try it out
GitHub Repo


Inspiration
We wanted to create an chat app in Facebook that would bring together people that wouldn't normally interact with each other.
What it does
It finds users with one common interest and many differences, and bring them together to anonymously talk. The intent is for the users to figure out their common interest, and use it as a way to build common ground between very different people.
How I built it
We used Node.js hosted on Heroku to implement the Facebook Messenger API.
Challenges I ran into
The facebook documentation was unwieldy and confusing, and we spent a lot of time understanding it. In addition, Heroku was something none of us had used, and getting webhooks to properly link was a good learning experience but took time. As most of our group were first time hackathoners, this whole experience was a significant hurdle to overcome, but we did it.
Accomplishments that I'm proud of
We managed to get a basic implementation working, but then broke it somehow, and Heroku kept crashing after that. However, creating our basic implementation, based on our starting knowledge, was a great accomplishment!
What I learned
We learned a lot about many different things, from developing our js skills, to building a web app for the first time, to how to use complex api's. As a team of mainly novices, we developed a lot from where we started.
What's next for Broadening Horizons
Fix the unknown error that seems to be crashing heroku
Built With
javascript
typescript
Try it out
GitHub Repo


Inspiration
Our inspiration is personal needs that need to be taken into consideration when attending events and/or functions. This is something that many people face as a challenge whenever they are part of an organized event.
What it does
Tapp uses NFC. Users fill out a form on their form including information such as name, age, and so on, but most importantly accessibility needs, dietary restrictions, and extra notes or requests. The event organizers will use their phone as the host to collect information using NFC and upload it to their database.
How I built it
We used Android Studio as a platform to make an app to use NFC on two phones, one being a host (for organizers) and one being a user (for attendees). When the phones are tapped together, the information is transferred.
Challenges I ran into
Using NFC is very challenging on its on. Android uses its on UI, Android Beam, which gets in the way of NFC functionality. We had to bypass this and implement multiple new functionalities together to get this to work in a limited amount of time.
Accomplishments that I'm proud of
Being able to access and build on NFC systems in most smartphones. This technology is looked past a lot of times but has incredible potential that we were able to build a project around.
What I learned
We learned to use different IDEs, technology, UI design, and implementing databases just to name a few!
What's next for Tapp
We plan to implement better UI for users, along with security like login to make the app safer for users and organizers as well.
Built With
android
nfc
studio


Inspiration
When running brew install I became concerned with what I was installing. After a few searches, I realized that open source supply chain is a major threat to enterprises.
I wanted a tool that allowed me to audit and manage every module running on my laptop and servers. This becomes challenging with dynamic languages that import modules at runtime.
We're turning clusters into federated app stores. Only signed code can run, but we'll integrate with DevOps pipelines to shore up enterprise security without additional developer overhead.
What it does
Allows a security operations center to certify modules with signatures and then verifying the signatures of open source modules as they are loaded. There is a central server for hosting signatures and an admin can revoke the validity of a signature at any time.
This is accomplished with a light weight agent written that monitors the modules being imported into the interpreter and verifies that each module has a valid signature.
How I built it
agent (signature validation) We leveraged GPGME - gpg made easy (ha!) - a low level C library for creating and verifying signatures at runtime.
signature creation: we implemented a tool to create and upload signatures to our backend
signature hosting: graphQL backend
frontend: vuejs
Challenges I ran into
Signature validation. Initially I was verifying binary signatures and not putting them in ASCII mode, which made dealing with them much harder.
Database management. We're backend folks. As in firmware. GraphQL was.... interesting.
Accomplishments that I'm proud of
The UI. We know that it could be better, but it was super cool to mark a file as invalid and then see the server side agent reject loading that module.
What I learned
There is a lot of work to be done in this space. Key management is a hard problem, but is more viable if the use case is fully managed.
What's next for BinBerry
Talk to potential customers. We need to see how it integrates into a large DevOps pipeline so we can better address customer needs.
Built With
c
gpg
javascript
linux
python
systemcalls
vuejs
Try it out
yc2019-20191123092955-hostingbucket-ycenv.s3-website-us-west-2.amazonaws.com


UBC LHD Build Day
Python Workshop
This workshop will walk you through how to build and deploy a simple Python app that serves a simple webpage that fetches data from the Google Maps API.
What's in this repository?
Scaffolding for the project, and a basic main.py. Throughout this workshop, we'll be actually writing code! This branch serves as the base for what we'll be building off of. Starting off, we won't be touching the templates and static folders for now, so don't worry about those.
0. Setup
Installing Python
We will be using Python 3.6.5 for this workshop. If you have another version of Python, it should still work but you may run into dependency issues. Here's the link to the download for Python 3. Check if you've installed it properly by making sure you can run python and pip in the terminal.
Installing Git
Git is a version control tool. You'll use this to download the repository and switch between branches! You can download the command line version here https://git-scm.com/downloads or if you prefer the GUI, https://www.gitkraken.com/
Project setup
Clone this project somewhere convenient. You can do this by opening your command prompt and navigating to a convenient folder.

e.g. cd ~/Documents

Then git clone https://github.com/jackyzha0/lhd-build-python-webapp and change directory into the folder cd lhd-build-python-webapp.
Installing dependencies

There are a few Python libraries we will be using today that will help us build today's app.

pip install flask requests
API Keys

Near the end of the workshop, we'll be integrating our app with the Google Maps API. Go ahead and get that key here: https://developers.google.com/places/web-service/get-api-key. Follow the 5 steps to get your API key. Create a file called secrets.txt with your API key and put that in this folder. You'll need it later!
1. The Backend
What is a backend?
"Backend" code is the stuff that powers everything on the internet from behind the scenes.
What is Flask?
Flask is a web framework written in python. Basically, it gives you the basic tools to build a web application, meaning you can serve websites and other cool stuff.
Getting started
Great, so how do I get started? If you've set up the project properly, you should find the main.py file in the folder. Open it up with your editor of choice. We've provided 3 examples in the file. We can get our Flask server up and running by executing python main.py.
Built With
css
html
python
Try it out
GitHub Repo


Inspiration
We're all international students at UBC, and adapting to a new place can be challenging at first, either as a passing by visitor or a permanent resident. This is a situation that a lot of international students struggle with, and it extends to anyone who's visiting a foreign city. Hence, we decided to make Internation-app, an application that integrates a series of topics that are helpful for anyone who's visiting a foreign city, from meeting new people to having handy emergency contacts. Our users will be incentivized to entry information belonging to their home city, allowing the content of the page to grow.
What it does
Our application is divided in 4 current tabs: meeting people, what to eat, useful resources and whats the weather. Meeting people gives you a series of events that are happening in the city and people who are traveling to those destinations in case you want a buddy. These would later be extracted from an eventbrite API or similar. What to eat gives a series of restaurants and signature foods that are in this city, and it offers a filtering system to meet dietary adjustments to anyone using it. Useful resources gives you a list of guidelines prior to going the destination of interest based on your country of origin (visas, permits etc), a getting around tab that lets you easily find ways of transportations and a list of emergency contacts to have accessible anywhere. Last but not least we have the whats the weather tab, that walks you through the apparel you should wear based on the season, tips for things to bring, etc.
How we built it
We mainly used react-native and css to establish the application hierarchy and styling.
Challenges we ran into
It's hard to keep up with the time designation and deliver an mvp given the scope of the hackathon. We wanted to achieve more but had to ditch some ideas along the way.
Accomplishments that we're proud of
We're proud of our homepage and overall working in the organization we had as a team. Since there were a lot of things to cover, we divided and conquered the tasks, played to our strengths, and ended up delivering a satisfactory product.
What we learned
We learned a lot about ourselves as team players; we hang out as buddies but we don't often code together as a group. We discovered the joy to work with one another, see your and your friend's results come to live, and have a great experience. Personally I didn't have much experience with react native, but my friends gave me a hand at the beginning and helped me get started. Overall great experience and potentially the start of a permanent team for future hackathons.
What's next for Internation-app
Welp, haha, there's a lot of design that needs to be put in place. I think the ideas are there, or at least thought out, which is great! The styling and the implementation of the rest of our features should be codd when finals are over and we get our lives back (ha ha..) but overall I'm happy we were able to put up our skills to the test and deliver our product :).
Built With
react-native
Try it out
GitHub Repo


Inspiration
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
- Coming up with an idea and setting up our environments was half the battle.
What's next for Peace
Peace is easily extensible


[nwPlus] Test Submission


From struggling with API integration to our lack of back-end knowledge, we may not have had the tools to build something in code at this point in time, but the proof of concept still stands.
Our concept is based similar to the interactive polling game Kahoot. However,
In order for us to be able to create something like this, we believe we would need further knowledge in:
Back-End Development Server-side / Client-side updates Real-time synchronization of network devices in code GUI Development
Built With
css
html
typescript
Try it out
GitHub Repo


Team Hyperloop
Inspiration
Our customers often ask how they can quickly develop a Proof of Concept of their product's next generation. Progress usually recommends a standard development approach, where they refactor existing logic, wrap it in a REST API and then develop a Front-End UI.
_ Let's flip that upside-down and try something new _
What it does
A new Progress product called Unite-UX enables a new Sketch to Code approach, where the User Experience can be designed right at the start, and from that flows the API required, and from that flows the Code.
The new Swagger API-First and CI/CD tool chain capabilities in the new OE 12 release fits well into this approach.
Time permitting, we will also include Kinvey, KinveyChat, HDP, MoveIT, WuG and MenuTrack services in the PoC we build.
How To build it
Take real world requirements from a candidate customer
Create a User Experience using Progress Unite UX Sketch
Create a KendoUI Front End from that using Progress Unite UX Studio
Design a Swagger API based on the Front End
Implement a REST API on a sample OE database from the customer
Link the layers together and demonstrate a working Prototype
Challenges
This project requires many differing skill-sets:
A Designer to use Sketch and create a superb User Experience
A Front-End Developer who can use Unite UX Studio and KendoUI
Someone with Swagger, REST and PASOE knowledge, application evolution expertise
An OE guru who can anchor the entire prototype with ABL and Data using the latest OE 12 features
A Project Manager to keep everything on track and get the coffee
What we will learn
How to use the latest Progress technologies to deliver astounding visions of what future Progress-based applications could look like and show how quickly and easily it can be done
Built With
kinvey
kinveychat
openedge12
uniteux


Inspiration
The inspiration for this project initially came from one of our team members, Fraser. After having worked extensively in the spinal cord injury field, the issues with accessibility for those with impaired mobility are apparent which lowers their quality of life. The inspiration came from the SCI center for which he worked at posting alternate routes to the building from transit hubs which were all downhill - much more navigable for wheelchairs - rather than the directions Google Maps suggested which often took users up steep hills.
What it does
The project is a simple website which utilizes Google Maps API to show a route for users to navigate to building entrances which have accessibility options such as ramps, elevators, etc.
How I built it
The project is built with html, css, javascript, bootstrap, node.js, and express.js. The front end utilizes html, css, bootstrap, and javascript, while the backend server is coded in node.js and express.
Challenges I ran into
Challenges included the understanding and implementation of Google Maps API, the connection of the front end to the backend, passing parsed data to js file from API call, and the use of Javascript to complete the API calls.
Accomplishments that I'm proud of
Successfully set up site and functional backend. We are very near completion in regards to connecting the backend to frontend.
What I learned
Patience, collaboration, group management, stress management, Git Kraken, Version Control, Reading API Documentation, Connecting Backend to Frontend
What's next for Geo Accessibility Map
Implementation of Mobile App. Refactoring of code Addition of features
Built With
css
express.js
html
javascript
node.js
Try it out
165.227.52.211


Inspiration
On our team, we are big music enthusiasts and like many others, have all experienced the annoying feeling of finding a song that we really like in a different language, but not being able to understand the meaning behind the lyrics. It is one thing to find a translation online, but something completely different to be able to experience the music along with the words, in a language that you do understand.
What it does
Our web app takes either the title of a song, or a .wav audio file and gets the lyrics of the song, through a search engine that we customized. We then use the googletrans API to translate the song into the user's language of choice and use a text-to-speech API that then converts the lyrics to spoken word. The pitch and frequency of the words are then manipulated to match those in the original song. Finally, we overlay the music and end up with the same song, but in a different language.
How I built it
The project was coded in python and HTML5 and made use of a lot of web APIs. We first setup the project with python and worked on basic functionalities such as: making API calls simultaneously to get lyrics from from the song name/.wav audio file, to translate lyrics from one language to another, to convert translated lyrics into speech (mainly using google api), and to get audio analysis data of the music and tagging the pitches back on the translated speech. Then, we combined all the functionalities together to return the song in a different language and play it on browser.
Challenges I ran into
We had some issues when trying to alter the pitch of the spoken word. There was LOTS of debugging involved!
Accomplishments that I'm proud of
We are really proud of the fact that we took a risk in choosing a project that was quite ambitious and that is very different from any other ones that we have done in the past. We worked very well as a team and learned so many new things together. Additionally, 2 out of the 4 of us haven't ever coded in python before, but were able to learn on the spot and make very helpful contributions to the project.
What I learned
We all learned a lot more about queuing web API requests and manipulating soundwave data. Although, no one on our team has any experience with UI, we were still able to create some sort of a web application, that interacts with the user and takes their input for song titles and language requests. For the two of us who have no experience with python, it was a very cool challenge to figure out how to both accomplish the required tasks, all while using new syntax.
What's next for lango-tune
The are still some challenges with pitch-matching that need to be resolved. Some improvements could also be made to the music overlay. As a team, we wish to continue working on this project after the hackathon is over, since it is something that we are all genuinely interested in and passionate about!
Built With
acrcloud
googletrans
html5
librosa
python
Try it out
GitHub Repo


Inspiration
There's never enough time. Sometimes we really want to take care of ourselves, but forget to when things get busy. We wanted to create an application that helps people track and visualize their moods without using up extensive resources and time.
What it does
M.O.O.D. is a simple app that tracks your mood on a daily basis and visualizes it on a colourful and intuitive dashboard. It only requires 30 seconds of a user's time per day as it merely requires a date and a mood rating on a scale of 1 to 5.
How we built it
We implemented the user interface in Android Studio and the logic is handled in Java.
Challenges we ran into
We spent more time than expected familiarizing ourselves with Android Studio because this was our first time using it. We had technical issues during set up (e.g. not enough disk space) and had to troubleshoot/pivot quickly to unblock ourselves.
Accomplishments that we're proud of
We are proud of being able to jump into Android Studio for the first time and being able to learn quickly, solve problems, and support each other along the way.
What we learned
We learned to build things quickly under time pressure and solve problems. We learned to use Git better to help us maintain an organized project.
What's next for M.O.O.D(Mark One Off Daily)
Our vision for future implementations is building a visual dashboard that supports accessibility colour themes and recommending articles/resources for users based on aggregate data of their mood over time.
Built With
android
android-studio
java
Try it out
GitHub Repo


Inspiration
Most of the talent available is not actively looking for a job making it hard for recruiters to attract candidates in to their recruiting funnel. Meanwhile, passive candidates ignore most of the out reach done by recruiters.
"Behind one of those cryptic recruiter templates, is a dream job sitting in your inbox."
What it does
Currently: PassivelySeeking parses recruiter outreach, augments it using a knowledge graph and request more information.
Our goal is to build integrated bots to require zero touches from the passive candidates until all the required information is gathered.
How we built it
For better or worst, we built this using python, flask and a sql database.
Challenges we ran into
Scrapping gently on a time crunch is hard.
Gathering labeled data to train a proper ML model
It turned out to be "fancy" fuzzy match and playing probabilities.
Accomplishments that we're proud of
Extracted information from recruiter emails and mapped it to external data source to provide salary ranges, location, and more.
What we learned
18 hours is not enough.
You might still need unit tests during a hackathon! Testing saved us.
What's next for PassivelySeeking
This can be seen as a 2-sided marketplace (candidates and recruiters).
Integrating with email clients and LinkedIn InMail to automate response and information gathering on behalf of the passive candidates
Build a conversational AI
Assist candidates with scheduling, interview preparation and salary negotiation
Incorporate human in the loop to give a premium experience
Start building a relationship with the candidates
Once a critical mass is obtained on the candidate side, we can start helping recruiter by:
Help them target candidates that are more likely response to their messages
Assist recruiters in composing relevant and effective messages personalized to the candidates
Built With
amazon-web-services
python


Inspiration
Due to their quantity and variety, keeping track of events in New York City is difficult. It is also quite challenging to plan social gathering while managing a full time work schedule. Outside of his role as a software engineer, Nikola loves keeping up with friends and participating in a variety of activities, but when he gets busy, he finds that he can fall out of touch with his friends and miss events. Outside of her role as a banker, Annie is an avid and detailed planner who keeps a full diary. However, coordinating friends and booking in the latest and hottest spots in town can take a lot of time. Pepper offers the solution for both personalities: streamlining the planning process, helping keep connected with your friends via gentle reminders, and making sure you don't miss out on the latest and greatest that's happening outside of the office.
What it does
First, Pepper will get to know your friends and your schedule. Pepper will then present you a bundle of activities within different categories e.g. drinks, dining out, fitness, art etc. Once you select the category you're interested in, Pepper will book the event in you and your friend's calendars. As a track record of interests and events builds, Pepper will improve its activities bundles and suggested events for appropriate friendship circles
How we built it
React and storyboarding
Challenges we ran into
The sequencing of user decision points, keeping them at a minimum to maximise convenience and the optimal design to present recommended activities
Accomplishments that we're proud of
This is our first hackathon and first time working together. We are pleased to have produced a prototype which delivers a workflow to help busy individuals plan seamlessly. Less time planning is more time enjoying.
What we learned
How to design a product that has minimal burden on the user's time. We also learnt the value of effective brainstorming and thinking how to practically implement changes to our initial design within a compressed timeframe.
What's next for Pepper
Pepper booking reservations for you Features for the advanced planner and increase customisation capabilities Greater integration with the large repository of food/activity blogs and review sites to one centralised and curated platform
Built With
react
react-dnd
react-dnd-html5-backend
react-icons
react-router
react-tag-input
react-tiny-popover


promover apoio ao GRAAC


Inspiration
I love to travel and I have traveled to some very beautiful place throughout the world but the problem with traveling is use your country's currency when you do not reside in the country that you are visiting, which can make your daily traveling very difficult. Therefore, that is why I decided to create this mobile application that includes a prototype to test the this banking mobile application.
What it does
This banking mobile application lets users deposit, transfer, and withdraw foreign currency, cash, checks, and bitcoin into their checking, savings, and credit account without having to pay a visit to a bank. That way users are able to create account where users can deposit, transfer, and withdraw foreign currency, bitcoin, cash, and checks to their checking, savings and credit account to purchase and pay without calling your bank when visiting other countries.
How I built it
Utilizing Adobe XD to create low to high fidelity wireframes of the banking mobile application that is user-centered to create the prototype to conduct usability testing to correct errors and to ensure that the banking mobile application is user-centered.
Challenges I ran into
The challenges that I ran into is the coding for the mobile application. I am familiar with web development and I am not sure how I will proceed with developing this into a mobile application. Luckily, I don't have to code a mobile application.
Accomplishments that I'm proud of
That I actually designed and created a mobile application that will do good for the world. Plus, this mobile banking application will make international traveling and banking easier for individuals that travel outside of their countries.
What I learned
I learned that this mobile application can achieve a lot for those who do enjoy traveling but don't want to deal with the foreign currency conversion.
What's next for ABC Banking App
Well, I enjoy traveling to other countries that are outside the United States of America and that is why I came up with this mobile banking application. When I travel to other countries, I always dread having to deal with calling my bank when I arrive in a foreign country because it is a hassle.
Built With
adobe-xd
Try it out
xd.adobe.com


UberEats inspired us. We have created a website that makes learning more accessible and affordable. All the user is required to do is choose the course they would like to take, and we will send the customer the material he or she would like to buy. Our courses are relatively affordable as a course would only cost around $20. We built this website by using javascript, HTML, and CSS. A challenge that we ran into was having a map show up, so the user could see where and when they would be receiving their materials. We are proud that we have a relatively functional and capable website. The next step for UberLearns is to improve the UI, UX, and code optimization.
Built With
css
html
javascript


Inspiration
Our inspiration came from the language barriers that we have all faced in our lives. Whether it is traveling to a different country, immigrating, or going on exchange, not knowing another language can be a major obstacle to learning and experiencing different cultures. International Exchange breaks down these language barriers by translating voice messages and text messages.
What it does
International Exchange connects two users of different language backgrounds and allows both users to communicate with each other in their respective languages. For instance, if a user who understands English wishes to communicate with another user who speaks French, the English user can speak or text in English, and International Exchange will translate the speech/text into French for the French user, and vice versa. This way, people of different languages and cultural backgrounds can communicate with ease, promoting a more culturally understanding, inclusive and diverse society.
What we learned
We learned to use Python, how to implement APIs, and web development. For all of us, it was our first hackathon and we learned to work and learn with each other.
What's next for International Exchange
An extra feature we will implement is video calling with translation subtitles. Additionally, we would like to design a mobile app for users. We would also like to include an algorithm that pairs users based on interests.
Built With
django
google-speech
google-trans
python
speech-recognition


Inspiration
People suffering from ADHD would struggle reading and attending static content. How can we help them?
What it does
By blurring surrounding words, our technology bring attention to the word you are reading. Moreover, there is a touch of gamification to keep the reader interested.
How I built it
Using Opencv and a pre-trained text/ word segmentation TensorFlow model
Challenges I ran into
Tobii eye tracker gave us motion sickness while we were testing
Accomplishments that I'm proud of
Improvements on Microsoft immersive reader
What I learned
Oh, So much
What's next for TunnelVision
Connecting the Tobii eye tracker to our interface.
Built With
azure
opencv
python
tobii
Try it out
GitHub Repo


The love of playing games and being competetive wanted us to create a stats web page that willl show stats of users
Built With
css
html
javascript
Try it out
GitHub Repo


Inspiration
Conversations with Peter Nguyen among others sparked interest (excuse the pun) in applying our awesome data integration products to creating a big data set for use with ML analysis... Extending our traditional DCI products' capabilities to access data from databases, REST APIs, SaaS applications and other datasources, with MoveIT's abilities as a secure MFT solution, gives us more complete coverage of the data integration space, allowing us to demonstrate broader range of implementation patterns. The explosion in the number of data scientists and the rise of ML-based analysis, driven by increasing awareness that there really is business value tied up in the massive datasets our customers and partners have lends itself to an ML-based demo use case. This also allows us to focus on using all our data products from an ETL perspective rather than a BI-tool perspective - bring-your-own-ETL rather than bring-your-own-BI - a growing space that our DCI demos have arguably under-served up to now...
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Aggregating DB, API & file data for ML pattern detection
Built With
apachespark
arc
etl
hdp
moveit
openedge
pasoe


Inspiration
Team fit becomes an increasingly important factor for recruiting decision-making. Recruiting processes, however, are often biased by subjective decisions either by the recruiter or the final decision of the manager. . AI-based video recognition combined with predefined questions tries to overcome this subjective process by comparing the performance to well-perfoming past employees. Similarly, some companies still rely on psychologically validated personality tests.
What it does
Our product tries to improve purely text-based personality tests by adding other communication cues being assessed with our AI.
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
We interviewed the recruiters here at the hackathon and learned that they don't believe in an algorithm to assess something that is such an essential human skill - the evaluation of whether two persons can work together well. It seems the human recruiters don't actually want AI interfering with their hiring process. They rather argue to trust their gut feeling while being well aware of negative biases they could run into.
What's next for varify
Built With
python
Try it out
GitHub Repo


Inspiration Make an impact on the refugee integration by using our programming skills
What it does Matches refugees and citizens of Munich by comparing their interests and offers events
How I built it Android studio, Firebase and patience
Challenges I ran into merge conflicts, tiredness, database integration issues
Accomplishments that I'm proud of database integration, amazing layout, social component
What I learned development of android apps
What's next for Meet me @ Odeonsplatz Publish on Play Store
Built With
android-studio
firebase
gitlab
Try it out
gitlab.lrz.de


Inspiration:
looking for houses has been a stressful time for us as this is our first time looking for houses on our own
How it Works:
takes user inputs of different variables to find them multiple options for their preferred house
Built With
google-spreadsheets
html
r
Try it out
docs.google.com
drive.google.com


To create an app that gives people advice ahead of time on how to not indulge in destructive financial habits using predictive analytics
Built With
balsamiq
Try it out
docs.google.com


Inspiration
One of our teammates,is constantly worried about leaving his doors unlocked when leaving or after entering his house. We created SafeHouse to alleviate his concern and those of others like him. The data created by SafeHouse can also be used by insurance companies to better calculate risk and assess damages, which will make SafeHouse accessible to all users for free.
What it does
SafeHouse AI leverages the security cameras already around his house and gives him the power to check the state of his doors through his Google Assistant and Google Home. When we realized that door locks look similar to stove knobs and garage locks, we decided to push it further and have those covered by SafeHouse as well.
How we built it
We collected a large dataset of door lock images in different states, and used a pre-trained ResNet34 model to fine-tune a Convolutional Neural Network in a Transfer Learning scheme to create a model that classifies their various states. We then deployed the model the PyTorch. The front-end is the Google Assistant/Google Home and we programmed our key commands through DialogFlow. Upon demand, the Assistant fires a request to our cameras, which takes pictures, crop the locks and sends it to our classifier. The classifier serves the pictures back to the Assistant along with a prediction of the lock states.
Challenges we ran into
It was extremely hard for us to figure out the cloud services(AWS, GCP) when deploying our classifier. And we ended up putting our classifier on Docker and then hosting the Docker on GCP.
Since the Google Assistant was our only user interface, we also had a lot of trouble dictating its behaviour to make it intuitive to the user.
No one in the team has ever used web hooks before, and we had a hard time figuring them out.
Accomplishments that we are proud of
It was our first time doing something of this complexity in such a short time. SafeHouse AI uses IoT, ML, and the cloud, topics our team were not particularly familiar with. We're proud of how polished our end product is, it is already in a very usable state.
What I learned
As a team, we learnt a lot about how IoT can provide a lot of conveniences and possibilities for the users. We also learnt a lot about Machine Learning and working with Docker and the various cloud platforms, all team members an expertise in a specific topic, and it resulted in massive exchange of knowledge.
What's next for SafeHouse AI
We want to continue to add features to our product, and transform into a comprehensive IoT home security software. In the near future, we want to add geolocation using IFTT to immediately notify the user when they have left their home in a dangerous state(unlocked doors, stove open, and other near future features).
Built With
dialogflow
docker
fastai
flask
google-cloud
pytorch


Inspiration
Well. Where do I start? Tinder, as any other online platform, relies on an algorithm that recommends you profiles to swipe. Their algo is based on ELO score at it's core. I thought it would be great to optimise my profile to suit the algo's needs. Your 1st profile is 60-80% of your success on Tinder — that's what we'll be optimising for you!
What it does
You upload two photos of yourself and then Facerank community votes for the best one. When sufficient number of people vote for your pics, you'll be able to unlock or buy a result.
How I built it
Nodejs / Sails / Gatsby / Cloudinary
Challenges I ran into
Getting more women on the app.
Accomplishments that I'm proud of
Didn't get shadow banned on Reddit https://www.reddit.com/r/Tinder/comments/asyces/building_an_app_to_ab_test_your_tinder_profile/
What I learned
What's next for Facerank
Built With
cloudinary
coffeescript
gatsby
heroku
node.js
react
sails.js
Try it out
facerank.app


Inspiration
I wanted to create a zero gravity space shooter that played similar to the retro Asteroids game. However, I wanted to make it more exciting with fun graphics, fx, and some customization. Additionally, I wanted to build it to be played in the web browser.
What it does
You fly around and shoot space rocks to see how long you can last and how high of a score you can reach. Power ups drop occasionally to help you out.
How I built it
I built it using the Unity Editor and exported the project into a WebGL build. After that, I created a new React project and imported the WebGL compiled code into it.
Challenges I ran into
One of the biggest challenges was to learn how to have the Unity WebGL code communicate with the React front-end code. Unity provides a way to do this but there is very little documentation on the subject. It took a lot of trial and error to get the two platforms talking. But once I was able to figure it out, I was able to integrate the blockstack auth and Gaia storage into the game.
Accomplishments that I'm proud of
This is my first polished Unity game and I'm excited to share it with the Blockstack community. I was also excited to be able to figure out how to integrate this game with the Blockstack ecosystem.
What's next for Apollos
I plan on incorporating more long term progression into the game by adding levels with specific challenges that can unlock some in-game rewards like different ship models, ship colors, starting bonues, etc.
Built With
javascript
react
unity
webgl
Try it out
apollos.ilava.games


I enjoyed the online betting and gambling experience here.


Inspiration
We are constantly surrounded by potential danger zones or restricted areas. Yet, when we walk around with headphones or fail to pay sufficient attention to what is going on around us, we can easily be oblivious to these. At Tresfailing, we believe that it is normal to get distracted and want to ensure the safety of everyone around. As someone approaches a zone they should avoid, their phone will begin to emit a frequency that will rise as they get closer, letting them know they should be alert. Much like a car alarm when backing up, we want to prevent as many accidents as possible.
What it does
Using only two cameras placed around the zone, we are able to track how close people are to a zone of danger and warn them in real time. The sound frequency coming from their phone will notify them how close they are to a restricted area. This product can be used on any scale: from helping parents make sure their children do not approach potentially dangerous home appliances to ensuring pedestrians stay clear of a construction zone.
Challenges we ran into
We had some difficulties installing the Wrnch API, creating the Android application, and the Web application.
What's next for Tresfailing
The next upgrade for Tresfailing is to add facial recognition and associate it with a user's phone to make sure as many people as want to register can be kept safer.
Built With
flask
java
python
unity
wrnch-api
Try it out
GitHub Repo
docs.google.com


Inspiration
placeholder
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for YSTRDY - Remembering together.


Inspiration
Make the money more digital and let everybody use it
What it does
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
What's next for Fusion Pay
Built With
email
ffdc
java
mongodb
node.js
postgresql
program-o-chatbot
rest
twilio
Try it out
fusionpay.herokuapp.com


Explore projects from Portfolios and hackathons


Inspiration
The inspiration for this project initially came from one of our team members, Fraser. After having worked extensively in the spinal cord injury field, the issues with accessibility for those with impaired mobility are apparent which lowers their quality of life. The inspiration came from the SCI center for which he worked at posting alternate routes to the building from transit hubs which were all downhill - much more navigable for wheelchairs - rather than the directions Google Maps suggested which often took users up steep hills.
What it does
The project is a simple website which utilizes Google Maps API to show a route for users to navigate to building entrances which have accessibility options such as ramps, elevators, etc.
How I built it
The project is built with html, css, javascript, bootstrap, node.js, and express.js. The front end utilizes html, css, bootstrap, and javascript, while the backend server is coded in node.js and express.
Challenges I ran into
Challenges included the understanding and implementation of Google Maps API, the connection of the front end to the backend, passing parsed data to js file from API call, and the use of Javascript to complete the API calls.
Accomplishments that I'm proud of
Successfully set up site and functional backend. We are very near completion in regards to connecting the backend to frontend.
What I learned
Patience, collaboration, group management, stress management, Git Kraken, Version Control, Reading API Documentation, Connecting Backend to Frontend
What's next for Geo Accessibility Map
Implementation of Mobile App. Refactoring of code Addition of features
Built With
css
express.js
html
javascript
node.js
Try it out
165.227.52.211


Inspiration
On our team, we are big music enthusiasts and like many others, have all experienced the annoying feeling of finding a song that we really like in a different language, but not being able to understand the meaning behind the lyrics. It is one thing to find a translation online, but something completely different to be able to experience the music along with the words, in a language that you do understand.
What it does
Our web app takes either the title of a song, or a .wav audio file and gets the lyrics of the song, through a search engine that we customized. We then use the googletrans API to translate the song into the user's language of choice and use a text-to-speech API that then converts the lyrics to spoken word. The pitch and frequency of the words are then manipulated to match those in the original song. Finally, we overlay the music and end up with the same song, but in a different language.
How I built it
The project was coded in python and HTML5 and made use of a lot of web APIs. We first setup the project with python and worked on basic functionalities such as: making API calls simultaneously to get lyrics from from the song name/.wav audio file, to translate lyrics from one language to another, to convert translated lyrics into speech (mainly using google api), and to get audio analysis data of the music and tagging the pitches back on the translated speech. Then, we combined all the functionalities together to return the song in a different language and play it on browser.
Challenges I ran into
We had some issues when trying to alter the pitch of the spoken word. There was LOTS of debugging involved!
Accomplishments that I'm proud of
We are really proud of the fact that we took a risk in choosing a project that was quite ambitious and that is very different from any other ones that we have done in the past. We worked very well as a team and learned so many new things together. Additionally, 2 out of the 4 of us haven't ever coded in python before, but were able to learn on the spot and make very helpful contributions to the project.
What I learned
We all learned a lot more about queuing web API requests and manipulating soundwave data. Although, no one on our team has any experience with UI, we were still able to create some sort of a web application, that interacts with the user and takes their input for song titles and language requests. For the two of us who have no experience with python, it was a very cool challenge to figure out how to both accomplish the required tasks, all while using new syntax.
What's next for lango-tune
The are still some challenges with pitch-matching that need to be resolved. Some improvements could also be made to the music overlay. As a team, we wish to continue working on this project after the hackathon is over, since it is something that we are all genuinely interested in and passionate about!
Built With
acrcloud
googletrans
html5
librosa
python
Try it out
GitHub Repo


Inspiration
There's never enough time. Sometimes we really want to take care of ourselves, but forget to when things get busy. We wanted to create an application that helps people track and visualize their moods without using up extensive resources and time.
What it does
M.O.O.D. is a simple app that tracks your mood on a daily basis and visualizes it on a colourful and intuitive dashboard. It only requires 30 seconds of a user's time per day as it merely requires a date and a mood rating on a scale of 1 to 5.
How we built it
We implemented the user interface in Android Studio and the logic is handled in Java.
Challenges we ran into
We spent more time than expected familiarizing ourselves with Android Studio because this was our first time using it. We had technical issues during set up (e.g. not enough disk space) and had to troubleshoot/pivot quickly to unblock ourselves.
Accomplishments that we're proud of
We are proud of being able to jump into Android Studio for the first time and being able to learn quickly, solve problems, and support each other along the way.
What we learned
We learned to build things quickly under time pressure and solve problems. We learned to use Git better to help us maintain an organized project.
What's next for M.O.O.D(Mark One Off Daily)
Our vision for future implementations is building a visual dashboard that supports accessibility colour themes and recommending articles/resources for users based on aggregate data of their mood over time.
Built With
android
android-studio
java
Try it out
GitHub Repo


Inspiration
Most of the talent available is not actively looking for a job making it hard for recruiters to attract candidates in to their recruiting funnel. Meanwhile, passive candidates ignore most of the out reach done by recruiters.
"Behind one of those cryptic recruiter templates, is a dream job sitting in your inbox."
What it does
Currently: PassivelySeeking parses recruiter outreach, augments it using a knowledge graph and request more information.
Our goal is to build integrated bots to require zero touches from the passive candidates until all the required information is gathered.
How we built it
For better or worst, we built this using python, flask and a sql database.
Challenges we ran into
Scrapping gently on a time crunch is hard.
Gathering labeled data to train a proper ML model
It turned out to be "fancy" fuzzy match and playing probabilities.
Accomplishments that we're proud of
Extracted information from recruiter emails and mapped it to external data source to provide salary ranges, location, and more.
What we learned
18 hours is not enough.
You might still need unit tests during a hackathon! Testing saved us.
What's next for PassivelySeeking
This can be seen as a 2-sided marketplace (candidates and recruiters).
Integrating with email clients and LinkedIn InMail to automate response and information gathering on behalf of the passive candidates
Build a conversational AI
Assist candidates with scheduling, interview preparation and salary negotiation
Incorporate human in the loop to give a premium experience
Start building a relationship with the candidates
Once a critical mass is obtained on the candidate side, we can start helping recruiter by:
Help them target candidates that are more likely response to their messages
Assist recruiters in composing relevant and effective messages personalized to the candidates
Built With
amazon-web-services
python


Inspiration
Due to their quantity and variety, keeping track of events in New York City is difficult. It is also quite challenging to plan social gathering while managing a full time work schedule. Outside of his role as a software engineer, Nikola loves keeping up with friends and participating in a variety of activities, but when he gets busy, he finds that he can fall out of touch with his friends and miss events. Outside of her role as a banker, Annie is an avid and detailed planner who keeps a full diary. However, coordinating friends and booking in the latest and hottest spots in town can take a lot of time. Pepper offers the solution for both personalities: streamlining the planning process, helping keep connected with your friends via gentle reminders, and making sure you don't miss out on the latest and greatest that's happening outside of the office.
What it does
First, Pepper will get to know your friends and your schedule. Pepper will then present you a bundle of activities within different categories e.g. drinks, dining out, fitness, art etc. Once you select the category you're interested in, Pepper will book the event in you and your friend's calendars. As a track record of interests and events builds, Pepper will improve its activities bundles and suggested events for appropriate friendship circles
How we built it
React and storyboarding
Challenges we ran into
The sequencing of user decision points, keeping them at a minimum to maximise convenience and the optimal design to present recommended activities
Accomplishments that we're proud of
This is our first hackathon and first time working together. We are pleased to have produced a prototype which delivers a workflow to help busy individuals plan seamlessly. Less time planning is more time enjoying.
What we learned
How to design a product that has minimal burden on the user's time. We also learnt the value of effective brainstorming and thinking how to practically implement changes to our initial design within a compressed timeframe.
What's next for Pepper
Pepper booking reservations for you Features for the advanced planner and increase customisation capabilities Greater integration with the large repository of food/activity blogs and review sites to one centralised and curated platform
Built With
react
react-dnd
react-dnd-html5-backend
react-icons
react-router
react-tag-input
react-tiny-popover


promover apoio ao GRAAC


Inspiration
I love to travel and I have traveled to some very beautiful place throughout the world but the problem with traveling is use your country's currency when you do not reside in the country that you are visiting, which can make your daily traveling very difficult. Therefore, that is why I decided to create this mobile application that includes a prototype to test the this banking mobile application.
What it does
This banking mobile application lets users deposit, transfer, and withdraw foreign currency, cash, checks, and bitcoin into their checking, savings, and credit account without having to pay a visit to a bank. That way users are able to create account where users can deposit, transfer, and withdraw foreign currency, bitcoin, cash, and checks to their checking, savings and credit account to purchase and pay without calling your bank when visiting other countries.
How I built it
Utilizing Adobe XD to create low to high fidelity wireframes of the banking mobile application that is user-centered to create the prototype to conduct usability testing to correct errors and to ensure that the banking mobile application is user-centered.
Challenges I ran into
The challenges that I ran into is the coding for the mobile application. I am familiar with web development and I am not sure how I will proceed with developing this into a mobile application. Luckily, I don't have to code a mobile application.
Accomplishments that I'm proud of
That I actually designed and created a mobile application that will do good for the world. Plus, this mobile banking application will make international traveling and banking easier for individuals that travel outside of their countries.
What I learned
I learned that this mobile application can achieve a lot for those who do enjoy traveling but don't want to deal with the foreign currency conversion.
What's next for ABC Banking App
Well, I enjoy traveling to other countries that are outside the United States of America and that is why I came up with this mobile banking application. When I travel to other countries, I always dread having to deal with calling my bank when I arrive in a foreign country because it is a hassle.
Built With
adobe-xd
Try it out
xd.adobe.com


UberEats inspired us. We have created a website that makes learning more accessible and affordable. All the user is required to do is choose the course they would like to take, and we will send the customer the material he or she would like to buy. Our courses are relatively affordable as a course would only cost around $20. We built this website by using javascript, HTML, and CSS. A challenge that we ran into was having a map show up, so the user could see where and when they would be receiving their materials. We are proud that we have a relatively functional and capable website. The next step for UberLearns is to improve the UI, UX, and code optimization.
Built With
css
html
javascript


Inspiration
Our inspiration came from the language barriers that we have all faced in our lives. Whether it is traveling to a different country, immigrating, or going on exchange, not knowing another language can be a major obstacle to learning and experiencing different cultures. International Exchange breaks down these language barriers by translating voice messages and text messages.
What it does
International Exchange connects two users of different language backgrounds and allows both users to communicate with each other in their respective languages. For instance, if a user who understands English wishes to communicate with another user who speaks French, the English user can speak or text in English, and International Exchange will translate the speech/text into French for the French user, and vice versa. This way, people of different languages and cultural backgrounds can communicate with ease, promoting a more culturally understanding, inclusive and diverse society.
What we learned
We learned to use Python, how to implement APIs, and web development. For all of us, it was our first hackathon and we learned to work and learn with each other.
What's next for International Exchange
An extra feature we will implement is video calling with translation subtitles. Additionally, we would like to design a mobile app for users. We would also like to include an algorithm that pairs users based on interests.
Built With
django
google-speech
google-trans
python
speech-recognition


Inspiration
People suffering from ADHD would struggle reading and attending static content. How can we help them?
What it does
By blurring surrounding words, our technology bring attention to the word you are reading. Moreover, there is a touch of gamification to keep the reader interested.
How I built it
Using Opencv and a pre-trained text/ word segmentation TensorFlow model
Challenges I ran into
Tobii eye tracker gave us motion sickness while we were testing
Accomplishments that I'm proud of
Improvements on Microsoft immersive reader
What I learned
Oh, So much
What's next for TunnelVision
Connecting the Tobii eye tracker to our interface.
Built With
azure
opencv
python
tobii
Try it out
GitHub Repo


The love of playing games and being competetive wanted us to create a stats web page that willl show stats of users
Built With
css
html
javascript
Try it out
GitHub Repo


Inspiration
Conversations with Peter Nguyen among others sparked interest (excuse the pun) in applying our awesome data integration products to creating a big data set for use with ML analysis... Extending our traditional DCI products' capabilities to access data from databases, REST APIs, SaaS applications and other datasources, with MoveIT's abilities as a secure MFT solution, gives us more complete coverage of the data integration space, allowing us to demonstrate broader range of implementation patterns. The explosion in the number of data scientists and the rise of ML-based analysis, driven by increasing awareness that there really is business value tied up in the massive datasets our customers and partners have lends itself to an ML-based demo use case. This also allows us to focus on using all our data products from an ETL perspective rather than a BI-tool perspective - bring-your-own-ETL rather than bring-your-own-BI - a growing space that our DCI demos have arguably under-served up to now...
What it does
How I built it
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Aggregating DB, API & file data for ML pattern detection
Built With
apachespark
arc
etl
hdp
moveit
openedge
pasoe


Inspiration
Team fit becomes an increasingly important factor for recruiting decision-making. Recruiting processes, however, are often biased by subjective decisions either by the recruiter or the final decision of the manager. . AI-based video recognition combined with predefined questions tries to overcome this subjective process by comparing the performance to well-perfoming past employees. Similarly, some companies still rely on psychologically validated personality tests.
What it does
Our product tries to improve purely text-based personality tests by adding other communication cues being assessed with our AI.
How we built it
Challenges we ran into
Accomplishments that we're proud of
What we learned
We interviewed the recruiters here at the hackathon and learned that they don't believe in an algorithm to assess something that is such an essential human skill - the evaluation of whether two persons can work together well. It seems the human recruiters don't actually want AI interfering with their hiring process. They rather argue to trust their gut feeling while being well aware of negative biases they could run into.
What's next for varify
Built With
python
Try it out
GitHub Repo


Inspiration Make an impact on the refugee integration by using our programming skills
What it does Matches refugees and citizens of Munich by comparing their interests and offers events
How I built it Android studio, Firebase and patience
Challenges I ran into merge conflicts, tiredness, database integration issues
Accomplishments that I'm proud of database integration, amazing layout, social component
What I learned development of android apps
What's next for Meet me @ Odeonsplatz Publish on Play Store
Built With
android-studio
firebase
gitlab
Try it out
gitlab.lrz.de


Inspiration:
looking for houses has been a stressful time for us as this is our first time looking for houses on our own
How it Works:
takes user inputs of different variables to find them multiple options for their preferred house
Built With
google-spreadsheets
html
r
Try it out
docs.google.com
drive.google.com


To create an app that gives people advice ahead of time on how to not indulge in destructive financial habits using predictive analytics
Built With
balsamiq
Try it out
docs.google.com


The idea does not end in the world to which we are, the fact of living always regenerates in us many other ideologies for thinking for new things. Constantly, Facebook has cracked the measure of security to finally prevent the swindlers, usurpation of account, etc ... Indeed, it is also good for protecting private lives in this environment of the social network; but is this measure definitely a strategy that puts an end to the ideologies of scammers? My project stipulates on the creation of the signaling or alert to the person who dares to consult your newspaper without your knowledge; why we can directly download your photo and make the manipulation dishonestly.
Built With
adobe-illustrator
excel
photoshop
word
Try it out
www.facebook.com


Everyone knows that Might & Magic Heroes Era of Chaos hack is important in getting free Diamonds. Thanks to it is easier to get more xp and higher level. It isn’t a secret that spending your own cash on buying Diamonds in game! Today we propose you to use our newest generator: Might & Magic Heroes Era of Chaos Cheats. Getting unlimited amounts of Diamonds and Cash is now very simple. There is no need to describe more. We wrote down whole proccess in just few steps below. No one should have any problems using it. Simple build and intuitive interface will allow you comfortable use in only few minutes. Remember to have active internet connection. Our Might & Magic Heroes Era of Chaos hack works online, you aren’t downloading anything. Read the steps and use it!
LINK Here : http://bit.ly/33vDvHZ
Trouble is brewing all over the country if you are not using Might & Magic Heroes Era of Chaos hack in game. DISCOVER A MASSIVE STORY CAMPAIGN Explore a massive world, gather warriors, creatures, resources, treasures, artifacts, and glory. Fight for justice and glory by leading massive armies into real-time ranged and siege battles. Choose the best formation ahead of battle and use your hero spells to turn the tide in your favor.
OUTPLAY YOUR OPPONENTS IN FAST-PACED PVP DUELS Order your units carefully on the battlefield and enter the PvP arena. Test your army’s strength and show off your strategic skills against other players with both asynchronous and real time multiplayer modes.
TEAM UP IN GUILD ADVENTURES & GUILD WARS True heroes never fight alone. Join a guild and fight alongside friends and other players from all around the world. Rush castles and take over ennemies' strongholds in epic PVP battles. Join the guild quests to reach the top of the guild leaderboard and collect rare loots.
COLLECT AND TRAIN MYTHICAL HEROES & UNITS Recruit various heroes from Might and Magic universe, each with their unique powers, weapons and artifacts. Collect, train and upgrade 40+ dreadful troops and creatures: Knights, Griffins, Archangels, Dragons, Orcs and many more.
IMMERSE YOURSELF IN A FANTASTIC WORLD Discover beloved heroes and foes, creatures and environments, in all-new colorful, anime-inspired 2D art style.
TAKE PART IN LIVE EVENTS & WEEKLY CHALLENGES Take part in a range of challenging Live Events to grind rare items. To help you reclaim the kingdom of Erathia, Queen Catherine has prepared many special bonuses, including super units, rare items and much more.


Proposed architecture
What it does
Brings privacy sensitive documents to mobile users in a secure way
Why
We have two customers (Monaco police and COA) that have a requirement for delivering personal documents / emails to mobile users in a secure way.
User Story
Customer has a mobile application and a traditional OE application that handles sensitive information of its users. At some point, the user of the mobile application needs access to documents that were generated locally from the OE application in a secure way. Mobile user authenticates against KeyCloak using oAuth2. and has the option to have sensitive data sent to him/her in a secure way in the form of a PDF document. Email is not considered a safe way.
Components
Simple mobile app with a request for some sort of sensitive data option (NativeScript / Angular)
Kinvey as a throughput for data, but also for sending the push notifications when a document is ready for download
MoveIT Transfer / MoveIT Automation for automated secure file transfer
OpenEdge database with sensitive data and a service (PASOE) that enables for the generation of PDF documents and creating tasks in MoveIT
How does it work
The user of the app will initiate a data request, the OE service will collate the PDF and drop it off somewhere and MiT can pick it up from here via a MiA script. The users would also install the MiT mobile app, so that they can download the file from that mobile app once it's ready. MiT server will get the LDAP info from their application server and the users will then use the same mobile app credentials for the MiT mobile app
Considerations
The main thing they would need to do outside of MOVEit is come up with a way of identifying who is requesting the PDF, but I assume you already have this covered. If you can create a folder structure on the network and we match the folder structure on Transfer, the application should detect who is requesting the file and place it into the proper folder (negates the need for email). Then we can have a task in automation that sweeps the folders, when it detects a file it moves it to the matching folder on transfer so the customer can see it. They can get notified when the file is ready to be downloaded via the MiT browser or mobile app.
What's next for Project SFT2Mobile
Implementation :D
Built With
abl
angular.js
generator
moveit
nativescript
openedge
pasoe
pdf
Try it out
gitlab.com


Inspiration
We were inspired to help the Amazonia because of the huge huge fires that harmed it in August. We knew we had to do something because even though most of the fires happened in Brazil, here in Colombia our forest are disappearing too, we've one only planet, one big home.
What it does
Currently, controlling the transportation of timber inside Colombia is tough and irregular. Our "salvoconductos" are counterfeit often. What our program does is making the permits almost unbreakable. We will check variables in the truck to determine the exact place and if it was loaded with more wood than allowed, or if the load was changed during a trip, leading to combat other types of trafficking. The idea is to compare this information to the official permits to guarantee that what is being transported is legal.
Goodwood is a solution based on the consumer, our philosophy is that the final consumer is able to cause an impact in the decision of the big companies that sells wood. Our team has proposed a stamp that will be given only to the companies that are committed to the responsible exploitation of the raw material. But how can we assure that?
Goodwood is a Hardware and software solution, that checks the state of the timber carried by a transporter, our system measures the position and the weight of the truck that carries a certain type of wood. Every time that the system detects an anomaly in the process of transportation it saves the position and the weight of the truck in that specific moment. This information will be sent to a server when it passes through control panels established in strategic points around Colombia, and our system will compare the data to the permits given by the authorities of the country. If the loaded place or the amount of wood does not match the permit, then Goodwood will inform the authorities and the company about the irregularity.
How we built it
We worked with hardware and software. We have a functional prototype that uses Arduino, a couple of sensors based on laser and Bluetooth to transmit information to a control point that communicates with a server that will determine if the truck was loaded with more wood than allowed or if the load was modified and the exact place the truck took it off. We use a database based on MySQL to store, in a relational model, the permits and be able to compare them with the data from the trucks and we built an Angular web page to display relevant information about the permits and trucks we have identified for carrying a load different to what the permit specifies... We designed a server based on Flask, a Python library, to connect all these services. Currently, the server is deployed locally.
We learn tools and use the guidance from the #Zoohackathon collaborators, from designers to programmers, to whom we thank immensely for their help.
Challenges we ran into
Transmitting the information from the truck to the computer was a big challenge. Also making the prototype work wasn't an easy task, it was really funny adding some unnecessary stuff to our truck, like brand new tires. Things stopped working often and we had to figure out multiple times how to fix it. Also, we needed to develop a mathematical model of the truck in order to make a measure of the compresión of the spring and know the wait, we base our model in the hooks' law and classical mechanics formalism.
Accomplishments that we're proud of
We're pleased of present a functional prototype that worked at real-time in the presentation, we were able to detect anomalies in front of the judges and report it in the webpage that we developed, also we made a project that everyone in the room was able to access through wi-fi and check their functionality while we were sharing our ideas. We can say that our first approximation it's completely functional and our prototype behaves as we wanted, even though we will update new versions of it. We are very proud of our project in general because it addresses creatively a problem that cost +1.500 billions of COP to our country. We were surprised by the viability of our project, in terms of cost, implementation, and massification.
What we learned
We all learned to hear other ideas and ask for help when we were stuck, it is really important to listen to opinions from other points of view. We all learned a bit of pitching, Arduino and python, as well as learning about deforestation, and general environment problems. Working with springs wasn't as easy as we thought.
What's next for GoodWood
Our main goal in the short term is to be able to work with the Ministry of Environment and Sustainable Development to implement our solution in Colombia and help reduce illegal timber traffic.
We want to extend to other markets, we know that our solution can help to fight other environmental threats, as it's the detection of changes in the load related to drug trafficking or cattle movement. These behaviors are the principal causes of deforestation and biodiversity decline, we want to regulate all transportation in Colombia in order to preserve our rich wild nature. But to accomplish that, we need first of all make a more robust prototype for the measure of the mass, we will use a 4 degree of freedom detector using more precise lasers at low cost. This will allow us, trough data treatment algorithms as autoencoders, to have a more precise detection of anomalies in the transport of shiploads. Then we want to develop a more efficient way to communicate control points with the microcontrollers, using alternative connections and be able to display more information on the web page. We also want to provide more layers of security in order to protect sensitive information and ensure privacy. Along with this, we want to make permits electronically signed so that they cant be cloned or reused.
We four made a great frienship and will probablly keep on going to Hackathons around Colombia. We are a really good match because we're very different. If we win this competition we would love to make our idea real.
Comments
Please download our presentation in the wetransfer link posted below and run the .html file for a better experience. Also, follow the instructions in the GitHub repository in order to run the whole project.
Built With
angular.js
arduino
flask
hardware
mysql
python
rest
Try it out
GitHub Repo
we.tl


Inspiration
It's very hard to integrate multiple services in large
What it does
How we built it
We build it on top of FFDC. Applications and all necessary components were deployed on Finastra developer environment (ffdcdev).
Challenges we ran into
None of the team members had Front end skills, we faced issues with angular.
Accomplishments that we're proud of
It works! We turned devops into front end developer in 48h.
What we learned
Language agnostic Contract testing / Angular
What's next for Fusion Contract
Integration with internal components of Finastra FFDC Platform and exposed APIs
Built With
angular.js
docker
java
kubernetes


Logo
Inspiration
As we received a list of the current Wildlife problem at the Zoo-Hackathon in Vienna.The important things for us was to find an easy to use application for the customs officer by helping them with "logic" on there smartphone. To make everything more clear, we define the problems:
Detect the suspect luggage for animals inside (by detecting movement)
Add luggage to a checklist for easy prioritising the large amount ever day on the airport
Safe Communication
What it does
Our primary target animal we want to find are the Glass Eels. As we got told in the intro this is a huge problem right no on the airports. In the beginning the customs officer has a list of all luggages sorted by predicted potential for animals detected. In the Top of the list, there are Suspect Luggages. The list also has the x-ray images from the boarding control. The movement of the animals we want to detect by taking 2 images in 5 seconds time distance. From each luggage to specify we can detect the moment by image differentiation. Also luggages with no X-Ray images are suspect for example corruption.
How I built it
User Interview
Empathise map to define the problems
Brain storming and Ideas --> Combine best solution
Visual prototype (Adobe xd)
Test and Implement (functional on iOS/swift)
Challenges I ran into
Team finding and also finding a topic all new team members wanted to work on, and also the short time...
Accomplishments that I'm proud of
In less than 20 hours solve the challenge with a team (4) that has never known one another before.
What I learned
Wildlife problems and how serious they are.
What are next (possible) steps for Un-Smuggle
More detailed talks with customs officers and wildlife experts to evaluate more in detail the project
Check and test the X-Ray boarding control with examples
Develop a web control panel and the mobile application.
Collect the Data each time Custom for Machine learning.
Built With
xcode
xdadobe
Try it out
GitHub Repo


Inspiration
assigning task on a contextual discussion platform.
Built With
spring
Try it out
drive.google.com


Inspiration Handling API calls via text message thereby saving time and effort.
What it does Send messages when you are in offline
How I built it Using Twillio
Challenges I ran into Integrate with platform apps
Accomplishments that I'm proud of
What I learned
What's next for SMS WebHook
Built With
twilio
Try it out
GitHub Repo


Inspiration
Agents ofter encounter huge number of tickets, often with the same priority. How can they furthur prioritize one over the other?
What it does
The application takes in custom fields from the ticket fields of the account and provides a customer score based on how the customer wants each of the custom fields to be prioritised. This is then used to filter the tickets which are sorted based on priority.
How I built it
The custom fields and the range with which they want to scale those fields are obtained when installation is done, along with the domain and the API key. This information is then used to calculate the score for the customer from the tickets that they have raised. Finally, a sorted list based of priority and our custom score is displayed.
What's next for Customer Score
The next step would be to show more contextual information about the customer. Bucketing all the tickets from their history and allowing the agent to be more mindful of the type of ticket and customer he/she may be handling. For example, if a customer has faced one particular issue over and over again, the next time they approach with the same problem, extra care and maybe Root Cause Analysis must be done.
Try it out
GitHub Repo


Inspiration
Inspired by media center on a WhatsApp group
What it does
In a ticket, attachments or screenshots play a major role to communicate the context effectively. There are multiple styles of attachments and embedded files on a ticket thread.
At present, an agent doesn’t have provisions to preview or take any action on an attachment without downloading. We as a team explored this space to give a better experience for an agent to proceed with his job seamlessly without any hassle.
The Attachment Previewer App provides…
Preview for multiple types of attachments (images, pdf, Xls, doc, txt, audio, video and so on…)
Also acts as a repository for all attachments including the embedded files
Helps the agent to take quick actions on top of an attachment (share via mail, Freshconnect, Freshchat… and download)
When an attachment is previewed, this app helps the agent by bringing in relevant message context in Freshdesk mail trail
Easy to navigate and find an attachment
No auto-downloads to preview an attachment
All of these will be helpful to save a lot of spilled out efforts, improves productivity and increases the turn around time of a ticket.
What I learned
We have learned to build the Market place application from scratch
What's next for Attachment previewer
Enhancing the user experience
Making this compatible with all Freshworks products
Built With
html
jquery


Transcript of the video demo
Hi,
Imagine me as a support center administrator and my primary role is to ensure that the health of my support center is on track. To achieve this, I monitor several dashboards to know the status which requires continuous efforts. what if my ambiance reflects the health of my support center. Welcome to Freshglow.
On installation of this app from the marketplace, we compute service level metrics based on the field that we feel appropriate like escalation, resolution, ticket load, etc. let me install the marketplace application. since this is not listed already, let me simulate the installation.
As you might have noticed, the health of the support center is reflected by the ambiance. According to the default configuration provided, If more than 90 percent of the tickets are resolved on time without escalation, my support center health is awesome. Let us take for an instance, a few tickets are escalated. let me simulate the same.
Now the health degrades and the ambiance becomes amber. This indicated that my health has gone below 90 percent.
Now let us escalate a few more tickets. now the health has gone down furthermore and the ambiance became red. This indicates that the support center needs to take immediate action.
now let us dive into the Ticket load monitoring mode.
in this mode, I will be able to set a threshold for a time range and a color of the ambience when threshold crosses the limit. Initially, the light will be turned off. let us now simulate the creation of a few tickets.
Let me set the time range as 1 hour and threshold as 2 tickets. so, if more than 2 tickets come in the past hour the ambiance will reflect the configuration. In this way, we can know that the ticket load is high in volume and I can act accordingly.
It doesn't have to be the full ambiance, even a small bulb at a corner can serve the purpose.
Built With
css
html
ifttt
iot
javascript
Try it out
drive.google.com


Inspiration
 With the increase in employee count in our company, it would be easy for HR's to maintain the employees credentials with an easy click. Also it maintains Data Integrity and automation reduces manual effort
What it does
 Sync fields between freshteam and workplace on Employee Create, Update, Delete, Terminate
How we built it
 Using FDK and Workplace Graph API
Challenges we ran into
 Understanding API's of Workplace 
Accomplishments that we're proud of
  Learned a lot on building apps and making a working one
What we learned
  Team coordination , time management and lot of tech things
What's next for Freshteam Workplace Integration
  Can be extended to sync Allsec , Fyle etc.
Try it out
GitHub Repo


Inspiration
To build an abstract ticket form to understand particular issue in freshdesk conversation
What it does
An abstract summary with categorization for whole ticket conversation which helps agents/managers/account holder to have an abstract idea of the entire conversation. I
How we built it
Using fdk app as a base platform.
Challenges we ran into
Basic challenge is to understand the fdk app and to narrow down our ideas and freeze.
Accomplishments that we're proud of
We built a working application in 36 hours
What we learned
Team coordination and time management. Also, how much time we have in 36 hours!.
What's next for Ticket Conversation Summary
Implement an NLP related API to automate the note classification based on the categories we have.


Inspiration
Freshchat does not have bot agent integration
What it does
Integrate google dialog flow in a freshchat bot for faster resolution of tickets
How we built it
Market place Application
Challenges we ran into
Limitations in the Market place application
Accomplishments that we're proud of
Integrated google dialog flow and did a webhook call from freshchat to dialog flow
What we learned
Extensive integration support for all freshworks suite of products by Market place Application
Built With
api
dialogflow
glitch
heroku
node.js
Try it out
GitHub Repo
docs.google.com


Inspiration
Our idea was inspired by listening to Cindy Lennon and Sean Cannon recount the struggles of Veterans with families trying to better themselves with professional development opportunities, but finding there was a lack of affordable childcare services geared towards military families.
What it does
The website offers a platform that allows Veteran families access to free-child care services by facilitating meet-ups between veterans to essentially “swap kids” for a few hours at a time. It is a short-term service that offers more than just babysitting—they provide social interaction, parental support, community involvement, and long-lasting friendships.
How we built it
By using front and back-end development utilizing Visual Studio Code, Javascript, Express.js, Node.js, and Adobe Spark.
Challenges we ran into
We faced difficulties when deciding on the logistics and process behind screening new applicants to ensure that those who use our service are from the Veteran community, and mitigating concerns on entrusting new individuals with their children.
Accomplishments that we're proud of
We came up with a unique concept that we felt hadn’t been addressed. We are proud of our collaboration as a team to unify all the elements that are part of fleshing out a functional website.
What we learned
The additional challenges that Veteran families face when finding affordable childcare resources. We also learned about all the elements it takes to build a straightforward and user-friendly web-page.
What's next for Child Share
We’d like to finalize the website build, and find a way to locally promote the service.Given time, we’d also like to potentially develop an app for parents on the go.
Built With
express.js
javascript
node.js
particle
visual-studio
Try it out
GitHub Repo
spark.adobe.com


Inspiration
We should be able to say we can monitor everything we offer. As it stands right now, WhatsUp Gold does not monitor any Progress solutions out of the box. This should be a mostly straight-forward project -- we just need people on the team that understand each of Progress software solutions. OpenEdge and SiteFinity are the primary focus, but I would love to be able to monitor all of Progress solutions. Stretch goals will be Kinvey, Corticon, HDP, ARC
What it does
Monitor SiteFinity, OpenEdge, and any other solution(s) that depend on hardware/software
How I built it
This will be built in WhatsUp Gold leveraging either built-in monitor types, custom scripted monitors, and/or Application Performance Monitor (APM)
Challenges I ran into
We need systems to test these monitors against.
Accomplishments that I'm proud of
SiteFinity deployed in WUG lab, OpenEdge 12.1 *nix deployed in lab, OpenEdge 12.1 Windows deployed in lab
What I learned
Progress teams don't work together very often.
What's next for Monitoring Progress Solutions with WhatsUp Gold
Once all of the monitoring is created, we can push to have this built into the solution and promote cross-selling for sales.
Built With
jscript
powershell
rest
snmp
vbs
wmi
wug


What it does
Agent assistant system helps the agent to solve user's query efficiently and quickly. As it reduce the agent's dependency on the developers the response time will be less than before . If the agent assistant cannot give proper response, then information will be collected which will be posted as a private note on the current channel
How we built it
It was built using javascript and dialogflow was integerated to train the model. Each time we collect user response and form a query , sends it to dialogflow and get back the answer.
Challenges we ran into
Dialogflow integration, Question hierarchy
Accomplishments that we're proud of
In our team no one knows the front development well, but we done what we planned.
What we learned
Few new technologies Managment Team Work
What's next for Agent Assistant
Currently we are creating private note for the conversation which are not resolved by the agent assistant. 2, In future the ticket will be created if the issue is not resolved by agent assistant
We can also suggest related conversations to agents which are already solve based on the data that are provided by the agent to our app.
Built With
dialogflow
html
javascript
Try it out
GitHub Repo


Inspiration
Choosing the right design, colors and style to mass produce is often times a decision that can make or break a retailers season or entire year. This fashion branding tool with enable retailers to learn the buying patterns of customers and classify customer's fashion choice by classifying popular styles, colors and design choice.
What it does
The fashion classifier will pull from multiple API (both behind the firewall and on cloud) from multiple suppliers of fabric, zippers, buttons, etc,classify the fabric and material styles and calculate cost of material in real-time based on certain rules that extrapolate how much initial demand will lead to 1) whether that color, style, fabric will make it to production 2) if it does make the final cut for production, how many copies to make.
How I built it
We will use either Tensorflow or Spark to build the fashion classifier. We will enable ARC to pull from suppliers API and check availability and cost of material. We can use HDP to pull data from on-premise and cloud data sources. We can use Corticon as a business rules manager to make the business rules decision on what makes the final cut and how much material to purchase.
Challenges I ran into
Accomplishments that I'm proud of
What I learned
What's next for Breast Cancer Classification
Built With
api
python
tensorflow


Inspiration
Inspired by various discussions with Marketing professionals in Higher Education vertical.
What it does
A demonstration of a personalized school website that gives a visitor access to on-demand critical information, and offers social media features, such as a campus profile page, optional contact information, blog (and images) that can be shared with social media accounts (social integration). The student, will be able to access school transcripts, and any other sensitive information for school transfer, job applications, etc. via email or download. Since college sites typically have an abundance of information, a chatbot could be used to direct students to the specific area for information they are seeking. Due to possible time-sensitive scenarios, the site & network needs to always perform at peak level and without downtime... A corresponding mobile app could be possible.
Why
One of the top complaints from marketing (or anyone who manages a school website) is the vast amount of information potential/new/current students need access to, and the difficulty of getting the right content to them at the right time. Also, with the recent changes to the rules of marketing in the higher education vertical, it is imperative that schools not only attract new students, but also keep students.
In today's world, people expect information to be immediately accessible digitally, and on multiple channels. It is no different for college students. The process of applying for college, filling out financial aid, requesting/submitting school transcripts, and any other possible required document is already difficult and time consuming. Minimizing the time and difficulty to access/submit this information would be a huge benefit for both administration and student.
In addition, social media presence is one of the top priorities for young adults. Not only is it used as a form of social interaction and entertainment, but it is also used to build brand/reputation for job seeking, political & community awareness, charity support, and so much more.
Showcasing the ability to personalize the student experience, offer help via a chatbot, provide access to critical documents would be greatly beneficial to the student and the school, and help alleviate the workload placed on administration. Also, if the school can provide a social campus channel, combined with possible interaction with the students other social channels, it would help keep the student engaged, thus providing more opportunity for marketing to engage with that student.
How I envision this be built
Sitefinity: website/portal
MoveIt: sensitve file transfer
KinveyChat / NativeChat: on-demand site content assistance
Nice to Haves:
WUG: site monitoring
Kinvey: mobile access
Challenges this project will face
Time: Is there enough time to build this
Technical: will need integration experience for each product
What I hope we learn and accomplish (in this order)
To have fun!
Get to know fellow colleagues better.
Learn some new technology.
Learn more about other Progress products
Win!
Built With
.net
kinvey
moveit
sitefinity
social
wug


Quote Maker for writers
Inspiration
Honestly, we highly inspired by our new generation, they really want some stuff like this. they want stuff that gives all the people some inspired so we will decide that we make an application that gives all the people some stuff like inspired but that will also for the writer if anyone has writing skills then they also show their writing skills in that place.
What it does
that can create quotes in your way. write quotes with author name. in this app there are many filters are available to make the quote more beautiful.
How I built it
we are using angular js, android, iPhone and many more to create this app.
Challenges I ran into
when we create this app we face many of the errors and warnings. but when we face this type of errors we work very hard on these errors and try to remove all these errors.
What I learned
we learned that when we create any of the Application there were always errors are come out, but we have learned from those errors and try hard solve these errors in less time.
What's next for Quote Maker
in Quote Maker we can add more filter and more new features So that you can make more stunning quotes.
Built With
android
angular.js
iphone-sdk
Try it out
Google Play Store
www.producthunt.com


Every agent on average spends time just to figure out where his next interaction his and will have to search the UI for the one specific action among the plethora of things that is infront of him. This app allows agents to quickly execute a sequence of actions instead of traversing through the UI. This allows the agents to type in their requirement and see it get executed. This can even be extended to use a personal assistant for the agent. For example instead of actually going and click multiple fields and then updating or some other action like adding a canned response. The agent can just type his entire requirement and get it done.
Built With
css
html
javascript
Try it out
GitHub Repo


Web_Automation_python_selenium
Objective
This Repo is about powerful web automation library called Selenium and its implementation in python to login automatically into different famous social media sites.Sometimes its worth time taking to login everytime into your social media and remembering credentials. Web automation is one of the most hottest fields now a days used by a large scale of organization to automate their different processes.
TOOLS USED
Python,Selenium,Time
FOLLOW THE FOLLOWING STEPS TO START
Download Chrome webdriver to enable Selenium to connect with your browser.
GOTO http://chromedriver.chromium.org/downloads
Downlaod the required version of Webdriver according to your Browser Version
Now extract the downloaded zip file and copy the .exe file to the Python main directory
INSTALL SELENIUM
Goto to command prompt and type pip install selenium as simple as that
THATS IT NOW YOU ARE READY TO GO
Built With
python
Try it out
GitHub Repo


Inspiration
Working on CRM we figured that Sales folks waste lot of time going through same emails again and again to find answers. We wanted something that can improve their productivity drastically.
What it does
It can parse email conversations and answer questions hidden in them. This can be extended to notes as well.
How we built it
We used Bidirectional attention flow model to build core ML model. API's were created on top of them to fetch and answer questions on email.
Challenges we ran into
Building an app for freshworks for the first time we faced challenges around available APIs and limitations on calling external APIs
Accomplishments that we're proud of
Building something useful in the first attempt.
What we learned
Building Freshworks apps is not difficult !!
What's next for udligon_bot
This can help auto fill many fields like product name, territory, etc. This information is usually hidden in mails and sales rep are lazy to fill.
Make the model lighter and faster
Integrate with freshcaller so that it can answer question based call log
Ability to answer across leads/contacts
Maintain privacy of sales rep. Answers should be restricted for a email/notes owner.
Built With
allennlp
python


TopReview.vn Là Website chuyên về Review đánh giá tổng hợp các lĩnh vực top 1 tại Việt Nam. Với phương châm cung cấp những thông tin chính xác nhất, hữu ích nhất cho người dùng thông qua các bài viết chất lượng cao, cùng đội ngũ kiểm duyệt chặt chẽ. Ngoài ra TopReview còn cung cấp các công cụ giúp người dùng đóng góp các nhận xét đánh giá khách quan của mình, giúp bổ sung các tiêu chí xếp hạng ngày càng chính xác, cập nhật nhằm đem lại những trải nghiệm tốt nhất cho độc giả.
Try it out
topreview.vn


